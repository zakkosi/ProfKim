{
  "doc_id": "pages_315_317",
  "text": "5.3 Mean shift and mode ﬁnding\n293\nx\nf (x)\nxi\nK(x)\nG(x)\nf '(xk)\nxk\nm(xk)\nFigure 5.17 One-dimensional visualization of the kernel density estimate, its derivative, and\na mean shift. The kernel density estimate f(x) is obtained by convolving the sparse set of\ninput samples xi with the kernel function K(x). The derivative of this function, f ′(x), can\nbe obtained by convolving the inputs with the derivative kernel G(x). Estimating the local\ndisplacement vectors around a current estimate xk results in the mean-shift vector m(xk),\nwhich, in a multi-dimensional setting, point in the same direction as the function gradient\n∇f(xk). The red dots indicate local maxima in f(x) to which the mean shifts converge.\nThe problem with this “brute force” approach is that, for higher dimensions, it becomes\ncomputationally prohibitive to evaluate f(x) over the complete search space.10 Instead, mean\nshift uses a variant of what is known in the optimization literature as multiple restart gradient\ndescent. Starting at some guess for a local maximum, yk, which can be a random input data\npoint xi, mean shift computes the gradient of the density estimate f(x) at yk and takes an\nuphill step in that direction (Figure 5.17). The gradient of f(x) is given by\n∇f(x) =\nX\ni\n(xi −x)G(x −xi) =\nX\ni\n(xi −x)g\n\u0012∥x −xi∥2\nh2\n\u0013\n,\n(5.35)\nwhere\ng(r) = −k′(r),\n(5.36)\nand k′(r) is the ﬁrst derivative of k(r). We can re-write the gradient of the density function\nas\n∇f(x) =\n\"X\ni\nG(x −xi)\n#\nm(x),\n(5.37)\nwhere the vector\nm(x) =\nP\ni xiG(x −xi)\nP\ni G(x −xi)\n−x\n(5.38)\nis called the mean shift, since it is the difference between the weighted mean of the neighbors\nxi around x and the current value of x.\n10 Even for one dimension, if the space is extremely sparse, it may be inefﬁcient.\n294\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nIn the mean-shift procedure, the current estimate of the mode yk at iteration k is replaced\nby its locally weighted mean,\nyk+1 = yk + m(yk) =\nP\ni xiG(yk −xi)\nP\ni G(yk −xi) .\n(5.39)\nComaniciu and Meer (2002) prove that this algorithm converges to a local maximum of f(x)\nunder reasonably weak conditions on the kernel k(r), i.e., that it is monotonically decreasing.\nThis convergence is not guaranteed for regular gradient descent unless appropriate step size\ncontrol is used.\nThe two kernels that Comaniciu and Meer (2002) studied are the Epanechnikov kernel,\nkE(r) = max(0, 1 −r),\n(5.40)\nwhich is a radial generalization of a bilinear kernel, and the Gaussian (normal) kernel,\nkN(r) = exp\n\u0012\n−1\n2r\n\u0013\n.\n(5.41)\nThe corresponding derivative kernels g(r) are a unit ball and another Gaussian, respectively.\nUsing the Epanechnikov kernel converges in a ﬁnite number of steps, while the Gaussian\nkernel has a smoother trajectory (and produces better results), but converges very slowly near\na mode (Exercise 5.5).\nThe simplest way to apply mean shift is to start a separate mean-shift mode estimate\ny at every input point xi and to iterate for a ﬁxed number of steps or until the mean-shift\nmagnitude is below a threshold. A faster approach is to randomly subsample the input points\nxi and to keep track of each point’s temporal evolution. The remaining points can then be\nclassiﬁed based on the nearest evolution path (Comaniciu and Meer 2002). Paris and Durand\n(2007) review a number of other more efﬁcient implementations of mean shift, including their\nown approach, which is based on using an efﬁcient low-resolution estimate of the complete\nmulti-dimensional space of f(x) along with its stationary points.\nThe color-based segmentation shown in Figure 5.16 only looks at pixel colors when deter-\nmining the best clustering. It may therefore cluster together small isolated pixels that happen\nto have the same color, which may not correspond to a semantically meaningful segmentation\nof the image.\nBetter results can usually be obtained by clustering in the joint domain of color and lo-\ncation. In this approach, the spatial coordinates of the image xs = (x, y), which are called\nthe spatial domain, are concatenated with the color values xr, which are known as the range\ndomain, and mean-shift clustering is applied in this ﬁve-dimensional space xj. Since location\nand color may have different scales, the kernels are adjusted accordingly, i.e., we use a kernel\nof the form\nK(xj) = k\n\u0012∥xr∥2\nh2r\n\u0013\nk\n\u0012∥xs∥2\nh2s\n\u0013\n,\n(5.42)\n5.3 Mean shift and mode ﬁnding\n295\nFigure 5.18\nMean-shift color image segmentation with parameters (hs, hr, M)\n=\n(16, 19, 40) (Comaniciu and Meer 2002) c⃝2002 IEEE.\nwhere separate parameters hs and hr are used to control the spatial and range bandwidths of\nthe ﬁlter kernels. Figure 5.18 shows an example of mean-shift clustering in the joint domain,\nwith parameters (hs, hr, M) = (16, 19, 40), where spatial regions containing less than M\npixels are eliminated.\nThe form of the joint domain ﬁlter kernel (5.42) is reminiscent of the bilateral ﬁlter kernel\n(3.34–3.37) discussed in Section 3.3.1. The difference between mean shift and bilateral ﬁl-\ntering, however, is that in mean shift the spatial coordinates of each pixel are adjusted along\nwith its color values, so that the pixel migrates more quickly towards other pixels with similar\ncolors, and can therefore later be used for clustering and segmentation.\nDetermining the best bandwidth parameters h to use with mean shift remains something\nof an art, although a number of approaches have been explored. These include optimizing\nthe bias–variance tradeoff, looking for parameter ranges where the number of clusters varies\nslowly, optimizing some external clustering criterion, or using top-down (application domain)\nknowledge (Comaniciu and Meer 2003). It is also possible to change the orientation of the\nkernel in joint parameter space for applications such as spatio-temporal (video) segmentations\n(Wang, Thiesson, Xu et al. 2004).\nMean shift has been applied to a number of different problems in computer vision, includ-\ning face tracking, 2D shape extraction, and texture segmentation (Comaniciu and Meer 2002),\nand more recently in stereo matching (Chapter 11) (Wei and Quan 2004), non-photorealistic\nrendering (Section 10.5.2) (DeCarlo and Santella 2002), and video editing (Section 10.4.5)\n(Wang, Bhat, Colburn et al. 2005). Paris and Durand (2007) provide a nice review of such\napplications, as well as techniques for more efﬁciently solving the mean-shift equations and\nproducing hierarchical segmentations.",
  "image_path": "page_316.jpg",
  "pages": [
    315,
    316,
    317
  ]
}