{
  "doc_id": "pages_502_504",
  "text": "480\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.10\nSample indoor image where the areas outside the window are overexposed\nand inside the room are too dark.\n1\n1,500\n25,000\n400,000\n2,000,000\nFigure 10.11 Relative brightness of different scenes, ranging from 1 inside a dark room lit\nby a monitor to 2,000,000 looking at the sun. Photos courtesy of Paul Debevec.\nscenes where any single exposure contains saturated (overexposed) and dark (underexposed)\nregions (Figure 10.10). This problem is quite common, because the natural world contains a\nrange of radiance values that is far greater than can be captured with any photographic sensor\nor ﬁlm (Figure 10.11). Taking a set of bracketed exposures (exposures taken by a camera\nin automatic exposure bracketing (AEB) mode to deliberately under- and over-expose the\nimage) gives you the material from which to create a properly exposed photograph, as shown\nin Figure 10.12 (Reinhard, Ward, Pattanaik et al. 2005; Freeman 2008; Gulbins and Gulbins\n2009; Hasinoff, Durand, and Freeman 2010).\nWhile it is possible to combine pixels from different exposures directly into a ﬁnal com-\n+\n+\n⇒\nFigure 10.12\nA bracketed set of shots (using the camera’s automatic exposure bracketing\n(AEB) mode) and the resulting high dynamic range (HDR) composite.\n10.2 High dynamic range imaging\n481\nposite (Burt and Kolczynski 1993; Mertens, Kautz, and Reeth 2007), this approach runs the\nrisk of creating contrast reversals and halos. Instead, the more common approach is to pro-\nceed in three stages:\n1. Estimate the radiometric response function from the aligned images.\n2. Estimate a radiance map by selecting or blending pixels from different exposures.\n3. Tone map the resulting high dynamic range (HDR) image back into a displayable\ngamut.\nThe idea behind estimating the radiometric response function is relatively straightforward\n(Mann and Picard 1995; Debevec and Malik 1997; Mitsunaga and Nayar 1999; Reinhard,\nWard, Pattanaik et al. 2005). Suppose you take three sets of images at different exposures\n(shutter speeds), say at ±2 exposure values.11 If we were able to determine the irradiance\n(exposure) Ei at each pixel (2.101), we could plot it against the measured pixel value zij for\neach exposure time tj, as shown in Figure 10.13.\nUnfortunately, we do not know the irradiance values Ei, so these have to be estimated\nat the same time as the radiometric response function f, which can be written (Debevec and\nMalik 1997) as\nzij = f(Ei tj),\n(10.3)\nwhere tj is the exposure time for the jth image. The inverse response curve f −1 is given by\nf −1(zij) = Ei tj.\n(10.4)\nTaking logarithms of both sides (base 2 is convenient, as we can now measure quantities in\nEVs), we obtain\ng(zij) = log f −1(zij) = log Ei + log tj,\n(10.5)\nwhere g = log f −1 (which maps pixel values zij into log irradiance) is the curve we are\nestimating (Figure 10.13 turned on its side).\nDebevec and Malik (1997) assume that the exposure times tj are known. (Recall that\nthese can be obtained from a camera’s EXIF tags, but that they actually follow a power of 2\nprogression . . . , 1/128, 1/64, 1/32, 1/16, 1/8, . . . instead of the marked . . . , 1/125, 1/60, 1/30,\n1/15, 1/8, . . . values—see Exercise 2.5.) The unknowns are therefore the per-pixel exposures\nEi and the response values gk = g(k), where g can be discretized according to the 256\npixel values commonly observed in eight-bit images. (The response curves are calibrated\nseparately for each color channel.)\n11 Changing the shutter speed is preferable to changing the aperture, as the latter can modify the vignetting and\nfocus. Using ±2 “f-stops” (technically, exposure values, or EVs, since f-stops refer to apertures) is usually the right\ncompromise between capturing a good dynamic range and having properly exposed pixels everywhere.\n482\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nlog Exposure\nPixel value\n3\n1\n2\nlog Exposure\nPixel value\nFigure 10.13 Radiometric calibration using multiple exposures (Debevec and Malik 1997).\nCorresponding pixel values are plotted as functions of log exposures (irradiance). The curves\non the left are shifted to account for each pixel’s unknown radiance until they all line up into\na single smooth curve.\nIn order to make the response curve smooth, Debevec and Malik (1997) add a second-\norder smoothness constraint\nλ\nX\nk\ng′′(k)2 = λ\nX\n[g(k −1) −2g(k) + g(k + 1)]2,\n(10.6)\nwhich is similar to the one used in snakes (5.3). Since pixel values are more reliable in the\nmiddle of their range (and the g function becomes singular near saturation values), they also\nadd a weighting (hat) function w(k) that decays to zero at both ends of the pixel value range,\nw(z) =\n(\nz −zmin\nz ≤(zmin + zmax)/2\nzmax −z\nz > (zmin + zmax)/2.\n(10.7)\nPutting all of these terms together, they obtain a least squares problem in the unknowns\n{gk} and {Ei},\nE =\nX\ni\nX\nj\nw(zi,j)[g(zi,j) −log Ei −log tj]2 + λ\nX\nk\nw(k)g′′(k)2.\n(10.8)\n(In order to remove the overall shift ambiguity in the response curve and irradiance values,\nthe middle of the response curve is set to 0.) Debevec and Malik (1997) show how this can\nbe implemented in 21 lines of MATLAB code, which partially accounts for the popularity of\ntheir technique.\nWhile Debevec and Malik (1997) assume that the exposure times tj are known exactly,\nthere is no reason why these additional variables cannot be thrown into the least squares\nproblem, constraining their ﬁnal estimated values to lie close to their nominal values ˆtj with\nan extra term η P\nj(tj −ˆtj)2.",
  "image_path": "page_503.jpg",
  "pages": [
    502,
    503,
    504
  ]
}