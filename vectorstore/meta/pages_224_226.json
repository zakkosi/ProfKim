{
  "doc_id": "pages_224_226",
  "text": "202\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n1. Click on a number of pixels and move (drag) them to new locations. Interpolate the\nresulting sparse displacement ﬁeld to obtain a dense motion ﬁeld (Sections 3.6.2 and\n3.5.1).\n2. Draw a number of lines in the image. Move the endpoints of the lines to specify their\nnew positions and use the Beier–Neely interpolation algorithm (Beier and Neely 1992),\ndiscussed in Section 3.6.2, to get a dense motion ﬁeld.\n3. Overlay a spline control grid and move one grid point at a time (optionally select the\nlevel of the deformation).\n4. Have a dense per-pixel ﬂow ﬁeld and use a soft “paintbrush” to design a horizontal and\nvertical velocity ﬁeld.\n5. (Optional): Prove whether the Beier–Neely warp does or does not reduce to a sparse\npoint-based deformation as the line segments become shorter (reduce to points).\nEx 3.24: Forward warping\nGiven a displacement ﬁeld from the previous exercise, write a\nforward warping algorithm:\n1. Write a forward warper using splatting, either nearest neighbor or soft accumulation\n(Section 3.6.1).\n2. Write a two-pass algorithm, which forward warps the displacement ﬁeld, ﬁlls in small\nholes, and then uses inverse warping (Shade, Gortler, He et al. 1998).\n3. Compare the quality of these two algorithms.\nEx 3.25: Feature-based morphing\nExtend the warping code you wrote in Exercise 3.23\nto import two different images and specify correspondences (point, line, or mesh-based) be-\ntween the two images.\n1. Create a morph by partially warping the images towards each other and cross-dissolving\n(Section 3.6.3).\n2. Try using your morphing algorithm to perform an image rotation and discuss whether\nit behaves the way you want it to.\nEx 3.26: 2D image editor\nExtend the program you wrote in Exercise 2.2 to import images\nand let you create a “collage” of pictures. You should implement the following steps:\n1. Open up a new image (in a separate window).\n3.9 Exercises\n203\nFigure 3.66 There is a faint image of a rainbow visible in the right hand side of this picture.\nCan you think of a way to enhance it (Exercise 3.29)?\n2. Shift drag (rubber-band) to crop a subregion (or select whole image).\n3. Paste into the current canvas.\n4. Select the deformation mode (motion model): translation, rigid, similarity, afﬁne, or\nperspective.\n5. Drag any corner of the outline to change its transformation.\n6. (Optional) Change the relative ordering of the images and which image is currently\nbeing manipulated.\nThe user should see the composition of the various images’ pieces on top of each other.\nThis exercise should be built on the image transformation classes supported in the soft-\nware library. Persistence of the created representation (save and load) should also be sup-\nported (for each image, save its transformation).\nEx 3.27: 3D texture-mapped viewer\nExtend the viewer you created in Exercise 2.3 to in-\nclude texture-mapped polygon rendering. Augment each polygon with (u, v, w) coordinates\ninto an image.\nEx 3.28: Image denoising\nImplement at least two of the various image denoising tech-\nniques described in this chapter and compare them on both synthetically noised image se-\nquences and real-world (low-light) sequences. Does the performance of the algorithm de-\npend on the correct choice of noise level estimate? Can you draw any conclusions as to\nwhich techniques work better?\n204\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 3.29: Rainbow enhancer—challenging\nTake a picture containing a rainbow, such as\nFigure 3.66, and enhance the strength (saturation) of the rainbow.\n1. Draw an arc in the image delineating the extent of the rainbow.\n2. Fit an additive rainbow function (explain why it is additive) to this arc (it is best to work\nwith linearized pixel values), using the spectrum as the cross section, and estimating\nthe width of the arc and the amount of color being added. This is the trickiest part of\nthe problem, as you need to tease apart the (low-frequency) rainbow pattern and the\nnatural image hiding behind it.\n3. Amplify the rainbow signal and add it back into the image, re-applying the gamma\nfunction if necessary to produce the ﬁnal image.\nEx 3.30: Image deblocking—challenging\nNow that you have some good techniques to\ndistinguish signal from noise, develop a technique to remove the blocking artifacts that occur\nwith JPEG at high compression settings (Section 2.3.3). Your technique can be as simple\nas looking for unexpected edges along block boundaries, to looking at the quantization step\nas a projection of a convex region of the transform coefﬁcient space onto the corresponding\nquantized values.\n1. Does the knowledge of the compression factor, which is available in the JPEG header\ninformation, help you perform better deblocking?\n2. Because the quantization occurs in the DCT transformed YCbCr space (2.115), it may\nbe preferable to perform the analysis in this space. On the other hand, image priors\nmake more sense in an RGB space (or do they?). Decide how you will approach this\ndichotomy and discuss your choice.\n3. While you are at it, since the YCbCr conversion is followed by a chrominance subsam-\npling stage (before the DCT), see if you can restore some of the lost high-frequency\nchrominance signal using one of the better restoration techniques discussed in this\nchapter.\n4. If your camera has a RAW + JPEG mode, how close can you come to the noise-free\ntrue pixel values? (This suggestion may not be that useful, since cameras generally use\nreasonably high quality settings for their RAW + JPEG models.)\nEx 3.31: Inference in de-blurring—challenging\nWrite down the graphical model corre-\nsponding to Figure 3.59 for a non-blind image deblurring problem, i.e., one where the blur\nkernel is known ahead of time.\nWhat kind of efﬁcient inference (optimization) algorithms can you think of for solving\nsuch problems?",
  "image_path": "page_225.jpg",
  "pages": [
    224,
    225,
    226
  ]
}