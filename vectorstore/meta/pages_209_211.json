{
  "doc_id": "pages_209_211",
  "text": "3.7 Global optimization\n187\nFigure 3.60\nAn unordered label MRF (Agarwala, Dontcheva, Agrawala et al. 2004) c⃝\n2004 ACM: Strokes in each of the source images on the left are used as constraints on an\nMRF optimization, which is solved using graph cuts. The resulting multi-valued label ﬁeld is\nshown as a color overlay in the middle image, and the ﬁnal composite is shown on the right.\nUnordered labels\nAnother case with multi-valued labels where Markov random ﬁelds are often applied are\nunordered labels, i.e., labels where there is no semantic meaning to the numerical difference\nbetween the values of two labels. For example, if we are classifying terrain from aerial\nimagery, it makes no sense to take the numeric difference between the labels assigned to\nforest, ﬁeld, water, and pavement. In fact, the adjacencies of these various kinds of terrain\neach have different likelihoods, so it makes more sense to use a prior of the form\nEp(i, j) = sx(i, j)V (l(i, j), l(i + 1, j)) + sy(i, j)V (l(i, j), l(i, j + 1)),\n(3.115)\nwhere V (l0, l1) is a general compatibility or potential function. (Note that we have also\nreplaced f(i, j) with l(i, j) to make it clearer that these are labels rather than discrete function\nsamples.) An alternative way to write this prior energy (Boykov, Veksler, and Zabih 2001;\nSzeliski, Zabih, Scharstein et al. 2008) is\nEp =\nX\n(p,q)∈N\nVp,q(lp, lq),\n(3.116)\nwhere the (p, q) are neighboring pixels and a spatially varying potential function Vp,q is eval-\nuated for each neighboring pair.\nAn important application of unordered MRF labeling is seam ﬁnding in image composit-\ning (Davis 1998; Agarwala, Dontcheva, Agrawala et al. 2004) (see Figure 3.60, which is\nexplained in more detail in Section 9.3.2). Here, the compatibility Vp,q(lp, lq) measures the\nquality of the visual appearance that would result from placing a pixel p from image lp next\nto a pixel q from image lq. As with most MRFs, we assume that Vp,q(l, l) = 0, i.e., it is per-\nfectly ﬁne to choose contiguous pixels from the same image. For different labels, however,\n188\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 3.61\nImage segmentation (Boykov and Funka-Lea 2006) c⃝2006 Springer: The user\ndraws a few red strokes in the foreground object and a few blue ones in the background. The\nsystem computes color distributions for the foreground and background and solves a binary\nMRF. The smoothness weights are modulated by the intensity gradients (edges), which makes\nthis a conditional random ﬁeld (CRF).\nthe compatibility Vp,q(lp, lq) may depend on the values of the underlying pixels Ilp(p) and\nIlq(q).\nConsider, for example, where one image I0 is all sky blue, i.e., I0(p) = I0(q) = B, while\nthe other image I1 has a transition from sky blue, I1(p) = B, to forest green, I1(q) = G.\nI0 :\np\nq\np\nq\n: I1\nIn this case, Vp,q(1, 0) = 0 (the colors agree), while Vp,q(0, 1) > 0 (the colors disagree).\nConditional random ﬁelds\nIn a classic Bayesian model (3.106–3.108),\np(x|y) ∝p(y|x)p(x),\n(3.117)\nthe prior distribution p(x) is independent of the observations y. Sometimes, however, it is\nuseful to modify our prior assumptions, say about the smoothness of the ﬁeld we are trying\nto estimate, in response to the sensed data. Whether this makes sense from a probability\nviewpoint is something we discuss once we have explained the new model.\nConsider the interactive image segmentation problem shown in Figure 3.61 (Boykov and\nFunka-Lea 2006). In this application, the user draws foreground (red) and background (blue)\nstrokes, and the system then solves a binary MRF labeling problem to estimate the extent of\nthe foreground object. In addition to minimizing a data term, which measures the pointwise\nsimilarity between pixel colors and the inferred region distributions (Section 5.5), the MRF\n3.7 Global optimization\n189\nf (i, j)\nsx(i, j)\nf (i, j+1)\nsy(i, j)\nw(i, j)\nd (i, j)\nf (i+1, j)\nf (i+1, j+1)\nFigure 3.62\nGraphical model for a conditional random ﬁeld (CRF). The additional green\nedges show how combinations of sensed data inﬂuence the smoothness in the underlying\nMRF prior model, i.e., sx(i, j) and sy(i, j) in (3.113) depend on adjacent d(i, j) values.\nThese additional links (factors) enable the smoothness to depend on the input data. However,\nthey make sampling from this MRF more complex.\nis modiﬁed so that the smoothness terms sx(x, y) and sy(x, y) in Figure 3.56 and (3.113)\ndepend on the magnitude of the gradient between adjacent pixels.25\nSince the smoothness term now depends on the data, Bayes’ Rule (3.117) no longer ap-\nplies. Instead, we use a direct model for the posterior distribution p(x|y), whose negative log\nlikelihood can be written as\nE(x|y)\n=\nEd(x, y) + Es(x, y)\n=\nX\np\nVp(xp, y) +\nX\n(p,q)∈N\nVp,q(xp, xq, y),\n(3.118)\nusing the notation introduced in (3.116). The resulting probability distribution is called a\nconditional random ﬁeld (CRF) and was ﬁrst introduced to the computer vision ﬁeld by Ku-\nmar and Hebert (2003), based on earlier work in text modeling by Lafferty, McCallum, and\nPereira (2001).\nFigure 3.62 shows a graphical model where the smoothness terms depend on the data\nvalues. In this particular model, each smoothness term depends only on its adjacent pair of\ndata values, i.e., terms are of the form Vp,q(xp, xq, yp, yq) in (3.118).\nThe idea of modifying smoothness terms in response to input data is not new. For ex-\nample, Boykov and Jolly (2001) used this idea for interactive segmentation, as shown in\nFigure 3.61, and it is now widely used in image segmentation (Section 5.5) (Blake, Rother,\n25 An alternative formulation that also uses detected edges to modulate the smoothness of a depth or motion ﬁeld\nand hence to integrate multiple lower level vision modules is presented by Poggio, Gamble, and Little (1988).",
  "image_path": "page_210.jpg",
  "pages": [
    209,
    210,
    211
  ]
}