{
  "doc_id": "pages_097_099",
  "text": "2.3 The digital camera\n75\nof the analog-to-digital converter. Many of the actual values for these parameters can be read\nfrom the EXIF tags embedded with digital images. while others can be obtained from the\ncamera manufacturers’ speciﬁcation sheets or from camera review or calibration Web sites.11\nShutter speed.\nThe shutter speed (exposure time) directly controls the amount of light\nreaching the sensor and, hence, determines if images are under- or over-exposed. (For bright\nscenes, where a large aperture or slow shutter speed are desired to get a shallow depth of ﬁeld\nor motion blur, neutral density ﬁlters are sometimes used by photographers.) For dynamic\nscenes, the shutter speed also determines the amount of motion blur in the resulting picture.\nUsually, a higher shutter speed (less motion blur) makes subsequent analysis easier (see Sec-\ntion 10.3 for techniques to remove such blur). However, when video is being captured for\ndisplay, some motion blur may be desirable to avoid stroboscopic effects.\nSampling pitch.\nThe sampling pitch is the physical spacing between adjacent sensor cells\non the imaging chip. A sensor with a smaller sampling pitch has a higher sampling density and\nhence provides a higher resolution (in terms of pixels) for a given active chip area. However,\na smaller pitch also means that each sensor has a smaller area and cannot accumulate as many\nphotons; this makes it not as light sensitive and more prone to noise.\nFill factor.\nThe ﬁll factor is the active sensing area size as a fraction of the theoretically\navailable sensing area (the product of the horizontal and vertical sampling pitches). Higher\nﬁll factors are usually preferable, as they result in more light capture and less aliasing (see\nSection 2.3.1). However, this must be balanced with the need to place additional electronics\nbetween the active sense areas.\nThe ﬁll factor of a camera can be determined empirically\nusing a photometric camera calibration process (see Section 10.1.4).\nChip size.\nVideo and point-and-shoot cameras have traditionally used small chip areas ( 1\n4-\ninch to 1\n2-inch sensors12), while digital SLR cameras try to come closer to the traditional size\nof a 35mm ﬁlm frame.13 When overall device size is not important, having a larger chip\nsize is preferable, since each sensor cell can be more photo-sensitive. (For compact cameras,\na smaller chip means that all of the optics can be shrunk down proportionately.) However,\n11 http://www.clarkvision.com/imagedetail/digital.sensor.performance.summary/ .\n12 These numbers refer to the “tube diameter” of the old vidicon tubes used in video cameras (http://www.\ndpreview.com/learn/?/Glossary/Camera System/sensor sizes 01.htm). The 1/2.5” sensor on the Canon SD800 cam-\nera actually measures 5.76mm × 4.29mm, i.e., a sixth of the size (on side) of a 35mm full-frame (36mm × 24mm)\nDSLR sensor.\n13 When a DSLR chip does not ﬁll the 35mm full frame, it results in a multiplier effect on the lens focal length.\nFor example, a chip that is only 0.6 the dimension of a 35mm frame will make a 50mm lens image the same angular\nextent as a 50/0.6 = 50 × 1.6 =80mm lens, as demonstrated in (2.60).\n76\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nlarger chips are more expensive to produce, not only because fewer chips can be packed into\neach wafer, but also because the probability of a chip defect goes up linearly with the chip\narea.\nAnalog gain.\nBefore analog-to-digital conversion, the sensed signal is usually boosted by\na sense ampliﬁer. In video cameras, the gain on these ampliﬁers was traditionally controlled\nby automatic gain control (AGC) logic, which would adjust these values to obtain a good\noverall exposure. In newer digital still cameras, the user now has some additional control\nover this gain through the ISO setting, which is typically expressed in ISO standard units\nsuch as 100, 200, or 400. Since the automated exposure control in most cameras also adjusts\nthe aperture and shutter speed, setting the ISO manually removes one degree of freedom from\nthe camera’s control, just as manually specifying aperture and shutter speed does. In theory, a\nhigher gain allows the camera to perform better under low light conditions (less motion blur\ndue to long exposure times when the aperture is already maxed out). In practice, however,\nhigher ISO settings usually amplify the sensor noise.\nSensor noise.\nThroughout the whole sensing process, noise is added from various sources,\nwhich may include ﬁxed pattern noise, dark current noise, shot noise, ampliﬁer noise and\nquantization noise (Healey and Kondepudy 1994; Tsin, Ramesh, and Kanade 2001). The\nﬁnal amount of noise present in a sampled image depends on all of these quantities, as well\nas the incoming light (controlled by the scene radiance and aperture), the exposure time, and\nthe sensor gain. Also, for low light conditions where the noise is due to low photon counts, a\nPoisson model of noise may be more appropriate than a Gaussian model.\nAs discussed in more detail in Section 10.1.1, Liu, Szeliski, Kang et al. (2008) use this\nmodel, along with an empirical database of camera response functions (CRFs) obtained by\nGrossberg and Nayar (2004), to estimate the noise level function (NLF) for a given image,\nwhich predicts the overall noise variance at a given pixel as a function of its brightness (a\nseparate NLF is estimated for each color channel). An alternative approach, when you have\naccess to the camera before taking pictures, is to pre-calibrate the NLF by taking repeated\nshots of a scene containing a variety of colors and luminances, such as the Macbeth Color\nChart shown in Figure 10.3b (McCamy, Marcus, and Davidson 1976). (When estimating\nthe variance, be sure to throw away or downweight pixels with large gradients, as small\nshifts between exposures will affect the sensed values at such pixels.) Unfortunately, the pre-\ncalibration process may have to be repeated for different exposure times and gain settings\nbecause of the complex interactions occurring within the sensing system.\nIn practice, most computer vision algorithms, such as image denoising, edge detection,\nand stereo matching, all beneﬁt from at least a rudimentary estimate of the noise level. Barring\nthe ability to pre-calibrate the camera or to take repeated shots of the same scene, the simplest\n2.3 The digital camera\n77\napproach is to look for regions of near-constant value and to estimate the noise variance in\nsuch regions (Liu, Szeliski, Kang et al. 2008).\nADC resolution.\nThe ﬁnal step in the analog processing chain occurring within an imaging\nsensor is the analog to digital conversion (ADC). While a variety of techniques can be used\nto implement this process, the two quantities of interest are the resolution of this process\n(how many bits it yields) and its noise level (how many of these bits are useful in practice).\nFor most cameras, the number of bits quoted (eight bits for compressed JPEG images and a\nnominal 16 bits for the RAW formats provided by some DSLRs) exceeds the actual number\nof usable bits. The best way to tell is to simply calibrate the noise of a given sensor, e.g.,\nby taking repeated shots of the same scene and plotting the estimated noise as a function of\nbrightness (Exercise 2.6).\nDigital post-processing.\nOnce the irradiance values arriving at the sensor have been con-\nverted to digital bits, most cameras perform a variety of digital signal processing (DSP)\noperations to enhance the image before compressing and storing the pixel values. These in-\nclude color ﬁlter array (CFA) demosaicing, white point setting, and mapping of the luminance\nvalues through a gamma function to increase the perceived dynamic range of the signal. We\ncover these topics in Section 2.3.2 but, before we do, we return to the topic of aliasing, which\nwas mentioned in connection with sensor array ﬁll factors.\n2.3.1 Sampling and aliasing\nWhat happens when a ﬁeld of light impinging on the image sensor falls onto the active sense\nareas in the imaging chip? The photons arriving at each active cell are integrated and then\ndigitized. However, if the ﬁll factor on the chip is small and the signal is not otherwise\nband-limited, visually unpleasing aliasing can occur.\nTo explore the phenomenon of aliasing, let us ﬁrst look at a one-dimensional signal (Fig-\nure 2.24), in which we have two sine waves, one at a frequency of f = 3/4 and the other at\nf = 5/4. If we sample these two signals at a frequency of f = 2, we see that they produce\nthe same samples (shown in black), and so we say that they are aliased.14 Why is this a bad\neffect? In essence, we can no longer reconstruct the original signal, since we do not know\nwhich of the two original frequencies was present.\nIn fact, Shannon’s Sampling Theorem shows that the minimum sampling (Oppenheim\nand Schafer 1996; Oppenheim, Schafer, and Buck 1999) rate required to reconstruct a signal\n14 An alias is an alternate name for someone, so the sampled signal corresponds to two different aliases.",
  "image_path": "page_098.jpg",
  "pages": [
    97,
    98,
    99
  ]
}