{
  "doc_id": "pages_481_483",
  "text": "9.3 Compositing\n459\nvertex cover (Uyttendaele, Eden, and Szeliski 2001) often produce similar looking results,\nalthough the former is signiﬁcantly slower since it optimizes over all pixels, while the latter\nis more sensitive to the thresholds used to determine regions of difference.\n9.3.3 Application: Photomontage\nWhile image stitching is normally used to composite partially overlapping photographs, it\ncan also be used to composite repeated shots of a scene taken with the aim of obtaining the\nbest possible composition and appearance of each element.\nFigure 9.16 shows the Photomontage system developed by Agarwala, Dontcheva, Agrawala\net al. (2004), where users draw strokes over a set of pre-aligned images to indicate which re-\ngions they wish to keep from each image. Once the system solves the resulting multi-label\ngraph cut (9.41–9.42), the various pieces taken from each source photo are blended together\nusing a variant of Poisson image blending (9.44–9.46). Their system can also be used to au-\ntomatically composite an all-focus image from a series of bracketed focus images (Hasinoff,\nKutulakos, Durand et al. 2009) or to remove wires and other unwanted elements from sets of\nphotographs. Exercise 9.10 has you implement this system and try out some of its variants.\n9.3.4 Blending\nOnce the seams between images have been determined and unwanted objects removed, we\nstill need to blend the images to compensate for exposure differences and other mis-alignments.\nThe spatially varying weighting (feathering) previously discussed can often be used to accom-\nplish this. However, it is difﬁcult in practice to achieve a pleasing balance between smoothing\nout low-frequency exposure variations and retaining sharp enough transitions to prevent blur-\nring (although using a high exponent in feathering can help).\nLaplacian pyramid blending.\nAn attractive solution to this problem is the Laplacian pyra-\nmid blending technique developed by Burt and Adelson (1983b), which we discussed in Sec-\ntion 3.5.5. Instead of using a single transition width, a frequency-adaptive width is used by\ncreating a band-pass (Laplacian) pyramid and making the transition widths within each level\na function of the level, i.e., the same width in pixels. In practice, a small number of levels,\ni.e., as few as two (Brown and Lowe 2007), may be adequate to compensate for differences\nin exposure. The result of applying this pyramid blending is shown in Figure 9.14h.\nGradient domain blending.\nAn alternative approach to multi-band image blending is to\nperform the operations in the gradient domain. Reconstructing images from their gradient\nﬁelds has a long history in computer vision (Horn 1986), starting originally with work in\n460\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.18\nPoisson image editing (P´erez, Gangnet, and Blake 2003) c⃝2003 ACM: (a)\nThe dog and the two children are chosen as source images to be pasted into the destination\nswimming pool. (b) Simple pasting fails to match the colors at the boundaries, whereas (c)\nPoisson image blending masks these differences.\nbrightness constancy (Horn 1974), shape from shading (Horn and Brooks 1989), and photo-\nmetric stereo (Woodham 1981). More recently, related ideas have been used for reconstruct-\ning images from their edges (Elder and Goldberg 2001), removing shadows from images\n(Weiss 2001), separating reﬂections from a single image (Levin, Zomet, and Weiss 2004;\nLevin and Weiss 2007), and tone mapping high dynamic range images by reducing the mag-\nnitude of image edges (gradients) (Fattal, Lischinski, and Werman 2002).\nP´erez, Gangnet, and Blake (2003) show how gradient domain reconstruction can be used\nto do seamless object insertion in image editing applications (Figure 9.18). Rather than copy-\ning pixels, the gradients of the new image fragment are copied instead. The actual pixel values\nfor the copied area are then computed by solving a Poisson equation that locally matches the\ngradients while obeying the ﬁxed Dirichlet (exact matching) conditions at the seam bound-\nary. P´erez, Gangnet, and Blake (2003) show that this is equivalent to computing an additive\nmembrane interpolant of the mismatch between the source and destination images along the\nboundary.14 In earlier work, Peleg (1981) also proposed adding a smooth function to enforce\nconsistency along the seam curve.\nAgarwala, Dontcheva, Agrawala et al. (2004) extended this idea to a multi-source formu-\nlation, where it no longer makes sense to talk of a destination image whose exact pixel values\nmust be matched at the seam. Instead, each source image contributes its own gradient ﬁeld\nand the Poisson equation is solved using Neumann boundary conditions, i.e., dropping any\nequations that involve pixels outside the boundary of the image.\n14 The membrane interpolant is known to have nicer interpolation properties for arbitrary-shaped constraints than\nfrequency-domain interpolants (Nielson 1993).\n9.3 Compositing\n461\nRather than solving the Poisson partial differential equations, Agarwala, Dontcheva, Agrawala\net al. (2004) directly minimize a variational problem,\nmin\nC(x) ∥∇C(x) −∇˜Il(x)(x)∥2.\n(9.44)\nThe discretized form of this equation is a set of gradient constraint equations\nC(x + ˆı) −C(x)\n=\n˜Il(x)(x + ˆı) −˜Il(x)(x) and\n(9.45)\nC(x + ˆ) −C(x)\n=\n˜Il(x)(x + ˆ) −˜Il(x)(x),\n(9.46)\nwhere ˆı = (1, 0) and ˆ= (0, 1) are unit vectors in the x and y directions.15 They then solve\nthe associated sparse least squares problem. Since this system of equations is only deﬁned\nup to an additive constraint, Agarwala, Dontcheva, Agrawala et al. (2004) ask the user to\nselect the value of one pixel. In practice, a better choice might be to weakly bias the solution\ntowards reproducing the original color values.\nIn order to accelerate the solution of this sparse linear system, Fattal, Lischinski, and\nWerman (2002) use multigrid, whereas Agarwala, Dontcheva, Agrawala et al. (2004) use\nhierarchical basis preconditioned conjugate gradient descent (Szeliski 1990b, 2006b) (Ap-\npendix A.5). In subsequent work, Agarwala (2007) shows how using a quadtree represen-\ntation for the solution can further accelerate the computation with minimal loss in accuracy,\nwhile Szeliski, Uyttendaele, and Steedly (2008) show how representing the per-image offset\nﬁelds using even coarser splines is even faster. This latter work also argues that blending\nin the log domain, i.e., using multiplicative rather than additive offsets, is preferable, as it\nmore closely matches texture contrasts across seam boundaries. The resulting seam blending\nworks very well in practice (Figure 9.14h), although care must be taken when copying large\ngradient values near seams so that a “double edge” is not introduced.\nCopying gradients directly from the source images after seam placement is just one ap-\nproach to gradient domain blending. The paper by Levin, Zomet, Peleg et al. (2004) examines\nseveral different variants of this approach, which they call Gradient-domain Image STitching\n(GIST). The techniques they examine include feathering (blending) the gradients from the\nsource images, as well as using an L1 norm in performing the reconstruction of the image\nfrom the gradient ﬁeld, rather than using an L2 norm as in Equation (9.44). Their preferred\ntechnique is the L1 optimization of a feathered (blended) cost function on the original image\ngradients (which they call GIST1-l1). Since L1 optimization using linear programming can\nbe slow, they develop a faster iterative median-based algorithm in a multigrid framework.\nVisual comparisons between their preferred approach and what they call optimal seam on\nthe gradients (which is equivalent to the approach of Agarwala, Dontcheva, Agrawala et al.\n(2004)) show similar results, while signiﬁcantly improving on pyramid blending and feather-\ning algorithms.\n15 At seam locations, the right hand side is replaced by the average of the gradients in the two source images.",
  "image_path": "page_482.jpg",
  "pages": [
    481,
    482,
    483
  ]
}