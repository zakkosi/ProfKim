{
  "doc_id": "pages_215_217",
  "text": "3.8 Additional reading\n193\napproximate any ﬁlter as a sum of separable components.\nThe literature on non-linear ﬁltering is quite wide and varied; it includes such topics as\nbilateral ﬁltering (Tomasi and Manduchi 1998; Durand and Dorsey 2002; Paris and Durand\n2006; Chen, Paris, and Durand 2007; Paris, Kornprobst, Tumblin et al. 2008), related itera-\ntive algorithms (Saint-Marc, Chen, and Medioni 1991; Nielsen, Florack, and Deriche 1997;\nBlack, Sapiro, Marimont et al. 1998; Weickert, ter Haar Romeny, and Viergever 1998; Weick-\nert 1998; Barash 2002; Scharr, Black, and Haussecker 2003; Barash and Comaniciu 2004),\nand variational approaches (Chan, Osher, and Shen 2001; Tschumperl´e and Deriche 2005;\nTschumperl´e 2006; Kaftory, Schechner, and Zeevi 2007).\nGood references to image morphology include (Haralick and Shapiro 1992, Section 5.2;\nBovik 2000, Section 2.2; Ritter and Wilson 2000, Section 7; Serra 1982; Serra and Vincent\n1992; Yuille, Vincent, and Geiger 1992; Soille 2006).\nThe classic papers for image pyramids and pyramid blending are by Burt and Adelson\n(1983a,b). Wavelets were ﬁrst introduced to the computer vision community by Mallat (1989)\nand good tutorial and review papers and books are available (Strang 1989; Simoncelli and\nAdelson 1990b; Rioul and Vetterli 1991; Chui 1992; Meyer 1993; Sweldens 1997). Wavelets\nare widely used in the computer graphics community to perform multi-resolution geomet-\nric processing (Stollnitz, DeRose, and Salesin 1996) and have been used in computer vision\nfor similar applications (Szeliski 1990b; Pentland 1994; Gortler and Cohen 1995; Yaou and\nChang 1994; Lai and Vemuri 1997; Szeliski 2006b), as well as for multi-scale oriented ﬁlter-\ning (Simoncelli, Freeman, Adelson et al. 1992) and denoising (Portilla, Strela, Wainwright et\nal. 2003).\nWhile image pyramids (Section 3.5.3) are usually constructed using linear ﬁltering op-\nerators, some recent work has started investigating non-linear ﬁlters, since these can better\npreserve details and other salient features. Some representative papers in the computer vision\nliterature are by Gluckman (2006a,b); Lyu and Simoncelli (2008) and in computational pho-\ntography by Bae, Paris, and Durand (2006); Farbman, Fattal, Lischinski et al. (2008); Fattal\n(2009).\nHigh-quality algorithms for image warping and resampling are covered both in the im-\nage processing literature (Wolberg 1990; Dodgson 1992; Gomes, Darsa, Costa et al. 1999;\nSzeliski, Winder, and Uyttendaele 2010) and in computer graphics (Williams 1983; Heckbert\n1986; Barkans 1997; Akenine-M¨oller and Haines 2002), where they go under the name of\ntexture mapping. Combination of image warping and image blending techniques are used to\nenable morphing between images, which is covered in a series of seminal papers and books\n(Beier and Neely 1992; Gomes, Darsa, Costa et al. 1999).\nThe regularization approach to computer vision problems was ﬁrst introduced to the vi-\nsion community by Poggio, Torre, and Koch (1985) and Terzopoulos (1986a,b, 1988) and\ncontinues to be a popular framework for formulating and solving low-level vision problems\n194\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Ju, Black, and Jepson 1996; Nielsen, Florack, and Deriche 1997; Nordstr¨om 1990; Brox,\nBruhn, Papenberg et al. 2004; Levin, Lischinski, and Weiss 2008). More detailed mathe-\nmatical treatment and additional applications can be found in the applied mathematics and\nstatistics literature (Tikhonov and Arsenin 1977; Engl, Hanke, and Neubauer 1996).\nThe literature on Markov random ﬁelds is truly immense, with publications in related\nﬁelds such as optimization and control theory of which few vision practitioners are even\naware. A good guide to the latest techniques is the book edited by Blake, Kohli, and Rother\n(2010). Other recent articles that contain nice literature reviews or experimental compar-\nisons include (Boykov and Funka-Lea 2006; Szeliski, Zabih, Scharstein et al. 2008; Kumar,\nVeksler, and Torr 2010).\nThe seminal paper on Markov random ﬁelds is the work of Geman and Geman (1984),\nwho introduced this formalism to computer vision researchers and also introduced the no-\ntion of line processes, additional binary variables that control whether smoothness penalties\nare enforced or not. Black and Rangarajan (1996) showed how independent line processes\ncould be replaced with robust pairwise potentials; Boykov, Veksler, and Zabih (2001) devel-\noped iterative binary, graph cut algorithms for optimizing multi-label MRFs; Kolmogorov\nand Zabih (2004) characterized the class of binary energy potentials required for these tech-\nniques to work; and Freeman, Pasztor, and Carmichael (2000) popularized the use of loopy\nbelief propagation for MRF inference. Many more additional references can be found in\nSections 3.7.2 and 5.5, and Appendix B.5.\n3.9 Exercises\nEx 3.1: Color balance\nWrite a simple application to change the color balance of an image\nby multiplying each color value by a different user-speciﬁed constant. If you want to get\nfancy, you can make this application interactive, with sliders.\n1. Do you get different results if you take out the gamma transformation before or after\ndoing the multiplication? Why or why not?\n2. Take the same picture with your digital camera using different color balance settings\n(most cameras control the color balance from one of the menus). Can you recover what\nthe color balance ratios are between the different settings? You may need to put your\ncamera on a tripod and align the images manually or automatically to make this work.\nAlternatively, use a color checker chart (Figure 10.3b), as discussed in Sections 2.3 and\n10.1.1.\n3. If you have access to the RAW image for the camera, perform the demosaicing yourself\n(Section 10.3.1) or downsample the image resolution to get a “true” RGB image. Does\n3.9 Exercises\n195\nyour camera perform a simple linear mapping between RAW values and the color-\nbalanced values in a JPEG? Some high-end cameras have a RAW+JPEG mode, which\nmakes this comparison much easier.\n4. Can you think of any reason why you might want to perform a color twist (Sec-\ntion 3.1.2) on the images? See also Exercise 2.9 for some related ideas.\nEx 3.2: Compositing and reﬂections\nSection 3.1.3 describes the process of compositing\nan alpha-matted image on top of another. Answer the following questions and optionally\nvalidate them experimentally:\n1. Most captured images have gamma correction applied to them. Does this invalidate the\nbasic compositing equation (3.8); if so, how should it be ﬁxed?\n2. The additive (pure reﬂection) model may have limitations. What happens if the glass is\ntinted, especially to a non-gray hue? How about if the glass is dirty or smudged? How\ncould you model wavy glass or other kinds of refractive objects?\nEx 3.3: Blue screen matting\nSet up a blue or green background, e.g., by buying a large\npiece of colored posterboard. Take a picture of the empty background, and then of the back-\nground with a new object in front of it. Pull the matte using the difference between each\ncolored pixel and its assumed corresponding background pixel, using one of the techniques\ndescribed in Section 3.1.3) or by Smith and Blinn (1996).\nEx 3.4: Difference keying\nImplement a difference keying algorithm (see Section 3.1.3)\n(Toyama, Krumm, Brumitt et al. 1999), consisting of the following steps:\n1. Compute the mean and variance (or median and robust variance) at each pixel in an\n“empty” video sequence.\n2. For each new frame, classify each pixel as foreground or background (set the back-\nground pixels to RGBA=0).\n3. (Optional) Compute the alpha channel and composite over a new background.\n4. (Optional) Clean up the image using morphology (Section 3.3.1), label the connected\ncomponents (Section 3.3.4), compute their centroids, and track them from frame to\nframe. Use this to build a “people counter”.\nEx 3.5: Photo effects\nWrite a variety of photo enhancement or effects ﬁlters: contrast, so-\nlarization (quantization), etc. Which ones are useful (perform sensible corrections) and which\nones are more creative (create unusual images)?",
  "image_path": "page_216.jpg",
  "pages": [
    215,
    216,
    217
  ]
}