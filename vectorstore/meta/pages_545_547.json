{
  "doc_id": "pages_545_547",
  "text": "10.5 Texture analysis and synthesis\n523\nA\nA′\nB\nB′\nFigure 10.54 Image analogies (Hertzmann, Jacobs, Oliver et al. 2001) c⃝2001 ACM. Given\nan example pair of a source image A and its rendered (ﬁltered) version A′, generate the\nrendered version B′ from another unﬁltered source image B.\nInstead of having the user program a certain non-photorealistic rendering effect, it is sufﬁcient\nto supply the system with examples of before and after images, and let the system synthesize\nthe novel image using exemplar-based synthesis, as shown in Figure 10.54.\nThe algorithm used to solve image analogies proceeds in a manner analogous to the tex-\nture synthesis algorithms of (Efros and Leung 1999; Wei and Levoy 2000). Once Gaus-\nsian pyramids have been computed for all of the source and reference images, the algorithm\nlooks for neighborhoods in the source ﬁltered pyramids generated from A′ that are simi-\nlar to the partially constructed neighborhood in B′, while at the same time having similar\nmulti-resolution appearances at corresponding locations in A and B. As with texture trans-\nfer, appearance characteristics can include not only (blurred) color or luminance values but\nalso orientations.\nThis general framework allows image analogies to be applied to a variety of rendering\ntasks. In addition to exemplar-based non-photorealistic rendering, image analogies can be\nused for traditional texture synthesis, super-resolution, and texture transfer (using the same\ntextured image for both A and A′). If only the ﬁltered (rendered) image A′ is available, as\nis the case with paintings, the missing reference image A can be hallucinated using a smart\n(edge preserving) blur operator. Finally, it is possible to train a system to perform texture-by-\nnumbers by manually painting over a natural image with pseudocolors corresponding to pix-\nels’ semantic meanings, e.g., water, trees, and grass (Figure 10.55a–b). The resulting system\ncan then convert a novel sketch into a fully rendered synthetic photograph (Figure 10.55c–d).\nIn more recent work, Cheng, Vishwanathan, and Zhang (2008) add ideas from image quilting\n(Efros and Freeman 2001) and MRF inference (Komodakis, Tziritas, and Paragios 2008) to\nthe basic image analogies algorithm, while Ramanarayanan and Bala (2007) recast this pro-\ncess as energy minimization, which means it can also be viewed as a conditional random ﬁeld\n(Section 3.7.2), and devise an efﬁcient algorithm to ﬁnd a good minimum.\nMore traditional ﬁltering and feature detection techniques can also be used for non-\n524\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nOriginal A′\nPainted A\nNovel painted B\nNovel textured B′\nFigure 10.55 Texture-by-numbers (Hertzmann, Jacobs, Oliver et al. 2001) c⃝2001 ACM.\nGiven a textured image A′ and a hand-labeled (painted) version A, synthesize a new image\nB′ given just the painted version B.\n(a)\n(b)\nFigure 10.56\nNon-photorealistic abstraction of photographs: (a) DeCarlo and Santella\n(2002) c⃝2002 ACM and (b) Farbman, Fattal, Lischinski et al. (2008) c⃝2008 ACM.\nphotorealistic rendering.23 For example, pen-and-ink illustration (Winkenbach and Salesin\n1994) and painterly rendering techniques (Litwinowicz 1997) use local color, intensity, and\norientation estimates as an input to their procedural rendering algorithms. Techniques for\nstylizing and simplifying photographs and video (DeCarlo and Santella 2002; Winnem¨oller,\nOlsen, and Gooch 2006; Farbman, Fattal, Lischinski et al. 2008), as in Figure 10.56, use\ncombinations of edge-preserving blurring (Section 3.3.1) and edge detection and enhance-\nment (Section 4.2.3).\n10.6 Additional reading\nA good overview of computational photography can be found in the book by Raskar and\nTumblin (2010), survey articles by Nayar (2006), Cohen and Szeliski (2006), Levoy (2006),\n23 For a good selection of papers, see the Symposia on Non-Photorealistic Animation and Rendering (NPAR) at\nhttp://www.npar.org/.\n10.6 Additional reading\n525\nDebevec (2006), and Hayes (2008), as well as two special journal issues edited by Bimber\n(2006) and Durand and Szeliski (2007). Notes from the courses on computational photog-\nraphy mentioned at the beginning of this chapter are another great source of material and\nreferences.24\nThe sub-ﬁeld of high dynamic range imaging has its own book discussing research in this\narea (Reinhard, Ward, Pattanaik et al. 2005), as well as some books describing related pho-\ntographic techniques (Freeman 2008; Gulbins and Gulbins 2009). Algorithms for calibrating\nthe radiometric response function of a camera can be found in articles by Mann and Picard\n(1995), Debevec and Malik (1997), and Mitsunaga and Nayar (1999).\nThe subject of tone mapping is treated extensively in (Reinhard, Ward, Pattanaik et al.\n2005). Representative papers from the large volume of literature on this topic include those\nby Tumblin and Rushmeier (1993), Larson, Rushmeier, and Piatko (1997), Pattanaik, Ferw-\nerda, Fairchild et al. (1998), Tumblin and Turk (1999), Durand and Dorsey (2002), Fattal,\nLischinski, and Werman (2002), Reinhard, Stark, Shirley et al. (2002), Lischinski, Farbman,\nUyttendaele et al. (2006b), and Farbman, Fattal, Lischinski et al. (2008).\nThe literature on super-resolution is quite extensive (Chaudhuri 2001; Park, Park, and\nKang 2003; Capel and Zisserman 2003; Capel 2004; van Ouwerkerk 2006). The term super-\nresolution usually describes techniques for aligning and merging multiple images to produce\nhigher-resolution composites (Keren, Peleg, and Brada 1988; Irani and Peleg 1991; Cheese-\nman, Kanefsky, Hanson et al. 1993; Mann and Picard 1994; Chiang and Boult 1996; Bascle,\nBlake, and Zisserman 1996; Capel and Zisserman 1998; Smelyanskiy, Cheeseman, Maluf et\nal. 2000; Capel and Zisserman 2000; Pickup, Capel, Roberts et al. 2009; Gulbins and Gul-\nbins 2009). However, single-image super-resolution techniques have also been developed\n(Freeman, Jones, and Pasztor 2002; Baker and Kanade 2002; Fattal 2007).\nA good survey on image matting is given by Wang and Cohen (2007a). Representative\npapers, which include extensive comparisons with previous work, include those by Chuang,\nCurless, Salesin et al. (2001), Wang and Cohen (2007b), Levin, Acha, and Lischinski (2008),\nRhemann, Rother, Rav-Acha et al. (2008), and Rhemann, Rother, Wang et al. (2009).\nThe literature on texture synthesis and hole ﬁlling includes traditional approaches to tex-\nture synthesis, which try to match image statistics between source and destination images\n(Heeger and Bergen 1995; De Bonet 1997; Portilla and Simoncelli 2000), as well as newer\napproaches, which search for matching neighborhoods or patches inside the source sample\n(Efros and Leung 1999; Wei and Levoy 2000; Efros and Freeman 2001). In a similar vein,\ntraditional approaches to hole ﬁlling involve the solution of local variational (smooth continu-\nation) problems (Bertalmio, Sapiro, Caselles et al. 2000; Bertalmio, Vese, Sapiro et al. 2003;\n24 MIT 6.815/6.865, http://stellar.mit.edu/S/course/6/sp08/6.815/materials.html, CMU 15-463, http://graphics.cs.\ncmu.edu/courses/15-463/2008 fall/, Stanford CS 448A, http://graphics.stanford.edu/courses/cs448a-08-spring/, and\nSIGGRAPH courses, http://web.media.mit.edu/∼raskar/photo/.",
  "image_path": "page_546.jpg",
  "pages": [
    545,
    546,
    547
  ]
}