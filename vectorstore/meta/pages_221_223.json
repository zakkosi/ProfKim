{
  "doc_id": "pages_221_223",
  "text": "3.9 Exercises\n199\n4. For each combination of image and noise, determine by eye which width of a Gaussian\nblurring ﬁlter σs gives the best denoised result. You will have to make a subjective\ndecision between sharpness and noise.\n5. Compute the Wiener ﬁltered version of all the noised images and compare them against\nyour hand-tuned Gaussian-smoothed images.\n6. (Optional) Do your image spectra have a lot of energy concentrated along the horizontal\nand vertical axes (fx = 0 and fy = 0)? Can you think of an explanation for this? Does\nrotating your image samples by 45◦move this energy to the diagonals? If not, could it\nbe due to edge effects in the Fourier transform? Can you suggest some techniques for\nreducing such effects?\nEx 3.17: Deblurring using Wiener ﬁltering\nUse Wiener ﬁltering to deblur some images.\n1. Modify the Wiener ﬁlter derivation (3.66–3.74) to incorporate blur (3.75).\n2. Discuss the resulting Wiener ﬁlter in terms of its noise suppression and frequency\nboosting characteristics.\n3. Assuming that the blur kernel is Gaussian and the image spectrum follows an inverse\nfrequency law, compute the frequency response of the Wiener ﬁlter, and compare it to\nthe unsharp mask.\n4. Synthetically blur two of your sample images with Gaussian blur kernels of different\nradii, add noise, and then perform Wiener ﬁltering.\n5. Repeat the above experiment with a “pillbox” (disc) blurring kernel, which is charac-\nteristic of a ﬁnite aperture lens (Section 2.2.3). Compare these results to Gaussian blur\nkernels (be sure to inspect your frequency plots).\n6. It has been suggested that regular apertures are anathema to de-blurring because they\nintroduce zeros in the sensed frequency spectrum (Veeraraghavan, Raskar, Agrawal et\nal. 2007). Show that this is indeed an issue if no prior model is assumed for the signal,\ni.e., P −1\ns\nl1. If a reasonable power spectrum is assumed, is this still a problem (do we\nstill get banding or ringing artifacts)?\nEx 3.18: High-quality image resampling\nImplement several of the low-pass ﬁlters pre-\nsented in Section 3.5.2 and also the discussion of the windowed sinc shown in Table 3.2 and\nFigure 3.29. Feel free to implement other ﬁlters (Wolberg 1990; Unser 1999).\nApply your ﬁlters to continuously resize an image, both magnifying (interpolating) and\nminifying (decimating) it; compare the resulting animations for several ﬁlters. Use both a\n200\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 3.65 Sample images for testing the quality of resampling algorithms: (a) a synthetic\nchirp; (b) and (c) some high-frequency images from the image compression community.\nsynthetic chirp image (Figure 3.65a) and natural images with lots of high-frequency detail\n(Figure 3.65b-c).27\nYou may ﬁnd it helpful to write a simple visualization program that continuously plays the\nanimations for two or more ﬁlters at once and that let you “blink” between different results.\nDiscuss the merits and deﬁciencies of each ﬁlter, as well as its tradeoff between speed and\nquality.\nEx 3.19: Pyramids\nConstruct an image pyramid. The inputs should be a grayscale or color\nimage, a separable ﬁlter kernel, and the number of desired levels. Implement at least the\nfollowing kernels:\n• 2 × 2 block ﬁltering;\n• Burt and Adelson’s binomial kernel 1/16(1, 4, 6, 4, 1) (Burt and Adelson 1983a);\n• a high-quality seven- or nine-tap ﬁlter.\nCompare the visual quality of the various decimation ﬁlters. Also, shift your input image by\n1 to 4 pixels and compare the resulting decimated (quarter size) image sequence.\nEx 3.20: Pyramid blending\nWrite a program that takes as input two color images and a\nbinary mask image and produces the Laplacian pyramid blend of the two images.\n1. Construct the Laplacian pyramid for each image.\n2. Construct the Gaussian pyramid for the two mask images (the input image and its\ncomplement).\n27 These particular images are available on the book’s Web site.\n3.9 Exercises\n201\n3. Multiply each Laplacian image by its corresponding mask and sum the images (see\nFigure 3.43).\n4. Reconstruct the ﬁnal image from the blended Laplacian pyramid.\nGeneralize your algorithm to input n images and a label image with values 1 . . . n (the value\n0 can be reserved for “no input”). Discuss whether the weighted summation stage (step 3)\nneeds to keep track of the total weight for renormalization, or whether the math just works\nout. Use your algorithm either to blend two differently exposed image (to avoid under- and\nover-exposed regions) or to make a creative blend of two different scenes.\nEx 3.21: Wavelet construction and applications\nImplement one of the wavelet families\ndescribed in Section 3.5.4 or by Simoncelli and Adelson (1990b), as well as the basic Lapla-\ncian pyramid (Exercise 3.19). Apply the resulting representations to one of the following two\ntasks:\n• Compression: Compute the entropy in each band for the different wavelet implemen-\ntations, assuming a given quantization level (say, 1/4 gray level, to keep the rounding\nerror acceptable). Quantize the wavelet coefﬁcients and reconstruct the original im-\nages. Which technique performs better? (See (Simoncelli and Adelson 1990b) or any\nof the multitude of wavelet compression papers for some typical results.)\n• Denoising. After computing the wavelets, suppress small values using coring, i.e., set\nsmall values to zero using a piecewise linear or other C0 function. Compare the results\nof your denoising using different wavelet and pyramid representations.\nEx 3.22: Parametric image warping\nWrite the code to do afﬁne and perspective image\nwarps (optionally bilinear as well). Try a variety of interpolants and report on their visual\nquality. In particular, discuss the following:\n• In a MIP-map, selecting only the coarser level adjacent to the computed fractional\nlevel will produce a blurrier image, while selecting the ﬁner level will lead to aliasing.\nExplain why this is so and discuss whether blending an aliased and a blurred image\n(tri-linear MIP-mapping) is a good idea.\n• When the ratio of the horizontal and vertical resampling rates becomes very different\n(anisotropic), the MIP-map performs even worse. Suggest some approaches to reduce\nsuch problems.\nEx 3.23: Local image warping\nOpen an image and deform its appearance in one of the\nfollowing ways:",
  "image_path": "page_222.jpg",
  "pages": [
    221,
    222,
    223
  ]
}