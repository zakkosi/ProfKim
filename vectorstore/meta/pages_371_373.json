{
  "doc_id": "pages_371_373",
  "text": "7.2 Two-frame structure from motion\n349\nrelationships gives us the epipolar line in the ﬁrst image as l0 = ET ˆx1 and e0 as the zero-\nvalue right singular vector of E.\nGiven this fundamental relationship (7.10), how can we use it to recover the camera\nmotion encoded in the essential matrix E?\nIf we have N corresponding measurements\n{(xi0, xi1)}, we can form N homogeneous equations in the nine elements of E = {e00 . . . e22},\nxi0xi1e00\n+\nyi0xi1e01\n+\nxi1e02\n+\nxi0yi1e00\n+\nyi0yi1e11\n+\nyi1e12\n+\nxi0e20\n+\nyi0e21\n+\ne22\n=\n0\n(7.13)\nwhere xij = (xij, yij, 1). This can be written more compactly as\n[xi1 xT\ni0] ⊗E = Zi ⊗E = zi · f = 0,\n(7.14)\nwhere ⊗indicates an element-wise multiplication and summation of matrix elements, and zi\nand f are the rasterized (vector) forms of the Zi = ˆxi1ˆxT\ni0 and E matrices.2 Given N ≥8\nsuch equations, we can compute an estimate (up to scale) for the entries in E using an SVD.\nIn the presence of noisy measurements, how close is this estimate to being statistically\noptimal? If you look at the entries in (7.13), you can see that some entries are the products\nof image measurements such as xi0yi1 and others are direct image measurements (or even\nthe identity). If the measurements have comparable noise, the terms that are products of\nmeasurements have their noise ampliﬁed by the other element in the product, which can lead\nto very poor scaling, e.g., an inordinately large inﬂuence of points with large coordinates (far\naway from the image center).\nIn order to counteract this trend, Hartley (1997a) suggests that the point coordinates\nshould be translated and scaled so that their centroid lies at the origin and their variance\nis unity, i.e.,\n˜xi\n=\ns(xi −µx)\n(7.15)\n˜yi\n=\ns(xi −µy)\n(7.16)\nsuch that P\ni ˜xi = P\ni ˜yi = 0 and P\ni ˜x2\ni + P\ni ˜y2\ni = 2n, where n is the number of points.3\nOnce the essential matrix ˜E has been computed from the transformed coordinates\n{(˜xi0, ˜xi1)}, where ˜xij = T j ˆxij, the original essential matrix E can be recovered as\nE = T 1 ˜ET 0.\n(7.17)\n2 We use f instead of e to denote the rasterized form of E to avoid confusion with the epipoles ej.\n3 More precisely, Hartley (1997a) suggests scaling the points “so that the average distance from the origin is equal\nto\n√\n2” but the heuristic of unit variance is faster to compute (does not require per-point square roots) and should\nyield comparable improvements.\n350\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nIn his paper, Hartley (1997a) compares the improvement due to his re-normalization strategy\nto alternative distance measures proposed by others such as Zhang (1998a,b) and concludes\nthat his simple re-normalization in most cases is as effective as (or better than) alternative\ntechniques. Torr and Fitzgibbon (2004) recommend a variant on this algorithm where the\nnorm of the upper 2 × 2 sub-matrix of E is set to 1 and show that it has even better stability\nwith respect to 2D coordinate transformations.\nOnce an estimate for the essential matrix E has been recovered, the direction of the trans-\nlation vector t can be estimated. Note that the absolute distance between the two cameras can\nnever be recovered from pure image measurements alone, regardless of how many cameras\nor points are used. Knowledge about absolute camera and point positions or distances, of-\nten called ground control points in photogrammetry, is always required to establish the ﬁnal\nscale, position, and orientation.\nTo estimate this direction ˆt, observe that under ideal noise-free conditions, the essential\nmatrix E is singular, i.e., ˆt\nT E = 0. This singularity shows up as a singular value of 0 when\nan SVD of E is performed,\nE = [ˆt]×R = UΣV T =\nh\nu0\nu1\nˆt\ni\n\n\n1\n1\n0\n\n\n\n\nvT\n0\nvT\n1\nvT\n2\n\n\n(7.18)\nWhen E is computed from noisy measurements, the singular vector associated with the small-\nest singular value gives us ˆt. (The other two singular values should be similar but are not, in\ngeneral, equal to 1 because E is only computed up to an unknown scale.)\nBecause E is rank-deﬁcient, it turns out that we actually only need seven correspondences\nof the form of Equation (7.14) instead of eight to estimate this matrix (Hartley 1994a; Torr and\nMurray 1997; Hartley and Zisserman 2004). (The advantage of using fewer correspondences\ninside a RANSAC robust ﬁtting stage is that fewer random samples need to be generated.)\nFrom this set of seven homogeneous equations (which we can stack into a 7 × 9 matrix for\nSVD analysis), we can ﬁnd two independent vectors, say f 0 and f 1 such that zi · f j = 0.\nThese two vectors can be converted back into 3 × 3 matrices E0 and E1, which span the\nsolution space for\nE = αE0 + (1 −α)E1.\n(7.19)\nTo ﬁnd the correct value of α, we observe that E has a zero determinant, since it is rank\ndeﬁcient, and hence\ndet |αE0 + (1 −α)E1| = 0.\n(7.20)\nThis gives us a cubic equation in α, which has either one or three solutions (roots). Substitut-\ning these values into (7.19) to obtain E, we can test this essential matrix against other unused\nfeature correspondences to select the correct one.\n7.2 Two-frame structure from motion\n351\nOnce ˆt has been recovered, how can we estimate the corresponding rotation matrix R?\nRecall that the cross-product operator [ˆt]× (2.32) projects a vector onto a set of orthogonal\nbasis vectors that include ˆt, zeros out the ˆt component, and rotates the other two by 90◦,\n[ˆt]× = SZR90◦ST =\nh\ns0\ns1\nˆt\ni\n\n\n1\n1\n0\n\n\n\n\n0\n−1\n1\n0\n1\n\n\n\n\nsT\n0\nsT\n1\nˆt\nT\n\n,\n(7.21)\nwhere ˆt = s0 × s1. From Equations (7.18 and 7.21), we get\nE = [ˆt]×R = SZR90◦ST R = UΣV T ,\n(7.22)\nfrom which we can conclude that S = U. Recall that for a noise-free essential matrix,\n(Σ = Z), and hence\nR90◦U T R = V T\n(7.23)\nand\nR = URT\n90◦V T .\n(7.24)\nUnfortunately, we only know both E and ˆt up to a sign. Furthermore, the matrices U and V\nare not guaranteed to be rotations (you can ﬂip both their signs and still get a valid SVD). For\nthis reason, we have to generate all four possible rotation matrices\nR = ±URT\n±90◦V T\n(7.25)\nand keep the two whose determinant |R| = 1. To disambiguate between the remaining pair\nof potential rotations, which form a twisted pair (Hartley and Zisserman 2004, p. 240), we\nneed to pair them with both possible signs of the translation direction ±ˆt and select the\ncombination for which the largest number of points is seen in front of both cameras.4\nThe property that points must lie in front of the camera, i.e., at a positive distance along\nthe viewing rays emanating from the camera, is known as chirality (Hartley 1998). In addition\nto determining the signs of the rotation and translation, as described above, the chirality (sign\nof the distances) of the points in a reconstruction can be used inside a RANSAC procedure\n(along with the reprojection errors) to distinguish between likely and unlikely conﬁgurations.5\nChirality can also be used to transform projective reconstructions (Sections 7.2.1 and 7.2.2)\ninto quasi-afﬁne reconstructions (Hartley 1998).\nThe normalized “eight-point algorithm” (Hartley 1997a) described above is not the only\nway to estimate the camera motion from correspondences. Variants include using seven points\n4 In the noise-free case, a single point sufﬁces. It is safer, however, to test all or a sufﬁcient subset of points,\ndownweighting the ones that lie close to the plane at inﬁnity, for which it is easy to get depth reversals.\n5 Note that as points get further away from a camera, i.e., closer toward the plane at inﬁnity, errors in chirality\nbecome more likely.",
  "image_path": "page_372.jpg",
  "pages": [
    371,
    372,
    373
  ]
}