{
  "doc_id": "pages_462_464",
  "text": "440\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 9.8 A cylindrical panorama (Szeliski and Shum 1997) c⃝1997 ACM: (a) two cylin-\ndrically warped images related by a horizontal translation; (b) part of a cylindrical panorama\ncomposited from a sequence of images.\nFigure 9.9\nA spherical panorama constructed from 54 photographs (Szeliski and Shum\n1997) c⃝1997 ACM.\nsometimes used for the acquisition of larger panoramas (Kopf, Uyttendaele, Deussen et al.\n2007).8 Not only do they ensure a uniform coverage of the visual ﬁeld with a desired amount\nof image overlap but they also make it possible to stitch the images using cylindrical or\nspherical coordinates and pure translations. In this case, pixel coordinates (x, y, f) must ﬁrst\nbe rotated using the known tilt and panning angles before being projected into cylindrical\nor spherical coordinates (Chen 1995). Having a roughly known panning angle also makes it\neasier to compute the alignment, since the rough relative positioning of all the input images is\nknown ahead of time, enabling a reduced search range for alignment. Figure 9.9 shows a full\n3D rotational panorama unwrapped onto the surface of a sphere (Szeliski and Shum 1997).\nOne ﬁnal coordinate mapping worth mentioning is the polar mapping, where the north\n8See also http://gigapan.org.\n9.2 Global alignment\n441\npole lies along the optical axis rather than the vertical axis,\n(cos θ sin φ, sin θ sin φ, cos φ) = s (x, y, z).\n(9.22)\nIn this case, the mapping equations become\nx′\n=\nsφ cos θ = sx\nr tan−1 r\nz ,\n(9.23)\ny′\n=\nsφ sin θ = sy\nr tan−1 r\nz ,\n(9.24)\nwhere r =\np\nx2 + y2 is the radial distance in the (x, y) plane and sφ plays a similar role\nin the (x′, y′) plane. This mapping provides an attractive visualization surface for certain\nkinds of wide-angle panoramas and is also a good model for the distortion induced by ﬁsheye\nlenses, as discussed in Section 2.1.6. Note how for small values of (x, y), the mapping\nequations reduce to x′ ≈sx/z, which suggests that s plays a role similar to the focal length\nf.\n9.2 Global alignment\nSo far, we have discussed how to register pairs of images using a variety of motion models. In\nmost applications, we are given more than a single pair of images to register. The goal is then\nto ﬁnd a globally consistent set of alignment parameters that minimize the mis-registration\nbetween all pairs of images (Szeliski and Shum 1997; Shum and Szeliski 2000; Sawhney and\nKumar 1999; Coorg and Teller 2000).\nIn this section, we extend the pairwise matching criteria (6.2, 8.1, and 8.50) to a global\nenergy function that involves all of the per-image pose parameters (Section 9.2.1). Once\nwe have computed the global alignment, we often need to perform local adjustments, such\nas parallax removal, to reduce double images and blurring due to local mis-registrations\n(Section 9.2.2). Finally, if we are given an unordered set of images to register, we need to\ndiscover which images go together to form one or more panoramas. This process of panorama\nrecognition is described in Section 9.2.3.\n9.2.1 Bundle adjustment\nOne way to register a large number of images is to add new images to the panorama one\nat a time, aligning the most recent image with the previous ones already in the collection\n(Szeliski and Shum 1997) and discovering, if necessary, which images it overlaps (Sawhney\nand Kumar 1999). In the case of 360◦panoramas, accumulated error may lead to the presence\nof a gap (or excessive overlap) between the two ends of the panorama, which can be ﬁxed\n442\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nby stretching the alignment of all the images using a process called gap closing (Szeliski and\nShum 1997). However, a better alternative is to simultaneously align all the images using a\nleast-squares framework to correctly distribute any mis-registration errors.\nThe process of simultaneously adjusting pose parameters for a large collection of overlap-\nping images is called bundle adjustment in the photogrammetry community (Triggs, McLauch-\nlan, Hartley et al. 1999). In computer vision, it was ﬁrst applied to the general structure from\nmotion problem (Szeliski and Kang 1994) and then later specialized for panoramic image\nstitching (Shum and Szeliski 2000; Sawhney and Kumar 1999; Coorg and Teller 2000).\nIn this section, we formulate the problem of global alignment using a feature-based ap-\nproach, since this results in a simpler system. An equivalent direct approach can be obtained\neither by dividing images into patches and creating a virtual feature correspondence for each\none (as discussed in Section 9.2.4 and by Shum and Szeliski (2000)) or by replacing the\nper-feature error metrics with per-pixel metrics.\nConsider the feature-based alignment problem given in Equation (6.2), i.e.,\nEpairwise−LS =\nX\ni\n∥ri∥2 = ∥˜x′\ni(xi; p) −ˆx′\ni∥2.\n(9.25)\nFor multi-image alignment, instead of having a single collection of pairwise feature corre-\nspondences, {(xi, ˆx′\ni)}, we have a collection of n features, with the location of the ith feature\npoint in the jth image denoted by xij and its scalar conﬁdence (i.e., inverse variance) denoted\nby cij.9 Each image also has some associated pose parameters.\nIn this section, we assume that this pose consists of a rotation matrix Rj and a focal\nlength fj, although formulations in terms of homographies are also possible (Szeliski and\nShum 1997; Sawhney and Kumar 1999). The equation mapping a 3D point xi into a point\nxij in frame j can be re-written from Equations (2.68) and (9.5) as\n˜xij ∼KjRjxi and xi ∼R−1\nj K−1\nj\n˜xij,\n(9.26)\nwhere Kj = diag(fj, fj, 1) is the simpliﬁed form of the calibration matrix. The motion\nmapping a point xij from frame j into a point xik in frame k is similarly given by\n˜xik ∼˜\nHkj ˜xij = KkRkR−1\nj K−1\nj\n˜xij.\n(9.27)\nGiven an initial set of {(Rj, fj)} estimates obtained from chaining pairwise alignments, how\ndo we reﬁne these estimates?\nOne approach is to directly extend the pairwise energy Epairwise−LS (9.25) to a multiview\nformulation,\nEall−pairs−2D =\nX\ni\nX\njk\ncijcik∥˜xik(ˆxij; Rj, fj, Rk, fk) −ˆxik∥2,\n(9.28)\n9 Features that are not seen in image j have cij = 0. We can also use 2 × 2 inverse covariance matrices Σ−1\nij in\nplace of cij, as shown in Equation (6.11).",
  "image_path": "page_463.jpg",
  "pages": [
    462,
    463,
    464
  ]
}