{
  "doc_id": "pages_414_416",
  "text": "392\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nI\nx\nei\nΔu I0(xi)\nI1(xi+u)\nJ1(xi+u)\nI0\nI1\nxi\nFigure 8.2\nTaylor series approximation of a function and the incremental computation of\nthe optical ﬂow correction amount. J1(xi + u) is the image gradient at (xi + u) and ei is\nthe current intensity difference.\nIn this case, care must be taken to choose a suitable range of s values that reasonably samples\nthe original image.\nFor images that are also translated by a small amount,\nI1(eˆs ˆRx + t) = I0(x),\n(8.32)\nDe Castro and Morandi (1987) propose an ingenious solution that uses several steps to esti-\nmate the unknown parameters. First, both images are converted to the Fourier domain and\nonly the magnitudes of the transformed images are retained. In principle, the Fourier mag-\nnitude images are insensitive to translations in the image plane (although the usual caveats\nabout border effects apply). Next, the two magnitude images are aligned in rotation and scale\nusing the polar or log-polar representations. Once rotation and scale are estimated, one of the\nimages can be de-rotated and scaled and a regular translational algorithm can be applied to\nestimate the translational shift.\nUnfortunately, this trick only applies when the images have large overlap (small transla-\ntional motion). For more general motion of patches or images, the parametric motion estima-\ntor described in Section 8.2 or the feature-based approaches described in Section 6.1 need to\nbe used.\n8.1.3 Incremental reﬁnement\nThe techniques described up till now can estimate alignment to the nearest pixel (or poten-\ntially fractional pixel if smaller search steps are used). In general, image stabilization and\nstitching applications require much higher accuracies to obtain acceptable results.\nTo obtain better sub-pixel estimates, we can use one of several techniques described by\nTian and Huhns (1986). One possibility is to evaluate several discrete (integer or fractional)\nvalues of (u, v) around the best value found so far and to interpolate the matching score to\nﬁnd an analytic minimum.\n8.1 Translational alignment\n393\nA more commonly used approach, ﬁrst proposed by Lucas and Kanade (1981), is to\nperform gradient descent on the SSD energy function (8.1), using a Taylor series expansion\nof the image function (Figure 8.2),\nELK−SSD(u + ∆u)\n=\nX\ni\n[I1(xi + u + ∆u) −I0(xi)]2\n(8.33)\n≈\nX\ni\n[I1(xi + u) + J1(xi + u)∆u −I0(xi)]2\n(8.34)\n=\nX\ni\n[J1(xi + u)∆u + ei]2,\n(8.35)\nwhere\nJ1(xi + u) = ∇I1(xi + u) = (∂I1\n∂x , ∂I1\n∂y )(xi + u)\n(8.36)\nis the image gradient or Jacobian at (xi + u) and\nei = I1(xi + u) −I0(xi),\n(8.37)\nﬁrst introduced in (8.1), is the current intensity error.7 The gradient at a particular sub-pixel\nlocation (xi + u) can be computed using a variety of techniques, the simplest of which is\nto simply take the horizontal and vertical differences between pixels x and x + (1, 0) or\nx + (0, 1). More sophisticated derivatives can sometimes lead to noticeable performance\nimprovements.\nThe linearized form of the incremental update to the SSD error (8.35) is often called the\noptical ﬂow constraint or brightness constancy constraint equation\nIxu + Iyv + It = 0,\n(8.38)\nwhere the subscripts in Ix and Iy denote spatial derivatives, and It is called the temporal\nderivative, which makes sense if we are computing instantaneous velocity in a video se-\nquence. When squared and summed or integrated over a region, it can be used to compute\noptic ﬂow (Horn and Schunck 1981).\nThe above least squares problem (8.35) can be minimized by solving the associated nor-\nmal equations (Appendix A.2),\nA∆u = b\n(8.39)\nwhere\nA =\nX\ni\nJT\n1 (xi + u)J1(xi + u)\n(8.40)\n7 We follow the convention, commonly used in robotics and by Baker and Matthews (2004), that derivatives with\nrespect to (column) vectors result in row vectors, so that fewer transposes are needed in the formulas.\n394\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nand\nb = −\nX\ni\neiJT\n1 (xi + u)\n(8.41)\nare called the (Gauss–Newton approximation of the) Hessian and gradient-weighted residual\nvector, respectively.8 These matrices are also often written as\nA =\n\"\nP I2\nx\nP IxIy\nP IxIy\nP I2\ny\n#\nand b = −\n\" P IxIt\nP IyIt\n#\n.\n(8.42)\nThe gradients required for J1(xi + u) can be evaluated at the same time as the image\nwarps required to estimate I1(xi + u) (Section 3.6.1 (3.89)) and, in fact, are often computed\nas a side-product of image interpolation. If efﬁciency is a concern, these gradients can be\nreplaced by the gradients in the template image,\nJ1(xi + u) ≈J0(xi),\n(8.43)\nsince near the correct alignment, the template and displaced target images should look sim-\nilar. This has the advantage of allowing the pre-computation of the Hessian and Jacobian\nimages, which can result in signiﬁcant computational savings (Hager and Belhumeur 1998;\nBaker and Matthews 2004). A further reduction in computation can be obtained by writing\nthe warped image I1(xi + u) used to compute ei in (8.37) as a convolution of a sub-pixel\ninterpolation ﬁlter with the discrete samples in I1 (Peleg and Rav-Acha 2006). Precomput-\ning the inner product between the gradient ﬁeld and shifted version of I1 allows the iterative\nre-computation of ei to be performed in constant time (independent of the number of pixels).\nThe effectiveness of the above incremental update rule relies on the quality of the Taylor\nseries approximation. When far away from the true displacement (say, 1–2 pixels), several\niterations may be needed. It is possible, however, to estimate a value for J1 using a least\nsquares ﬁt to a series of larger displacements in order to increase the range of convergence\n(Jurie and Dhome 2002) or to “learn” a special-purpose recognizer for a given patch (Avi-\ndan 2001; Williams, Blake, and Cipolla 2003; Lepetit, Pilet, and Fua 2006; Hinterstoisser,\nBenhimane, Navab et al. 2008; ¨Ozuysal, Calonder, Lepetit et al. 2010) as discussed in Sec-\ntion 4.1.4.\nA commonly used stopping criterion for incremental updating is to monitor the magnitude\nof the displacement correction ∥u∥and to stop when it drops below a certain threshold (say,\n1/10 of a pixel). For larger motions, it is usual to combine the incremental update rule with a\nhierarchical coarse-to-ﬁne search strategy, as described in Section 8.1.1.\n8 The true Hessian is the full second derivative of the error function E, which may not be positive deﬁnite—see\nSection 6.1.3 and Appendix A.3.",
  "image_path": "page_415.jpg",
  "pages": [
    414,
    415,
    416
  ]
}