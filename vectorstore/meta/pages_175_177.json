{
  "doc_id": "pages_175_177",
  "text": "3.5 Pyramids and wavelets\n153\nH\nL\n↓2\nH0\nH\nL\n↓2\nL1\nH1\nL2\nQ\nF\nI\n↑2\nF\nI\n↑2\nQ\nQ\nH0\nL1\nH1\nL2\nI\nO\n(a)\nL\n↓2\nH0\nL1\nQ\nI\n↑2\nH0\nL1\nI\n↑2\n–\n(b)\nFigure 3.34 The Laplacian pyramid: (a) The conceptual ﬂow of images through processing\nstages: images are high-pass and low-pass ﬁltered, and the low-pass ﬁltered images are pro-\ncessed in the next stage of the pyramid. During reconstruction, the interpolated image and the\n(optionally ﬁltered) high-pass image are added back together. The Q box indicates quantiza-\ntion or some other pyramid processing, e.g., noise removal by coring (setting small wavelet\nvalues to 0). (b) The actual computation of the high-pass ﬁlter involves ﬁrst interpolating the\ndownsampled low-pass image and then subtracting it. This results in perfect reconstruction\nwhen Q is the identity. The high-pass (or band-pass) images are typically called Laplacian\nimages, while the low-pass images are called Gaussian images.\n154\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nspace:\n−\n=\nfrequency:\n−\n=\nlow-pass\nlower-pass\nFigure 3.35 The difference of two low-pass ﬁlters results in a band-pass ﬁlter. The dashed\nblue lines show the close ﬁt to a half-octave Laplacian of Gaussian.\ncent levels, the authors claim that coarse-to-ﬁne algorithms perform better. In the image-\nprocessing community, half-octave pyramids combined with checkerboard sampling grids\nare known as quincunx sampling (Feilner, Van De Ville, and Unser 2005). In detecting multi-\nscale features (Section 4.1.1), it is often common to use half-octave or even quarter-octave\npyramids (Lowe 2004; Triggs 2004). However, in this case, the subsampling only occurs\nat every octave level, i.e., the image is repeatedly blurred with wider Gaussians until a full\noctave of resolution change has been achieved (Figure 4.11).\n3.5.4 Wavelets\nWhile pyramids are used extensively in computer vision applications, some people use wavelet\ndecompositions as an alternative. Wavelets are ﬁlters that localize a signal in both space\nand frequency (like the Gabor ﬁlter in Table 3.2) and are deﬁned over a hierarchy of scales.\nWavelets provide a smooth way to decompose a signal into frequency components without\nblocking and are closely related to pyramids.\nWavelets were originally developed in the applied math and signal processing communi-\nties and were introduced to the computer vision community by Mallat (1989). Strang (1989);\nSimoncelli and Adelson (1990b); Rioul and Vetterli (1991); Chui (1992); Meyer (1993) all\nprovide nice introductions to the subject along with historical reviews, while Chui (1992) pro-\nvides a more comprehensive review and survey of applications. Sweldens (1997) describes\nthe more recent lifting approach to wavelets that we discuss shortly.\nWavelets are widely used in the computer graphics community to perform multi-resolution\ngeometric processing (Stollnitz, DeRose, and Salesin 1996) and have also been used in com-\nputer vision for similar applications (Szeliski 1990b; Pentland 1994; Gortler and Cohen 1995;\nYaou and Chang 1994; Lai and Vemuri 1997; Szeliski 2006b), as well as for multi-scale ori-\nented ﬁltering (Simoncelli, Freeman, Adelson et al. 1992) and denoising (Portilla, Strela,\n3.5 Pyramids and wavelets\n155\nfine\nmedium\ncoarse\nl = 0\nl = 1\nl = 2\nl = 3\nl = 4\nfine\nmedium\ncoarse\nl = 0\nl = 1\nl = 2\n(a)\n(b)\nFigure 3.36\nMultiresolution pyramids: (a) pyramid with half-octave (quincunx) sampling\n(odd levels are colored gray for clarity). (b) wavelet pyramid—each wavelet level stores 3/4\nof the original pixels (usually the horizontal, vertical, and mixed gradients), so that the total\nnumber of wavelet coefﬁcients and original pixels is the same.\nWainwright et al. 2003).\nSince both image pyramids and wavelets decompose an image into multi-resolution de-\nscriptions that are localized in both space and frequency, how do they differ? The usual\nanswer is that traditional pyramids are overcomplete, i.e., they use more pixels than the orig-\ninal image to represent the decomposition, whereas wavelets provide a tight frame, i.e., they\nkeep the size of the decomposition the same as the image (Figure 3.36b). However, some\nwavelet families are, in fact, overcomplete in order to provide better shiftability or steering in\norientation (Simoncelli, Freeman, Adelson et al. 1992). A better distinction, therefore, might\nbe that wavelets are more orientation selective than regular band-pass pyramids.\nHow are two-dimensional wavelets constructed? Figure 3.37a shows a high-level dia-\ngram of one stage of the (recursive) coarse-to-ﬁne construction (analysis) pipeline alongside\nthe complementary re-construction (synthesis) stage. In this diagram, the high-pass ﬁlter\nfollowed by decimation keeps 3/4 of the original pixels, while 1/4 of the low-frequency coef-\nﬁcients are passed on to the next stage for further analysis. In practice, the ﬁltering is usually\nbroken down into two separable sub-stages, as shown in Figure 3.37b. The resulting three\nwavelet images are sometimes called the high–high (HH), high–low (HL), and low–high\n(LH) images. The high–low and low–high images accentuate the horizontal and vertical\nedges and gradients, while the high–high image contains the less frequently occurring mixed\nderivatives.\nHow are the high-pass H and low-pass L ﬁlters shown in Figure 3.37b chosen and how\ncan the corresponding reconstruction ﬁlters I and F be computed? Can ﬁlters be designed",
  "image_path": "page_176.jpg",
  "pages": [
    175,
    176,
    177
  ]
}