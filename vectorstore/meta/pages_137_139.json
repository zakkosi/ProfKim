{
  "doc_id": "pages_137_139",
  "text": "3.2 Linear ﬁltering\n115\nzero\nwrap\nclamp\nmirror\nblurred zero\nnormalized zero\nblurred clamp\nblurred mirror\nFigure 3.13 Border padding (top row) and the results of blurring the padded image (bottom\nrow). The normalized zero image is the result of dividing (normalizing) the blurred zero-\npadded RGBA image by its corresponding soft alpha value.\n• mirror: reﬂect pixels across the image edge;\n• extend: extend the signal by subtracting the mirrored version of the signal from the\nedge pixel value.\nIn the computer graphics literature (Akenine-M¨oller and Haines 2002, p. 124), these mech-\nanisms are known as the wrapping mode (OpenGL) or texture addressing mode (Direct3D).\nThe formulas for each of these modes are left to the reader (Exercise 3.8).\nFigure 3.13 shows the effects of padding an image with each of the above mechanisms and\nthen blurring the resulting padded image. As you can see, zero padding darkens the edges,\nclamp (replication) padding propagates border values inward, mirror (reﬂection) padding pre-\nserves colors near the borders. Extension padding (not shown) keeps the border pixels ﬁxed\n(during blur).\nAn alternative to padding is to blur the zero-padded RGBA image and to then divide the\nresulting image by its alpha value to remove the darkening effect. The results can be quite\ngood, as seen in the normalized zero image in Figure 3.13.\n3.2.1 Separable ﬁltering\nThe process of performing a convolution requires K2 (multiply-add) operations per pixel,\nwhere K is the size (width or height) of the convolution kernel, e.g., the box ﬁlter in Fig-\n116\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n1\nK2\n1\n1\n· · ·\n1\n1\n1\n· · ·\n1\n...\n...\n1\n...\n1\n1\n· · ·\n1\n1\n16\n1\n2\n1\n2\n4\n2\n1\n2\n1\n1\n256\n1\n4\n6\n4\n1\n4\n16\n24\n16\n4\n6\n24\n36\n24\n6\n4\n16\n24\n16\n4\n1\n4\n6\n4\n1\n1\n8\n−1\n0\n1\n−2\n0\n2\n−1\n0\n1\n1\n4\n1\n−2\n1\n−2\n4\n−2\n1\n−2\n1\n1\nK\n1\n1\n· · ·\n1\n1\n4\n1\n2\n1\n1\n16\n1\n4\n6\n4\n1\n1\n2\n−1\n0\n1\n1\n2\n1\n−2\n1\n(a) box, K = 5\n(b) bilinear\n(c) “Gaussian”\n(d) Sobel\n(e) corner\nFigure 3.14\nSeparable linear ﬁlters: For each image (a)–(e), we show the 2D ﬁlter kernel\n(top), the corresponding horizontal 1D kernel (middle), and the ﬁltered image (bottom). The\nﬁltered Sobel and corner images are signed, scaled up by 2× and 4×, respectively, and added\nto a gray offset before display.\nure 3.14a. In many cases, this operation can be signiﬁcantly sped up by ﬁrst performing a\none-dimensional horizontal convolution followed by a one-dimensional vertical convolution\n(which requires a total of 2K operations per pixel). A convolution kernel for which this is\npossible is said to be separable.\nIt is easy to show that the two-dimensional kernel K corresponding to successive con-\nvolution with a horizontal kernel h and a vertical kernel v is the outer product of the two\nkernels,\nK = vhT\n(3.20)\n(see Figure 3.14 for some examples). Because of the increased efﬁciency, the design of\nconvolution kernels for computer vision applications is often inﬂuenced by their separability.\nHow can we tell if a given kernel K is indeed separable? This can often be done by\ninspection or by looking at the analytic form of the kernel (Freeman and Adelson 1991). A\nmore direct method is to treat the 2D kernel as a 2D matrix K and to take its singular value\ndecomposition (SVD),\nK =\nX\ni\nσiuivT\ni\n(3.21)\n(see Appendix A.1.1 for the deﬁnition of the SVD). If only the ﬁrst singular value σ0 is\nnon-zero, the kernel is separable and √σ0u0 and √σ0vT\n0 provide the vertical and horizontal\n3.2 Linear ﬁltering\n117\nkernels (Perona 1995). For example, the Laplacian of Gaussian kernel (3.26 and 4.23) can be\nimplemented as the sum of two separable ﬁlters (4.24) (Wiejak, Buxton, and Buxton 1985).\nWhat if your kernel is not separable and yet you still want a faster way to implement\nit? Perona (1995), who ﬁrst made the link between kernel separability and SVD, suggests\nusing more terms in the (3.21) series, i.e., summing up a number of separable convolutions.\nWhether this is worth doing or not depends on the relative sizes of K and the number of sig-\nniﬁcant singular values, as well as other considerations, such as cache coherency and memory\nlocality.\n3.2.2 Examples of linear ﬁltering\nNow that we have described the process for performing linear ﬁltering, let us examine a\nnumber of frequently used ﬁlters.\nThe simplest ﬁlter to implement is the moving average or box ﬁlter, which simply averages\nthe pixel values in a K ×K window. This is equivalent to convolving the image with a kernel\nof all ones and then scaling (Figure 3.14a). For large kernels, a more efﬁcient implementation\nis to slide a moving window across each scanline (in a separable ﬁlter) while adding the\nnewest pixel and subtracting the oldest pixel from the running sum. This is related to the\nconcept of summed area tables, which we describe shortly.\nA smoother image can be obtained by separably convolving the image with a piecewise\nlinear “tent” function (also known as a Bartlett ﬁlter). Figure 3.14b shows a 3 × 3 version\nof this ﬁlter, which is called the bilinear kernel, since it is the outer product of two linear\n(ﬁrst-order) splines (see Section 3.5.2).\nConvolving the linear tent function with itself yields the cubic approximating spline,\nwhich is called the “Gaussian” kernel (Figure 3.14c) in Burt and Adelson’s (1983a) Lapla-\ncian pyramid representation (Section 3.5). Note that approximate Gaussian kernels can also\nbe obtained by iterated convolution with box ﬁlters (Wells 1986). In applications where the\nﬁlters really need to be rotationally symmetric, carefully tuned versions of sampled Gaussians\nshould be used (Freeman and Adelson 1991) (Exercise 3.10).\nThe kernels we just discussed are all examples of blurring (smoothing) or low-pass ker-\nnels (since they pass through the lower frequencies while attenuating higher frequencies).\nHow good are they at doing this? In Section 3.4, we use frequency-space Fourier analysis to\nexamine the exact frequency response of these ﬁlters. We also introduce the sinc ((sin x)/x)\nﬁlter, which performs ideal low-pass ﬁltering.\nIn practice, smoothing kernels are often used to reduce high-frequency noise. We have\nmuch more to say about using variants on smoothing to remove noise later (see Sections 3.3.1,\n3.4, and 3.7).\nSurprisingly, smoothing kernels can also be used to sharpen images using a process called",
  "image_path": "page_138.jpg",
  "pages": [
    137,
    138,
    139
  ]
}