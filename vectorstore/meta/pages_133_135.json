{
  "doc_id": "pages_133_135",
  "text": "3.2 Linear ﬁltering\n111\ntions, including the construction of SIFT feature descriptors (Section 4.1.3) and vocabulary\ntrees (Section 14.3.2).\n3.1.5 Application: Tonal adjustment\nOne of the most widely used applications of point-wise image processing operators is the\nmanipulation of contrast or tone in photographs, to make them look either more attractive or\nmore interpretable. You can get a good sense of the range of operations possible by opening\nup any photo manipulation tool and trying out a variety of contrast, brightness, and color\nmanipulation options, as shown in Figures 3.2 and 3.7.\nExercises 3.1, 3.5, and 3.6 have you implement some of these operations, in order to\nbecome familiar with basic image processing operators. More sophisticated techniques for\ntonal adjustment (Reinhard, Ward, Pattanaik et al. 2005; Bae, Paris, and Durand 2006) are\ndescribed in the section on high dynamic range tone mapping (Section 10.2.1).\n3.2 Linear ﬁltering\nLocally adaptive histogram equalization is an example of a neighborhood operator or local\noperator, which uses a collection of pixel values in the vicinity of a given pixel to deter-\nmine its ﬁnal output value (Figure 3.10). In addition to performing local tone adjustment,\nneighborhood operators can be used to ﬁlter images in order to add soft blur, sharpen de-\ntails, accentuate edges, or remove noise (Figure 3.11b–d). In this section, we look at linear\nﬁltering operators, which involve weighted combinations of pixels in small neighborhoods.\nIn Section 3.3, we look at non-linear operators such as morphological ﬁlters and distance\ntransforms.\nThe most commonly used type of neighborhood operator is a linear ﬁlter, in which an\noutput pixel’s value is determined as a weighted sum of input pixel values (Figure 3.10),\ng(i, j) =\nX\nk,l\nf(i + k, j + l)h(k, l).\n(3.12)\nThe entries in the weight kernel or mask h(k, l) are often called the ﬁlter coefﬁcients. The\nabove correlation operator can be more compactly notated as\ng = f ⊗h.\n(3.13)\nA common variant on this formula is\ng(i, j) =\nX\nk,l\nf(i −k, j −l)h(k, l) =\nX\nk,l\nf(k, l)h(i −k, j −l),\n(3.14)\n112\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n45\n60\n98\n127 132 133 137 133\n46\n65\n98\n123 126 128 131 133\n69\n95\n116 125 129 132\n47\n65\n96\n115 119 123 135 137\n0.1\n0.1\n0.1\n68\n92\n110 120 126 132\n47\n63\n91\n107 113 122 138 134\n*\n0.1\n0.2\n0.1\n=\n66\n86\n104 114 124 132\n50\n59\n80\n97\n110 123 133 134\n0.1\n0.1\n0.1\n62\n78\n94\n108 120 129\n49\n53\n68\n83\n97\n113 128 133\n57\n69\n83\n98\n112 124\n50\n50\n58\n70\n84\n102 116 126\n53\n60\n71\n85\n100 114\n50\n50\n52\n58\n69\n86\n101 120\nf (x,y )\nh (x,y )\ng (x,y )\nFigure 3.10 Neighborhood ﬁltering (convolution): The image on the left is convolved with\nthe ﬁlter in the middle to yield the image on the right. The light blue pixels indicate the source\nneighborhood for the light green destination pixel.\nwhere the sign of the offsets in f has been reversed. This is called the convolution operator,\ng = f ∗h,\n(3.15)\nand h is then called the impulse response function.4 The reason for this name is that the kernel\nfunction, h, convolved with an impulse signal, δ(i, j) (an image that is 0 everywhere except\nat the origin) reproduces itself, h ∗δ = h, whereas correlation produces the reﬂected signal.\n(Try this yourself to verify that it is so.)\nIn fact, Equation (3.14) can be interpreted as the superposition (addition) of shifted im-\npulse response functions h(i−k, j −l) multiplied by the input pixel values f(k, l). Convolu-\ntion has additional nice properties, e.g., it is both commutative and associative. As well, the\nFourier transform of two convolved images is the product of their individual Fourier trans-\nforms (Section 3.4).\nBoth correlation and convolution are linear shift-invariant (LSI) operators, which obey\nboth the superposition principle (3.5),\nh ◦(f0 + f1) = h ◦f0 + h ◦f1,\n(3.16)\nand the shift invariance principle,\ng(i, j) = f(i + k, j + l) ⇔(h ◦g)(i, j) = (h ◦f)(i + k, j + l),\n(3.17)\nwhich means that shifting a signal commutes with applying the operator (◦stands for the LSI\noperator). Another way to think of shift invariance is that the operator “behaves the same\neverywhere”.\n4 The continuous version of convolution can be written as g(x) = R\nf(x −u)h(u)du.\n3.2 Linear ﬁltering\n113\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 3.11 Some neighborhood operations: (a) original image; (b) blurred; (c) sharpened;\n(d) smoothed with edge-preserving ﬁlter; (e) binary image; (f) dilated; (g) distance transform;\n(h) connected components. For the dilation and connected components, black (ink) pixels are\nassumed to be active, i.e., to have a value of 1 in Equations (3.41–3.45).",
  "image_path": "page_134.jpg",
  "pages": [
    133,
    134,
    135
  ]
}