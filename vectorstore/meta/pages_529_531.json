{
  "doc_id": "pages_529_531",
  "text": "10.4 Image matting and compositing\n507\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 10.39 Natural image matting (Chuang, Curless, Salesin et al. 2001) c⃝2001 IEEE:\n(a) input image with a “natural” (non-constant) background; (b) hand-drawn trimap—gray\nindicates unknown regions; (c) extracted alpha map; (d) extracted (premultiplied) foreground\ncolors; (e) composite over a new background.\n10.4.1 Blue screen matting\nBlue screen matting involves ﬁlming an actor (or object) in front of a constant colored back-\nground. While originally bright blue was the preferred color, bright green is now more com-\nmonly used (Wright 2006; Brinkmann 2008). Smith and Blinn (1996) discuss a number of\ntechniques for blue screen matting, which are mostly described in patents rather than in the\nopen research literature. Early techniques used linear combination of object color channels\nwith user-tuned parameters to estimate the opacity α.\nChuang, Curless, Salesin et al. (2001) describe a newer technique called Mishima’s al-\ngorithm, which involves ﬁtting two polyhedral surfaces (centered at the mean background\ncolor), separating the foreground and background color distributions and then measuring the\nrelative distance of a novel color to these surfaces to estimate α (Figure 10.41e). While this\ntechnique works well in many studio settings, it can still suffer from blue spill, where translu-\ncent pixels around the edges of an object acquire some of the background blue coloration\n(Figure 10.40).\nTwo-screen matting.\nIn their paper, Smith and Blinn (1996) also introduce an algorithm\ncalled triangulation matting that uses more than one known background color to over-constrain\nthe equations required to estimate the opacity α and foreground color F.\n508\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.40\nBlue-screen matting results (Chuang, Curless, Salesin et al. 2001) c⃝2001\nIEEE. Mishima’s method produces visible blue spill (color fringing in the hair), while\nChuang’s Bayesian matting approach produces accurate results.\nFor example, consider in the compositing equation (10.30) setting the background color\nto black, i.e., B = 0. The resulting composite image C is therefore equal to αF. Replacing\nthe background color with a different known non-zero value B now results in\nC −αF = (1 −α)B,\n(10.31)\nwhich is an overconstrained set of (color) equations for estimating α. In practice, B should\nbe chosen so as not to saturate C and, for best accuracy, several values of B should be used.\nIt is also important that colors be linearized before processing, which is the case for all image\nmatting algorithms. Papers that generate ground truth alpha mattes for evaluation purposes\nnormally use these techniques to obtain accurate matte estimates (Chuang, Curless, Salesin\net al. 2001; Wang and Cohen 2007b; Levin, Acha, and Lischinski 2008; Rhemann, Rother,\nRav-Acha et al. 2008; Rhemann, Rother, Wang et al. 2009).22 Exercise 10.8 has you do this\nas well.\n22 See the alpha matting evaluation Web site at http://alphamatting.com/.\n10.4 Image matting and compositing\n509\nDifference matting.\nA related approach when the background is irregular but known is\ncalled difference matting (Wright 2006; Brinkmann 2008). It is most commonly used when\nthe actor or object is ﬁlmed against a static background, e.g., for ofﬁce videoconferencing,\nperson tracking applications (Toyama, Krumm, Brumitt et al. 1999), or to produce silhou-\nettes for volumetric 3D reconstruction techniques (Section 11.6.2) (Szeliski 1993; Seitz and\nDyer 1997; Seitz, Curless, Diebel et al. 2006). It can also be used with a panning camera\nwhere the background is composited from frames where the foreground has been removed\nusing a garbage matte (Section 10.4.5) (Chuang, Agarwala, Curless et al. 2002). Another\nrecent application is the detection of visual continuity errors in ﬁlms, i.e., differences in the\nbackground when a shot is re-taken at later time (Pickup and Zisserman 2009).\nIn the case where the foreground and background motions can both be speciﬁed with\nparametric transforms, high-quality mattes can be extracted using a generalization of triangu-\nlation matting (Wexler, Fitzgibbon, and Zisserman 2002). When frames need to be processed\nindependently, however, the results are often of poor quality (Figure 10.42). In such cases,\nusing a pair of stereo cameras as input can dramatically improve the quality of the results\n(Criminisi, Cross, Blake et al. 2006; Yin, Criminisi, Winn et al. 2007).\n10.4.2 Natural image matting\nThe most general version of image matting is when nothing is known about the background\nexcept, perhaps, for a rough segmentation of the scene into foreground, background, and\nunknown regions, which is known as the trimap (Figure 10.39b). Some recent techniques,\nhowever, relax this requirement and allow the user to just draw a few strokes or scribbles in\nthe image, see Figures 10.45 and 10.46 (Wang and Cohen 2005; Wang, Agrawala, and Cohen\n2007; Levin, Lischinski, and Weiss 2008; Rhemann, Rother, Rav-Acha et al. 2008; Rhemann,\nRother, and Gelautz 2008). Fully automated single image matting results have also been\nreported (Levin, Acha, and Lischinski 2008; Singaraju, Rother, and Rhemann 2009). The\nsurvey paper by Wang and Cohen (2007a) has detailed descriptions and comparisons of all of\nthese techniques, a selection of which are described brieﬂy below.\nA relatively simple algorithm for performing natural image matting is Knockout, as de-\nscribed by Chuang, Curless, Salesin et al. (2001) and illustrated in Figure 10.41f. In this\nalgorithm, the nearest known foreground and background pixels (in image space) are deter-\nmined and then blended with neighboring known pixels to produce a per-pixel foreground F\nand background B color estimate. The background color is then adjusted so that the measured\ncolor C lies on the line between F and B. Finally, opacity α is estimated on a per-channel\nbasis, and the three estimates are combined based on per-channel color differences. (This is\nan approximation to the least squares solution for α.) Figure 10.42 shows that Knockout has\nproblems when the background consists of more than one dominant local color.",
  "image_path": "page_530.jpg",
  "pages": [
    529,
    530,
    531
  ]
}