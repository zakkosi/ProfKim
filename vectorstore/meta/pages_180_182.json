{
  "doc_id": "pages_180_182",
  "text": "158\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n-½\n-½\n-½\n-½\n¼\n¼\n¼\n¼\nL0\nH0\nL1\nH1\nL2\n½\n½\n-¼\n-¼\n-¼\n-¼\nL0\nH0\nL1\nH1\nL2\n½\n½\n(a)\n(b)\nFigure 3.39 Lifted transform shown as a signal processing diagram: (a) The analysis stage\nﬁrst predicts the odd value from its even neighbors, stores the difference wavelet, and then\ncompensates the coarser even value by adding in a fraction of the wavelet. (b) The synthesis\nstage simply reverses the ﬂow of computation and the signs of some of the ﬁlters and op-\nerations. The light blue lines show what happens if we use four taps for the prediction and\ncorrection instead of just two.\ndeed a low-pass ﬁlter.) During synthesis, the same operations are reversed with a judicious\nchange in sign.\nOf course, we need not restrict ourselves to two-tap ﬁlters. Figure 3.39 shows as light\nblue arrows additional ﬁlter coefﬁcients that could optionally be added to the lifting scheme\nwithout affecting its reversibility. In fact, the low-pass and high-pass ﬁltering operations can\nbe interchanged, e.g., we could use a ﬁve-tap cubic low-pass ﬁlter on the odd sequence (plus\ncenter value) ﬁrst, followed by a four-tap cubic low-pass predictor to estimate the wavelet,\nalthough I have not seen this scheme written down.\nLifted wavelets are called second-generation wavelets because they can easily adapt to\nnon-regular sampling topologies, e.g., those that arise in computer graphics applications such\nas multi-resolution surface manipulation (Schr¨oder and Sweldens 1995). It also turns out that\nlifted weighted wavelets, i.e., wavelets whose coefﬁcients adapt to the underlying problem\nbeing solved (Fattal 2009), can be extremely effective for low-level image manipulation tasks\nand also for preconditioning the kinds of sparse linear systems that arise in the optimization-\nbased approaches to vision algorithms that we discuss in Section 3.7 (Szeliski 2006b).\nAn alternative to the widely used “separable” approach to wavelet construction, which de-\ncomposes each level into horizontal, vertical, and “cross” sub-bands, is to use a representation\nthat is more rotationally symmetric and orientationally selective and also avoids the aliasing\ninherent in sampling signals below their Nyquist frequency.17 Simoncelli, Freeman, Adelson\net al. (1992) introduce such a representation, which they call a pyramidal radial frequency\n17 Such aliasing can often be seen as the signal content moving between bands as the original signal is slowly\nshifted.\n3.5 Pyramids and wavelets\n159\n(a)\n(b)\n(c)\n(d)\nFigure 3.40 Steerable shiftable multiscale transforms (Simoncelli, Freeman, Adelson et al.\n1992) c⃝1992 IEEE: (a) radial multi-scale frequency domain decomposition; (b) original\nimage; (c) a set of four steerable ﬁlters; (d) the radial multi-scale wavelet decomposition.\nimplementation of shiftable multi-scale transforms or, more succinctly, steerable pyramids.\nTheir representation is not only overcomplete (which eliminates the aliasing problem) but is\nalso orientationally selective and has identical analysis and synthesis basis functions, i.e., it is\nself-inverting, just like “regular” wavelets. As a result, this makes steerable pyramids a much\nmore useful basis for the structural analysis and matching tasks commonly used in computer\nvision.\nFigure 3.40a shows how such a decomposition looks in frequency space. Instead of re-\ncursively dividing the frequency domain into 2 × 2 squares, which results in checkerboard\nhigh frequencies, radial arcs are used instead. Figure 3.40b illustrates the resulting pyramid\nsub-bands. Even through the representation is overcomplete, i.e., there are more wavelet co-\nefﬁcients than input pixels, the additional frequency and orientation selectivity makes this\nrepresentation preferable for tasks such as texture analysis and synthesis (Portilla and Simon-\ncelli 2000) and image denoising (Portilla, Strela, Wainwright et al. 2003; Lyu and Simoncelli\n2009).\n160\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 3.41 Laplacian pyramid blending (Burt and Adelson 1983b) c⃝1983 ACM: (a) orig-\ninal image of apple, (b) original image of orange, (c) regular splice, (d) pyramid blend.\n3.5.5 Application: Image blending\nOne of the most engaging and fun applications of the Laplacian pyramid presented in Sec-\ntion 3.5.3 is the creation of blended composite images, as shown in Figure 3.41 (Burt and\nAdelson 1983b). While splicing the apple and orange images together along the midline\nproduces a noticeable cut, splining them together (as Burt and Adelson (1983b) called their\nprocedure) creates a beautiful illusion of a truly hybrid fruit. The key to their approach is\nthat the low-frequency color variations between the red apple and the orange are smoothly\nblended, while the higher-frequency textures on each fruit are blended more quickly to avoid\n“ghosting” effects when two textures are overlaid.\nTo create the blended image, each source image is ﬁrst decomposed into its own Lapla-\ncian pyramid (Figure 3.42, left and middle columns). Each band is then multiplied by a\nsmooth weighting function whose extent is proportional to the pyramid level. The simplest\nand most general way to create these weights is to take a binary mask image (Figure 3.43c)\nand to construct a Gaussian pyramid from this mask. Each Laplacian pyramid image is then",
  "image_path": "page_181.jpg",
  "pages": [
    180,
    181,
    182
  ]
}