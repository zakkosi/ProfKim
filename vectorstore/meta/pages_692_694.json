{
  "doc_id": "pages_692_694",
  "text": "670\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 14.12 Humans can recognize low-resolution faces of familiar people (Sinha, Balas,\nOstrovsky et al. 2006) c⃝2006 IEEE.\namong a small number of family members and friends has found its way into consumer-level\nphoto applications, such as Picasa and iPhoto. Face recognition can also be used in a variety\nof additional applications, including human–computer interaction (HCI), identity veriﬁcation\n(Kirovski, Jojic, and Jancke 2004), desktop login, parental controls, and patient monitoring\n(Zhao, Chellappa, Phillips et al. 2003).\nToday’s face recognizers work best when they are given full frontal images of faces under\nrelatively uniform illumination conditions, although databases that include large amounts\nof pose and lighting variation have been collected (Phillips, Moon, Rizvi et al. 2000; Sim,\nBaker, and Bsat 2003; Gross, Shi, and Cohn 2005; Huang, Ramesh, Berg et al. 2007; Phillips,\nScruggs, O’Toole et al. 2010). (See Table 14.1 in Section 14.6 for more details.)\nSome of the earliest approaches to face recognition involved ﬁnding the locations of\ndistinctive image features, such as the eyes, nose, and mouth, and measuring the distances\nbetween these feature locations (Fischler and Elschlager 1973; Kanade 1977; Yuille 1991).\nMore recent approaches rely on comparing gray-level images projected onto lower dimen-\nsional subspaces called eigenfaces (Section 14.2.1) and jointly modeling shape and appear-\nance variations (while discounting pose variations) using active appearance models (Sec-\ntion 14.2.2).\nDescriptions of additional face recognition techniques can be found in a number of sur-\nveys and books on this topic (Chellappa, Wilson, and Sirohey 1995; Zhao, Chellappa, Phillips\net al. 2003; Li and Jain 2005) as well as the Face Recognition Web site.6 The survey on face\nrecognition by humans by Sinha, Balas, Ostrovsky et al. (2006) is also well worth reading; it\nincludes a number of surprising results, such as humans’ ability to recognize low-resolution\nimages of familiar faces (Figure 14.12) and the importance of eyebrows in recognition.\n6 http://www.face-rec.org/.\n14.2 Face recognition\n671\n(a)\n(b)\n(c)\n(d)\nFigure 14.13 Face modeling and compression using eigenfaces (Moghaddam and Pentland\n1997) c⃝1997 IEEE: (a) input image; (b) the ﬁrst eight eigenfaces; (c) image reconstructed\nby projecting onto this basis and compressing the image to 85 bytes; (d) image reconstructed\nusing JPEG (530 bytes).\n14.2.1 Eigenfaces\nEigenfaces rely on the observation ﬁrst made by Kirby and Sirovich (1990) that an arbitrary\nface image x can be compressed and reconstructed by starting with a mean image m (Fig-\nure 14.1b) and adding a small number of scaled signed images ui,7\n˜x = m +\nM−1\nX\ni=0\naiui,\n(14.8)\nwhere the signed basis images (Figure 14.13b) can be derived from an ensemble of train-\ning images using principal component analysis (also known as eigenvalue analysis or the\nKarhunen–Lo`eve transform). Turk and Pentland (1991a) recognized that the coefﬁcients ai\nin the eigenface expansion could themselves be used to construct a fast image matching algo-\nrithm.\nIn more detail, let us start with a collection of training images {xj}, from which we can\ncompute the mean image m and a scatter or covariance matrix\nC = 1\nN\nN−1\nX\nj=0\n(xj −m)(xj −m)T .\n(14.9)\nWe can apply the eigenvalue decomposition (A.6) to represent this matrix as\nC = UΛU T =\nN−1\nX\ni=0\nλiuiuT\ni ,\n(14.10)\nwhere the λi are the eigenvalues of C and the ui are the eigenvectors. For general im-\nages, Kirby and Sirovich (1990) call these vectors eigenpictures; for faces, Turk and Pentland\n7 In previous chapters, we used I to indicate images; in this chapter, we use the more abstract quantities x and u\nto indicate collections of pixels in an image turned into a vector.\n672\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nx\nDFFS\nDIFS\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nF\nF\n_\nm\n~x\nFigure 14.14 Projection onto the linear subspace spanned by the eigenface images (Moghad-\ndam and Pentland 1997) c⃝1997 IEEE. The distance from face space (DFFS) is the orthog-\nonal distance to the plane, while the distance in face space (DIFS) is the distance along the\nplane from the mean image. Both distances can be turned into Mahalanobis distances and\ngiven probabilistic interpretations.\n(1991a) call them eigenfaces (Figure 14.13b).8\nTwo important properties of the eigenvalue decomposition are that the optimal (best ap-\nproximation) coefﬁcients ai for any new image x can be computed as\nai = (x −m) · ui,\n(14.11)\nand that, assuming the eigenvalues {λi} are sorted in decreasing order, truncating the ap-\nproximation given in (14.8) at any point M gives the best possible approximation (least er-\nror) between ˜x and x. Figure 14.13c shows the resulting approximation corresponding to\nFigure 14.13a and shows how much better it is at compressing a face image than JPEG.\nTruncating the eigenface decomposition of a face image (14.8) after M components is\nequivalent to projecting the image onto a linear subspace F, which we can call the face space\n(Figure 14.14). Because the eigenvectors (eigenfaces) are orthogonal and of unit norm, the\ndistance of a projected face ˜x to the mean face m can be written as\nDIFS = ∥˜x −m∥=\nv\nu\nu\nt\nM−1\nX\ni=0\na2\ni ,\n(14.12)\nwhere DIFS stands for distance in face space (Moghaddam and Pentland 1997). The re-\nmaining distance between the original image x and its projection onto face space ˜x, i.e., the\n8 In actual practice, the full P ×P scatter matrix (14.9) is never computed. Instead, a smaller N ×N matrix con-\nsisting of the inner products between all the signed deviations (xi−m) is accumulated instead. See Appendix A.1.2\n(A.13–A.14) for details.",
  "image_path": "page_693.jpg",
  "pages": [
    692,
    693,
    694
  ]
}