{
  "doc_id": "pages_534_536",
  "text": "512\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nThis is equivalent to minimizing the negative log likelihood\nL(F, B, α|C) = L(C|F, B, α) + L(F) + L(B) + L(α)\n(10.33)\n(dropping the L(C) term since it is constant).\nLet us examine each of these terms in turn. The ﬁrst, L(C|F, B, α), is the likelihood that\npixel color C was observed given values for the unknowns (F, B, α). If we assume Gaussian\nnoise in our observation with variance σ2\nC, this negative log likelihood (data term) is\nL(C) = 1/2∥C −[αF + (1 −α)B]∥2/σ2\nC,\n(10.34)\nas illustrated in Figure 10.41h.\nThe second term, L(F), corresponds to the likelihood that a particular foreground color F\ncomes from the mixture of Gaussians distribution. After partitioning the sample foreground\ncolors into clusters, a weighted mean and covariance is computed, where the weights are\nproportional to a given foreground pixel’s opacity and distance from the unknown pixel. The\nnegative log likelihood for each cluster is thus given by\nL(F) = (F −F)T Σ−1\nF (F −F).\n(10.35)\nA similar method is used to estimate unknown background color distributions. If the back-\nground is already known, i.e., for blue screen or difference matting applications, its measured\ncolor value and variance are used instead.\nAn alternative to modeling the foreground and background color distributions as mixtures\nof Gaussians is to keep around the original color samples and to compute the most likely\npairings that explain the observed color C (Wang and Cohen 2005, 2007b). These techniques\nare described in more detail in (Wang and Cohen 2007a).\nIn their Bayesian matting paper, Chuang, Curless, Salesin et al. (2001) assume a constant\n(non-informative) distribution for L(α). More recent papers assume this distribution to be\nmore peaked around 0 and 1, or sometimes use Markov random ﬁelds (MRFs) to deﬁne a\nglobal correlated prior on P(α) (Wang and Cohen 2007a).\nTo compute the most likely estimates for (F, B, α), the Bayesian matting algorithm alter-\nnates between computing (F, B) and α, since each of these problems is quadratic and hence\ncan be solved as a small linear system. When several color clusters are estimated, the most\nlikely pairing of foreground and background color clusters is used.\nBayesian image matting produces results that improve on the original natural image mat-\nting algorithm by Ruzon and Tomasi (2000), as can be seen in Figure 10.42. However, com-\npared to more recent techniques (Wang and Cohen 2007a), its performance is not as good for\ncomplex background or inaccurate trimaps (Figure 10.44).\n10.4 Image matting and compositing\n513\n10.4.3 Optimization-based matting\nAn alternative to estimating each pixel’s opacity and foreground color independently is to use\nglobal optimization to compute a matte that takes into account correlations between neigh-\nboring α values. Two examples of this are border matting in the GrabCut interactive segmen-\ntation system (Rother, Kolmogorov, and Blake 2004) and Poisson Matting (Sun, Jia, Tang et\nal. 2004).\nBorder matting ﬁrst dilates the region around the binary segmentation produced by Grab-\nCut (Section 5.5) and then solves for a sub-pixel boundary location ∆and a blur width σ for\nevery point along the boundary (Figure 10.38). Smoothness in these parameters along the\nboundary is enforced using regularization and the optimization is performed using dynamic\nprogramming. While this technique can obtain good results for smooth boundaries, such as a\nperson’s face, it has difﬁculty with ﬁne details, such as hair.\nPoisson matting (Sun, Jia, Tang et al. 2004) assumes a known foreground and background\ncolor for each pixel in the trimap (as with Bayesian matting). However, instead of indepen-\ndently estimating each α value, it assumes that the gradient of the alpha matte and the gradient\nof the color image are related by\n∇α =\nF −B\n∥F −B∥2 · ∇C,\n(10.36)\nwhich can be derived by taking gradients of both sides of (10.30) and assuming that the\nforeground and background vary slowly. The per-pixel gradient estimates are then integrated\ninto a continuous α(x) ﬁeld using the regularization (least squares) technique ﬁrst described\nin Section 3.7.1 (3.100) and subsequently used in Poisson blending (Section 9.3.4, 9.44) and\ngradient-based dynamic range compression mapping (Section 10.2.1, 10.19). This technique\nworks well when good foreground and background color estimates are available and these\ncolors vary slowly.\nInstead of computing per-pixel foreground and background colors, Levin, Lischinski, and\nWeiss (2008) assume only that these color distribution can locally be well approximated as\nmixtures of two colors, which is known as the color line model (Figure 10.43a–c). Under this\nassumption, a closed-form estimate for α at each pixel i in a (say, 3 × 3) window Wk is given\nby\nαi = ak · (Ci −B0) = ak · C + bk,\n(10.37)\nwhere Ci is the pixel color treated as a three-vector, B0 is any pixel along the background\ncolor line, and ak is the vector joining the two closest points on the foreground and back-\nground color lines, as shown in Figure 10.43c. (Note that the geometric derivation shown\nin this ﬁgure is an alternative to the algebraic derivation presented by Levin, Lischinski, and\nWeiss (2008).) Minimizing the deviations of the alpha values αi from their respective color\n514\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nak\nα=0\nα=0.5\nα=1\nB0\nCi\n(d)\nCi\nμk\nΣk\nCj\nFigure 10.43 Color line matting (Levin, Lischinski, and Weiss 2008): (a) local 3 × 3 patch\nof colors; (b) potential assignment of α values; (c) foreground and background color lines,\nthe vector ak joining their closest points of intersection, and the family of parallel planes of\nconstant α values, αi = ak ·(Ci −B0); (d) a scatter plot of sample colors and the deviations\nfrom the mean µk for two sample colors Ci and Cj.\nline models (10.37) over all overlapping windows Wk in the image gives rise to the cost\nEα =\nX\nk\n X\ni∈Wk\n(αi −ak · Ci −bk)2 + ϵ∥ak∥\n!\n,\n(10.38)\nwhere the ϵ term is used to regularize the value of ak in the case where the two color distri-\nbutions overlap (i.e., in constant α regions).\nBecause this formula is quadratic in the unknowns {(ak, bk)}, they can be eliminated\ninside each window Wk, leading to a ﬁnal energy\nEα = αT Lα,\n(10.39)\nwhere the entries in the L matrix are given by\nLij =\nX\nk:i∈Wk∧j∈Wk\n\u0012\nδij −1\nM\n\u0010\n1 + (Ci −µk)T ˆΣ\n−1\nk (Cj −µk)\n\u0011\u0013\n,\n(10.40)\nwhere M = |Wk| is the number of pixels in each (overlapping) window, µk is the mean color\nof the pixels in window Wk, and ˆΣk is the 3 × 3 covariance of the pixel colors plus ϵ/MI.\nFigure 10.43d shows the intuition behind the entries in this afﬁnity matrix, which is called\nthe matting Laplacian. Note how when two pixels Ci and Cj in Wk point in opposite direc-\ntions away from the mean µk, their weighted dot product is close to −1, and so their afﬁnity\nbecomes close to 0. Pixels close to each other in color space (and hence with similar expected\nα values) will have afﬁnities close to −2/M.\nMinimizing the quadratic energy (10.39) constrained by the known values of α = {0, 1}\nat scribbles only requires the solution of a sparse set of linear equations, which is why the",
  "image_path": "page_535.jpg",
  "pages": [
    534,
    535,
    536
  ]
}