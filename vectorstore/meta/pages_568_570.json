{
  "doc_id": "pages_568_570",
  "text": "546\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFor example, local (window-based) algorithms (Section 11.4), where the disparity com-\nputation at a given point depends only on intensity values within a ﬁnite window, usually\nmake implicit smoothness assumptions by aggregating support. Some of these algorithms\ncan cleanly be broken down into steps 1, 2, 3. For example, the traditional sum-of-squared-\ndifferences (SSD) algorithm can be described as:\n1. The matching cost is the squared difference of intensity values at a given disparity.\n2. Aggregation is done by summing the matching cost over square windows with constant\ndisparity.\n3. Disparities are computed by selecting the minimal (winning) aggregated value at each\npixel.\nSome local algorithms, however, combine steps 1 and 2 and use a matching cost that is based\non a support region, e.g. normalized cross-correlation (Hannah 1974; Bolles, Baker, and Han-\nnah 1993) and the rank transform (Zabih and Woodﬁll 1994) and other ordinal measures (Bhat\nand Nayar 1998). (This can also be viewed as a preprocessing step; see (Section 11.3.1).)\nGlobal algorithms, on the other hand, make explicit smoothness assumptions and then\nsolve a a global optimization problem (Section 11.5). Such algorithms typically do not per-\nform an aggregation step, but rather seek a disparity assignment (step 3) that minimizes a\nglobal cost function that consists of data (step 1) terms and smoothness terms. The main dis-\ntinctions among these algorithms is the minimization procedure used, e.g., simulated anneal-\ning (Marroquin, Mitter, and Poggio 1987; Barnard 1989), probabilistic (mean-ﬁeld) diffusion\n(Scharstein and Szeliski 1998), expectation maximization (EM) (Birchﬁeld, Natarajan, and\nTomasi 2007), graph cuts (Boykov, Veksler, and Zabih 2001), or loopy belief propagation\n(Sun, Zheng, and Shum 2003), to name just a few.\nIn between these two broad classes are certain iterative algorithms that do not explicitly\nspecify a global function to be minimized, but whose behavior mimics closely that of iterative\noptimization algorithms (Marr and Poggio 1976; Zitnick and Kanade 2000). Hierarchical\n(coarse-to-ﬁne) algorithms resemble such iterative algorithms, but typically operate on an\nimage pyramid where results from coarser levels are used to constrain a more local search at\nﬁner levels (Witkin, Terzopoulos, and Kass 1987; Quam 1984; Bergen, Anandan, Hanna et\nal. 1992).\n11.3.1 Similarity measures\nThe ﬁrst component of any dense stereo matching algorithm is a similarity measure that\ncompares pixel values in order to determine how likely they are to be in correspondence. In\nthis section, we brieﬂy review the similarity measures introduced in Section 8.1 and mention a\n11.3 Dense correspondence\n547\nfew others that have been developed speciﬁcally for stereo matching (Scharstein and Szeliski\n2002; Hirschm¨uller and Scharstein 2009).\nThe most common pixel-based matching costs include sums of squared intensity differ-\nences (SSD) (Hannah 1974) and absolute intensity differences (SAD) (Kanade 1994). In\nthe video processing community, these matching criteria are referred to as the mean-squared\nerror (MSE) and mean absolute difference (MAD) measures; the term displaced frame dif-\nference is also often used (Tekalp 1995).\nMore recently, robust measures (8.2), including truncated quadratics and contaminated\nGaussians, have been proposed (Black and Anandan 1996; Black and Rangarajan 1996;\nScharstein and Szeliski 1998). These measures are useful because they limit the inﬂuence\nof mismatches during aggregation. Vaish, Szeliski, Zitnick et al. (2006) compare a number\nof such robust measures, including a new one based on the entropy of the pixel values at a\nparticular disparity hypothesis (Zitnick, Kang, Uyttendaele et al. 2004), which is particularly\nuseful in multi-view stereo.\nOther traditional matching costs include normalized cross-correlation (8.11) (Hannah\n1974; Bolles, Baker, and Hannah 1993; Evangelidis and Psarakis 2008), which behaves\nsimilarly to sum-of-squared-differences (SSD), and binary matching costs (i.e., match or no\nmatch) (Marr and Poggio 1976), based on binary features such as edges (Baker and Binford\n1981; Grimson 1985) or the sign of the Laplacian (Nishihara 1984). Because of their poor\ndiscriminability, simple binary matching costs are no longer used in dense stereo matching.\nSome costs are insensitive to differences in camera gain or bias, for example gradient-\nbased measures (Seitz 1989; Scharstein 1994), phase and ﬁlter-bank responses (Marr and\nPoggio 1979; Kass 1988; Jenkin, Jepson, and Tsotsos 1991; Jones and Malik 1992), ﬁlters\nthat remove regular or robust (bilaterally ﬁltered) means (Ansar, Castano, and Matthies 2004;\nHirschm¨uller and Scharstein 2009), dense feature descriptor (Tola, Lepetit, and Fua 2010),\nand non-parametric measures such as rank and census transforms (Zabih and Woodﬁll 1994),\nordinal measures (Bhat and Nayar 1998), or entropy (Zitnick, Kang, Uyttendaele et al. 2004;\nZitnick and Kang 2007). The census transform, which converts each pixel inside a moving\nwindow into a bit vector representing which neighbors are above or below the central pixel,\nwas found by Hirschm¨uller and Scharstein (2009) to be quite robust against large-scale, non-\nstationary exposure and illumination changes.\nIt is also possible to correct for differing global camera characteristics by performing\na preprocessing or iterative reﬁnement step that estimates inter-image bias–gain variations\nusing global regression (Gennert 1988), histogram equalization (Cox, Roy, and Hingorani\n1995), or mutual information (Kim, Kolmogorov, and Zabih 2003; Hirschm¨uller 2008). Lo-\ncal, smoothly varying compensation ﬁelds have also been proposed (Strecha, Tuytelaars, and\nVan Gool 2003; Zhang, McMillan, and Yu 2006).\nIn order to compensate for sampling issues, i.e., dramatically different pixel values in\n548\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nhigh-frequency areas, Birchﬁeld and Tomasi (1998) proposed a matching cost that is less sen-\nsitive to shifts in image sampling. Rather than just comparing pixel values shifted by integral\namounts (which may miss a valid match), they compare each pixel in the reference image\nagainst a linearly interpolated function of the other image. More detailed studies of these\nand additional matching costs are explored in (Szeliski and Scharstein 2004; Hirschm¨uller\nand Scharstein 2009). In particular, if you expect there to be signiﬁcant exposure or appear-\nance variation between images that you are matching, some of the more robust measures\nthat performed well in the evaluation by Hirschm¨uller and Scharstein (2009), such as the\ncensus transform (Zabih and Woodﬁll 1994), ordinal measures (Bhat and Nayar 1998), bi-\nlateral subtraction (Ansar, Castano, and Matthies 2004), or hierarchical mutual information\n(Hirschm¨uller 2008), should be used.\n11.4 Local methods\nLocal and window-based methods aggregate the matching cost by summing or averaging\nover a support region in the DSI C(x, y, d).4 A support region can be either two-dimensional\nat a ﬁxed disparity (favoring fronto-parallel surfaces), or three-dimensional in x-y-d space\n(supporting slanted surfaces). Two-dimensional evidence aggregation has been implemented\nusing square windows or Gaussian convolution (traditional), multiple windows anchored at\ndifferent points, i.e., shiftable windows (Arnold 1983; Fusiello, Roberto, and Trucco 1997;\nBobick and Intille 1999), windows with adaptive sizes (Okutomi and Kanade 1992; Kanade\nand Okutomi 1994; Kang, Szeliski, and Chai 2001; Veksler 2001, 2003), windows based on\nconnected components of constant disparity (Boykov, Veksler, and Zabih 1998), or the re-\nsults of color-based segmentation (Yoon and Kweon 2006; Tombari, Mattoccia, Di Stefano\net al. 2008). Three-dimensional support functions that have been proposed include limited\ndisparity difference (Grimson 1985), limited disparity gradient (Pollard, Mayhew, and Frisby\n1985), Prazdny’s coherence principle (Prazdny 1985), and the more recent work (which in-\ncludes visibility and occlusion reasoning) by Zitnick and Kanade (2000).\nAggregation with a ﬁxed support region can be performed using 2D or 3D convolution,\nC(x, y, d) = w(x, y, d) ∗C0(x, y, d),\n(11.6)\nor, in the case of rectangular windows, using efﬁcient moving average box-ﬁlters (Sec-\ntion 3.2.2) (Kanade, Yoshida, Oda et al. 1996; Kimura, Shinbo, Yamaguchi et al. 1999).\nShiftable windows can also be implemented efﬁciently using a separable sliding min-ﬁlter\n(Figure 11.8) (Scharstein and Szeliski 2002, Section 4.2). Selecting among windows of dif-\nferent shapes and sizes can be performed more efﬁciently by ﬁrst computing a summed area\n4 For two recent surveys and comparisons of such techniques, please see the work of Gong, Yang, Wang et al.\n(2007) and Tombari, Mattoccia, Di Stefano et al. (2008).",
  "image_path": "page_569.jpg",
  "pages": [
    568,
    569,
    570
  ]
}