{
  "doc_id": "pages_106_108",
  "text": "84\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nBecause the response of the human visual system is roughly logarithmic (we can perceive\nrelative luminance differences of about 1%), the CIE deﬁned a non-linear re-mapping of the\nXYZ space called L*a*b* (also sometimes called CIELAB), where differences in luminance\nor chrominance are more perceptually uniform.19\nThe L* component of lightness is deﬁned as\nL∗= 116f\n\u0012 Y\nYn\n\u0013\n,\n(2.105)\nwhere Yn is the luminance value for nominal white (Fairchild 2005) and\nf(t) =\n(\nt1/3\nt > δ3\nt/(3δ2) + 2δ/3\nelse,\n(2.106)\nis a ﬁnite-slope approximation to the cube root with δ = 6/29. The resulting 0 . . . 100 scale\nroughly measures equal amounts of lightness perceptibility.\nIn a similar fashion, the a* and b* components are deﬁned as\na∗= 500\n\u0014\nf\n\u0012 X\nXn\n\u0013\n−f\n\u0012 Y\nYn\n\u0013\u0015\nand b∗= 200\n\u0014\nf\n\u0012 Y\nYn\n\u0013\n−f\n\u0012 Z\nZn\n\u0013\u0015\n,\n(2.107)\nwhere again, (Xn, Yn, Zn) is the measured white point. Figure 2.32i–k show the L*a*b*\nrepresentation for a sample color image.\nColor cameras\nWhile the preceding discussion tells us how we can uniquely describe the perceived tri-\nstimulus description of any color (spectral distribution), it does not tell us how RGB still\nand video cameras actually work. Do they just measure the amount of light at the nominal\nwavelengths of red (700.0nm), green (546.1nm), and blue (435.8nm)? Do color monitors just\nemit exactly these wavelengths and, if so, how can they emit negative red light to reproduce\ncolors in the cyan range?\nIn fact, the design of RGB video cameras has historically been based around the availabil-\nity of colored phosphors that go into television sets. When standard-deﬁnition color television\nwas invented (NTSC), a mapping was deﬁned between the RGB values that would drive the\nthree color guns in the cathode ray tube (CRT) and the XYZ values that unambiguously de-\nﬁne perceived color (this standard was called ITU-R BT.601). With the advent of HDTV and\nnewer monitors, a new standard called ITU-R BT.709 was created, which speciﬁes the XYZ\n19 Another perceptually motivated color space called L*u*v* was developed and standardized simultaneously\n(Fairchild 2005).\n2.3 The digital camera\n85\nvalues of each of the color primaries,\n\n\nX\nY\nZ\n\n=\n\n\n0.412453\n0.357580\n0.180423\n0.212671\n0.715160\n0.072169\n0.019334\n0.119193\n0.950227\n\n\n\n\nR709\nG709\nB709\n\n.\n(2.108)\nIn practice, each color camera integrates light according to the spectral response function\nof its red, green, and blue sensors,\nR\n=\nZ\nL(λ)SR(λ)dλ,\nG\n=\nZ\nL(λ)SG(λ)dλ,\n(2.109)\nB\n=\nZ\nL(λ)SB(λ)dλ,\nwhere L(λ) is the incoming spectrum of light at a given pixel and {SR(λ), SG(λ), SB(λ)}\nare the red, green, and blue spectral sensitivities of the corresponding sensors.\nCan we tell what spectral sensitivities the cameras actually have? Unless the camera\nmanufacturer provides us with this data or we observe the response of the camera to a whole\nspectrum of monochromatic lights, these sensitivities are not speciﬁed by a standard such as\nBT.709. Instead, all that matters is that the tri-stimulus values for a given color produce the\nspeciﬁed RGB values. The manufacturer is free to use sensors with sensitivities that do not\nmatch the standard XYZ deﬁnitions, so long as they can later be converted (through a linear\ntransform) to the standard colors.\nSimilarly, while TV and computer monitors are supposed to produce RGB values as spec-\niﬁed by Equation (2.108), there is no reason that they cannot use digital logic to transform the\nincoming RGB values into different signals to drive each of the color channels. Properly cal-\nibrated monitors make this information available to software applications that perform color\nmanagement, so that colors in real life, on the screen, and on the printer all match as closely\nas possible.\nColor ﬁlter arrays\nWhile early color TV cameras used three vidicons (tubes) to perform their sensing and later\ncameras used three separate RGB sensing chips, most of today’s digital still and video cam-\neras cameras use a color ﬁlter array (CFA), where alternating sensors are covered by different\ncolored ﬁlters.20\n20 A newer chip design by Foveon (http://www.foveon.com) stacks the red, green, and blue sensors beneath each\nother, but it has not yet gained widespread adoption.\n86\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nrgB\nrGb\nrgB\nrGb\nrGb\nRgb\nrGb\nRgb\nrgB\nrGb\nrgB\nrGb\nrGb\nRgb\nrGb\nRgb\nB\nG\nB\nG\nG\nR\nG\nR\nG\nB\nG\nR\nG\nR\nB\nG\nFigure 2.30 Bayer RGB pattern: (a) color ﬁlter array layout; (b) interpolated pixel values,\nwith unknown (guessed) values shown as lower case.\nThe most commonly used pattern in color cameras today is the Bayer pattern (Bayer\n1976), which places green ﬁlters over half of the sensors (in a checkerboard pattern), and red\nand blue ﬁlters over the remaining ones (Figure 2.30). The reason that there are twice as many\ngreen ﬁlters as red and blue is because the luminance signal is mostly determined by green\nvalues and the visual system is much more sensitive to high frequency detail in luminance\nthan in chrominance (a fact that is exploited in color image compression—see Section 2.3.3).\nThe process of interpolating the missing color values so that we have valid RGB values for\nall the pixels is known as demosaicing and is covered in detail in Section 10.3.1.\nSimilarly, color LCD monitors typically use alternating stripes of red, green, and blue\nﬁlters placed in front of each liquid crystal active area to simulate the experience of a full color\ndisplay. As before, because the visual system has higher resolution (acuity) in luminance than\nchrominance, it is possible to digitally pre-ﬁlter RGB (and monochrome) images to enhance\nthe perception of crispness (Betrisey, Blinn, Dresevic et al. 2000; Platt 2000).\nColor balance\nBefore encoding the sensed RGB values, most cameras perform some kind of color balancing\noperation in an attempt to move the white point of a given image closer to pure white (equal\nRGB values). If the color system and the illumination are the same (the BT.709 system uses\nthe daylight illuminant D65 as its reference white), the change may be minimal. However,\nif the illuminant is strongly colored, such as incandescent indoor lighting (which generally\nresults in a yellow or orange hue), the compensation can be quite signiﬁcant.\nA simple way to perform color correction is to multiply each of the RGB values by a\ndifferent factor (i.e., to apply a diagonal matrix transform to the RGB color space). More\ncomplicated transforms, which are sometimes the result of mapping to XYZ space and back,",
  "image_path": "page_107.jpg",
  "pages": [
    106,
    107,
    108
  ]
}