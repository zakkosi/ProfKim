{
  "doc_id": "pages_536_538",
  "text": "514\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nak\nα=0\nα=0.5\nα=1\nB0\nCi\n(d)\nCi\nμk\nΣk\nCj\nFigure 10.43 Color line matting (Levin, Lischinski, and Weiss 2008): (a) local 3 × 3 patch\nof colors; (b) potential assignment of α values; (c) foreground and background color lines,\nthe vector ak joining their closest points of intersection, and the family of parallel planes of\nconstant α values, αi = ak ·(Ci −B0); (d) a scatter plot of sample colors and the deviations\nfrom the mean µk for two sample colors Ci and Cj.\nline models (10.37) over all overlapping windows Wk in the image gives rise to the cost\nEα =\nX\nk\n X\ni∈Wk\n(αi −ak · Ci −bk)2 + ϵ∥ak∥\n!\n,\n(10.38)\nwhere the ϵ term is used to regularize the value of ak in the case where the two color distri-\nbutions overlap (i.e., in constant α regions).\nBecause this formula is quadratic in the unknowns {(ak, bk)}, they can be eliminated\ninside each window Wk, leading to a ﬁnal energy\nEα = αT Lα,\n(10.39)\nwhere the entries in the L matrix are given by\nLij =\nX\nk:i∈Wk∧j∈Wk\n\u0012\nδij −1\nM\n\u0010\n1 + (Ci −µk)T ˆΣ\n−1\nk (Cj −µk)\n\u0011\u0013\n,\n(10.40)\nwhere M = |Wk| is the number of pixels in each (overlapping) window, µk is the mean color\nof the pixels in window Wk, and ˆΣk is the 3 × 3 covariance of the pixel colors plus ϵ/MI.\nFigure 10.43d shows the intuition behind the entries in this afﬁnity matrix, which is called\nthe matting Laplacian. Note how when two pixels Ci and Cj in Wk point in opposite direc-\ntions away from the mean µk, their weighted dot product is close to −1, and so their afﬁnity\nbecomes close to 0. Pixels close to each other in color space (and hence with similar expected\nα values) will have afﬁnities close to −2/M.\nMinimizing the quadratic energy (10.39) constrained by the known values of α = {0, 1}\nat scribbles only requires the solution of a sparse set of linear equations, which is why the\n10.4 Image matting and compositing\n515\nFigure 10.44 Comparative matting results for a medium accuracy trimap. Wang and Cohen\n(2007a) describe the individual techniques being compared.\nauthors call their technique a closed-form solution to natural image matting. Once α has\nbeen computed, the foreground and background colors are estimated using a least squares\nminimization of the compositing equation (10.30) regularized with a spatially varying ﬁrst-\norder smoothness,\nEB,F =\nX\ni\n∥Ci −[α + Fi + (1 −αi)Bi]∥2 + λ|∇αi|(∥∇Fi∥2 + ∥∇Bi∥2),\n(10.41)\nwhere the |∇αi| weight is applied separately for the x and y components of the F and B\nderivatives (Levin, Lischinski, and Weiss 2008).\nLaplacian (closed-form) matting is just one of many optimization-based techniques sur-\nveyed and compared by Wang and Cohen (2007a). Some of these techniques use alternative\nformulations for the afﬁnities or smoothness terms on the α matte, alternative estimation\ntechniques such as belief propagation, or alternative representations (e.g., local histograms)\nfor modeling local foreground and background color distributions (Wang and Cohen 2005,\n2007b,c). Some of these techniques also provide real-time results as the user draws a contour\nline or sparse set of scribbles (Wang, Agrawala, and Cohen 2007; Rhemann, Rother, Rav-\nAcha et al. 2008) or even pre-segment the image into a small number of mattes that the user\ncan select with simple clicks (Levin, Acha, and Lischinski 2008).\nFigure 10.44 shows the results of running a number of the surveyed algorithms on a region\nof toy animal fur where a trimap has been speciﬁed, while Figure 10.45 shows results for\ntechniques that can produce mattes with only a few scribbles as input. Figure 10.46 shows\na result for an even more recent algorithm (Rhemann, Rother, Rav-Acha et al. 2008) that\nclaims to outperform all of the techniques surveyed by Wang and Cohen (2007a).\nPasting.\nOnce a matte has been pulled from an image, it is usually composited directly\nover the new background, unless the seams between the cutout and background regions are\n516\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.45\nComparative matting results with scribble-based inputs. Wang and Cohen\n(2007a) describe the individual techniques being compared.\nFigure 10.46\nStroke-based segmentation result (Rhemann, Rother, Rav-Acha et al. 2008)\nc⃝2008 IEEE.\nto be hidden, in which case Poisson blending (P´erez, Gangnet, and Blake 2003) can be used\n(Section 9.3.4).\nIn the latter case, it is helpful if the matte boundary passes through regions that either\nhave little texture or look similar in the old and new images. Papers by Jia, Sun, Tang et al.\n(2006) and Wang and Cohen (2007c) explain how to do this.\n10.4.4 Smoke, shadow, and ﬂash matting\nIn addition to matting out solid objects with fractional boundaries, it is also possible to matte\nout translucent media such as smoke (Chuang, Agarwala, Curless et al. 2002). Starting with\na video sequence, each pixel is modeled as a linear combination of its (unknown) background\ncolor and a constant foreground (smoke) color that is common to all pixels. Voting in color",
  "image_path": "page_537.jpg",
  "pages": [
    536,
    537,
    538
  ]
}