{
  "doc_id": "pages_045_047",
  "text": "1.3 Book overview\n23\nnext chapter and dip into this material later. In Chapter 2, we break down image formation\ninto three major components. Geometric image formation (Section 2.1) deals with points,\nlines, and planes, and how these are mapped onto images using projective geometry and other\nmodels (including radial lens distortion). Photometric image formation (Section 2.2) covers\nradiometry, which describes how light interacts with surfaces in the world, and optics, which\nprojects light onto the sensor plane. Finally, Section 2.3 covers how sensors work, including\ntopics such as sampling and aliasing, color sensing, and in-camera compression.\nChapter 3 covers image processing, which is needed in almost all computer vision appli-\ncations. This includes topics such as linear and non-linear ﬁltering (Section 3.3), the Fourier\ntransform (Section 3.4), image pyramids and wavelets (Section 3.5), geometric transforma-\ntions such as image warping (Section 3.6), and global optimization techniques such as regu-\nlarization and Markov Random Fields (MRFs) (Section 3.7). While most of this material is\ncovered in courses and textbooks on image processing, the use of optimization techniques is\nmore typically associated with computer vision (although MRFs are now being widely used\nin image processing as well). The section on MRFs is also the ﬁrst introduction to the use\nof Bayesian inference techniques, which are covered at a more abstract level in Appendix B.\nChapter 3 also presents applications such as seamless image blending and image restoration.\nIn Chapter 4, we cover feature detection and matching. A lot of current 3D reconstruction\nand recognition techniques are built on extracting and matching feature points (Section 4.1),\nso this is a fundamental technique required by many subsequent chapters (Chapters 6, 7, 9\nand 14). We also cover edge and straight line detection in Sections 4.2 and 4.3.\nChapter 5 covers region segmentation techniques, including active contour detection and\ntracking (Section 5.1). Segmentation techniques include top-down (split) and bottom-up\n(merge) techniques, mean shift techniques that ﬁnd modes of clusters, and various graph-\nbased segmentation approaches. All of these techniques are essential building blocks that are\nwidely used in a variety of applications, including performance-driven animation, interactive\nimage editing, and recognition.\nIn Chapter 6, we cover geometric alignment and camera calibration. We introduce the\nbasic techniques of feature-based alignment in Section 6.1 and show how this problem can\nbe solved using either linear or non-linear least squares, depending on the motion involved.\nWe also introduce additional concepts, such as uncertainty weighting and robust regression,\nwhich are essential to making real-world systems work. Feature-based alignment is then used\nas a building block for 3D pose estimation (extrinsic calibration) in Section 6.2 and camera\n(intrinsic) calibration in Section 6.3. Chapter 6 also describes applications of these techniques\nto photo alignment for ﬂip-book animations, 3D pose estimation from a hand-held camera,\nand single-view reconstruction of building models.\nChapter 7 covers the topic of structure from motion, which involves the simultaneous\nrecovery of 3D camera motion and 3D scene structure from a collection of tracked 2D fea-\n24\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ntures. This chapter begins with the easier problem of 3D point triangulation (Section 7.1),\nwhich is the 3D reconstruction of points from matched features when the camera positions\nare known. It then describes two-frame structure from motion (Section 7.2), for which al-\ngebraic techniques exist, as well as robust sampling techniques such as RANSAC that can\ndiscount erroneous feature matches. The second half of Chapter 7 describes techniques for\nmulti-frame structure from motion, including factorization (Section 7.3), bundle adjustment\n(Section 7.4), and constrained motion and structure models (Section 7.5). It also presents\napplications in view morphing, sparse 3D model construction, and match move.\nIn Chapter 8, we go back to a topic that deals directly with image intensities (as op-\nposed to feature tracks), namely dense intensity-based motion estimation (optical ﬂow). We\nstart with the simplest possible motion models, translational motion (Section 8.1), and cover\ntopics such as hierarchical (coarse-to-ﬁne) motion estimation, Fourier-based techniques, and\niterative reﬁnement. We then present parametric motion models, which can be used to com-\npensate for camera rotation and zooming, as well as afﬁne or planar perspective motion (Sec-\ntion 8.2). This is then generalized to spline-based motion models (Section 8.3) and ﬁnally\nto general per-pixel optical ﬂow (Section 8.4), including layered and learned motion models\n(Section 8.5). Applications of these techniques include automated morphing, frame interpo-\nlation (slow motion), and motion-based user interfaces.\nChapter 9 is devoted to image stitching, i.e., the construction of large panoramas and com-\nposites. While stitching is just one example of computation photography (see Chapter 10),\nthere is enough depth here to warrant a separate chapter. We start by discussing various pos-\nsible motion models (Section 9.1), including planar motion and pure camera rotation. We\nthen discuss global alignment (Section 9.2), which is a special (simpliﬁed) case of general\nbundle adjustment, and then present panorama recognition, i.e., techniques for automatically\ndiscovering which images actually form overlapping panoramas. Finally, we cover the topics\nof image compositing and blending (Section 9.3), which involve both selecting which pixels\nfrom which images to use and blending them together so as to disguise exposure differences.\nImage stitching is a wonderful application that ties together most of the material covered\nin earlier parts of this book. It also makes for a good mid-term course project that can build\non previously developed techniques such as image warping and feature detection and match-\ning. Chapter 9 also presents more specialized variants of stitching such as whiteboard and\ndocument scanning, video summarization, panography, full 360◦spherical panoramas, and\ninteractive photomontage for blending repeated action shots together.\nChapter 10 presents additional examples of computational photography, which is the pro-\ncess of creating new images from one or more input photographs, often based on the careful\nmodeling and calibration of the image formation process (Section 10.1). Computational pho-\ntography techniques include merging multiple exposures to create high dynamic range images\n(Section 10.2), increasing image resolution through blur removal and super-resolution (Sec-\n1.3 Book overview\n25\ntion 10.3), and image editing and compositing operations (Section 10.4). We also cover the\ntopics of texture analysis, synthesis and inpainting (hole ﬁlling) in Section 10.5, as well as\nnon-photorealistic rendering (Section 10.5.2).\nIn Chapter 11, we turn to the issue of stereo correspondence, which can be thought of\nas a special case of motion estimation where the camera positions are already known (Sec-\ntion 11.1). This additional knowledge enables stereo algorithms to search over a much smaller\nspace of correspondences and, in many cases, to produce dense depth estimates that can\nbe converted into visible surface models (Section 11.3). We also cover multi-view stereo\nalgorithms that build a true 3D surface representation instead of just a single depth map\n(Section 11.6). Applications of stereo matching include head and gaze tracking, as well as\ndepth-based background replacement (Z-keying).\nChapter 12 covers additional 3D shape and appearance modeling techniques. These in-\nclude classic shape-from-X techniques such as shape from shading, shape from texture, and\nshape from focus (Section 12.1), as well as shape from smooth occluding contours (Sec-\ntion 11.2.1) and silhouettes (Section 12.5). An alternative to all of these passive computer\nvision techniques is to use active rangeﬁnding (Section 12.2), i.e., to project patterned light\nonto scenes and recover the 3D geometry through triangulation. Processing all of these 3D\nrepresentations often involves interpolating or simplifying the geometry (Section 12.3), or\nusing alternative representations such as surface point sets (Section 12.4).\nThe collection of techniques for going from one or more images to partial or full 3D\nmodels is often called image-based modeling or 3D photography. Section 12.6 examines\nthree more specialized application areas (architecture, faces, and human bodies), which can\nuse model-based reconstruction to ﬁt parameterized models to the sensed data. Section 12.7\nexamines the topic of appearance modeling, i.e., techniques for estimating the texture maps,\nalbedos, or even sometimes complete bi-directional reﬂectance distribution functions (BRDFs)\nthat describe the appearance of 3D surfaces.\nIn Chapter 13, we discuss the large number of image-based rendering techniques that\nhave been developed in the last two decades, including simpler techniques such as view in-\nterpolation (Section 13.1), layered depth images (Section 13.2), and sprites and layers (Sec-\ntion 13.2.1), as well as the more general framework of light ﬁelds and Lumigraphs (Sec-\ntion 13.3) and higher-order ﬁelds such as environment mattes (Section 13.4). Applications of\nthese techniques include navigating 3D collections of photographs using photo tourism and\nviewing 3D models as object movies.\nIn Chapter 13, we also discuss video-based rendering, which is the temporal extension of\nimage-based rendering. The topics we cover include video-based animation (Section 13.5.1),\nperiodic video turned into video textures (Section 13.5.2), and 3D video constructed from\nmultiple video streams (Section 13.5.4). Applications of these techniques include video de-\nnoising, morphing, and tours based on 360◦video.",
  "image_path": "page_046.jpg",
  "pages": [
    45,
    46,
    47
  ]
}