{
  "doc_id": "pages_784_786",
  "text": "762\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(inlier) noise. Estimating such noise levels directly from the measurements or their residuals,\nhowever, can be problematic, as such estimates themselves become contaminated by outliers.\nThe robust statistics literature contains a variety of techniques to estimate such parameters.\nOne of the simplest and most effective is the median absolute deviation (MAD),\nMAD = medi∥ri∥,\n(B.20)\nwhich, when multiplied by 1.4, provides a robust estimate of the standard deviation of the\ninlier noise process.\nAs mentioned in Section 6.1.4, it is often better to start iterative non-linear minimiza-\ntion techniques, such as IRLS, in the vicinity of a good solution by ﬁrst randomly selecting\nsmall subsets of measurements until a good set of inliers is found. The best known of these\ntechniques is RANdom SAmple Consensus (RANSAC) (Fischler and Bolles 1981), although\neven better variants such as Preemptive RANSAC (Nist´er 2003) and PROgressive SAmple\nConsensus (PROSAC) (Chum and Matas 2005) have since been developed.\nB.4 Prior models and Bayesian inference\nWhile maximum likelihood estimation can often lead to good solutions, in some cases the\nrange of possible solutions consistent with the measurements is too large to be useful. For\nexample, consider the problem of image denoising (Sections 3.4.4 and 3.7.3). If we esti-\nmate each pixel separately based on just its noisy version, we cannot make any progress,\nas there are a large number of values that could lead to each noisy measurement.4 Instead,\nwe need to rely on typical properties of images, e.g., that they tend to be piecewise smooth\n(Section 3.7.1).\nThe propensity of images to be piecewise smooth can be encoded in a prior distribution\np(x), which measures the likelihood of an image being a natural image. For example, to\nencode piecewise smoothness, we can use a Markov random ﬁeld model (3.109 and B.24)\nwhose negative log likelihood is proportional to a robustiﬁed measure of image smoothness\n(gradient magnitudes).\nPrior models need not be restricted to image processing applications. For example, we\nmay have some external knowledge about the rough dimensions of an object being scanned,\nthe focal length of a lens being calibrated, or the likelihood that a particular object might\nappear in an image. All of these are examples of prior distributions or probabilities and they\ncan be used to produce more reliable estimates.\nAs we have already seen in (3.68) and (3.106), Bayes’ Rule states that a posterior distribu-\ntion p(x|y) over the unknowns x given the measurements y can be obtained by multiplying\n4 In fact, the maximum likelihood estimate is just the noisy image itself.\nB.5 Markov random ﬁelds\n763\nthe measurement likelihood p(y|x) by the prior distribution p(x),\np(x|y) = p(y|x)p(x)\np(y)\n,\n(B.21)\nwhere p(y) =\nR\nx p(y|x)p(x) is a normalizing constant used to make the p(x|y) distribution\nproper (integrate to 1). Taking the negative logarithm of both sides of Equation (B.21), we\nget\n−log p(x|y) = −log p(y|x) −log p(x) + log p(y),\n(B.22)\nwhich is the negative posterior log likelihood. It is common to drop the constant log p(y) be-\ncause its value does not matter during energy minimization. However, if the prior distribution\np(x) depends on some unknown parameters, we may wish to keep log p(y) in order to com-\npute the most likely value of these parameters using Occam’s razor, i.e., by maximizing the\nlikelihood of the observations, or to select the correct number of free parameters using model\nselection (Hastie, Tibshirani, and Friedman 2001; Torr 2002; Bishop 2006; Robert 2007).\nTo ﬁnd the most likely (maximum a posteriori or MAP) solution x given some measure-\nments y, we simply minimize this negative log likelihood, which can also be thought of as an\nenergy,\nE(x, y) = Ed(x, y) + Ep(x).\n(B.23)\nThe ﬁrst term Ed(x, y) is the data energy or data penalty and measures the negative log\nlikelihood that the measurements y were observed given the unknown state x. The second\nterm Ep(x) is the prior energy and it plays a role analogous to the smoothness energy in\nregularization. Note that the MAP estimate may not always be desirable, since it selects the\n“peak” in the posterior distribution rather than some more stable statistic such as MSE—see\nthe discussion in Appendix B.2 about loss functions and decision theory.\nB.5 Markov random ﬁelds\nMarkov random ﬁelds (Blake, Kohli, and Rother 2010) are the most popular types of prior\nmodel for gridded image-like data,5 which include not only regular natural images (Sec-\ntion 3.7.2) but also two-dimensional ﬁelds such as optic ﬂow (Chapter 8) or depth maps\n(Chapter 11), as well as binary ﬁelds, such as segmentations (Section 5.5).\nAs we discussed in Section 3.7.2, the prior probability p(x) for a Markov random ﬁeld is\na Gibbs or Boltzmann distribution, whose negative log likelihood (according to the Hammer-\n5 Alternative formulations include power spectra (Section 3.4.3) and non-local means (Buades, Coll, and Morel\n2008).\n764\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nf (i, j)\nsx(i, j)\nf (i, j+1)\nsy(i, j)\nw(i, j)\nd (i, j)\nf (i+1, j)\nf (i+1, j+1)\nFigure B.1\nGraphical model for an N4 neighborhood Markov random ﬁeld. The white\ncircles are the unknowns f(i, j), while the dark circles are the input data d(i, j). The sx(i, j)\nand sy(i, j) black boxes denote arbitrary interaction potentials between adjacent nodes in the\nrandom ﬁeld, and the w(i, j) denote the data penalty functions. They are all examples of the\ngeneral potentials Vi,j,k,l(f(i, j), f(k, l)) used in Equation (B.24).\nsley–Clifford Theorem) can be written as a sum of pairwise interaction potentials,\nEp(x) =\nX\n{(i,j),(k,l)}∈N\nVi,j,k,l(f(i, j), f(k, l)),\n(B.24)\nwhere N(i, j) denotes the neighbors of pixel (i, j). In the more general case, MRFs can also\ncontain unary potentials, as well as higher-order potentials deﬁned over larger cardinality\ncliques (Kindermann and Snell 1980; Geman and Geman 1984; Bishop 2006; Potetz and Lee\n2008; Kohli, Kumar, and Torr 2009; Kohli, Ladick´y, and Torr 2009; Rother, Kohli, Feng et\nal. 2009; Alahari, Kohli, and Torr 2011). They can also contain line processes, i.e., additional\nbinary variables that mediate discontinuities between adjacent elements (Geman and Geman\n1984). Black and Rangarajan (1996) show how independent line process variables can be\neliminated and incorporated into regular MRFs using robust pairwise penalty functions.\nThe most commonly used neighborhood in Markov random ﬁeld modeling is the N4\nneighborhood, where each pixel in the ﬁeld f(i, j) interacts only with its immediate neighbors—\nFigure B.1 shows such an N4 MRF. The sx(i, j) and sy(i, j) black boxes denote arbitrary\ninteraction potentials between adjacent nodes in the random ﬁeld and the w(i, j) denote the\nelemental data penalty terms in Ed (B.23). These square nodes can also be interpreted as fac-\ntors in a factor graph version of the undirected graphical model (Bishop 2006; Wainwright\nand Jordan 2008; Koller and Friedman 2009), which is another name for interaction poten-\ntials. (Strictly speaking, the factors are improper probability functions whose product is the\nun-normalized posterior distribution.)\nMore complex and higher-dimensional interaction models and neighborhoods are also",
  "image_path": "page_785.jpg",
  "pages": [
    784,
    785,
    786
  ]
}