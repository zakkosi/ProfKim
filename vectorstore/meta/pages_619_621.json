{
  "doc_id": "pages_619_621",
  "text": "12.5 Volumetric representations\n597\nthe object.\nAn early example of using implicit functions to model 3D objects in computer vision are\nsuperquadrics, which are a generalization of quadric (e.g., ellipsoidal) parametric volumetric\nmodels,\nF(x, y, z) =\n \u0012 x\na1\n\u00132/ϵ2\n+\n\u0012 y\na2\n\u00132/ϵ2!ϵ2/ϵ1\n+\n\u0012 x\na1\n\u00132/ϵ1\n−1 = 0\n(12.8)\n(Pentland 1986; Solina and Bajcsy 1990; Waithe and Ferrie 1991; Leonardis, Jakliˇc, and\nSolina 1997). The values of (a1, a2, a3) control the extent of model along each (x, y, z) axis,\nwhile the values of (ϵ1, ϵ2) control how “square” it is. To model a wider variety of shapes,\nsuperquadrics are usually combined with either rigid or non-rigid deformations (Terzopoulos\nand Metaxas 1991; Metaxas and Terzopoulos 2002). Superquadric models can either be ﬁt to\nrange data or used directly for stereo matching.\nA different kind of implicit shape model can be constructed by deﬁning a signed distance\nfunction over a regular three-dimensional grid, optionally using an octree spline to represent\nthis function more coarsely away from its surface (zero-set) (Lavall´ee and Szeliski 1995;\nSzeliski and Lavall´ee 1996; Frisken, Perry, Rockwood et al. 2000; Ohtake, Belyaev, Alexa\net al. 2003). We have already seen examples of signed distance functions being used to\nrepresent distance transforms (Section 3.3.3), level sets for 2D contour ﬁtting and tracking\n(Section 5.1.4), volumetric stereo (Section 11.6.1), range data merging (Section 12.2.1), and\npoint-based modeling (Section 12.4). The advantage of representing such functions directly\non a grid is that it is quick and easy to look up distance function values for any (x, y, z)\nlocation and also easy to extract the isosurface using the marching cubes algorithm (Lorensen\nand Cline 1987). The work of Ohtake, Belyaev, Alexa et al. (2003) is particularly notable\nsince it allows for several distance functions to be used simultaneously and then combined\nlocally to produce sharp features such as creases.\nPoisson surface reconstruction (Kazhdan, Bolitho, and Hoppe 2006) uses a closely related\nvolumetric function, namely a smoothed 0/1 inside–outside (characteristic) function, which\ncan be thought of as a clipped signed distance function. The gradients for this function are\nset to lie along oriented surface normals near known surface points and 0 elsewhere. The\nfunction itself is represented using a quadratic tensor-product B-spline over an octree, which\nprovides a compact representation with larger cells away from the surface or in regions of\nlower point density, and also admits the efﬁcient solution of the related Poisson equations\n(3.100–3.102), see Section 9.3.4 (P´erez, Gangnet, and Blake 2003).\nIt is also possible to replace the quadratic penalties used in the Poisson equations with\nL1 (total variation) constraints and still obtain a convex optimization problem, which can be\nsolved using either continuous (Zach, Pock, and Bischof 2007b; Zach 2008) or discrete graph\ncut (Lempitsky and Boykov 2007) techniques.\n598\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nSigned distance functions also play an integral role in level-set evolution equations ((Sec-\ntions 5.1.4 and 11.6.1), where the values of distance transforms on the mesh are updated as\nthe surface evolves to ﬁt multi-view stereo photoconsistency measures (Faugeras and Keriven\n1998).\n12.6 Model-based reconstruction\nWhen we know something ahead of time about the objects we are trying to model, we can\nconstruct more detailed and reliable 3D models using specialized techniques and representa-\ntions. For example, architecture is usually made up of large planar regions and other para-\nmetric forms (such as surfaces of revolution), usually oriented perpendicular to gravity and\nto each other (Section 12.6.1). Heads and faces can be represented using low-dimensional,\nnon-rigid shape models, since the variability in shape and appearance of human faces, while\nextremely large, is still bounded (Section 12.6.2). Human bodies or parts, such as hands, form\nhighly articulated structures, which can be represented using kinematic chains of piecewise\nrigid skeletal elements linked by joints (Section 12.6.4).\nIn this section, we highlight some of the main ideas, representations, and modeling algo-\nrithms used for these three cases. Additional details and references can be found in special-\nized conferences and workshops devoted to these topics, e.g., the International Symposium on\n3D Data Processing, Visualization, and Transmission (3DPVT), the International Conference\non 3D Digital Imaging and Modeling (3DIM), the International Conference on Automatic\nFace and Gesture Recognition (FG), the IEEE Workshop on Analysis and Modeling of Faces\nand Gestures, and the International Workshop on Tracking Humans for the Evaluation of their\nMotion in Image Sequences (THEMIS).\n12.6.1 Architecture\nArchitectural modeling, especially from aerial photography, has been one of the longest stud-\nied problems in both photogrammetry and computer vision (Walker and Herman 1988). Re-\ncently, the development of reliable image-based modeling techniques, as well as the preva-\nlence of digital cameras and 3D computer games, has spurred renewed interest in this area.\nThe work by Debevec, Taylor, and Malik (1996) was one of the earliest hybrid geometry-\nand image-based modeling and rendering systems. Their Fac¸ade system combines an inter-\nactive image-guided geometric modeling tool with model-based (local plane plus parallax)\nstereo matching and view-dependent texture mapping. During the interactive photogrammet-\nric modeling phase, the user selects block elements and aligns their edges with visible edges\nin the input images (Figure 12.14a). The system then automatically computes the dimensions\nand locations of the blocks along with the camera positions using constrained optimization\n12.6 Model-based reconstruction\n599\nFigure 12.14 Interactive architectural modeling using the Fac¸ade system (Debevec, Taylor,\nand Malik 1996) c⃝1996 ACM: (a) input image with user-drawn edges shown in green;\n(b) shaded 3D solid model; (c) geometric primitives overlaid onto the input image; (d) ﬁnal\nview-dependent, texture-mapped 3D model.\n(Figure 12.14b–c). This approach is intrinsically more reliable than general feature-based\nstructure from motion, because it exploits the strong geometry available in the block primi-\ntives. Related work by Becker and Bove (1995), Horry, Anjyo, and Arai (1997), and Crimin-\nisi, Reid, and Zisserman (2000) exploits similar information available from vanishing points.\nIn the interactive, image-based modeling system of Sinha, Steedly, Szeliski et al. (2008),\nvanishing point directions are used to guide the user drawing of polygons, which are then\nautomatically ﬁtted to sparse 3D points recovered using structure from motion.\nOnce the rough geometry has been estimated, more detailed offset maps can be com-\nputed for each planar face using a local plane sweep, which Debevec, Taylor, and Malik\n(1996) call model-based stereo. Finally, during rendering, images from different viewpoints\nare warped and blended together as the camera moves around the scene, using a process (re-\nlated to light ﬁeld and Lumigraph rendering, see Section 13.3) called view-dependent texture\nmapping (Figure 12.14d).\nFor interior modeling, instead of working with single pictures, it is more useful to work\nwith panoramas, since you can see larger extents of walls and other structures. The 3D mod-\neling system developed by Shum, Han, and Szeliski (1998) ﬁrst constructs calibrated panora-\nmas from multiple images (Section 7.4) and then has the user draw vertical and horizontal\nlines in the image to demarcate the boundaries of planar regions. The lines are initially used\nto establish an absolute rotation for each panorama and are later used (along with the inferred\nvertices and planes) to optimize the 3D structure, which can be recovered up to scale from\none or more images (Figure 12.15). 360◦high dynamic range panoramas can also be used for\noutdoor modeling, since they provide highly reliable estimates of relative camera orientations\nas well as vanishing point directions (Antone and Teller 2002; Teller, Antone, Bodnar et al.",
  "image_path": "page_620.jpg",
  "pages": [
    619,
    620,
    621
  ]
}