{
  "doc_id": "pages_500_502",
  "text": "478\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n−2\n−1\n0\n1\n2\n−2\n−1\n0 \n1 \n2 \n−2\n−1\n0\n1\n2\n−2\n−1\n0 \n1 \n2 \n−2\n−1\n0\n1\n2\n−2\n−1\n0 \n1 \n2 \n−2\n−1\n0\n1\n2\n−2\n−1\n0 \n1 \n2 \n(a)\n(b)\n(c)\nFigure 10.8 Point spread function estimation using a calibration target (Joshi, Szeliski, and\nKriegman 2008) c⃝2008 IEEE. (a) Sub-pixel PSFs at successively higher resolutions (note\nthe interaction between the square sensing area and the circular lens blur). (b) The radial\ndistortion and chromatic aberration can also be estimated and removed. (c) PSF for a mis-\nfocused (blurred) lens showing some diffraction and vignetting effects in the corners.\nSection 10.3. Figure 10.8b shows how the radial distortion and chromatic aberration manifest\nthemselves as elongated and displaced PSFs, along with the result of removing these effects\nin a region of the calibration target.\nThe local 2D PSF estimation technique can also be used to estimate vignetting. Fig-\nure 10.8c shows how the mechanical vignetting manifests itself as clipping of the PSF in the\ncorners of the image. In order for the overall dimming associated with vignetting to be prop-\nerly captured, the modiﬁed intensities of the ideal pattern need to be extrapolated from the\ncenter, which is best done with a uniformly illuminated target.\nWhen working with RAW Bayer-pattern images, the correct way to estimate the PSF is\nto only evaluate the least squares terms in (10.1) at sensed pixel values, while interpolating\nthe ideal image to all values. For JPEG images, you should linearize your intensities ﬁrst,\ne.g., remove the gamma and any other non-linearities in your estimated radiometric response\nfunction.\nWhat if you have an image that was taken with an uncalibrated camera? Can you still\nrecover the PSF an use it to correct the image? In fact, with a slight modiﬁcation, the previous\nalgorithms still work.\nInstead of assuming a known calibration image, you can detect strong elongated edges\nand ﬁt ideal step edges in such regions (Figure 10.9b), resulting in the sharp image shown\n10.2 High dynamic range imaging\n479\nMin\nMax\nR\nR\nValid  Region\n(a)\n(b)\n(c)\n(d)\nFigure 10.9\nEstimating the PSF without using a calibration pattern (Joshi, Szeliski, and\nKriegman 2008) c⃝2008 IEEE: (a) Input image with blue cross-section (proﬁle) location, (b)\nProﬁle of sensed and predicted step edges, (c–d) Locations and values of the predicted colors\nnear the edge locations.\nin Figure 10.9d. For every pixel that is surrounded by a complete set of valid estimated\nneighbors (green pixels in Figure 10.9c), apply the least squares formula (10.1) to estimate\nthe kernel K. The resulting locally estimated PSFs can be used to correct for chromatic\naberration (since the relative displacements between per-channel PSFs can be computed), as\nshown by Joshi, Szeliski, and Kriegman (2008).\nExercise 10.4 provides some more detailed instructions for implementing and testing\nedge-based PSF estimation algorithms. An alternative approach, which does not require the\nexplicit detection of edges but uses image statistics (gradient distributions) instead, is pre-\nsented by Fergus, Singh, Hertzmann et al. (2006).\n10.2 High dynamic range imaging\nAs we mentioned earlier in this chapter, registered images taken at different exposures can be\nused to calibrate the radiometric response function of a camera. More importantly, they can\nhelp you create well-exposed photographs under challenging conditions, such as brightly lit\n480\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.10\nSample indoor image where the areas outside the window are overexposed\nand inside the room are too dark.\n1\n1,500\n25,000\n400,000\n2,000,000\nFigure 10.11 Relative brightness of different scenes, ranging from 1 inside a dark room lit\nby a monitor to 2,000,000 looking at the sun. Photos courtesy of Paul Debevec.\nscenes where any single exposure contains saturated (overexposed) and dark (underexposed)\nregions (Figure 10.10). This problem is quite common, because the natural world contains a\nrange of radiance values that is far greater than can be captured with any photographic sensor\nor ﬁlm (Figure 10.11). Taking a set of bracketed exposures (exposures taken by a camera\nin automatic exposure bracketing (AEB) mode to deliberately under- and over-expose the\nimage) gives you the material from which to create a properly exposed photograph, as shown\nin Figure 10.12 (Reinhard, Ward, Pattanaik et al. 2005; Freeman 2008; Gulbins and Gulbins\n2009; Hasinoff, Durand, and Freeman 2010).\nWhile it is possible to combine pixels from different exposures directly into a ﬁnal com-\n+\n+\n⇒\nFigure 10.12\nA bracketed set of shots (using the camera’s automatic exposure bracketing\n(AEB) mode) and the resulting high dynamic range (HDR) composite.",
  "image_path": "page_501.jpg",
  "pages": [
    500,
    501,
    502
  ]
}