{
  "doc_id": "pages_305_307",
  "text": "5.1 Active contours\n283\n(a)\n(b)\nFigure 5.11\nLevel set segmentation (Cremers, Rousson, and Deriche 2007) c⃝2007\nSpringer: (a) grayscale image segmentation and (b) color image segmentation. Uni-variate\nand multi-variate Gaussians are used to model the foreground and background pixel dis-\ntributions. The initial circles evolve towards an accurate segmentation of foreground and\nbackground, adapting their topology as they evolve.\nfor performance-driven animation (Terzopoulos and Waters 1990; Lee, Terzopoulos, and Wa-\nters 1995; Parke and Waters 1996; Bregler, Covell, and Slaney 1997) (Figure 5.2b). They can\nalso be used to track heads and people, as shown in Figure 5.8, as well as moving vehicles\n(Paragios and Deriche 2000). Additional applications include medical image segmentation,\nwhere contours can be tracked from slice to slice in computerized tomography (3D medical\nimagery) (Cootes and Taylor 2001) or over time, as in ultrasound scans.\nAn interesting application that is closer to computer animation and visual effects is ro-\ntoscoping, which uses the tracked contours to deform a set of hand-drawn animations (or\nto modify or replace the original video frames).7 Agarwala, Hertzmann, Seitz et al. (2004)\npresent a system based on tracking hand-drawn B-spline contours drawn at selected keyframes,\nusing a combination of geometric and appearance-based criteria (Figure 5.12). They also pro-\nvide an excellent review of previous rotoscoping and image-based, contour-tracking systems.\n7 The term comes from a device (a rotoscope) that projected frames of a live-action ﬁlm underneath an acetate so\nthat artists could draw animations directly over the actors’ shapes.\n284\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 5.12 Keyframe-based rotoscoping (Agarwala, Hertzmann, Seitz et al. 2004) c⃝2004\nACM: (a) original frames; (b) rotoscoped contours; (c) re-colored blouse; (d) rotoscoped\nhand-drawn animation.\nAdditional applications of rotoscoping (object contour detection and segmentation), such\nas cutting and pasting objects from one photograph into another, are presented in Section 10.4.\n5.2 Split and merge\nAs mentioned in the introduction to this chapter, the simplest possible technique for seg-\nmenting a grayscale image is to select a threshold and then compute connected components\n(Section 3.3.2). Unfortunately, a single threshold is rarely sufﬁcient for the whole image\nbecause of lighting and intra-object statistical variations.\nIn this section, we describe a number of algorithms that proceed either by recursively\nsplitting the whole image into pieces based on region statistics or, conversely, merging pixels\nand regions together in a hierarchical fashion. It is also possible to combine both splitting and\nmerging by starting with a medium-grain segmentation (in a quadtree representation) and\nthen allowing both merging and splitting operations (Horowitz and Pavlidis 1976; Pavlidis\nand Liow 1990).\n5.2.1 Watershed\nA technique related to thresholding, since it operates on a grayscale image, is watershed com-\nputation (Vincent and Soille 1991). This technique segments an image into several catchment\nbasins, which are the regions of an image (interpreted as a height ﬁeld or landscape) where\n5.2 Split and merge\n285\n(a)\n(b)\n(c)\nFigure 5.13\nLocally constrained watershed segmentation (Beare 2006) c⃝2006 IEEE: (a)\noriginal confocal microscopy image with marked seeds (line segments); (b) standard water-\nshed segmentation; (c) locally constrained watershed segmentation.\nrain would ﬂow into the same lake. An efﬁcient way to compute such regions is to start ﬂood-\ning the landscape at all of the local minima and to label ridges wherever differently evolving\ncomponents meet. The whole algorithm can be implemented using a priority queue of pixels\nand breadth-ﬁrst search (Vincent and Soille 1991).8\nSince images rarely have dark regions separated by lighter ridges, watershed segmen-\ntation is usually applied to a smoothed version of the gradient magnitude image, which also\nmakes it usable with color images. As an alternative, the maximum oriented energy in a steer-\nable ﬁlter (3.28–3.29) (Freeman and Adelson 1991) can be used as the basis of the oriented\nwatershed transform developed by Arbel´aez, Maire, Fowlkes et al. (2010). Such techniques\nend up ﬁnding smooth regions separated by visible (higher gradient) boundaries. Since such\nboundaries are what active contours usually follow, active contour algorithms (Mortensen and\nBarrett 1999; Li, Sun, Tang et al. 2004) often precompute such a segmentation using either\nthe watershed or the related tobogganing technique (Section 5.1.3).\nUnfortunately, watershed segmentation associates a unique region with each local mini-\nmum, which can lead to over-segmentation. Watershed segmentation is therefore often used\nas part of an interactive system, where the user ﬁrst marks seed locations (with a click or\na short stroke) that correspond to the centers of different desired components. Figure 5.13\nshows the results of running the watershed algorithm with some manually placed markers on\na confocal microscopy image. It also shows the result for an improved version of watershed\nthat uses local morphology to smooth out and optimize the boundaries separating the regions\n(Beare 2006).\n8 A related algorithm can be used to compute maximally stable extremal regions (MSERs) efﬁciently (Sec-\ntion 4.1.1) (Nist´er and Stew´enius 2008).",
  "image_path": "page_306.jpg",
  "pages": [
    305,
    306,
    307
  ]
}