{
  "doc_id": "pages_507_509",
  "text": "10.2 High dynamic range imaging\n485\n(a)\n(b)\n(c)\nFigure 10.17 HDR merging with large amounts of motion (Eden, Uyttendaele, and Szeliski\n2006) c⃝2006 IEEE: (a) registered bracketed input images; (b) results after the ﬁrst pass of\nimage selection: reference labels, image, and tone-mapped image; (c) results after the second\npass of image selection: ﬁnal labels, compressed HDR image, and tone-mapped image\nthe weighting function must emphasize both higher pixel values and larger gradients in the\ntransfer function, i.e.,\nw(z) = g(z)/g′(z),\n(10.10)\nwhere the weights w are used to form the ﬁnal irradiance estimate\nlog Ei =\nP\nj w(zij)[g(zij) −log tj]\nP\nj w(zij)\n.\n(10.11)\nExercise 10.1 has you implement one of the radiometric response function calibration tech-\nniques and then use it to create radiance maps.\nUnder real-world conditions, casually acquired images may not be perfectly registered\nand may contain moving objects. Ward (2003) uses a global (parametric) transform to align\nthe input images, while Kang, Uyttendaele, Winder et al. (2003) present an algorithm that\ncombines global registration with local motion estimation (optical ﬂow) to accurately align\nthe images before blending their radiance estimates (Figure 10.16). Since the images may\n486\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.18 Fuji SuperCCD high dynamic range image sensor. The paired large and small\nactive areas provide two different effective exposures.\nhave widely different exposures, care must be taken when estimating the motions, which must\nthemselves be checked for consistency to avoid the creation of ghosts and object fragments.\nEven this approach, however, may not work when the camera is simultaneously undergo-\ning large panning motions and exposure changes, which is a common occurrence in casually\nacquired panoramas. Under such conditions, different parts of the image may be seen at one\nor more exposures. Devising a method to blend all of these different sources while avoid-\ning sharp transitions and dealing with scene motion is a challenging problem. One approach\nis to ﬁrst ﬁnd a consensus mosaic and to then selectively compute radiances in under- and\nover-exposed regions (Eden, Uyttendaele, and Szeliski 2006), as shown in Figure 10.17.\nRecently, some cameras, such as the Sony α550 and Pentax K-7, have started integrating\nmultiple exposure merging and tone mapping directly into the camera body. In the future,\nthe need to compute high dynamic range images from multiple exposures may be eliminated\nby advances in camera sensor technology (Figure 10.18) (Yang, El Gamal, Fowler et al.\n1999; Nayar and Mitsunaga 2000; Nayar and Branzoi 2003; Kang, Uyttendaele, Winder et\nal. 2003; Narasimhan and Nayar 2005; Tumblin, Agrawal, and Raskar 2005). However, the\nneed to blend such images and to tone map them to lower-gamut displays is likely to remain.\nHDR image formats.\nBefore we discuss techniques for mapping HDR images back to a\ndisplayable gamut, we should discuss the commonly used formats for storing HDR images.\nIf storage space is not an issue, storing each of the R, G, and B values as a 32-bit IEEE\nﬂoat is the best solution. The commonly used Portable PixMap (.ppm) format, which supports\nboth uncompressed ASCII and raw binary encodings of values, can be extended to a Portable\nFloatMap (.pfm) format by modifying the header. TIFF also supports full ﬂoating point\nvalues.\nA more compact representation is the Radiance format (.pic, .hdr) (Ward 1994), which\nuses a single common exponent and per-channel mantissas (10.19b). An intermediate encod-\n10.2 High dynamic range imaging\n487\n96 bits / pixel\nsign\nexponent\nmantissa\n(a)\n32 bits / pixel\nred\ngreen\nblue\nexponent\n(b)\n48 bits / pixel\nsign exponent\nmantissa\n(c)\nFigure 10.19\nHDR image encoding formats: (a) Portable PixMap (.ppm); (b) Radiance\n(.pic, .hdr); (c) OpenEXR (.exr).\ning, OpenEXR from ILM,12 uses 16-bit ﬂoats for each channel (10.19c), which is a format\nsupported natively on most modern GPUs. Ward (2004) describes these and other data for-\nmats such as LogLuv (Larson 1998) in more detail, as do the books by Reinhard, Ward,\nPattanaik et al. (2005) and Freeman (2008). An even more recent HDR image format is the\nJPEG XR standard.13\n10.2.1 Tone mapping\nOnce a radiance map has been computed, it is usually necessary to display it on a lower gamut\n(i.e., eight-bit) screen or printer. A variety of tone mapping techniques has been developed for\nthis purpose, which involve either computing spatially varying transfer functions or reducing\nimage gradients to ﬁt the available dynamic range (Reinhard, Ward, Pattanaik et al. 2005).\nThe simplest way to compress a high dynamic range radiance image into a low dynamic\nrange gamut is to use a global transfer curve (Larson, Rushmeier, and Piatko 1997). Fig-\nure 10.20 shows one such example, where a gamma curve is used to map an HDR image back\n12 http://www.openexr.net/.\n13 http://www.itu.int/rec/T-REC-T.832-200903-I/en.",
  "image_path": "page_508.jpg",
  "pages": [
    507,
    508,
    509
  ]
}