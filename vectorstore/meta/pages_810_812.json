{
  "doc_id": "pages_810_812",
  "text": "788\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ndouble urand()\n{\nreturn ((double) rand()) / ((double) RAND MAX);\n}\nvoid grand(double& g1, double& g2)\n{\n#ifndef M PI\n#define M PI 3.14159265358979323846\n#endif // M PI\ndouble n1 = urand();\ndouble n2 = urand();\ndouble x1 = n1 + (n1 == 0); /* guard against log(0) */\ndouble sqlogn1 = sqrt(-2.0 * log (x1));\ndouble angl = (2.0 * M PI) * n2;\ng1 = sqlogn1 * cos(angl);\ng2 = sqlogn1 * sin(angl);\n}\nAlgorithm C.1 C algorithm for Gaussian random noise generation, using the Box–Muller\ntransform.\nGaussian noise generation.\nA lot of basic software packages come with a uniform random\nnoise generator (e.g., the rand() routine in Unix), but not all have a Gaussian random\nnoise generator. To compute a normally distributed random variable, you can use the Box–\nMuller transform (Box and Muller 1958), whose C code is given in Algorithm C.1—note that\nthis routine returns pairs of random variables. Alternative methods for generating Gaussian\nrandom numbers are given by Thomas, Luk, Leong et al. (2007).\nPseudocolor generation.\nIn many applications, it is convenient to be able to visualize the\nset of labels assigned to an image (or to image features such as lines). One of the easiest\nways to do this is to assign a unique color to each integer label. In my work, I have found it\nconvenient to distribute these labels in a quasi-uniform fashion around the RGB color cube\nusing the following idea.\nFor each (non-negative) label value, consider the bits as being split among the three color\nchannels, e.g., for a nine-bit value, the bits could be labeled RGBRGBRGB. After collecting\neach of the three color values, reverse the bits so that the low-order bits vary the most quickly.\nC.3 Slides and lectures\n789\nIn practice, for eight-bit color channels, this bit reverse can be stored in a table or a complete\ntable mapping from labels to pseudocolors (say with 4092 entries) can be pre-computed.\nFigure 8.16 shows an example of such a pseudo-color mapping.\nGPU implementation\nThe advent of programmable GPUs with capabilities such as pixel shaders and compute\nshaders has led to the development of fast computer vision algorithms for real-time appli-\ncations such as segmentation, tracking, stereo, and motion estimation (Pock, Unger, Cremers\net al. 2008; Vineet and Narayanan 2008; Zach, Gallup, and Frahm 2008). A good source\nfor learning about such algorithms is the CVPR 2008 workshop on Visual Computer Vision\non GPUs (CVGPU), http://www.cs.unc.edu/∼jmf/Workshop on Computer Vision on GPU.\nhtml, whose papers can be found on the CVPR 2008 proceedings DVD. Additional sources\nfor GPU algorithms include the GPGPU Web site and workshops, http://gpgpu.org/, and the\nOpenVIDIA Web site, http://openvidia.sourceforge.net/index.php/OpenVIDIA.\nC.3 Slides and lectures\nAs I mentioned in the preface, I hope to post slides corresponding to the material in the book.\nUntil these are ready, your best bet is to look at the slides from the courses I have co-taught\nat the University of Washington, as well as related courses that have used a similar syllabus.\nHere is a partial list of such courses:\nUW 455: Undergraduate Computer Vision, http://www.cs.washington.edu/education/\ncourses/455/.\nUW 576: Graduate Computer Vision, http://www.cs.washington.edu/education/courses/\n576/.\nStanford CS233B: Introduction to Computer Vision, http://vision.stanford.edu/teaching/\ncs223b/.\nMIT 6.869: Advances in Computer Vision, http://people.csail.mit.edu/torralba/courses/\n6.869/6.869.computervision.htm.\nBerkeley CS 280: Computer Vision, http://www.eecs.berkeley.edu/∼trevor/CS280.html.\nUNC COMP 776: Computer Vision, http://www.cs.unc.edu/∼lazebnik/spring10/.\nMiddlebury CS 453: Computer Vision, http://www.cs.middlebury.edu/∼schar/courses/\ncs453-s10/.\n790\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nRelated courses have also been taught on the topic of Computational Photography, e.g.,\nCMU 15-463: Computational Photography, http://graphics.cs.cmu.edu/courses/15-463/.\nMIT 6.815/6.865: Advanced Computational Photography, http://stellar.mit.edu/S/course/\n6/sp09/6.815/.\nStanford CS 448A: Computational photography on cell phones, http://graphics.stanford.\nedu/courses/cs448a-10/.\nSIGGRAPH courses on Computational Photography, http://web.media.mit.edu/∼raskar/\nphoto/.\nThere is also an excellent set of on-line lectures available on a range of computer vision\ntopics, such as belief propagation and graph cuts, at the UW-MSR Course of Vision Algo-\nrithms http://www.cs.washington.edu/education/courses/577/04sp/.\nC.4 Bibliography\nWhile a bibliography (BibTex .bib ﬁle) for all of the references cited in this book is avail-\nable on the book’s Web site, a much more comprehensive partially annotated bibliography\nof nearly all computer vision publications is maintained by Keith Price at http://iris.usc.edu/\nVision-Notes/bibliography/contents.html. There is also a searchable computer graphics bibli-\nography at http://www.siggraph.org/publications/bibliography/. Additional good sources for\ntechnical papers are Google Scholar and CiteSeerx.",
  "image_path": "page_811.jpg",
  "pages": [
    810,
    811,
    812
  ]
}