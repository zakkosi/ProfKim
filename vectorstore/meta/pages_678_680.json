{
  "doc_id": "pages_678_680",
  "text": "656\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\n(i)\nFigure 14.1\nRecognition:\nface recognition with (a) pictorial structures (Fischler and\nElschlager 1973) c⃝1973 IEEE and (b) eigenfaces (Turk and Pentland 1991b);\n(c) real-\ntime face detection (Viola and Jones 2004) c⃝2004 Springer; (d) instance (known object)\nrecognition (Lowe 1999) c⃝1999 IEEE; (e) feature-based recognition (Fergus, Perona, and\nZisserman 2007); (f) region-based recognition (Mori, Ren, Efros et al. 2004) c⃝2004 IEEE;\n(g) simultaneous recognition and segmentation (Shotton, Winn, Rother et al. 2009) c⃝2009\nSpringer; (h) location recognition (Philbin, Chum, Isard et al. 2007) c⃝2007 IEEE; (i) using\ncontext (Russell, Torralba, Liu et al. 2007).\n14 Recognition\n657\nOf all the visual tasks we might ask a computer to perform, analyzing a scene and recog-\nnizing all of the constituent objects remains the most challenging. While computers excel at\naccurately reconstructing the 3D shape of a scene from images taken from different views,\nthey cannot name all the objects and animals present in a picture, even at the level of a two-\nyear-old child. There is not even any consensus among researchers on when this level of\nperformance might be achieved.\nWhy is recognition so hard? The real world is made of a jumble of objects, which all oc-\nclude one another and appear in different poses. Furthermore, the variability intrinsic within\na class (e.g., dogs), due to complex non-rigid articulation and extreme variations in shape and\nappearance (e.g., between different breeds), makes it unlikely that we can simply perform\nexhaustive matching against a database of exemplars.1\nThe recognition problem can be broken down along several axes. For example, if we\nknow what we are looking for, the problem is one of object detection (Section 14.1), which\ninvolves quickly scanning an image to determine where a match may occur (Figure 14.1c). If\nwe have a speciﬁc rigid object we are trying to recognize (instance recognition, Section 14.3),\nwe can search for characteristic feature points (Section 4.1) and verify that they align in a\ngeometrically plausible way (Section 14.3.1) (Figure 14.1d).\nThe most challenging version of recognition is general category (or class) recognition\n(Section 14.4), which may involve recognizing instances of extremely varied classes such\nas animals or furniture. Some techniques rely purely on the presence of features (known\nas a “bag of words” model—see Section 14.4.1), their relative positions (part-based models\n(Section 14.4.2)), Figure 14.1e, while others involve segmenting the image into semantically\nmeaningful regions (Section 14.4.3) (Figure 14.1f). In many instances, recognition depends\nheavily on the context of surrounding objects and scene elements (Section 14.5). Woven into\nall of these techniques is the topic of learning (Section 14.5.1), since hand-crafting speciﬁc\nobject recognizers seems like a futile approach given the complexity of the problem.\nGiven the extremely rich and complex nature of this topic, this chapter is structured to\nbuild from simpler concepts to more complex ones. We begin with a discussion of face and\nobject detection (Section 14.1), where we introduce a number of machine-learning techniques\nsuch as boosting, neural networks, and support vector machines. Next, we study face recogni-\ntion (Section 14.2), which is one of the more widely known applications of recognition. This\ntopic serves as an introduction to subspace (PCA) models and Bayesian approaches to recog-\nnition and classiﬁcation. We then present techniques for instance recognition (Section 14.3),\nbuilding upon earlier topics in this book, such as feature detection, matching, and geomet-\nric alignment (Section 14.3.1). We introduce topics from the information and document re-\ntrieval communities, such as frequency vectors, feature quantization, and inverted indices\n1 However, some recent research suggests that direct image matching may be feasible for large enough databases\n(Russell, Torralba, Liu et al. 2007; Malisiewicz and Efros 2008; Torralba, Freeman, and Fergus 2008).\n658\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Section 14.3.2). We also present applications of location recognition (Section 14.3.3).\nIn the second half of the chapter, we address the most challenging variant of recognition,\nnamely the problem of category recognition (Section 14.4). This includes approaches that use\nbags of features (Section 14.4.1), parts (Section 14.4.2), and segmentation (Section 14.4.3).\nWe show how such techniques can be used to automate photo editing tasks, such as 3D mod-\neling, scene completion, and creating collages (Section 14.4.4). Next, we discuss the role\nthat context can play in both individual object recognition and more holistic scene under-\nstanding (Section 14.5). We close this chapter with a discussion of databases and test sets for\nconstructing and evaluating recognition systems (Section 14.6).\nWhile there is no comprehensive reference on object recognition, an excellent set of notes\ncan be found in the ICCV 2009 short course (Fei-Fei, Fergus, and Torralba 2009), Antonio\nTorralba’s more comprehensive MIT course (Torralba 2008), and two recent collections of\npapers (Ponce, Hebert, Schmid et al. 2006; Dickinson, Leonardis, Schiele et al. 2007) and a\nsurvey on object categorization (Pinz 2005). An evaluation of some of the best performing\nrecognition algorithms can be found on the PASCAL Visual Object Classes (VOC) Challenge\nWeb site at http://pascallin.ecs.soton.ac.uk/challenges/VOC/.\n14.1 Object detection\nIf we are given an image to analyze, such as the group portrait in Figure 14.2, we could try to\napply a recognition algorithm to every possible sub-window in this image. Such algorithms\nare likely to be both slow and error-prone. Instead, it is more effective to construct special-\npurpose detectors, whose job it is to rapidly ﬁnd likely regions where particular objects might\noccur.\nWe begin this section with face detectors, which are some of the more successful examples\nof recognition. For example, such algorithms are built into most of today’s digital cameras to\nenhance auto-focus and into video conferencing systems to control pan-tilt heads. We then\nlook at pedestrian detectors, as an example of more general methods for object detection.\nSuch detectors can be used in automotive safety applications, e.g., detecting pedestrians and\nother cars from moving vehicles (Leibe, Cornelis, Cornelis et al. 2007).\n14.1.1 Face detection\nBefore face recognition can be applied to a general image, the locations and sizes of any faces\nmust ﬁrst be found (Figures 14.1c and 14.2). In principle, we could apply a face recognition\nalgorithm at every pixel and scale (Moghaddam and Pentland 1997) but such a process would\nbe too slow in practice.",
  "image_path": "page_679.jpg",
  "pages": [
    678,
    679,
    680
  ]
}