{
  "doc_id": "pages_283_285",
  "text": "4.5 Exercises\n261\nEx 4.4: Feature matcher\nAfter extracting features from a collection of overlapping or dis-\ntorted images,10 match them up by their descriptors either using nearest neighbor matching\nor a more efﬁcient matching strategy such as a k-d tree.\nSee whether you can improve the accuracy of your matches using techniques such as the\nnearest neighbor distance ratio.\nEx 4.5: Feature tracker\nInstead of ﬁnding feature points independently in multiple images\nand then matching them, ﬁnd features in the ﬁrst image of a video or image sequence and\nthen re-locate the corresponding points in the next frames using either search and gradient\ndescent (Shi and Tomasi 1994) or learned feature detectors (Lepetit, Pilet, and Fua 2006;\nFossati, Dimitrijevic, Lepetit et al. 2007). When the number of tracked points drops below a\nthreshold or new regions in the image become visible, ﬁnd additional points to track.\n(Optional) Winnow out incorrect matches by estimating a homography (6.19–6.23) or\nfundamental matrix (Section 7.2.1).\n(Optional) Reﬁne the accuracy of your matches using the iterative registration algorithm\ndescribed in Section 8.2 and Exercise 8.2.\nEx 4.6: Facial feature tracker\nApply your feature tracker to tracking points on a person’s\nface, either manually initialized to interesting locations such as eye corners or automatically\ninitialized at interest points.\n(Optional) Match features between two people and use these features to perform image\nmorphing (Exercise 3.25).\nEx 4.7: Edge detector\nImplement an edge detector of your choice. Compare its perfor-\nmance to that of your classmates’ detectors or code downloaded from the Internet.\nA simple but well-performing sub-pixel edge detector can be created as follows:\n1. Blur the input image a little,\nBσ(x) = Gσ(x) ∗I(x).\n2. Construct a Gaussian pyramid (Exercise 3.19),\nP = Pyramid{Bσ(x)}\n3. Subtract an interpolated coarser-level pyramid image from the original resolution blurred\nimage,\nS(x) = Bσ(x) −P.InterpolatedLevel(L).\n10 http://www.robots.ox.ac.uk/∼vgg/research/afﬁne/.\n262\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nstruct SEdgel {\nfloat e[2][2];\n// edgel endpoints (zero crossing)\nfloat x, y;\n// sub-pixel edge position (midpoint)\nfloat n_x, n_y;\n// orientation, as normal vector\nfloat theta;\n// orientation, as angle (degrees)\nfloat length;\n// length of edgel\nfloat strength;\n// strength of edgel (gradient magnitude)\n};\nstruct SLine : public SEdgel {\nfloat line_length;\n// length of line (est. from ellipsoid)\nfloat sigma;\n// estimated std. dev. of edgel noise\nfloat r;\n// line equation: x * n_y - y * n_x = r\n};\nFigure 4.48 A potential C++ structure for edgel and line elements.\n4. For each quad of pixels, {(i, j), (i + 1, j), (i, j + 1), (i + 1, j + 1)}, count the number\nof zero crossings along the four edges.\n5. When there are exactly two zero crossings, compute their locations using (4.25) and\nstore these edgel endpoints along with the midpoint in the edgel structure (Figure 4.48).\n6. For each edgel, compute the local gradient by taking the horizontal and vertical differ-\nences between the values of S along the zero crossing edges.\n7. Store the magnitude of this gradient as the edge strength and either its orientation or\nthat of the segment joining the edgel endpoints as the edge orientation.\n8. Add the edgel to a list of edgels or store it in a 2D array of edgels (addressed by pixel\ncoordinates).\nFigure 4.48 shows a possible representation for each computed edgel.\nEx 4.8: Edge linking and thresholding\nLink up the edges computed in the previous exer-\ncise into chains and optionally perform thresholding with hysteresis.\nThe steps may include:\n1. Store the edgels either in a 2D array (say, an integer image with indices into the edgel\nlist) or pre-sort the edgel list ﬁrst by (integer) x coordinates and then y coordinates, for\nfaster neighbor ﬁnding.\n4.5 Exercises\n263\n2. Pick up an edgel from the list of unlinked edgels and ﬁnd its neighbors in both direc-\ntions until no neighbor is found or a closed contour is obtained. Flag edgels as linked\nas you visit them and push them onto your list of linked edgels.\n3. Alternatively, generalize a previously developed connected component algorithm (Ex-\nercise 3.14) to perform the linking in just two raster passes.\n4. (Optional) Perform hysteresis-based thresholding (Canny 1986). Use two thresholds\n”hi” and ”lo” for the edge strength. A candidate edgel is considered an edge if either\nits strength is above the ”hi” threshold or its strength is above the ”lo” threshold and it\nis (recursively) connected to a previously detected edge.\n5. (Optional) Link together contours that have small gaps but whose endpoints have sim-\nilar orientations.\n6. (Optional) Find junctions between adjacent contours, e.g., using some of the ideas (or\nreferences) from Maire, Arbelaez, Fowlkes et al. (2008).\nEx 4.9: Contour matching\nConvert a closed contour (linked edgel list) into its arc-length\nparameterization and use this to match object outlines.\nThe steps may include:\n1. Walk along the contour and create a list of (xi, yi, si) triplets, using the arc-length\nformula\nsi+1 = si + ∥xi+1 −xi∥.\n(4.32)\n2. Resample this list onto a regular set of (xj, yj, j) samples using linear interpolation of\neach segment.\n3. Compute the average values of x and y, i.e., x and y and subtract them from your\nsampled curve points.\n4. Resample the original (xi, yi, si) piecewise-linear function onto a length-independent\nset of samples, say j ∈[0, 1023]. (Using a length which is a power of two makes\nsubsequent Fourier transforms more convenient.)\n5. Compute the Fourier transform of the curve, treating each (x, y) pair as a complex\nnumber.\n6. To compare two curves, ﬁt a linear equation to the phase difference between the two\ncurves. (Careful: phase wraps around at 360◦. Also, you may wish to weight samples\nby their Fourier spectrum magnitude—see Section 8.1.2.)",
  "image_path": "page_284.jpg",
  "pages": [
    283,
    284,
    285
  ]
}