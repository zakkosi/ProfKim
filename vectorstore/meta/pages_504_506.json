{
  "doc_id": "pages_504_506",
  "text": "482\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nlog Exposure\nPixel value\n3\n1\n2\nlog Exposure\nPixel value\nFigure 10.13 Radiometric calibration using multiple exposures (Debevec and Malik 1997).\nCorresponding pixel values are plotted as functions of log exposures (irradiance). The curves\non the left are shifted to account for each pixel’s unknown radiance until they all line up into\na single smooth curve.\nIn order to make the response curve smooth, Debevec and Malik (1997) add a second-\norder smoothness constraint\nλ\nX\nk\ng′′(k)2 = λ\nX\n[g(k −1) −2g(k) + g(k + 1)]2,\n(10.6)\nwhich is similar to the one used in snakes (5.3). Since pixel values are more reliable in the\nmiddle of their range (and the g function becomes singular near saturation values), they also\nadd a weighting (hat) function w(k) that decays to zero at both ends of the pixel value range,\nw(z) =\n(\nz −zmin\nz ≤(zmin + zmax)/2\nzmax −z\nz > (zmin + zmax)/2.\n(10.7)\nPutting all of these terms together, they obtain a least squares problem in the unknowns\n{gk} and {Ei},\nE =\nX\ni\nX\nj\nw(zi,j)[g(zi,j) −log Ei −log tj]2 + λ\nX\nk\nw(k)g′′(k)2.\n(10.8)\n(In order to remove the overall shift ambiguity in the response curve and irradiance values,\nthe middle of the response curve is set to 0.) Debevec and Malik (1997) show how this can\nbe implemented in 21 lines of MATLAB code, which partially accounts for the popularity of\ntheir technique.\nWhile Debevec and Malik (1997) assume that the exposure times tj are known exactly,\nthere is no reason why these additional variables cannot be thrown into the least squares\nproblem, constraining their ﬁnal estimated values to lie close to their nominal values ˆtj with\nan extra term η P\nj(tj −ˆtj)2.\n10.2 High dynamic range imaging\n483\n(a)\n(b)\nFigure 10.14\nRecovered response function and radiance image for a real digital camera\n(DCS460) (Debevec and Malik 1997) c⃝1997 ACM.\nFigure 10.14 shows the recovered radiometric response function for a digital camera along\nwith select (relative) radiance values in the overall radiance map. Figure 10.15 shows the\nbracketed input images captured on color ﬁlm and the corresponding radiance map.\nWhile Debevec and Malik (1997) use a general second-order smooth curve g to parame-\nterize their response curve, Mann and Picard (1995) use a three-parameter function\nf(E) = α + βEγ,\n(10.9)\nwhile Mitsunaga and Nayar (1999) use a low-order (N ≤10) polynomial for the inverse\nresponse function g. Pal, Szeliski, Uyttendaele et al. (2004) derive a Bayesian model that\nestimates an independent smooth response function for each image, which can better model\nthe more sophisticated (and hence less predictable) automatic contrast and tone adjustment\nperformed in today’s digital cameras.\nOnce the response function has been estimated, the second step in creating high dynamic\nrange photographs is to merge the input images into a composite radiance map. If the re-\nsponse function and images were known exactly, i.e., if they were noise free, you could use\nany non-saturated pixel value to estimate the corresponding radiance by mapping it through\nthe inverse response curve E = g(z).\nUnfortunately, pixels are noisy, especially under low-light conditions when fewer photons\narrive at the sensor. To compensate for this, Mann and Picard (1995) use the derivative of\nthe response function as a weight in determining the ﬁnal radiance estimate, since “ﬂatter”\nregions of the curve tell us less about the incoming irradiance. Debevec and Malik (1997)\nuse a hat function (10.7) which accentuates mid-tone pixels while avoiding saturated values.\nMitsunaga and Nayar (1999) show that in order to maximize the signal-to-noise ratio (SNR),\n484\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.15\nBracketed set of exposures captured with a ﬁlm camera and the resulting\nradiance image displayed in pseudocolor (Debevec and Malik 1997) c⃝1997 ACM.\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 10.16\nMerging multiple exposures to create a high dynamic range composite (Kang,\nUyttendaele, Winder et al. 2003): (a–c) three different exposures; (d) merging the exposures\nusing classic algorithms (note the ghosting due to the horse’s head movement); (e) merging\nthe exposures with motion compensation.",
  "image_path": "page_505.jpg",
  "pages": [
    504,
    505,
    506
  ]
}