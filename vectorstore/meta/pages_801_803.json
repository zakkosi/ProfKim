{
  "doc_id": "pages_801_803",
  "text": "C.1 Data sets\n779\nChapter 5: Segmentation\nBerkeley Segmentation Dataset and Benchmark of 1000 images labeled by 30 humans,\nalong with an evaluation, http://www.eecs.berkeley.edu/Research/Projects/CS/vision/\ngrouping/segbench/ (Martin, Fowlkes, Tal et al. 2001).\nWeizmann segmentation evaluation database of 100 grayscale images with ground\ntruth segmentations, http://www.wisdom.weizmann.ac.il/∼vision/Seg Evaluation DB/\nindex.html (Alpert, Galun, Basri et al. 2007).\nChapter 8: Dense motion estimation\nThe Middlebury optic ﬂow evaluation Web site, http://vision.middlebury.edu/ﬂow/data\n(Baker, Scharstein, Lewis et al. 2009).\nThe Human-Assisted Motion Annotation database,\nhttp://people.csail.mit.edu/celiu/motionAnnotation/ (Liu, Freeman, Adelson et al. 2008)\nChapter 10: Computational photography\nHigh Dynamic Range radiance maps, http://www.debevec.org/Research/HDR/ (De-\nbevec and Malik 1997).\nAlpha matting evaluation Web site, http://alphamatting.com/ (Rhemann, Rother, Wang\net al. 2009).\nChapter 11: Stereo correspondence\nMiddlebury Stereo Datasets and Evaluation, http://vision.middlebury.edu/stereo/ (Scharstein\nand Szeliski 2002).\nStereo Classiﬁcation and Performance Evaluation of different aggregation costs for\nstereo matching, http://www.vision.deis.unibo.it/spe/SPEHome.aspx (Tombari, Mat-\ntoccia, Di Stefano et al. 2008).\nMiddlebury Multi-View Stereo Datasets, http://vision.middlebury.edu/mview/data/ (Seitz,\nCurless, Diebel et al. 2006).\nMulti-view and Oxford Colleges building reconstructions, http://www.robots.ox.ac.uk/\n∼vgg/data/data-mview.html.\nMulti-View Stereo Datasets, http://cvlab.epﬂ.ch/data/strechamvs/ (Strecha, Fransens,\nand Van Gool 2006).\n780\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nMulti-View Evaluation, http://cvlab.epﬂ.ch/∼strecha/multiview/ (Strecha, von Hansen,\nVan Gool et al. 2008).\nChapter 12: 3D reconstruction\nHumanEva: synchronized video and motion capture dataset for evaluation of artic-\nulated human motion, http://vision.cs.brown.edu/humaneva/ (Sigal, Balan, and Black\n2010).\nChapter 13: Image-based rendering\nThe (New) Stanford Light Field Archive, http://lightﬁeld.stanford.edu/ (Wilburn, Joshi,\nVaish et al. 2005).\nVirtual Viewpoint Video: multi-viewpoint video with per-frame depth maps, http:\n//research.microsoft.com/en-us/um/redmond/groups/ivm/vvv/ (Zitnick, Kang, Uytten-\ndaele et al. 2004).\nChapter 14: Recognition\nFor a list of visual recognition datasets, see Tables 14.1–14.2. In addition to those,\nthere are also:\nBuffy pose classes, http://www.robots.ox.ac.uk/∼vgg/data/buffy pose classes/ and Buffy\nstickmen V2.1, http://www.robots.ox.ac.uk/∼vgg/data/stickmen/index.html (Ferrari, Marin-\nJimenez, and Zisserman 2009; Eichner and Ferrari 2009).\nH3D database of pose/joint annotated photographs of humans, http://www.eecs.berkeley.\nedu/∼lbourdev/h3d/ (Bourdev and Malik 2009).\nAction Recognition Datasets, http://www.cs.berkeley.edu/projects/vision/action, has point-\ners to several datasets for action and activity recognition, as well as some papers. The\nhuman action database at http://www.nada.kth.se/cvap/actions/ contains more action\nsequences.\nC.2 Software\nOne of the best sources for computer vision algorithms is the Open Source Computer Vision\n(OpenCV) library (http://opencv.willowgarage.com/wiki/), which was developed by Gary\nBradski and his colleagues at Intel and is now being maintained and extended at Willow\nGarage (Bradsky and Kaehler 2008). A partial list of the available functions, taken from\nhttp://opencv.willowgarage.com/documentation/cpp/ includes:\nC.2 Software\n781\n• image processing and transforms (ﬁltering, morphology, pyramids);\n• geometric image transformations (rotations, resizing);\n• miscellaneous image transformations (Fourier transforms, distance transforms);\n• histograms;\n• segmentation (watershed, mean shift);\n• feature detection (Canny, Harris, Hough, MSER, SURF);\n• motion analysis and object tracking (Lucas–Kanade, mean shift);\n• camera calibration and 3D reconstruction;\n• machine learning (k nearest neighbors, support vector machines, decision trees, boost-\ning, random trees, expectation-maximization, and neural networks).\nThe Intel Performance Primitives (IPP) library, http://software.intel.com/en-us/intel-ipp/,\ncontains highly optimized code for a variety of image processing tasks. Many of the routines\nin OpenCV take advantage of this library, if it is installed, to run even faster. In terms of\nfunctionality, it has many of the same operators as those found in OpenCV, plus additional\nlibraries for image and video compression, signal and speech processing, and matrix algebra.\nThe MATLAB Image Processing Toolbox, http://www.mathworks.com/products/image/,\ncontains routines for spatial transformations (rotations, resizing), normalized cross-correla-\ntion, image analysis and statistics (edges, Hough transform), image enhancement (adaptive\nhistogram equalization, median ﬁltering) and restoration (deblurring), linear ﬁltering (con-\nvolution), image transforms (Fourier and DCT), and morphological operations (connected\ncomponents and distance transforms).\nTwo older libraries, which no longer appear to be under active development but contain\nmany useful routines, are VXL (C++ Libraries for Computer Vision Research and Implemen-\ntation, http://vxl.sourceforge.net/) and LTI-Lib 2 (http://www.ie.itcr.ac.cr/palvarado/ltilib-2/\nhomepage/).\nPhoto editing and viewing packages, such as Windows Live Photo Gallery, iPhoto, Picasa,\nGIMP, and IrfanView, can be useful for performing common processing tasks, converting for-\nmats, and viewing your results. They can also serve as interesting reference implementations\nfor image processing algorithms (such as tone correction or denoising) that you are trying to\ndevelop from scratch.\nThere are also software packages and infrastructure that can be helpful for building real-\ntime video processing demos. Vision on Tap (http://www.visionontap.com/) provides a Web",
  "image_path": "page_802.jpg",
  "pages": [
    801,
    802,
    803
  ]
}