{
  "doc_id": "pages_263_265",
  "text": "4.2 Edges\n241\nIn fact, it is not strictly necessary to take differences between adjacent levels when com-\nputing the edge ﬁeld. Think about what a zero crossing in a “generalized” difference of\nGaussians image represents. The ﬁner (smaller kernel) Gaussian is a noise-reduced version\nof the original image. The coarser (larger kernel) Gaussian is an estimate of the average in-\ntensity over a larger region. Thus, whenever the DoG image changes sign, this corresponds\nto the (slightly blurred) image going from relatively darker to relatively lighter, as compared\nto the average intensity in that neighborhood.\nOnce we have computed the sign function S(x), we must ﬁnd its zero crossings and\nconvert these into edge elements (edgels). An easy way to detect and represent zero crossings\nis to look for adjacent pixel locations xi and xj where the sign changes value, i.e., [S(xi) >\n0] ̸= [S(xj) > 0].\nThe sub-pixel location of this crossing can be obtained by computing the “x-intercept” of\nthe “line” connecting S(xi) and S(xj),\nxz = xiS(xj) −xjS(xi)\nS(xj) −S(xi)\n.\n(4.25)\nThe orientation and strength of such edgels can be obtained by linearly interpolating the\ngradient values computed on the original pixel grid.\nAn alternative edgel representation can be obtained by linking adjacent edgels on the\ndual grid to form edgels that live inside each square formed by four adjacent pixels in the\noriginal pixel grid.5 The (potential) advantage of this representation is that the edgels now\nlive on a grid offset by half a pixel from the original pixel grid and are thus easier to store\nand access.\nAs before, the orientations and strengths of the edges can be computed by\ninterpolating the gradient ﬁeld or estimating these values from the difference of Gaussian\nimage (see Exercise 4.7).\nIn applications where the accuracy of the edge orientation is more important, higher-order\nsteerable ﬁlters can be used (Freeman and Adelson 1991) (see Section 3.2.3). Such ﬁlters are\nmore selective for more elongated edges and also have the possibility of better modeling curve\nintersections because they can represent multiple orientations at the same pixel (Figure 3.16).\nTheir disadvantage is that they are more expensive to compute and the directional derivative\nof the edge strength does not have a simple closed form solution.6\n242\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 4.32\nScale selection for edge detection (Elder and Zucker 1998) c⃝1998 IEEE:\n(a) original image; (b–c) Canny/Deriche edge detector tuned to the ﬁner (mannequin) and\ncoarser (shadow) scales; (d) minimum reliable scale for gradient estimation; (e) minimum\nreliable scale for second derivative estimation; (f) ﬁnal detected edges.\nScale selection and blur estimation\nAs we mentioned before, the derivative, Laplacian, and Difference of Gaussian ﬁlters (4.20–\n4.23) all require the selection of a spatial scale parameter σ. If we are only interested in\ndetecting sharp edges, the width of the ﬁlter can be determined from image noise characteris-\ntics (Canny 1986; Elder and Zucker 1998). However, if we want to detect edges that occur at\ndifferent resolutions (Figures 4.32b–c), a scale-space approach that detects and then selects\nedges at different scales may be necessary (Witkin 1983; Lindeberg 1994, 1998a; Nielsen,\nFlorack, and Deriche 1997).\nElder and Zucker (1998) present a principled approach to solving this problem. Given\na known image noise level, their technique computes, for every pixel, the minimum scale\nat which an edge can be reliably detected (Figure 4.32d). Their approach ﬁrst computes\n5 This algorithm is a 2D version of the 3D marching cubes isosurface extraction algorithm (Lorensen and Cline\n1987).\n6 In fact, the edge orientation can have a 180◦ambiguity for “bar edges”, which makes the computation of zero\ncrossings in the derivative more tricky.\n4.2 Edges\n243\ngradients densely over an image by selecting among gradient estimates computed at different\nscales, based on their gradient magnitudes. It then performs a similar estimate of minimum\nscale for directed second derivatives and uses zero crossings of this latter quantity to robustly\nselect edges (Figures 4.32e–f). As an optional ﬁnal step, the blur width of each edge can\nbe computed from the distance between extrema in the second derivative response minus the\nwidth of the Gaussian ﬁlter.\nColor edge detection\nWhile most edge detection techniques have been developed for grayscale images, color im-\nages can provide additional information. For example, noticeable edges between iso-luminant\ncolors (colors that have the same luminance) are useful cues but fail to be detected by grayscale\nedge operators.\nOne simple approach is to combine the outputs of grayscale detectors run on each color\nband separately.7 However, some care must be taken. For example, if we simply sum up\nthe gradients in each of the color bands, the signed gradients may actually cancel each other!\n(Consider, for example a pure red-to-green edge.) We could also detect edges independently\nin each band and then take the union of these, but this might lead to thickened or doubled\nedges that are hard to link.\nA better approach is to compute the oriented energy in each band (Morrone and Burr\n1988; Perona and Malik 1990a), e.g., using a second-order steerable ﬁlter (Section 3.2.3)\n(Freeman and Adelson 1991), and then sum up the orientation-weighted energies and ﬁnd\ntheir joint best orientation. Unfortunately, the directional derivative of this energy may not\nhave a closed form solution (as in the case of signed ﬁrst-order steerable ﬁlters), so a simple\nzero crossing-based strategy cannot be used. However, the technique described by Elder and\nZucker (1998) can be used to compute these zero crossings numerically instead.\nAn alternative approach is to estimate local color statistics in regions around each pixel\n(Ruzon and Tomasi 2001; Martin, Fowlkes, and Malik 2004). This has the advantage that\nmore sophisticated techniques (e.g., 3D color histograms) can be used to compare regional\nstatistics and that additional measures, such as texture, can also be considered. Figure 4.33\nshows the output of such detectors.\nOf course, many other approaches have been developed for detecting color edges, dating\nback to early work by Nevatia (1977). Ruzon and Tomasi (2001) and Gevers, van de Weijer,\nand Stokman (2006) provide good reviews of these approaches, which include ideas such as\nfusing outputs from multiple channels, using multidimensional gradients, and vector-based\n7 Instead of using the raw RGB space, a more perceptually uniform color space such as L*a*b* (see Section 2.3.2)\ncan be used instead. When trying to match human performance (Martin, Fowlkes, and Malik 2004), this makes sense.\nHowever, in terms of the physics of the underlying image formation and sensing, it may be a questionable strategy.",
  "image_path": "page_264.jpg",
  "pages": [
    263,
    264,
    265
  ]
}