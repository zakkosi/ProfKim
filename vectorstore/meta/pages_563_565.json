{
  "doc_id": "pages_563_565",
  "text": "11.1 Epipolar geometry\n541\nVirtual camera\nd\nx\ny\nInput  image k\nu\nv\nHomography:\n  u = H x\nx\ny\nk\nd\nk\n(a)\n(b)\nFigure 11.6 Sweeping a set of planes through a scene (Szeliski and Golland 1999) c⃝1999\nSpringer: (a) The set of planes seen from a virtual camera induces a set of homographies in\nany other source (input) camera image. (b) The warped images from all the other cameras can\nbe stacked into a generalized disparity space volume ˜I(x, y, d, k) indexed by pixel location\n(x, y), disparity d, and camera k.\n1997)), the last row of a full-rank 4 × 4 projection matrix ˜\nP can be set to an arbitrary plane\nequation p3 = s3[ˆn0|c0]. The resulting four-dimensional projective transform (collineation)\n(2.68) maps 3D world points p = (X, Y, Z, 1) into screen coordinates xs = (xs, ys, 1, d),\nwhere the projective depth (or parallax) d (2.66) is 0 on the reference plane (Figure 2.11).\nSweeping d through a series of disparity hypotheses, as shown in Figure 11.6a, corre-\nsponds to mapping each input image into the virtual camera ˜\nP deﬁning the disparity space\nthrough a series of homographies (2.68–2.71),\n˜xk ∼˜\nP k ˜\nP\n−1xs = ˜\nHk˜x + tkd = ( ˜\nHk + tk[0 0 d])˜x,\n(11.3)\nas shown in Figure 2.12b, where ˜xk and ˜x are the homogeneous pixel coordinates in the\nsource and virtual (reference) images (Szeliski and Golland 1999). The members of the fam-\nily of homographies ˜\nHk(d) = ˜\nHk + tk[0 0 d], which are parametererized by the addition of\na rank-1 matrix, are related to each other through a planar homology (Hartley and Zisserman\n2004, A5.2).\nThe choice of virtual camera and parameterization is application dependent and is what\ngives this framework a lot of its ﬂexibility. In many applications, one of the input cameras\n(the reference camera) is used, thus computing a depth map that is registered with one of the\ninput images and which can later be used for image-based rendering (Sections 13.1 and 13.2).\nIn other applications, such as view interpolation for gaze correction in video-conferencing\n542\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Section 11.4.2) (Ott, Lewis, and Cox 1993; Criminisi, Shotton, Blake et al. 2003), a camera\ncentrally located between the two input cameras is preferable, since it provides the needed\nper-pixel disparities to hallucinate the virtual middle image.\nThe choice of disparity sampling, i.e., the setting of the zero parallax plane and the scaling\nof integer disparities, is also application dependent, and is usually set to bracket the range of\ninterest, i.e., the working volume, while scaling disparities to sample the image in pixel (or\nsub-pixel) shifts. For example, when using stereo vision for obstacle avoidance in robot\nnavigation, it is most convenient to set up disparity to measure per-pixel elevation above the\nground (Ivanchenko, Shen, and Coughlan 2009).\nAs each input image is warped onto the current planes parameterized by disparity d, it\ncan be stacked into a generalized disparity space image ˜I(x, y, d, k) for further processing\n(Figure 11.6b) (Szeliski and Golland 1999). In most stereo algorithms, the photoconsistency\n(e.g., sum of squared or robust differences) with respect to the reference image Ir is calculated\nand stored in the DSI\nC(x, y, d) =\nX\nk\nρ(˜I(x, y, d, k) −Ir(x, y)).\n(11.4)\nHowever, it is also possible to compute alternative statistics such as robust variance, focus,\nor entropy (Section 11.3.1) (Vaish, Szeliski, Zitnick et al. 2006) or to use this representation\nto reason about occlusions (Szeliski and Golland 1999; Kang and Szeliski 2004). The gen-\neralized DSI will come in particularly handy when we come back to the topic of multi-view\nstereo in Section 11.6.\nOf course, planes are not the only surfaces that can be used to deﬁne a 3D sweep through\nthe space of interest. Cylindrical surfaces, especially when coupled with panoramic photog-\nraphy (Chapter 9), are often used (Ishiguro, Yamamoto, and Tsuji 1992; Kang and Szeliski\n1997; Shum and Szeliski 1999; Li, Shum, Tang et al. 2004; Zheng, Kang, Cohen et al. 2007).\nIt is also possible to deﬁne other manifold topologies, e.g., ones where the camera rotates\naround a ﬁxed axis (Seitz 2001).\nOnce the DSI has been computed, the next step in most stereo correspondence algorithms\nis to produce a univalued function in disparity space d(x, y) that best describes the shape of\nthe surfaces in the scene. This can be viewed as ﬁnding a surface embedded in the disparity\nspace image that has some optimality property, such as lowest cost and best (piecewise)\nsmoothness (Yang, Yuille, and Lu 1993). Figure 11.5 shows examples of slices through a\ntypical DSI. More ﬁgures of this kind can be found in the paper by Bobick and Intille (1999).\n11.2 Sparse correspondence\n543\n11.2 Sparse correspondence\nEarly stereo matching algorithms were feature-based, i.e., they ﬁrst extracted a set of poten-\ntially matchable image locations, using either interest operators or edge detectors, and then\nsearched for corresponding locations in other images using a patch-based metric (Hannah\n1974; Marr and Poggio 1979; Mayhew and Frisby 1980; Baker and Binford 1981; Arnold\n1983; Grimson 1985; Ohta and Kanade 1985; Bolles, Baker, and Marimont 1987; Matthies,\nKanade, and Szeliski 1989; Hsieh, McKeown, and Perlant 1992; Bolles, Baker, and Hannah\n1993). This limitation to sparse correspondences was partially due to computational resource\nlimitations, but was also driven by a desire to limit the answers produced by stereo algorithms\nto matches with high certainty. In some applications, there was also a desire to match scenes\nwith potentially very different illuminations, where edges might be the only stable features\n(Collins 1996). Such sparse 3D reconstructions could later be interpolated using surface ﬁt-\nting algorithms such as those discussed in Sections 3.7.1 and 12.3.1.\nMore recent work in this area has focused on ﬁrst extracting highly reliable features and\nthen using these as seeds to grow additional matches (Zhang and Shan 2000; Lhuillier and\nQuan 2002). Similar approaches have also been extended to wide baseline multi-view stereo\nproblems and combined with 3D surface reconstruction (Lhuillier and Quan 2005; Strecha,\nTuytelaars, and Van Gool 2003; Goesele, Snavely, Curless et al. 2007) or free-space reasoning\n(Taylor 2003), as described in more detail in Section 11.6.\n11.2.1 3D curves and proﬁles\nAnother example of sparse correspondence is the matching of proﬁle curves (or occluding\ncontours), which occur at the boundaries of objects (Figure 11.7) and at interior self occlu-\nsions, where the surface curves away from the camera viewpoint.\nThe difﬁculty in matching proﬁle curves is that in general, the locations of proﬁle curves\nvary as a function of camera viewpoint. Therefore, matching curves directly in two images\nand then triangulating these matches can lead to erroneous shape measurements. Fortunately,\nif three or more closely spaced frames are available, it is possible to ﬁt a local circular arc to\nthe locations of corresponding edgels (Figure 11.7a) and therefore obtain semi-dense curved\nsurface meshes directly from the matches (Figures 11.7c and g). Another advantage of match-\ning such curves is that they can be used to reconstruct surface shape for untextured surfaces,\nso long as there is a visible difference between foreground and background colors.\nOver the years, a number of different techniques have been developed for reconstructing\nsurface shape from proﬁle curves (Giblin and Weiss 1987; Cipolla and Blake 1992; Vaillant\nand Faugeras 1992; Zheng 1994; Boyer and Berger 1997; Szeliski and Weiss 1998). Cipolla\nand Giblin (2000) describe many of these techniques, as well as related topics such as in-",
  "image_path": "page_564.jpg",
  "pages": [
    563,
    564,
    565
  ]
}