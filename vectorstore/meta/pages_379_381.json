{
  "doc_id": "pages_379_381",
  "text": "7.3 Factorization\n357\na deeper or shallower reconstruction, which is an example of a bas-relief ambiguity (Sec-\ntion 7.4.3).) Hartley and Zisserman (2004) recommend using techniques based on three or\nmore frames. However, if you ﬁnd two images for which the estimates of (f 2\n0 , λf 2\n1 , λ) are\nwell conditioned, they can be used to initialize a more complete bundle adjustment of all\nthe parameters (Section 7.4). An alternative, which is often used in systems such as Photo\nTourism, is to use camera EXIF tags or generic default values to initialize focal length esti-\nmates and reﬁne them as part of bundle adjustment.\n7.2.3 Application: View morphing\nAn interesting application of basic two-frame structure from motion is view morphing (also\nknown as view interpolation, see Section 13.1), which can be used to generate a smooth 3D\nanimation from one view of a 3D scene to another (Chen and Williams 1993; Seitz and Dyer\n1996).\nTo create such a transition, you must ﬁrst smoothly interpolate the camera matrices, i.e.,\nthe camera positions, orientations, and focal lengths. While simple linear interpolation can be\nused (representing rotations as quaternions (Section 2.1.4)), a more pleasing effect is obtained\nby easing in and easing out the camera parameters, e.g., using a raised cosine, as well as\nmoving the camera along a more circular trajectory (Snavely, Seitz, and Szeliski 2006).\nTo generate in-between frames, either a full set of 3D correspondences needs to be es-\ntablished (Section 11.3) or 3D models (proxies) must be created for each reference view.\nSection 13.1 describes several widely used approaches to this problem. One of the simplest\nis to just triangulate the set of matched feature points in each image, e.g., using Delaunay\ntriangulation. As the 3D points are re-projected into their intermediate views, pixels can be\nmapped from their original source images to their new views using afﬁne or projective map-\nping (Szeliski and Shum 1997). The ﬁnal image is then composited using a linear blend of\nthe two reference images, as with usual morphing (Section 3.6.3).\n7.3 Factorization\nWhen processing video sequences, we often get extended feature tracks (Section 4.1.4) from\nwhich it is possible to recover the structure and motion using a process called factorization.\nConsider the tracks generated by a rotating ping pong ball, which has been marked with\ndots to make its shape and motion more discernable (Figure 7.5). We can readily see from\nthe shape of the tracks that the moving object must be a sphere, but how can we infer this\nmathematically?\nIt turns out that, under orthography or related models we discuss below, the shape and\nmotion can be recovered simultaneously using a singular value decomposition (Tomasi and\n358\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 7.5\n3D reconstruction of a rotating ping pong ball using factorization (Tomasi and\nKanade 1992) c⃝1992 Springer: (a) sample image with tracked features overlaid; (b) sub-\nsampled feature motion stream; (c) two views of the reconstructed 3D model.\nKanade 1992). Consider the orthographic and weak perspective projection models introduced\nin Equations (2.47–2.49). Since the last row is always [0 0 0 1], there is no perspective division\nand we can write\nxji = ˜\nP j ¯pi,\n(7.40)\nwhere xji is the location of the ith point in the jth frame, ˜\nP j is the upper 2 × 4 portion of\nthe projection matrix P j, and ¯pi = (Xi, Yi, Zi, 1) is the augmented 3D point position.10\nLet us assume (for now) that every point i is visible in every frame j. We can take the\ncentroid (average) of the projected point locations xji in frame j,\n¯xj = 1\nN\nX\ni\nxji = ˜\nP j\n1\nN\nX\ni\n¯pi = ˜\nP j¯c,\n(7.41)\nwhere ¯c = ( ¯X, ¯Y , ¯Z, 1) is the augmented 3D centroid of the point cloud.\nSince world coordinate frames in structure from motion are always arbitrary, i.e., we\ncannot recover true 3D locations without ground control points (known measurements), we\ncan place the origin of the world at the centroid of the points, i.e, ¯X = ¯Y = ¯Z = 0, so that\n¯c = (0, 0, 0, 1). We see from this that the centroid of the 2D points in each frame ¯xj directly\ngives us the last element of ˜\nP j.\nLet ˜xji = xji −¯xj be the 2D point locations after their image centroid has been sub-\ntracted. We can now write\n˜xji = M jpi,\n(7.42)\n10 In this section, we index the 2D point positions as xji instead of xij, since this is the convention adopted by\nfactorization papers (Tomasi and Kanade 1992) and is consistent with the factorization given in (7.43).\n7.3 Factorization\n359\nwhere M j is the upper 2 × 3 portion of the projection matrix P j and pi = (Xi, Yi, Zi). We\ncan concatenate all of these measurement equations into one large matrix\nˆ\nX =\n\n\n˜x11 · · · ˜x1i · · · ˜x1N\n...\n...\n...\n˜xj1 · · · ˜xji · · · ˜xjN\n...\n...\n...\n˜xM1 · · · ˜xMi · · · ˜xMN\n\n\n=\n\n\nM 1\n...\nM j\n...\nM M\n\n\nh\np1 · · · pi · · · pN\ni\n= ˆ\nM ˆS.\n(7.43)\nˆ\nX is called the measurement matrix and ˆ\nM and ( ˆS are the motion) and structure matrices,\nrespectively (Tomasi and Kanade 1992).\nBecause the motion matrix ˆ\nM is 2M × 3 and the structure matrix ˆS is 3 × N, an SVD\napplied to ˆ\nX has only three non-zero singular values. In the case where the measurements in\nˆ\nX are noisy, SVD returns the rank-three factorization of ˆ\nX that is the closest to ˆ\nX in a least\nsquares sense (Tomasi and Kanade 1992; Golub and Van Loan 1996; Hartley and Zisserman\n2004).\nIt would be nice if the SVD of ˆ\nX = UΣV T directly returned the matrices ˆ\nM and ˆS,\nbut it does not. Instead, we can write the relationship\nˆ\nX = UΣV T = [UQ][Q−1ΣV T ]\n(7.44)\nand set ˆ\nM = UQ and ˆS = Q−1ΣV T .11\nHow can we recover the values of the 3×3 matrix Q? This depends on the motion model\nbeing used. In the case of orthographic projection (2.47), the entries in M j are the ﬁrst two\nrows of rotation matrices Rj, so we have\nmj0 · mj0 =\nu2jQQT uT\n2j\n= 1,\nmj0 · mj1 =\nu2jQQT uT\n2j+1\n= 0,\nmj1 · mj1 =\nu2j+1QQT uT\n2j+1\n= 1,\n(7.45)\nwhere uk are the 3 × 1 rows of the matrix U. This gives us a large set of equations for the\nentries in the matrix QQT , from which the matrix Q can be recovered using a matrix square\nroot (Appendix A.1.4). If we have scaled orthography (2.48), i.e., M j = sjRj, the ﬁrst and\nthird equations are equal to sj and can be set equal to each other.\nNote that even once Q has been recovered, there still exists a bas-relief ambiguity, i.e.,\nwe can never be sure if the object is rotating left to right or if its depth reversed version is\nmoving the other way. (This can be seen in the classic rotating Necker Cube visual illusion.)\n11 Tomasi and Kanade (1992) ﬁrst take the square root of Σ and distribute this to U and V , but there is no\nparticular reason to do this.",
  "image_path": "page_380.jpg",
  "pages": [
    379,
    380,
    381
  ]
}