{
  "doc_id": "pages_602_604",
  "text": "580\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(FG), the IEEE Workshop on Analysis and Modeling of Faces and Gestures, and the Interna-\ntional Workshop on Tracking Humans for the Evaluation of their Motion in Image Sequences\n(THEMIS).\n12.1 Shape from X\nIn addition to binocular disparity, shading, texture, and focus all play a role in how we per-\nceive shape. The study of how shape can be inferred from such cues is sometimes called\nshape from X, since the individual instances are called shape from shading, shape from tex-\nture, and shape from focus.1 In this section, we look at these three cues and how they can\nbe used to reconstruct 3D geometry. A good overview of all these topics can be found in the\ncollection of papers on physics-based shape inference edited by Wolff, Shafer, and Healey\n(1992b).\n12.1.1 Shape from shading and photometric stereo\nWhen you look at images of smooth shaded objects, such as the ones shown in Figure 12.2,\nyou can clearly see the shape of the object from just the shading variation. How is this\npossible? The answer is that as the surface normal changes across the object, the apparent\nbrightness changes as a function of the angle between the local surface orientation and the\nincident illumination, as shown in Figure 2.15 (Section 2.2.2).\nThe problem of recovering the shape of a surface from this intensity variation is known as\nshape from shading and is one of the classic problems in computer vision (Horn 1975). The\ncollection of papers edited by Horn and Brooks (1989) is a great source of information on\nthis topic, especially the chapter on variational approaches. The survey by Zhang, Tsai, Cryer\net al. (1999) not only reviews more recent techniques, but also provides some comparative\nresults.\nMost shape from shading algorithms assume that the surface under consideration is of a\nuniform albedo and reﬂectance, and that the light source directions are either known or can\nbe calibrated by the use of a reference object. Under the assumptions of distant light sources\nand observer, the variation in intensity (irradiance equation) become purely a function of the\nlocal surface orientation,\nI(x, y) = R(p(x, y), q(x, y)),\n(12.1)\nwhere (p, q) = (zx, zy) are the depth map derivatives and R(p, q) is called the reﬂectance\nmap. For example, a diffuse (Lambertian) surface has a reﬂectance map that is the (non-\n1 We have already seen examples of shape from stereo, shape from proﬁles, and shape from silhouettes in Chap-\nter 11.\n12.1 Shape from X\n581\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 12.2 Synthetic shape from shading (Zhang, Tsai, Cryer et al. 1999) c⃝1999 IEEE:\nshaded images, (a–b) with light from in front (0, 0, 1) and (c–d) with light the front right\n(1, 0, 1); (e–f) corresponding shape from shading reconstructions using the technique of Tsai\nand Shah (1994).\nnegative) dot product (2.88) between the surface normal ˆn = (p, q, 1)/\np\n1 + p2 + q2 and\nthe light source direction v = (vx, vy, vz),\nR(p, q) = max\n \n0, ρpvx + qvy + vz\np\n1 + p2 + q2\n!\n,\n(12.2)\nwhere ρ is the surface reﬂectance factor (albedo).\nIn principle, Equations (12.1–12.2) can be used to estimate (p, q) using non-linear least\nsquares or some other method. Unfortunately, unless additional constraints are imposed, there\nare more unknowns per pixel (p, q) than there are measurements (I). One commonly used\nconstraint is the smoothness constraint,\nEs =\nZ\np2\nx + p2\ny + q2\nx + q2\ny dx dy =\nZ\n∥∇p∥2 + ∥∇q∥2 dx dy,\n(12.3)\nwhich we already saw in Section 3.7.1 (3.94). The other is the integrability constraint,\nEi =\nZ\n(py −qx)2 dx dy,\n(12.4)\n582\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nwhich arises naturally, since for a valid depth map z(x, y) with (p, q) = (zx, zy), we have\npy = zxy = zyx = qx.\nInstead of ﬁrst recovering the orientation ﬁelds (p, q) and integrating them to obtain a\nsurface, it is also possible to directly minimize the discrepancy in the image formation equa-\ntion (12.1) while ﬁnding the optimal depth map z(x, y) (Horn 1990). Unfortunately, shape\nfrom shading is susceptible to local minima in the search space and, like other variational\nproblems that involve the simultaneous estimation of many variables, can also suffer from\nslow convergence. Using multi-resolution techniques (Szeliski 1991a) can help accelerate\nthe convergence, while using more sophisticated optimization techniques (Dupuis and Olien-\nsis 1994) can help avoid local minima.\nIn practice, surfaces other than plaster casts are rarely of a single uniform albedo. Shape\nfrom shading therefore needs to be combined with some other technique or extended in some\nway to make it useful. One way to do this is to combine it with stereo matching (Fua and\nLeclerc 1995) or known texture (surface patterns) (White and Forsyth 2006). The stereo and\ntexture components provide information in textured regions, while shape from shading helps\nﬁll in the information across uniformly colored regions and also provides ﬁner information\nabout surface shape.\nPhotometric stereo.\nAnother way to make shape from shading more reliable is to use mul-\ntiple light sources that can be selectively turned on and off. This technique is called photo-\nmetric stereo, since the light sources play a role analogous to the cameras located at different\nlocations in traditional stereo (Woodham 1981).2 For each light source, we have a differ-\nent reﬂectance map, R1(p, q), R2(p, q), etc. Given the corresponding intensities I1, I2, etc.\nat a pixel, we can in principle recover both an unknown albedo ρ and a surface orientation\nestimate (p, q).\nFor diffuse surfaces (12.2), if we parameterize the local orientation by ˆn, we get (for\nnon-shadowed pixels) a set of linear equations of the form\nIk = ρˆn · vk,\n(12.5)\nfrom which we can recover ρˆn using linear least squares. These equations are well condi-\ntioned as long as the (three or more) vectors vk are linearly independent, i.e., they are not\nalong the same azimuth (direction away from the viewer).\nOnce the surface normals or gradients have been recovered at each pixel, they can be\nintegrated into a depth map using a variant of regularized surface ﬁtting (3.100). (Nehab,\nRusinkiewicz, Davis et al. (2005) and Harker and O’Leary (2008) have produced some recent\nwork in this area.)\n2 An alternative to turning lights on-and-off is to use three colored lights (Woodham 1994; Hernandez, Vogiatzis,\nBrostow et al. 2007; Hernandez and Vogiatzis 2010).",
  "image_path": "page_603.jpg",
  "pages": [
    602,
    603,
    604
  ]
}