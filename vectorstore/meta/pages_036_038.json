{
  "doc_id": "pages_036_038",
  "text": "14\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.8 Examples of computer vision algorithms from the 1980s: (a) pyramid blending\n(Burt and Adelson 1983b) c⃝1983 ACM, (b) shape from shading (Freeman and Adelson\n1991) c⃝1991 IEEE, (c) edge detection (Freeman and Adelson 1991) c⃝1991 IEEE, (d)\nphysically based models (Terzopoulos and Witkin 1988) c⃝1988 IEEE, (e) regularization-\nbased surface reconstruction (Terzopoulos 1988) c⃝1988 IEEE, (f) range data acquisition\nand merging (Banno, Masuda, Oishi et al. 2008) c⃝2008 Springer.\n(Adelson, Simoncelli, and Hingorani 1987; Mallat 1989; Simoncelli and Adelson 1990a,b;\nSimoncelli, Freeman, Adelson et al. 1992).\nThe use of stereo as a quantitative shape cue was extended by a wide variety of shape-\nfrom-X techniques, including shape from shading (Figure 1.8b) (see Section 12.1.1 and Horn\n1975; Pentland 1984; Blake, Zimmerman, and Knowles 1985; Horn and Brooks 1986, 1989),\nphotometric stereo (see Section 12.1.1 and Woodham 1981), shape from texture (see Sec-\ntion 12.1.2 and Witkin 1981; Pentland 1984; Malik and Rosenholtz 1997), and shape from\nfocus (see Section 12.1.3 and Nayar, Watanabe, and Noguchi 1995). Horn (1986) has a nice\ndiscussion of most of these techniques.\nResearch into better edge and contour detection (Figure 1.8c) (see Section 4.2) was also\nactive during this period (Canny 1986; Nalwa and Binford 1986), including the introduc-\ntion of dynamically evolving contour trackers (Section 5.1.1) such as snakes (Kass, Witkin,\nand Terzopoulos 1988), as well as three-dimensional physically based models (Figure 1.8d)\n(Terzopoulos, Witkin, and Kass 1987; Kass, Witkin, and Terzopoulos 1988; Terzopoulos and\nFleischer 1988; Terzopoulos, Witkin, and Kass 1988).\nResearchers noticed that a lot of the stereo, ﬂow, shape-from-X, and edge detection al-\n1.2 A brief history\n15\ngorithms could be uniﬁed, or at least described, using the same mathematical framework if\nthey were posed as variational optimization problems (see Section 3.7) and made more ro-\nbust (well-posed) using regularization (Figure 1.8e) (see Section 3.7.1 and Terzopoulos 1983;\nPoggio, Torre, and Koch 1985; Terzopoulos 1986b; Blake and Zisserman 1987; Bertero, Pog-\ngio, and Torre 1988; Terzopoulos 1988). Around the same time, Geman and Geman (1984)\npointed out that such problems could equally well be formulated using discrete Markov Ran-\ndom Field (MRF) models (see Section 3.7.2), which enabled the use of better (global) search\nand optimization algorithms, such as simulated annealing.\nOnline variants of MRF algorithms that modeled and updated uncertainties using the\nKalman ﬁlter were introduced a little later (Dickmanns and Graefe 1988; Matthies, Kanade,\nand Szeliski 1989; Szeliski 1989). Attempts were also made to map both regularized and\nMRF algorithms onto parallel hardware (Poggio and Koch 1985; Poggio, Little, Gamble\net al. 1988; Fischler, Firschein, Barnard et al. 1989). The book by Fischler and Firschein\n(1987) contains a nice collection of articles focusing on all of these topics (stereo, ﬂow,\nregularization, MRFs, and even higher-level vision).\nThree-dimensional range data processing (acquisition, merging, modeling, and recogni-\ntion; see Figure 1.8f) continued being actively explored during this decade (Agin and Binford\n1976; Besl and Jain 1985; Faugeras and Hebert 1987; Curless and Levoy 1996). The compi-\nlation by Kanade (1987) contains a lot of the interesting papers in this area.\n1990s.\nWhile a lot of the previously mentioned topics continued to be explored, a few of\nthem became signiﬁcantly more active.\nA burst of activity in using projective invariants for recognition (Mundy and Zisserman\n1992) evolved into a concerted effort to solve the structure from motion problem (see Chap-\nter 7). A lot of the initial activity was directed at projective reconstructions, which did not\nrequire knowledge of camera calibration (Faugeras 1992; Hartley, Gupta, and Chang 1992;\nHartley 1994a; Faugeras and Luong 2001; Hartley and Zisserman 2004). Simultaneously, fac-\ntorization techniques (Section 7.3) were developed to solve efﬁciently problems for which or-\nthographic camera approximations were applicable (Figure 1.9a) (Tomasi and Kanade 1992;\nPoelman and Kanade 1997; Anandan and Irani 2002) and then later extended to the perspec-\ntive case (Christy and Horaud 1996; Triggs 1996). Eventually, the ﬁeld started using full\nglobal optimization (see Section 7.4 and Taylor, Kriegman, and Anandan 1991; Szeliski and\nKang 1994; Azarbayejani and Pentland 1995), which was later recognized as being the same\nas the bundle adjustment techniques traditionally used in photogrammetry (Triggs, McLauch-\nlan, Hartley et al. 1999). Fully automated (sparse) 3D modeling systems were built using such\ntechniques (Beardsley, Torr, and Zisserman 1996; Schaffalitzky and Zisserman 2002; Brown\nand Lowe 2003; Snavely, Seitz, and Szeliski 2006).\nWork begun in the 1980s on using detailed measurements of color and intensity combined\n16\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.9 Examples of computer vision algorithms from the 1990s: (a) factorization-based\nstructure from motion (Tomasi and Kanade 1992) c⃝1992 Springer, (b) dense stereo match-\ning (Boykov, Veksler, and Zabih 2001), (c) multi-view reconstruction (Seitz and Dyer 1999)\nc⃝1999 Springer, (d) face tracking (Matthews, Xiao, and Baker 2007), (e) image segmenta-\ntion (Belongie, Fowlkes, Chung et al. 2002) c⃝2002 Springer, (f) face recognition (Turk and\nPentland 1991a).\nwith accurate physical models of radiance transport and color image formation created its own\nsubﬁeld known as physics-based vision. A good survey of the ﬁeld can be found in the three-\nvolume collection on this topic (Wolff, Shafer, and Healey 1992a; Healey and Shafer 1992;\nShafer, Healey, and Wolff 1992).\nOptical ﬂow methods (see Chapter 8) continued to be improved (Nagel and Enkelmann\n1986; Bolles, Baker, and Marimont 1987; Horn and Weldon Jr. 1988; Anandan 1989; Bergen,\nAnandan, Hanna et al. 1992; Black and Anandan 1996; Bruhn, Weickert, and Schn¨orr 2005;\nPapenberg, Bruhn, Brox et al. 2006), with (Nagel 1986; Barron, Fleet, and Beauchemin 1994;\nBaker, Black, Lewis et al. 2007) being good surveys. Similarly, a lot of progress was made\non dense stereo correspondence algorithms (see Chapter 11, Okutomi and Kanade (1993,\n1994); Boykov, Veksler, and Zabih (1998); Birchﬁeld and Tomasi (1999); Boykov, Veksler,\nand Zabih (2001), and the survey and comparison in Scharstein and Szeliski (2002)), with\nthe biggest breakthrough being perhaps global optimization using graph cut techniques (Fig-\nure 1.9b) (Boykov, Veksler, and Zabih 2001).",
  "image_path": "page_037.jpg",
  "pages": [
    36,
    37,
    38
  ]
}