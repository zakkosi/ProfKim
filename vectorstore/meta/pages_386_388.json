{
  "doc_id": "pages_386_388",
  "text": "364\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWhile most of the boxes (transforms) in Figure 7.7 have previously been explained (6.47),\nthe leftmost box has not. This box performs a robust comparison of the predicted and mea-\nsured 2D locations ˆxij and ˜xij after re-scaling by the measurement noise covariance Σij. In\nmore detail, this operation can be written as\nrij\n=\n˜xij −ˆxij,\n(7.51)\ns2\nij\n=\nrT\nijΣ−1\nij rij,\n(7.52)\neij\n=\nˆρ(s2\nij),\n(7.53)\nwhere ˆρ(r2) = ρ(r). The corresponding Jacobians (partial derivatives) can be written as\n∂eij\n∂s2\nij\n=\nˆρ′(s2\nij),\n(7.54)\n∂s2\nij\n∂˜xij\n=\nΣ−1\nij rij.\n(7.55)\nThe advantage of the chained representation introduced above is that it not only makes\nthe computations of the partial derivatives and Jacobians simpler but it can also be adapted\nto any camera conﬁguration. Consider for example a pair of cameras mounted on a robot\nthat is moving around in the world, as shown in Figure 7.8a. By replacing the rightmost\ntwo transformations in Figure 7.7 with the transformations shown in Figure 7.8b, we can\nsimultaneously recover the position of the robot at each time and the calibration of each\ncamera with respect to the rig, in addition to the 3D structure of the world.\n7.4.1 Exploiting sparsity\nLarge bundle adjustment problems, such as those involving reconstructing 3D scenes from\nthousands of Internet photographs (Snavely, Seitz, and Szeliski 2008b; Agarwal, Snavely,\nSimon et al. 2009; Agarwal, Furukawa, Snavely et al. 2010; Snavely, Simon, Goesele et al.\n2010), can require solving non-linear least squares problems with millions of measurements\n(feature matches) and tens of thousands of unknown parameters (3D point positions and cam-\nera poses). Unless some care is taken, these kinds of problem can become intractable, since\nthe (direct) solution of dense least squares problems is cubic in the number of unknowns.\nFortunately, structure from motion is a bipartite problem in structure and motion. Each\nfeature point xij in a given image depends on one 3D point position pi and one 3D camera\npose (Rj, cj). This is illustrated in Figure 7.9a, where each circle (1–9) indicates a 3D point,\neach square (A–D) indicates a camera, and lines (edges) indicate which points are visible in\nwhich cameras (2D features). If the values for all the points are known or ﬁxed, the equations\nfor all the cameras become independent, and vice versa.\n7.4 Bundle adjustment\n365\npi\nw\npi\nr\n(Rt\nr,ct\nr)\n(Rj\nc,cj\nc)\nY\nX\n(a)\nfR(x)\n= Rj\ncx\nqj\nc\nfT(x)\n= x-cj\nc\ncj\nc\ny(1)\ny(2)\nfR(x)\n= Rt\nrx\nqt\nr\nfT(x)\n= x-ct\nr\nct\nr\npi\nw\ny(0)\npi\nr\n…\n(b)\nFigure 7.8\nA camera rig and its associated transform chain. (a) As the mobile rig (robot)\nmoves around in the world, its pose with respect to the world at time t is captured by (Rr\nt, cr\nt).\nEach camera’s pose with respect to the rig is captured by (Rc\nj, cc\nj). (b) A 3D point with world\ncoordinates pw\ni is ﬁrst transformed into rig coordinates pr\ni, and then through the rest of the\ncamera-speciﬁc chain, as shown in Figure 7.7.\nA\nB\nC\nD\n1\n2\n3\n4\n5\n6\n7\n8\n9\n1\n2\n3\n4\n5\n6\n7\n8\n9\nA\nB\nC\nD\n1A\n1B\n2A\n2B\n3A\n3B\n4A\n4B\n4C\n5B\n5C\n6B\n6C\n7C\n7D\n8C\n8D\n9C\n9D\n1\n2\n3\n4\n5\n6\n7\n8\n9\nA\nB\nC\nD\n1\n2\n3\n4\n5\n6\n7\n8\n9\nA\nB\nC\nD\n(a)\n(b)\n(c)\nFigure 7.9\n(a) Bipartite graph for a toy structure from motion problem and (b) its associated\nJacobian J and (c) Hessian A. Numbers indicate 3D points and letters indicate cameras. The\ndashed arcs and light blue squares indicate the ﬁll-in that occurs when the structure (point)\nvariables are eliminated.\n366\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nIf we order the structure variables before the motion variables in the Hessian matrix A\n(and hence also the right hand side vector b), we obtain a structure for the Hessian shown in\nFigure 7.9c.14 When such a system is solved using sparse Cholesky factorization (see Ap-\npendix A.4) (Bj¨orck 1996; Golub and Van Loan 1996), the ﬁll-in occurs in the smaller motion\nHessian Acc (Szeliski and Kang 1994; Triggs, McLauchlan, Hartley et al. 1999; Hartley and\nZisserman 2004; Lourakis and Argyros 2009; Engels, Stew´enius, and Nist´er 2006). Some re-\ncent papers by (Byr¨od and øAstr¨om 2009), Jeong, Nist´er, Steedly et al. (2010) and (Agarwal,\nSnavely, Seitz et al. 2010) explore the use of iterative (conjugate gradient) techniques for the\nsolution of bundle adjustment problems.\nIn more detail, the reduced motion Hessian is computed using the Schur complement,\nA′\ncc = Acc −AT\npcA−1\npp Apc,\n(7.56)\nwhere App is the point (structure) Hessian (the top left block of Figure 7.9c), Apc is the\npoint-camera Hessian (the top right block), and Acc and A′\ncc are the motion Hessians before\nand after the point variable elimination (the bottom right block of Figure 7.9c). Notice that\nA′\ncc has a non-zero entry between two cameras if they see any 3D point in common. This is\nindicated with dashed arcs in Figure 7.9a and light blue squares in Figure 7.9c.\nWhenever there are global parameters present in the reconstruction algorithm, such as\ncamera intrinsics that are common to all of the cameras, or camera rig calibration parameters\nsuch as those shown in Figure 7.8, they should be ordered last (placed along the right and\nbottom edges of A) in order to reduce ﬁll-in.\nEngels, Stew´enius, and Nist´er (2006) provide a nice recipe for sparse bundle adjustment,\nincluding all the steps needed to initialize the iterations, as well as typical computation times\nfor a system that uses a ﬁxed number of backward-looking frames in a real-time setting. They\nalso recommend using homogeneous coordinates for the structure parameters pi, which is a\ngood idea, since it avoids numerical instabilities for points near inﬁnity.\nBundle adjustment is now the standard method of choice for most structure-from-motion\nproblems and is commonly applied to problems with hundreds of weakly calibrated images\nand tens of thousands of points, e.g., in systems such as Photosynth. (Much larger prob-\nlems are commonly solved in photogrammetry and aerial imagery, but these are usually care-\nfully calibrated and make use of surveyed ground control points.) However, as the problems\nbecome larger, it becomes impractical to re-solve full bundle adjustment problems at each\niteration.\nOne approach to dealing with this problem is to use an incremental algorithm, where new\ncameras are added over time. (This makes particular sense if the data is being acquired from\n14 This ordering is preferable when there are fewer cameras than 3D points, which is the usual case. The exception\nis when we are tracking a small number of points through many video frames, in which case this ordering should be\nreversed.",
  "image_path": "page_387.jpg",
  "pages": [
    386,
    387,
    388
  ]
}