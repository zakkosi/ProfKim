{
  "doc_id": "pages_461_463",
  "text": "9.1 Motion models\n439\nthis mapping equation is given by\nx\n=\nf tan θ = f tan x′\ns ,\n(9.15)\ny\n=\nh\np\nx2 + f 2 = y′\ns f\nq\n1 + tan2 x′/s = f y′\ns sec x′\ns .\n(9.16)\nImages can also be projected onto a spherical surface (Szeliski and Shum 1997), which\nis useful if the ﬁnal panorama includes a full sphere or hemisphere of views, instead of just\na cylindrical strip. In this case, the sphere is parameterized by two angles (θ, φ), with 3D\nspherical coordinates given by\n(sin θ cos φ, sin φ, cos θ cos φ) ∝(x, y, f),\n(9.17)\nas shown in Figure 9.7b.6 The correspondence between coordinates is now given by (Szeliski\nand Shum 1997):\nx′\n=\nsθ = s tan−1 x\nf ,\n(9.18)\ny′\n=\nsφ = s tan−1\ny\np\nx2 + f 2 ,\n(9.19)\nwhile the inverse is given by\nx\n=\nf tan θ = f tan x′\ns ,\n(9.20)\ny\n=\np\nx2 + f 2 tan φ = tan y′\ns f\nq\n1 + tan2 x′/s = f tan y′\ns sec x′\ns .\n(9.21)\nNote that it may be simpler to generate a scaled (x, y, z) direction from Equation (9.17)\nfollowed by a perspective division by z and a scaling by f.\nCylindrical image stitching algorithms are most commonly used when the camera is\nknown to be level and only rotating around its vertical axis (Chen 1995). Under these condi-\ntions, images at different rotations are related by a pure horizontal translation.7 This makes\nit attractive as an initial class project in an introductory computer vision course, since the\nfull complexity of the perspective alignment algorithm (Sections 6.1, 8.2, and 9.1.3) can be\navoided. Figure 9.8 shows how two cylindrically warped images from a leveled rotational\npanorama are related by a pure translation (Szeliski and Shum 1997).\nProfessional panoramic photographers often use pan-tilt heads that make it easy to control\nthe tilt and to stop at speciﬁc detents in the rotation angle. Motorized rotation heads are also\n6 Note that these are not the usual spherical coordinates, ﬁrst presented in Equation (2.8). Here, the y axis points\nat the north pole instead of the z axis, since we are used to viewing images taken horizontally, i.e., with the y axis\npointing in the direction of the gravity vector.\n7Small vertical tilts can sometimes be compensated for with vertical translations.\n440\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 9.8 A cylindrical panorama (Szeliski and Shum 1997) c⃝1997 ACM: (a) two cylin-\ndrically warped images related by a horizontal translation; (b) part of a cylindrical panorama\ncomposited from a sequence of images.\nFigure 9.9\nA spherical panorama constructed from 54 photographs (Szeliski and Shum\n1997) c⃝1997 ACM.\nsometimes used for the acquisition of larger panoramas (Kopf, Uyttendaele, Deussen et al.\n2007).8 Not only do they ensure a uniform coverage of the visual ﬁeld with a desired amount\nof image overlap but they also make it possible to stitch the images using cylindrical or\nspherical coordinates and pure translations. In this case, pixel coordinates (x, y, f) must ﬁrst\nbe rotated using the known tilt and panning angles before being projected into cylindrical\nor spherical coordinates (Chen 1995). Having a roughly known panning angle also makes it\neasier to compute the alignment, since the rough relative positioning of all the input images is\nknown ahead of time, enabling a reduced search range for alignment. Figure 9.9 shows a full\n3D rotational panorama unwrapped onto the surface of a sphere (Szeliski and Shum 1997).\nOne ﬁnal coordinate mapping worth mentioning is the polar mapping, where the north\n8See also http://gigapan.org.\n9.2 Global alignment\n441\npole lies along the optical axis rather than the vertical axis,\n(cos θ sin φ, sin θ sin φ, cos φ) = s (x, y, z).\n(9.22)\nIn this case, the mapping equations become\nx′\n=\nsφ cos θ = sx\nr tan−1 r\nz ,\n(9.23)\ny′\n=\nsφ sin θ = sy\nr tan−1 r\nz ,\n(9.24)\nwhere r =\np\nx2 + y2 is the radial distance in the (x, y) plane and sφ plays a similar role\nin the (x′, y′) plane. This mapping provides an attractive visualization surface for certain\nkinds of wide-angle panoramas and is also a good model for the distortion induced by ﬁsheye\nlenses, as discussed in Section 2.1.6. Note how for small values of (x, y), the mapping\nequations reduce to x′ ≈sx/z, which suggests that s plays a role similar to the focal length\nf.\n9.2 Global alignment\nSo far, we have discussed how to register pairs of images using a variety of motion models. In\nmost applications, we are given more than a single pair of images to register. The goal is then\nto ﬁnd a globally consistent set of alignment parameters that minimize the mis-registration\nbetween all pairs of images (Szeliski and Shum 1997; Shum and Szeliski 2000; Sawhney and\nKumar 1999; Coorg and Teller 2000).\nIn this section, we extend the pairwise matching criteria (6.2, 8.1, and 8.50) to a global\nenergy function that involves all of the per-image pose parameters (Section 9.2.1). Once\nwe have computed the global alignment, we often need to perform local adjustments, such\nas parallax removal, to reduce double images and blurring due to local mis-registrations\n(Section 9.2.2). Finally, if we are given an unordered set of images to register, we need to\ndiscover which images go together to form one or more panoramas. This process of panorama\nrecognition is described in Section 9.2.3.\n9.2.1 Bundle adjustment\nOne way to register a large number of images is to add new images to the panorama one\nat a time, aligning the most recent image with the previous ones already in the collection\n(Szeliski and Shum 1997) and discovering, if necessary, which images it overlaps (Sawhney\nand Kumar 1999). In the case of 360◦panoramas, accumulated error may lead to the presence\nof a gap (or excessive overlap) between the two ends of the panorama, which can be ﬁxed",
  "image_path": "page_462.jpg",
  "pages": [
    461,
    462,
    463
  ]
}