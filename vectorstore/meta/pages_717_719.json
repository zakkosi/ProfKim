{
  "doc_id": "pages_717_719",
  "text": "14.4 Category recognition\n695\nFigure 14.33\nAutomatic mining, annotation, and localization of community photo collec-\ntions (Quack, Leibe, and Van Gool 2008) c⃝2008 ACM. This ﬁgure does not show the textual\nannotations or corresponding Wikipedia entries, which are also discovered.\nA\nB\nC\nD\n(a)\n(b)\nFigure 14.34 Locating star ﬁelds using astrometry, http://astrometry.net/. (a) Input star ﬁeld\nand some selected star quads. (b) The 2D coordinates of stars C and D are encoded relative\nto the unit square deﬁned by A and B.\nQuack et al. 2009).\nThe concept of organizing the world’s photo collections by location has even been re-\ncently extended to organizing all of the universe’s (astronomical) photos in an application\ncalled astrometry, http://astrometry.net/. The technique used to match any two star ﬁelds is\nto take quadruplets of nearby stars (a pair of stars and another pair inside their diameter) to\nform a 30-bit geometric hash by encoding the relative positions of the second pair of points\nusing the inscribed square as the reference frame, as shown in Figure 14.34. Traditional in-\nformation retrieval techniques (k-d trees built for different parts of a sky atlas) are then used\nto ﬁnd matching quads as potential star ﬁeld location hypotheses, which can then be veriﬁed\nusing a similarity transform.\n696\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 14.35 Sample images from the Xerox 10 class dataset (Csurka, Dance, Perronnin et\nal. 2006) c⃝2007 Springer. Imagine trying to write a program to distinguish such images\nfrom other photographs.\n14.4 Category recognition\nWhile instance recognition techniques are relatively mature and are used in commercial ap-\nplications, such as Photosynth (Section 13.1.2), generic category (class) recognition is still\na largely unsolved problem. Consider for example the set of photographs in Figure 14.35,\nwhich shows objects taken from 10 different visual categories. (I’ll leave it up to you to name\neach of the categories.) How would you go about writing a program to categorize each of\nthese images into the appropriate class, especially if you were also given the choice “none of\nthe above”?\nAs you can tell from this example, visual category recognition is an extremely challenging\nproblem; no one has yet constructed a system that approaches the performance level of a two-\nyear-old child. However, the progress in the ﬁeld has been quite dramatic, if judged by how\nmuch better today’s algorithms are compared to those of a decade ago.\nFigure 14.54 shows a sample image from each of the 20 categories used in the 2008\nPASCAL Visual Object Classes Challenge. The yellow boxes represent the extent of each of\nthe objects found in a given image. On such closed world collections where the task is to\ndecide among 20 categories, today’s classiﬁcation algorithms can do remarkably well.\n14.4 Category recognition\n697\nFigure 14.36 A typical processing pipeline for a bag-of-words category recognition system\n(Csurka, Dance, Perronnin et al. 2006) c⃝2007 Springer. Features are ﬁrst extracted at\nkeypoints and then quantized to get a distribution (histogram) over the learned visual words\n(feature cluster centers). The feature distribution histogram is used to learn a decision surface\nusing a classiﬁcation algorithm, such as a support vector machine.\nIn this section, we look at a number of approaches to solving category recognition. While\nhistorically, part-based representations and recognition algorithms (Section 14.4.2) were the\npreferred approach (Fischler and Elschlager 1973; Felzenszwalb and Huttenlocher 2005;\nFergus, Perona, and Zisserman 2007), we begin by describing simpler bag-of-features ap-\nproaches (Section 14.4.1) that represent objects and images as unordered collections of fea-\nture descriptors. We then look at the problem of simultaneously segmenting images while\nrecognizing objects (Section 14.4.3) and also present some applications of such techniques to\nphoto manipulation (Section 14.4.4). In Section 14.5, we look at how context and scene un-\nderstanding, as well as machine learning, can improve overall recognition results. Additional\ndetails on the techniques presented in this section can be found in (Pinz 2005; Ponce, Hebert,\nSchmid et al. 2006; Dickinson, Leonardis, Schiele et al. 2007; Fei-Fei, Fergus, and Torralba\n2009).\n14.4.1 Bag of words\nOne of the simplest algorithms for category recognition is the bag of words (also known as\nbag of features or bag of keypoints) approach (Csurka, Dance, Fan et al. 2004; Lazebnik,\nSchmid, and Ponce 2006; Csurka, Dance, Perronnin et al. 2006; Zhang, Marszalek, Lazeb-\nnik et al. 2007). As shown in Figure 14.36, this algorithm simply computes the distribu-\ntion (histogram) of visual words found in the query image and compares this distribution\nto those found in the training images. We have already seen elements of this approach in\nSection 14.3.2, Equations (14.33–14.35) and Algorithm 14.2. The biggest difference from\ninstance recognition is the absence of a geometric veriﬁcation stage (Section 14.3.1), since\nindividual instances of generic visual categories, such as those shown in Figure 14.35, have\nrelatively little spatial coherence to their features (but see the work by Lazebnik, Schmid, and",
  "image_path": "page_718.jpg",
  "pages": [
    717,
    718,
    719
  ]
}