{
  "doc_id": "pages_343_345",
  "text": "6.2 Pose estimation\n321\nthe 3 × 3 correlation matrix\nC =\nX\ni\nˆx′ˆxT = UΣV T .\n(6.32)\nThe rotation matrix is then obtained as R = UV T . (Verify this for yourself when ˆx′ = Rˆx.)\nAnother technique is the absolute orientation algorithm (Horn 1987) for estimating the\nunit quaternion corresponding to the rotation matrix R, which involves forming a 4×4 matrix\nfrom the entries in C and then ﬁnding the eigenvector associated with its largest positive\neigenvalue.\nLorusso, Eggert, and Fisher (1995) experimentally compare these two techniques to two\nadditional techniques proposed in the literature, but ﬁnd that the difference in accuracy is\nnegligible (well below the effects of measurement noise).\nIn situations where these closed-form algorithms are not applicable, e.g., when full 3D\ncovariances are being used or when the 3D alignment is part of some larger optimization, the\nincremental rotation update introduced in Section 2.1.4 (2.35–2.36), which is parameterized\nby an instantaneous rotation vector ω, can be used (See Section 9.1.3 for an application to\nimage stitching.)\nIn some situations, e.g., when merging range data maps, the correspondence between\ndata points is not known a priori. In this case, iterative algorithms that start by matching\nnearby points and then update the most likely correspondence can be used (Besl and McKay\n1992; Zhang 1994; Szeliski and Lavall´ee 1996; Gold, Rangarajan, Lu et al. 1998; David,\nDeMenthon, Duraiswami et al. 2004; Li and Hartley 2007; Enqvist, Josephson, and Kahl\n2009). These techniques are discussed in more detail in Section 12.2.1.\n6.2 Pose estimation\nA particular instance of feature-based alignment, which occurs very often, is estimating an\nobject’s 3D pose from a set of 2D point projections. This pose estimation problem is also\nknown as extrinsic calibration, as opposed to the intrinsic calibration of internal camera pa-\nrameters such as focal length, which we discuss in Section 6.3. The problem of recovering\npose from three correspondences, which is the minimal amount of information necessary,\nis known as the perspective-3-point-problem (P3P), with extensions to larger numbers of\npoints collectively known as PnP (Haralick, Lee, Ottenberg et al. 1994; Quan and Lan 1999;\nMoreno-Noguer, Lepetit, and Fua 2007).\nIn this section, we look at some of the techniques that have been developed to solve such\nproblems, starting with the direct linear transform (DLT), which recovers a 3×4 camera ma-\ntrix, followed by other “linear” algorithms, and then looking at statistically optimal iterative\nalgorithms.\n322\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n6.2.1 Linear algorithms\nThe simplest way to recover the pose of the camera is to form a set of linear equations analo-\ngous to those used for 2D motion estimation (6.19) from the camera matrix form of perspec-\ntive projection (2.55–2.56),\nxi\n=\np00Xi + p01Yi + p02Zi + p03\np20Xi + p21Yi + p22Zi + p23\n(6.33)\nyi\n=\np10Xi + p11Yi + p12Zi + p13\np20Xi + p21Yi + p22Zi + p23\n,\n(6.34)\nwhere (xi, yi) are the measured 2D feature locations and (Xi, Yi, Zi) are the known 3D\nfeature locations (Figure 6.4). As with (6.21), this system of equations can be solved in a\nlinear fashion for the unknowns in the camera matrix P by multiplying the denominator on\nboth sides of the equation.9 The resulting algorithm is called the direct linear transform\n(DLT) and is commonly attributed to Sutherland (1974). (For a more in-depth discussion,\nrefer to the work of Hartley and Zisserman (2004).) In order to compute the 12 (or 11)\nunknowns in P , at least six correspondences between 3D and 2D locations must be known.\nAs with the case of estimating homographies (6.21–6.23), more accurate results for the\nentries in P can be obtained by directly minimizing the set of Equations (6.33–6.34) using\nnon-linear least squares with a small number of iterations.\nOnce the entries in P have been recovered, it is possible to recover both the intrinsic\ncalibration matrix K and the rigid transformation (R, t) by observing from Equation (2.56)\nthat\nP = K[R|t].\n(6.35)\nSince K is by convention upper-triangular (see the discussion in Section 2.1.5), both K and\nR can be obtained from the front 3 × 3 sub-matrix of P using RQ factorization (Golub and\nVan Loan 1996).10\nIn most applications, however, we have some prior knowledge about the intrinsic cali-\nbration matrix K, e.g., that the pixels are square, the skew is very small, and the optical\ncenter is near the center of the image (2.57–2.59). Such constraints can be incorporated into\na non-linear minimization of the parameters in K and (R, t), as described in Section 6.2.2.\nIn the case where the camera is already calibrated, i.e., the matrix K is known (Sec-\ntion 6.3), we can perform pose estimation using as few as three points (Fischler and Bolles\n1981; Haralick, Lee, Ottenberg et al. 1994; Quan and Lan 1999). The basic observation that\nthese linear PnP (perspective n-point) algorithms employ is that the visual angle between any\n9 Because P is unknown up to a scale, we can either ﬁx one of the entries, e.g., p23 = 1, or ﬁnd the smallest\nsingular vector of the set of linear equations.\n10 Note the unfortunate clash of terminologies: In matrix algebra textbooks, R represents an upper-triangular\nmatrix; in computer vision, R is an orthogonal rotation.\n6.2 Pose estimation\n323\npi = (Xi,Yi,Zi,Wi)\nxi\npj\ndij\ndi\ndj\nxj\nθij\nc\nFigure 6.4\nPose estimation by the direct linear transform and by measuring visual angles\nand distances between pairs of points.\npair of 2D points ˆxi and ˆxj must be the same as the angle between their corresponding 3D\npoints pi and pj (Figure 6.4).\nGiven a set of corresponding 2D and 3D points {(ˆxi, pi)}, where the ˆxi are unit directions\nobtained by transforming 2D pixel measurements xi to unit norm 3D directions ˆxi through\nthe inverse calibration matrix K,\nˆxi = N(K−1xi) = K−1xi/∥K−1xi∥,\n(6.36)\nthe unknowns are the distances di from the camera origin c to the 3D points pi, where\npi = diˆxi + c\n(6.37)\n(Figure 6.4). The cosine law for triangle ∆(c, pi, pj) gives us\nfij(di, dj) = d2\ni + d2\nj −2didjcij −d2\nij = 0,\n(6.38)\nwhere\ncij = cos θij = ˆxi · ˆxj\n(6.39)\nand\nd2\nij = ∥pi −pj∥2.\n(6.40)\nWe can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using\nSylvester resultants (Cox, Little, and O’Shea 2007) to obtain a quartic equation in d2\ni ,\ngijk(d2\ni ) = a4d8\ni + a3d6\ni + a2d4\ni + a1d2\ni + a0 = 0.\n(6.41)\nGiven ﬁve or more correspondences, we can generate (n−1)(n−2)\n2\ntriplets to obtain a linear\nestimate (using SVD) for the values of (d8\ni , d6\ni , d4\ni , d2\ni ) (Quan and Lan 1999). Estimates for",
  "image_path": "page_344.jpg",
  "pages": [
    343,
    344,
    345
  ]
}