{
  "doc_id": "pages_726_728",
  "text": "704\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\npart model (Bouchard and Triggs 2005; Carneiro and Lowe 2006). k-fans, in which a clique\nof size k forms the root of a star-shaped model (Figure 14.41c) have inference complexity\nO(N k+1), although with distance transforms and Gaussian priors, this can be lowered to\nO(N k) (Crandall, Felzenszwalb, and Huttenlocher 2005; Crandall and Huttenlocher 2006).\nFinally, fully connected constellation models (Figure 14.41a) are the most general, but the\nassignment of features to parts becomes intractable for moderate numbers of parts P, since\nthe complexity of such an assignment is O(N P ) (Fergus, Perona, and Zisserman 2007).\nThe original constellation model was developed by Burl, Weber, and Perona (1998) and\nconsists of a number of parts whose relative positions are encoded by their mean locations\nand a full covariance matrix, which is used to denote not only positional uncertainty but also\npotential correlations (covariance) between different parts (Figure 14.42a). Weber, Welling,\nand Perona (2000) extended this technique to a weakly supervised setting, where both the\nappearance of each part and its locations are automatically learned given only whole image\nlabels. Fergus, Perona, and Zisserman (2007) further extend this approach to simultaneous\nlearning of appearance and shape models from scale-invariant keypoint detections.\nFigure 14.42a shows the shape model learned for the motorcycle class. The top ﬁgure\nshows the mean relative locations for each part along with their position covariances (inter-\npart covariances are not shown) and likelihood of occurrence. The bottom curve shows the\nGaussian PDFs for the relative log-scale of each part with respect to the “landmark” feature.\nFigure 14.42b shows the appearance model learned for each part, visualized as the patches\naround detected features in the training database that best match the appearance model. Fig-\nure 14.42c shows the features detected in the test database (pink dots) along with the corre-\nsponding parts that they were assigned to (colored circles). As you can see, the system has\nsuccessfully learned and then used a fairly complex model of motorcycle appearance.\nThe part-based approach to recognition has also been extended to learning new categories\nfrom small numbers of examples, building on recognition components developed for other\nclasses (Fei-Fei, Fergus, and Perona 2006). More complex hierarchical part-based models can\nbe developed using the concept of grammars (Bouchard and Triggs 2005; Zhu and Mumford\n2006). A simpler way to use parts is to have keypoints that are recognized as being part of\na class vote for the estimated part locations, as shown in the top row of Figure 14.43 (Leibe,\nLeonardis, and Schiele 2008). (Implicitly, this corresponds to having a star-shaped geometric\nmodel.)\n14.4.3 Recognition with segmentation\nThe most challenging version of generic object recognition is to simultaneously perform\nrecognition with accurate boundary segmentation (Fergus 2007a). For instance recognition\n(Section 14.3.1), this can sometimes be achieved by backprojecting the object model into\n14.4 Category recognition\n705\n(a)\n(b)\nCorrect\nCorrect\nINCORRECT\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nINCORRECT\nINCORRECT\nCorrect\nINCORRECT\nCorrect\nCorrect\nCorrect\n(c)\nFigure 14.42\nPart-based recognition (Fergus, Perona, and Zisserman 2007)\nc⃝2007\nSpringer: (a) locations and covariance ellipses for each part, along with their occurrence\nprobabilities (top) and relative log-scale densities (bottom); (b) part examples drawn from\nthe training images that best match the average appearance; (c) recognition results for the\nmotorcycle class, showing detected features (pink dots) and parts (colored circles).\n706\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 14.43\nInterleaved recognition and segmentation (Leibe, Leonardis, and Schiele\n2008) c⃝2008 Springer. The process starts by re-recognizing visual words (codebook en-\ntries) in a new image (scene) and having each part vote for likely locations and size in a\n3D (x, y, s) voting space (top row). Once a maximum has been found, the parts (features)\ncorresponding to this instance are determined by backprojecting the contributing votes. The\nforeground–background segmentation for each object can be found by backprojecting proba-\nbilistic masks associated with each codebook entry. The whole recognition and segmentation\nprocess can then be repeated.\nthe scene (Lowe 2004), as shown in Figure 14.1d, or matching portions of the new scene to\npre-learned (segmented) object models (Ferrari, Tuytelaars, and Van Gool 2006b; Kannala,\nRahtu, Brandt et al. 2008).\nFor more complex (ﬂexible) object models, such as those for humans Figure 14.1f, a\ndifferent approach is to pre-segment the image into larger or smaller pieces (Chapter 5) and\nthen match such pieces to portions of the model (Mori, Ren, Efros et al. 2004; Mori 2005;\nHe, Zemel, and Ray 2006; Gu, Lim, Arbelaez et al. 2009).\nAn alternative approach by Leibe, Leonardis, and Schiele (2008), which we introduced\nin the previous section, votes for potential object locations and scales based on the detec-\ntion of features corresponding to pre-clustered visual codebook entries (Figure 14.43). To\nsupport segmentation, each codebook entry has an associated foreground–background mask,\nwhich is learned as part of the codebook clustering process from pre-labeled object segmen-\ntation masks. During recognition, once a maximum in the voting space is found, the masks\nassociated with the entries that voted for this instance are combined to obtain an object seg-\nmentation, as shown on the left side of Figure 14.43.\nA more holistic approach to recognition and segmentation is to formulate the problem as\none of labeling every pixel in an image with its class membership, and to solve this prob-",
  "image_path": "page_727.jpg",
  "pages": [
    726,
    727,
    728
  ]
}