{
  "doc_id": "pages_420_422",
  "text": "398\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nNote that here, in deriving the Lucas–Kanade update from the original weighted SSD function\n(8.5), we have neglected taking the derivative of the w1(xi + u) weighting function with\nrespect to u, which is usually acceptable in practice, especially if the weighting function is a\nbinary mask with relatively few transitions.\nBaker, Gross, Ishikawa et al. (2003) only use the w0(x) term, which is reasonable if the\ntwo images have the same extent and no (independent) cutouts in the overlap region. They\nalso discuss the idea of making the weighting proportional to ∇I(x), which helps for very\nnoisy images, where the gradient itself is noisy. Similar observations, formulated in terms\nof total least squares (Van Huffel and Vandewalle 1991; Van Huffel and Lemmerling 2002),\nhave been made by other researchers studying optical ﬂow (Weber and Malik 1995; Bab-\nHadiashar and Suter 1998b; M¨uhlich and Mester 1998). Lastly, Baker, Gross, Ishikawa et al.\n(2003) show how evaluating Equation (8.47) at just the most reliable (highest gradient) pixels\ndoes not signiﬁcantly reduce performance for large enough images, even if only 5–10% of\nthe pixels are used. (This idea was originally proposed by Dellaert and Collins (1999), who\nused a more sophisticated selection criterion.)\nThe Lucas–Kanade incremental reﬁnement step can also be applied to the robust error\nmetric introduced in Section 8.1,\nELK−SRD(u + ∆u) =\nX\ni\nρ(J1(xi + u)∆u + ei),\n(8.48)\nwhich can be solved using the iteratively reweighted least squares technique described in\nSection 6.1.4.\n8.2 Parametric motion\nMany image alignment tasks, for example image stitching with handheld cameras, require\nthe use of more sophisticated motion models, as described in Section 2.1.2. Since these\nmodels, e.g., afﬁne deformations, typically have more parameters than pure translation, a\nfull search over the possible range of values is impractical. Instead, the incremental Lucas–\nKanade algorithm can be generalized to parametric motion models and used in conjunction\nwith a hierarchical search algorithm (Lucas and Kanade 1981; Rehg and Witkin 1991; Fuh\nand Maragos 1991; Bergen, Anandan, Hanna et al. 1992; Shashua and Toelg 1997; Shashua\nand Wexler 2001; Baker and Matthews 2004).\nFor parametric motion, instead of using a single constant translation vector u, we use\na spatially varying motion ﬁeld or correspondence map, x′(x; p), parameterized by a low-\ndimensional vector p, where x′ can be any of the motion models presented in Section 2.1.2.\n8.2 Parametric motion\n399\nThe parametric incremental motion update rule now becomes\nELK−PM(p + ∆p)\n=\nX\ni\n[I1(x′(xi; p + ∆p)) −I0(xi)]2\n(8.49)\n≈\nX\ni\n[I1(x′\ni) + J1(x′\ni)∆p −I0(xi)]2\n(8.50)\n=\nX\ni\n[J1(x′\ni)∆p + ei]2,\n(8.51)\nwhere the Jacobian is now\nJ1(x′\ni) = ∂I1\n∂p = ∇I1(x′\ni)∂x′\n∂p (xi),\n(8.52)\ni.e., the product of the image gradient ∇I1 with the Jacobian of the correspondence ﬁeld,\nJx′ = ∂x′/∂p.\nThe motion Jacobians Jx′ for the 2D planar transformations introduced in Section 2.1.2\nand Table 2.1 are given in Table 6.1. Note how we have re-parameterized the motion matrices\nso that they are always the identity at the origin p = 0. This becomes useful later, when we\ntalk about the compositional and inverse compositional algorithms. (It also makes it easier to\nimpose priors on the motions.)\nFor parametric motion, the (Gauss–Newton) Hessian and gradient-weighted residual vec-\ntor become\nA =\nX\ni\nJTx′(xi)[∇IT\n1 (x′\ni)∇I1(x′\ni)]Jx′(xi)\n(8.53)\nand\nb = −\nX\ni\nJTx′(xi)[ei∇IT\n1 (x′\ni)].\n(8.54)\nNote how the expressions inside the square brackets are the same ones evaluated for the\nsimpler translational motion case (8.40–8.41).\nPatch-based approximation.\nThe computation of the Hessian and residual vectors for\nparametric motion can be signiﬁcantly more expensive than for the translational case. For\nparametric motion with n parameters and N pixels, the accumulation of A and b takes\nO(n2N) operations (Baker and Matthews 2004). One way to reduce this by a signiﬁcant\namount is to divide the image up into smaller sub-blocks (patches) Pj and to only accumulate\nthe simpler 2 × 2 quantities inside the square brackets at the pixel level (Shum and Szeliski\n2000),\nAj\n=\nX\ni∈Pj\n∇IT\n1 (x′\ni)∇I1(x′\ni)\n(8.55)\nbj\n=\nX\ni∈Pj\nei∇IT\n1 (x′\ni).\n(8.56)\n400\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nThe full Hessian and residual can then be approximated as\nA ≈\nX\nj\nJTx′(ˆxj)[\nX\ni∈Pj\n∇IT\n1 (x′\ni)∇I1(x′\ni)]Jx′(ˆxj) =\nX\nj\nJTx′(ˆxj)AjJx′(ˆxj)\n(8.57)\nand\nb ≈−\nX\nj\nJTx′(ˆxj)[\nX\ni∈Pj\nei∇IT\n1 (x′\ni)] = −\nX\nj\nJTx′(ˆxj)bj,\n(8.58)\nwhere ˆxj is the center of each patch Pj (Shum and Szeliski 2000). This is equivalent to\nreplacing the true motion Jacobian with a piecewise-constant approximation. In practice,\nthis works quite well. The relationship of this approximation to feature-based registration is\ndiscussed in Section 9.2.4.\nCompositional approach.\nFor a complex parametric motion such as a homography, the\ncomputation of the motion Jacobian becomes complicated and may involve a per-pixel divi-\nsion. Szeliski and Shum (1997) observed that this can be simpliﬁed by ﬁrst warping the target\nimage I1 according to the current motion estimate x′(x; p),\n˜I1(x) = I1(x′(x; p)),\n(8.59)\nand then comparing this warped image against the template I0(x),\nELK−SS(∆p)\n=\nX\ni\n[˜I1(˜x(xi; ∆p)) −I0(xi)]2\n(8.60)\n≈\nX\ni\n[ ˜J1(xi)∆p + ei]2\n(8.61)\n=\nX\ni\n[∇˜I1(xi)J ˜x(xi)∆p + ei]2.\n(8.62)\nNote that since the two images are assumed to be fairly similar, only an incremental para-\nmetric motion is required, i.e., the incremental motion can be evaluated around p = 0, which\ncan lead to considerable simpliﬁcations. For example, the Jacobian of the planar projective\ntransform (6.19) now becomes\nJ ˜x = ∂˜x\n∂p\n\f\f\f\fp=0\n=\n\"\nx\ny\n1\n0\n0\n0\n−x2\n−xy\n0\n0\n0\nx\ny\n1\n−xy\n−y2\n#\n.\n(8.63)\nOnce the incremental motion ˜x has been computed, it can be prepended to the previously\nestimated motion, which is easy to do for motions represented with transformation matrices,\nsuch as those given in Tables 2.1 and 6.1. Baker and Matthews (2004) call this the forward\ncompositional algorithm, since the target image is being re-warped and the ﬁnal motion esti-\nmates are being composed.",
  "image_path": "page_421.jpg",
  "pages": [
    420,
    421,
    422
  ]
}