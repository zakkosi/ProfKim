{
  "doc_id": "pages_412_414",
  "text": "390\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWindowed correlation.\nUnfortunately, the Fourier convolution theorem only applies when\nthe summation over xi is performed over all the pixels in both images, using a circular shift\nof the image when accessing pixels outside the original boundaries. While this is acceptable\nfor small shifts and comparably sized images, it makes no sense when the images overlap by\na small amount or one image is a small subset of the other.\nIn that case, the cross-correlation function should be replaced with a windowed (weighted)\ncross-correlation function,\nEWCC(u)\n=\nX\ni\nw0(xi)I0(xi) w1(xi + u)I1(xi + u),\n(8.21)\n=\n[w0(x)I0(x)]¯∗[w1(x)I1(x)]\n(8.22)\nwhere the weighting functions w0 and w1 are zero outside the valid ranges of the images\nand both images are padded so that circular shifts return 0 values outside the original image\nboundaries.\nAn even more interesting case is the computation of the weighted SSD function intro-\nduced in Equation (8.5),\nEWSSD(u)\n=\nX\ni\nw0(xi)w1(xi + u)[I1(xi + u) −I0(xi)]2.\n(8.23)\nExpanding this as a sum of correlations and deriving the appropriate set of Fourier transforms\nis left for Exercise 8.1.\nThe same kind of derivation can also be applied to the bias–gain corrected sum of squared\ndifference function EBG (8.9). Again, Fourier transforms can be used to efﬁciently compute\nall the correlations needed to perform the linear regression in the bias and gain parameters in\norder to estimate the exposure-compensated difference for each potential shift (Exercise 8.1).\nPhase correlation.\nA variant of regular correlation (8.18) that is sometimes used for motion\nestimation is phase correlation (Kuglin and Hines 1975; Brown 1992). Here, the spectrum of\nthe two signals being matched is whitened by dividing each per-frequency product in (8.18)\nby the magnitudes of the Fourier transforms,\nF {EPC(u)} =\nI0(ω)I∗\n1(ω)\n∥I0(ω)∥∥I1(ω)∥\n(8.24)\nbefore taking the ﬁnal inverse Fourier transform. In the case of noiseless signals with perfect\n(cyclic) shift, we have I1(x + u) = I0(x) and hence, from Equation (8.17), we obtain\nF {I1(x + u)}\n=\nI1(ω)e−2πju·ω = I0(ω) and\nF {EPC(u)}\n=\ne−2πju·ω.\n(8.25)\n8.1 Translational alignment\n391\nThe output of phase correlation (under ideal conditions) is therefore a single spike (impulse)\nlocated at the correct value of u, which (in principle) makes it easier to ﬁnd the correct\nestimate.\nPhase correlation has a reputation in some quarters of outperforming regular correlation,\nbut this behavior depends on the characteristics of the signals and noise. If the original images\nare contaminated by noise in a narrow frequency band (e.g., low-frequency noise or peaked\nfrequency “hum”), the whitening process effectively de-emphasizes the noise in these regions.\nHowever, if the original signals have very low signal-to-noise ratio at some frequencies (say,\ntwo blurry or low-textured images with lots of high-frequency noise), the whitening process\ncan actually decrease performance (see Exercise 8.1).\nRecently, gradient cross-correlation has emerged as a promising alternative to phase cor-\nrelation (Argyriou and Vlachos 2003), although further systematic studies are probably war-\nranted. Phase correlation has also been studied by Fleet and Jepson (1990) as a method for\nestimating general optical ﬂow and stereo disparity.\nRotations and scale.\nWhile Fourier-based alignment is mostly used to estimate transla-\ntional shifts between images, it can, under certain limited conditions, also be used to estimate\nin-plane rotations and scales. Consider two images that are related purely by rotation, i.e.,\nI1( ˆRx) = I0(x).\n(8.26)\nIf we re-sample the images into polar coordinates,\n˜I0(r, θ) = I0(r cos θ, r sin θ) and ˜I1(r, θ) = I1(r cos θ, r sin θ),\n(8.27)\nwe obtain\n˜I1(r, θ + ˆθ) = ˜I0(r, θ).\n(8.28)\nThe desired rotation can then be estimated using a Fast Fourier Transform (FFT) shift-based\ntechnique.\nIf the two images are also related by a scale,\nI1(eˆs ˆRx) = I0(x),\n(8.29)\nwe can re-sample into log-polar coordinates,\n˜I0(s, θ) = I0(es cos θ, es sin θ) and ˜I1(s, θ) = I1(es cos θ, es sin θ),\n(8.30)\nto obtain\n˜I1(s + ˆs, θ + ˆθ) = I0(s, θ).\n(8.31)\n392\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nI\nx\nei\nΔu I0(xi)\nI1(xi+u)\nJ1(xi+u)\nI0\nI1\nxi\nFigure 8.2\nTaylor series approximation of a function and the incremental computation of\nthe optical ﬂow correction amount. J1(xi + u) is the image gradient at (xi + u) and ei is\nthe current intensity difference.\nIn this case, care must be taken to choose a suitable range of s values that reasonably samples\nthe original image.\nFor images that are also translated by a small amount,\nI1(eˆs ˆRx + t) = I0(x),\n(8.32)\nDe Castro and Morandi (1987) propose an ingenious solution that uses several steps to esti-\nmate the unknown parameters. First, both images are converted to the Fourier domain and\nonly the magnitudes of the transformed images are retained. In principle, the Fourier mag-\nnitude images are insensitive to translations in the image plane (although the usual caveats\nabout border effects apply). Next, the two magnitude images are aligned in rotation and scale\nusing the polar or log-polar representations. Once rotation and scale are estimated, one of the\nimages can be de-rotated and scaled and a regular translational algorithm can be applied to\nestimate the translational shift.\nUnfortunately, this trick only applies when the images have large overlap (small transla-\ntional motion). For more general motion of patches or images, the parametric motion estima-\ntor described in Section 8.2 or the feature-based approaches described in Section 6.1 need to\nbe used.\n8.1.3 Incremental reﬁnement\nThe techniques described up till now can estimate alignment to the nearest pixel (or poten-\ntially fractional pixel if smaller search steps are used). In general, image stabilization and\nstitching applications require much higher accuracies to obtain acceptable results.\nTo obtain better sub-pixel estimates, we can use one of several techniques described by\nTian and Huhns (1986). One possibility is to evaluate several discrete (integer or fractional)\nvalues of (u, v) around the best value found so far and to interpolate the matching score to\nﬁnd an analytic minimum.",
  "image_path": "page_413.jpg",
  "pages": [
    412,
    413,
    414
  ]
}