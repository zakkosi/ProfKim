{
  "doc_id": "pages_482_484",
  "text": "460\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.18\nPoisson image editing (P´erez, Gangnet, and Blake 2003) c⃝2003 ACM: (a)\nThe dog and the two children are chosen as source images to be pasted into the destination\nswimming pool. (b) Simple pasting fails to match the colors at the boundaries, whereas (c)\nPoisson image blending masks these differences.\nbrightness constancy (Horn 1974), shape from shading (Horn and Brooks 1989), and photo-\nmetric stereo (Woodham 1981). More recently, related ideas have been used for reconstruct-\ning images from their edges (Elder and Goldberg 2001), removing shadows from images\n(Weiss 2001), separating reﬂections from a single image (Levin, Zomet, and Weiss 2004;\nLevin and Weiss 2007), and tone mapping high dynamic range images by reducing the mag-\nnitude of image edges (gradients) (Fattal, Lischinski, and Werman 2002).\nP´erez, Gangnet, and Blake (2003) show how gradient domain reconstruction can be used\nto do seamless object insertion in image editing applications (Figure 9.18). Rather than copy-\ning pixels, the gradients of the new image fragment are copied instead. The actual pixel values\nfor the copied area are then computed by solving a Poisson equation that locally matches the\ngradients while obeying the ﬁxed Dirichlet (exact matching) conditions at the seam bound-\nary. P´erez, Gangnet, and Blake (2003) show that this is equivalent to computing an additive\nmembrane interpolant of the mismatch between the source and destination images along the\nboundary.14 In earlier work, Peleg (1981) also proposed adding a smooth function to enforce\nconsistency along the seam curve.\nAgarwala, Dontcheva, Agrawala et al. (2004) extended this idea to a multi-source formu-\nlation, where it no longer makes sense to talk of a destination image whose exact pixel values\nmust be matched at the seam. Instead, each source image contributes its own gradient ﬁeld\nand the Poisson equation is solved using Neumann boundary conditions, i.e., dropping any\nequations that involve pixels outside the boundary of the image.\n14 The membrane interpolant is known to have nicer interpolation properties for arbitrary-shaped constraints than\nfrequency-domain interpolants (Nielson 1993).\n9.3 Compositing\n461\nRather than solving the Poisson partial differential equations, Agarwala, Dontcheva, Agrawala\net al. (2004) directly minimize a variational problem,\nmin\nC(x) ∥∇C(x) −∇˜Il(x)(x)∥2.\n(9.44)\nThe discretized form of this equation is a set of gradient constraint equations\nC(x + ˆı) −C(x)\n=\n˜Il(x)(x + ˆı) −˜Il(x)(x) and\n(9.45)\nC(x + ˆ) −C(x)\n=\n˜Il(x)(x + ˆ) −˜Il(x)(x),\n(9.46)\nwhere ˆı = (1, 0) and ˆ= (0, 1) are unit vectors in the x and y directions.15 They then solve\nthe associated sparse least squares problem. Since this system of equations is only deﬁned\nup to an additive constraint, Agarwala, Dontcheva, Agrawala et al. (2004) ask the user to\nselect the value of one pixel. In practice, a better choice might be to weakly bias the solution\ntowards reproducing the original color values.\nIn order to accelerate the solution of this sparse linear system, Fattal, Lischinski, and\nWerman (2002) use multigrid, whereas Agarwala, Dontcheva, Agrawala et al. (2004) use\nhierarchical basis preconditioned conjugate gradient descent (Szeliski 1990b, 2006b) (Ap-\npendix A.5). In subsequent work, Agarwala (2007) shows how using a quadtree represen-\ntation for the solution can further accelerate the computation with minimal loss in accuracy,\nwhile Szeliski, Uyttendaele, and Steedly (2008) show how representing the per-image offset\nﬁelds using even coarser splines is even faster. This latter work also argues that blending\nin the log domain, i.e., using multiplicative rather than additive offsets, is preferable, as it\nmore closely matches texture contrasts across seam boundaries. The resulting seam blending\nworks very well in practice (Figure 9.14h), although care must be taken when copying large\ngradient values near seams so that a “double edge” is not introduced.\nCopying gradients directly from the source images after seam placement is just one ap-\nproach to gradient domain blending. The paper by Levin, Zomet, Peleg et al. (2004) examines\nseveral different variants of this approach, which they call Gradient-domain Image STitching\n(GIST). The techniques they examine include feathering (blending) the gradients from the\nsource images, as well as using an L1 norm in performing the reconstruction of the image\nfrom the gradient ﬁeld, rather than using an L2 norm as in Equation (9.44). Their preferred\ntechnique is the L1 optimization of a feathered (blended) cost function on the original image\ngradients (which they call GIST1-l1). Since L1 optimization using linear programming can\nbe slow, they develop a faster iterative median-based algorithm in a multigrid framework.\nVisual comparisons between their preferred approach and what they call optimal seam on\nthe gradients (which is equivalent to the approach of Agarwala, Dontcheva, Agrawala et al.\n(2004)) show similar results, while signiﬁcantly improving on pyramid blending and feather-\ning algorithms.\n15 At seam locations, the right hand side is replaced by the average of the gradients in the two source images.\n462\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nExposure compensation.\nPyramid and gradient domain blending can do a good job of\ncompensating for moderate amounts of exposure differences between images.\nHowever,\nwhen the exposure differences become large, alternative approaches may be necessary.\nUyttendaele, Eden, and Szeliski (2001) iteratively estimate a local correction between\neach source image and a blended composite. First, a block-based quadratic transfer function is\nﬁt between each source image and an initial feathered composite. Next, transfer functions are\naveraged with their neighbors to get a smoother mapping and per-pixel transfer functions are\ncomputed by splining (interpolating) between neighboring block values. Once each source\nimage has been smoothly adjusted, a new feathered composite is computed and the process is\nrepeated (typically three times). The results shown by Uyttendaele, Eden, and Szeliski (2001)\ndemonstrate that this does a better job of exposure compensation than simple feathering and\ncan handle local variations in exposure due to effects such as lens vignetting.\nUltimately, however, the most principled way to deal with exposure differences is to stitch\nimages in the radiance domain, i.e., to convert each image into a radiance image using its\nexposure value and then create a stitched, high dynamic range image, as discussed in Sec-\ntion 10.2 (Eden, Uyttendaele, and Szeliski 2006).\n9.4 Additional reading\nThe literature on image stitching dates back to work in the photogrammetry community in\nthe 1970s (Milgram 1975, 1977; Slama 1980). In computer vision, papers started appearing\nin the early 1980s (Peleg 1981), while the development of fully automated techniques came\nabout a decade later (Mann and Picard 1994; Chen 1995; Szeliski 1996; Szeliski and Shum\n1997; Sawhney and Kumar 1999; Shum and Szeliski 2000). Those techniques used direct\npixel-based alignment but feature-based approaches are now the norm (Zoghlami, Faugeras,\nand Deriche 1997; Capel and Zisserman 1998; Cham and Cipolla 1998; Badra, Qumsieh, and\nDudek 1998; McLauchlan and Jaenicke 2002; Brown and Lowe 2007). A collection of some\nof these papers can be found in the book by Benosman and Kang (2001). Szeliski (2006a)\nprovides a comprehensive survey of image stitching, on which the material in this chapter is\nbased.\nHigh-quality techniques for optimal seam ﬁnding and blending are another important\ncomponent of image stitching systems. Important developments in this ﬁeld include work by\nMilgram (1977), Burt and Adelson (1983b), Davis (1998), Uyttendaele, Eden, and Szeliski\n(2001),P´erez, Gangnet, and Blake (2003), Levin, Zomet, Peleg et al. (2004), Agarwala,\nDontcheva, Agrawala et al. (2004), Eden, Uyttendaele, and Szeliski (2006), and Kopf, Uyt-\ntendaele, Deussen et al. (2007).\nIn addition to the merging of multiple overlapping photographs taken for aerial or ter-",
  "image_path": "page_483.jpg",
  "pages": [
    482,
    483,
    484
  ]
}