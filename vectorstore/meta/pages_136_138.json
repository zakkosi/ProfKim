{
  "doc_id": "pages_136_138",
  "text": "114\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n72\n88\n62\n52\n37 ∗\n1/4\n1/2\n1/4\n⇔\n1\n4\n\n\n2\n1\n.\n.\n.\n1\n2\n1\n.\n.\n.\n1\n2\n1\n.\n.\n.\n1\n2\n1\n.\n.\n.\n1\n2\n\n\n\n\n72\n88\n62\n52\n37\n\n\nFigure 3.12\nOne-dimensional signal convolution as a sparse matrix-vector multiply, g =\nHf.\nOccasionally, a shift-variant version of correlation or convolution may be used, e.g.,\ng(i, j) =\nX\nk,l\nf(i −k, j −l)h(k, l; i, j),\n(3.18)\nwhere h(k, l; i, j) is the convolution kernel at pixel (i, j). For example, such a spatially\nvarying kernel can be used to model blur in an image due to variable depth-dependent defocus.\nCorrelation and convolution can both be written as a matrix-vector multiply, if we ﬁrst\nconvert the two-dimensional images f(i, j) and g(i, j) into raster-ordered vectors f and g,\ng = Hf,\n(3.19)\nwhere the (sparse) H matrix contains the convolution kernels. Figure 3.12 shows how a\none-dimensional convolution can be represented in matrix-vector form.\nPadding (border effects)\nThe astute reader will notice that the matrix multiply shown in Figure 3.12 suffers from\nboundary effects, i.e., the results of ﬁltering the image in this form will lead to a darkening of\nthe corner pixels. This is because the original image is effectively being padded with 0 values\nwherever the convolution kernel extends beyond the original image boundaries.\nTo compensate for this, a number of alternative padding or extension modes have been\ndeveloped (Figure 3.13):\n• zero: set all pixels outside the source image to 0 (a good choice for alpha-matted cutout\nimages);\n• constant (border color): set all pixels outside the source image to a speciﬁed border\nvalue;\n• clamp (replicate or clamp to edge): repeat edge pixels indeﬁnitely;\n• (cyclic) wrap (repeat or tile): loop “around” the image in a “toroidal” conﬁguration;\n3.2 Linear ﬁltering\n115\nzero\nwrap\nclamp\nmirror\nblurred zero\nnormalized zero\nblurred clamp\nblurred mirror\nFigure 3.13 Border padding (top row) and the results of blurring the padded image (bottom\nrow). The normalized zero image is the result of dividing (normalizing) the blurred zero-\npadded RGBA image by its corresponding soft alpha value.\n• mirror: reﬂect pixels across the image edge;\n• extend: extend the signal by subtracting the mirrored version of the signal from the\nedge pixel value.\nIn the computer graphics literature (Akenine-M¨oller and Haines 2002, p. 124), these mech-\nanisms are known as the wrapping mode (OpenGL) or texture addressing mode (Direct3D).\nThe formulas for each of these modes are left to the reader (Exercise 3.8).\nFigure 3.13 shows the effects of padding an image with each of the above mechanisms and\nthen blurring the resulting padded image. As you can see, zero padding darkens the edges,\nclamp (replication) padding propagates border values inward, mirror (reﬂection) padding pre-\nserves colors near the borders. Extension padding (not shown) keeps the border pixels ﬁxed\n(during blur).\nAn alternative to padding is to blur the zero-padded RGBA image and to then divide the\nresulting image by its alpha value to remove the darkening effect. The results can be quite\ngood, as seen in the normalized zero image in Figure 3.13.\n3.2.1 Separable ﬁltering\nThe process of performing a convolution requires K2 (multiply-add) operations per pixel,\nwhere K is the size (width or height) of the convolution kernel, e.g., the box ﬁlter in Fig-\n116\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n1\nK2\n1\n1\n· · ·\n1\n1\n1\n· · ·\n1\n...\n...\n1\n...\n1\n1\n· · ·\n1\n1\n16\n1\n2\n1\n2\n4\n2\n1\n2\n1\n1\n256\n1\n4\n6\n4\n1\n4\n16\n24\n16\n4\n6\n24\n36\n24\n6\n4\n16\n24\n16\n4\n1\n4\n6\n4\n1\n1\n8\n−1\n0\n1\n−2\n0\n2\n−1\n0\n1\n1\n4\n1\n−2\n1\n−2\n4\n−2\n1\n−2\n1\n1\nK\n1\n1\n· · ·\n1\n1\n4\n1\n2\n1\n1\n16\n1\n4\n6\n4\n1\n1\n2\n−1\n0\n1\n1\n2\n1\n−2\n1\n(a) box, K = 5\n(b) bilinear\n(c) “Gaussian”\n(d) Sobel\n(e) corner\nFigure 3.14\nSeparable linear ﬁlters: For each image (a)–(e), we show the 2D ﬁlter kernel\n(top), the corresponding horizontal 1D kernel (middle), and the ﬁltered image (bottom). The\nﬁltered Sobel and corner images are signed, scaled up by 2× and 4×, respectively, and added\nto a gray offset before display.\nure 3.14a. In many cases, this operation can be signiﬁcantly sped up by ﬁrst performing a\none-dimensional horizontal convolution followed by a one-dimensional vertical convolution\n(which requires a total of 2K operations per pixel). A convolution kernel for which this is\npossible is said to be separable.\nIt is easy to show that the two-dimensional kernel K corresponding to successive con-\nvolution with a horizontal kernel h and a vertical kernel v is the outer product of the two\nkernels,\nK = vhT\n(3.20)\n(see Figure 3.14 for some examples). Because of the increased efﬁciency, the design of\nconvolution kernels for computer vision applications is often inﬂuenced by their separability.\nHow can we tell if a given kernel K is indeed separable? This can often be done by\ninspection or by looking at the analytic form of the kernel (Freeman and Adelson 1991). A\nmore direct method is to treat the 2D kernel as a 2D matrix K and to take its singular value\ndecomposition (SVD),\nK =\nX\ni\nσiuivT\ni\n(3.21)\n(see Appendix A.1.1 for the deﬁnition of the SVD). If only the ﬁrst singular value σ0 is\nnon-zero, the kernel is separable and √σ0u0 and √σ0vT\n0 provide the vertical and horizontal",
  "image_path": "page_137.jpg",
  "pages": [
    136,
    137,
    138
  ]
}