{
  "doc_id": "pages_478_480",
  "text": "456\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.15\nComputation of regions of difference (RODs) (Uyttendaele, Eden, and Szeliski\n2001) c⃝2001 IEEE: (a) three overlapping images with a moving face; (b) corresponding\nRODs; (c) graph of coincident RODs.\nsince the seam selection is performed sequentially as new images are added in, some artifacts\ncan occur.\nOptimal seam selection.\nComputing the Voronoi diagram is one way to select the seams\nbetween regions where different images contribute to the ﬁnal composite. However, Voronoi\nimages totally ignore the local image structure underlying the seam.\nA better approach is to place the seams in regions where the images agree, so that tran-\nsitions from one source to another are not visible. In this way, the algorithm avoids “cutting\nthrough” moving objects where a seam would look unnatural (Davis 1998). For a pair of\nimages, this process can be formulated as a simple dynamic program starting from one edge\nof the overlap region and ending at the other (Milgram 1975, 1977; Davis 1998; Efros and\nFreeman 2001).\nWhen multiple images are being composited, the dynamic program idea does not readily\ngeneralize. (For square texture tiles being composited sequentially, Efros and Freeman (2001)\nrun a dynamic program along each of the four tile sides.)\nTo overcome this problem, Uyttendaele, Eden, and Szeliski (2001) observed that, for\nwell-registered images, moving objects produce the most visible artifacts, namely translu-\ncent looking ghosts. Their system therefore decides which objects to keep and which ones\nto erase. First, the algorithm compares all overlapping input image pairs to determine re-\ngions of difference (RODs) where the images disagree. Next, a graph is constructed with the\nRODs as vertices and edges representing ROD pairs that overlap in the ﬁnal composite (Fig-\nure 9.15). Since the presence of an edge indicates an area of disagreement, vertices (regions)\nmust be removed from the ﬁnal composite until no edge spans a pair of remaining vertices.\nThe smallest such set can be computed using a vertex cover algorithm. Since several such\ncovers may exist, a weighted vertex cover is used instead, where the vertex weights are com-\nputed by summing the feather weights in the ROD (Uyttendaele, Eden, and Szeliski 2001).\nThe algorithm therefore prefers removing regions that are near the edge of the image, which\nreduces the likelihood that partially visible objects will appear in the ﬁnal composite. (It is\n9.3 Compositing\n457\nFigure 9.16\nPhotomontage (Agarwala, Dontcheva, Agrawala et al. 2004) c⃝2004 ACM.\nFrom a set of ﬁve source images (of which four are shown on the left), Photomontage quickly\ncreates a composite family portrait in which everyone is smiling and looking at the camera\n(right). Users simply ﬂip through the stack and coarsely draw strokes using the designated\nsource image objective over the people they wish to add to the composite. The user-applied\nstrokes and computed regions (middle) are color-coded by the borders of the source images\non the left.\nalso possible to infer which object in a region of difference is the foreground object by the\n“edginess” (pixel differences) across the ROD boundary, which should be higher when an\nobject is present (Herley 2005).) Once the desired excess regions of difference have been\nremoved, the ﬁnal composite can be created by feathering (Figure 9.14f).\nA different approach to pixel selection and seam placement is described by Agarwala,\nDontcheva, Agrawala et al. (2004). Their system computes the label assignment that opti-\nmizes the sum of two objective functions. The ﬁrst is a per-pixel image objective that deter-\nmines which pixels are likely to produce good composites,\nCD =\nX\nx\nD(x, l(x)),\n(9.41)\nwhere D(x, l) is the data penalty associated with choosing image l at pixel x. In their system,\nusers can select which pixels to use by “painting” over an image with the desired object or\nappearance, which sets D(x, l) to a large value for all labels l other than the one selected\nby the user (Figure 9.16). Alternatively, automated selection criteria can be used, such as\nmaximum likelihood, which prefers pixels that occur repeatedly in the background (for object\nremoval), or minimum likelihood for objects that occur infrequently, i.e., for moving object\nretention. Using a more traditional center-weighted data term tends to favor objects that are\ncentered in the input images (Figure 9.17).\nThe second term is a seam objective that penalizes differences in labelings between adja-\ncent images,\nCS =\nX\n(x,y)∈N\nS(x, y, l(x), l(y)),\n(9.42)\n458\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 9.17\nSet of ﬁve photos tracking a snowboarder’s jump stitched together into a seam-\nless composite. Because the algorithm prefers pixels near the center of the image, multiple\ncopies of the boarder are retained.\nwhere S(x, y, lx, ly) is the image-dependent interaction penalty or seam cost of placing a\nseam between pixels x and y, and N is the set of N4 neighboring pixels. For example,\nthe simple color-based seam penalty used in (Kwatra, Sch¨odl, Essa et al. 2003; Agarwala,\nDontcheva, Agrawala et al. 2004) can be written as\nS(x, y, lx, ly) = ∥˜Ilx(x) −˜Ily(x)∥+ ∥˜Ilx(y) −˜Ily(y)∥.\n(9.43)\nMore sophisticated seam penalties can also look at image gradients or the presence of image\nedges (Agarwala, Dontcheva, Agrawala et al. 2004). Seam penalties are widely used in other\ncomputer vision applications such as stereo matching (Boykov, Veksler, and Zabih 2001) to\ngive the labeling function its coherence or smoothness. An alternative approach, which places\nseams along strong consistent edges in overlapping images using a watershed computation is\ndescribed by Soille (2006).\nThe sum of these two objective functions gives rise to a Markov random ﬁeld (MRF),\nfor which good optimization algorithms are described in Sections 3.7.2 and 5.5 and Ap-\npendix B.5. For label computations of this kind, the α-expansion algorithm developed by\nBoykov, Veksler, and Zabih (2001) works particularly well (Szeliski, Zabih, Scharstein et al.\n2008).\nFor the result shown in Figure 9.14g, Agarwala, Dontcheva, Agrawala et al. (2004) use\na large data penalty for invalid pixels and 0 for valid pixels. Notice how the seam placement\nalgorithm avoids regions of difference, including those that border the image and that might\nresult in objects being cut off. Graph cuts (Agarwala, Dontcheva, Agrawala et al. 2004) and",
  "image_path": "page_479.jpg",
  "pages": [
    478,
    479,
    480
  ]
}