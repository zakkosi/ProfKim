{
  "doc_id": "pages_031_033",
  "text": "1.1 What is computer vision?\n9\nThe great thing about these applications is that they are already familiar to most students;\nthey are, at least, technologies that students can immediately appreciate and use with their\nown personal media. Since computer vision is a challenging topic, given the wide range\nof mathematics being covered4 and the intrinsically difﬁcult nature of the problems being\nsolved, having fun and relevant problems to work on can be highly motivating and inspiring.\nThe other major reason why this book has a strong focus on applications is that they can\nbe used to formulate and constrain the potentially open-ended problems endemic in vision.\nFor example, if someone comes to me and asks for a good edge detector, my ﬁrst question is\nusually to ask why? What kind of problem are they trying to solve and why do they believe\nthat edge detection is an important component? If they are trying to locate faces, I usually\npoint out that most successful face detectors use a combination of skin color detection (Exer-\ncise 2.8) and simple blob features Section 14.1.1; they do not rely on edge detection. If they\nare trying to match door and window edges in a building for the purpose of 3D reconstruction,\nI tell them that edges are a ﬁne idea but it is better to tune the edge detector for long edges\n(see Sections 3.2.3 and 4.2) and link them together into straight lines with common vanishing\npoints before matching (see Section 4.3).\nThus, it is better to think back from the problem at hand to suitable techniques, rather\nthan to grab the ﬁrst technique that you may have heard of. This kind of working back from\nproblems to solutions is typical of an engineering approach to the study of vision and reﬂects\nmy own background in the ﬁeld. First, I come up with a detailed problem deﬁnition and\ndecide on the constraints and speciﬁcations for the problem. Then, I try to ﬁnd out which\ntechniques are known to work, implement a few of these, evaluate their performance, and\nﬁnally make a selection. In order for this process to work, it is important to have realistic test\ndata, both synthetic, which can be used to verify correctness and analyze noise sensitivity,\nand real-world data typical of the way the system will ﬁnally be used.\nHowever, this book is not just an engineering text (a source of recipes). It also takes a\nscientiﬁc approach to basic vision problems. Here, I try to come up with the best possible\nmodels of the physics of the system at hand: how the scene is created, how light interacts\nwith the scene and atmospheric effects, and how the sensors work, including sources of noise\nand uncertainty. The task is then to try to invert the acquisition process to come up with the\nbest possible description of the scene.\nThe book often uses a statistical approach to formulating and solving computer vision\nproblems. Where appropriate, probability distributions are used to model the scene and the\nnoisy image acquisition process. The association of prior distributions with unknowns is often\n3 For a fun student project on this topic, see the “PhotoBook” project at http://www.cc.gatech.edu/dvfx/videos/\ndvfx2005.html.\n4 These techniques include physics, Euclidean and projective geometry, statistics, and optimization. They make\ncomputer vision a fascinating ﬁeld to study and a great way to learn techniques widely applicable in other ﬁelds.\n10\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ncalled Bayesian modeling (Appendix B). It is possible to associate a risk or loss function with\nmis-estimating the answer (Section B.2) and to set up your inference algorithm to minimize\nthe expected risk. (Consider a robot trying to estimate the distance to an obstacle: it is\nusually safer to underestimate than to overestimate.) With statistical techniques, it often helps\nto gather lots of training data from which to learn probabilistic models. Finally, statistical\napproaches enable you to use proven inference techniques to estimate the best answer (or\ndistribution of answers) and to quantify the uncertainty in the resulting estimates.\nBecause so much of computer vision involves the solution of inverse problems or the esti-\nmation of unknown quantities, my book also has a heavy emphasis on algorithms, especially\nthose that are known to work well in practice. For many vision problems, it is all too easy to\ncome up with a mathematical description of the problem that either does not match realistic\nreal-world conditions or does not lend itself to the stable estimation of the unknowns. What\nwe need are algorithms that are both robust to noise and deviation from our models and rea-\nsonably efﬁcient in terms of run-time resources and space. In this book, I go into these issues\nin detail, using Bayesian techniques, where applicable, to ensure robustness, and efﬁcient\nsearch, minimization, and linear system solving algorithms to ensure efﬁciency. Most of the\nalgorithms described in this book are at a high level, being mostly a list of steps that have to\nbe ﬁlled in by students or by reading more detailed descriptions elsewhere. In fact, many of\nthe algorithms are sketched out in the exercises.\nNow that I’ve described the goals of this book and the frameworks that I use, I devote the\nrest of this chapter to two additional topics. Section 1.2 is a brief synopsis of the history of\ncomputer vision. It can easily be skipped by those who want to get to “the meat” of the new\nmaterial in this book and do not care as much about who invented what when.\nThe second is an overview of the book’s contents, Section 1.3, which is useful reading for\neveryone who intends to make a study of this topic (or to jump in partway, since it describes\nchapter inter-dependencies). This outline is also useful for instructors looking to structure\none or more courses around this topic, as it provides sample curricula based on the book’s\ncontents.\n1.2 A brief history\nIn this section, I provide a brief personal synopsis of the main developments in computer\nvision over the last 30 years (Figure 1.6); at least, those that I ﬁnd personally interesting\nand which appear to have stood the test of time. Readers not interested in the provenance\nof various ideas and the evolution of this ﬁeld should skip ahead to the book overview in\nSection 1.3.\n1.2 A brief history\n11\nDigital image processing\nBlocks world, line labeling\nGeneralized cylinders\n197\nGeneralized cylinders\nPictorial structures\nStereo correspondence\nIntrinsic images\nOptical flow\nStructure from motion\n70\nImage pyramids\nScale-space processing\nShape from shading, \ntexture, and focus\nPhysically-based  modeling\n1980\nRegularization\nMarkov Random Fields\nKalman filters\n3D range data processing\nProjective invariants\nFactorization\n1\nFactorization\nPhysics-based vision\nGraph cuts\nParticle filtering\nEnergy-based segmentation\nFace recognition and detection\n1990\nFace recognition and detection\nSubspace methods\nImage-based modeling \nand rendering\nTexture synthesis and inpainting\nComputational photography\n2000\nFeature-based  recognition\nMRF inference algorithms\nCategory recognition\nLearning\nFigure 1.6\nA rough timeline of some of the most active topics of research in computer\nvision.\n1970s.\nWhen computer vision ﬁrst started out in the early 1970s, it was viewed as the\nvisual perception component of an ambitious agenda to mimic human intelligence and to\nendow robots with intelligent behavior. At the time, it was believed by some of the early\npioneers of artiﬁcial intelligence and robotics (at places such as MIT, Stanford, and CMU)\nthat solving the “visual input” problem would be an easy step along the path to solving more\ndifﬁcult problems such as higher-level reasoning and planning. According to one well-known\nstory, in 1966, Marvin Minsky at MIT asked his undergraduate student Gerald Jay Sussman\nto “spend the summer linking a camera to a computer and getting the computer to describe\nwhat it saw” (Boden 2006, p. 781).5 We now know that the problem is slightly more difﬁcult\nthan that.6\nWhat distinguished computer vision from the already existing ﬁeld of digital image pro-\ncessing (Rosenfeld and Pfaltz 1966; Rosenfeld and Kak 1976) was a desire to recover the\nthree-dimensional structure of the world from images and to use this as a stepping stone to-\nwards full scene understanding. Winston (1975) and Hanson and Riseman (1978) provide\ntwo nice collections of classic papers from this early period.\nEarly attempts at scene understanding involved extracting edges and then inferring the\n3D structure of an object or a “blocks world” from the topological structure of the 2D lines\n(Roberts 1965). Several line labeling algorithms (Figure 1.7a) were developed at that time\n(Huffman 1971; Clowes 1971; Waltz 1975; Rosenfeld, Hummel, and Zucker 1976; Kanade\n1980). Nalwa (1993) gives a nice review of this area. The topic of edge detection was also\n5 Boden (2006) cites (Crevier 1993) as the original source. The actual Vision Memo was authored by Seymour\nPapert (1966) and involved a whole cohort of students.\n6 To see how far robotic vision has come in the last four decades, have a look at the towel-folding robot at\nhttp://rll.eecs.berkeley.edu/pr/icra10/ (Maitin-Shepard, Cusumano-Towner, Lei et al. 2010).",
  "image_path": "page_032.jpg",
  "pages": [
    31,
    32,
    33
  ]
}