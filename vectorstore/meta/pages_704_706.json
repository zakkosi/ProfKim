{
  "doc_id": "pages_704_706",
  "text": "682\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 14.22 Principal modes of variation in active appearance models (Cootes, Edwards,\nand Taylor 2001) c⃝2001 IEEE. The four images show the effects of simultaneously changing\nthe ﬁrst four modes of variation in both shape and texture by ±σ from the mean. You can\nclearly see how the shape of the face and the shading are simultaneously affected.\nIn more detail, Cootes, Edwards, and Taylor (2001) compute the derivatives of a set of\ntraining images with respect to each of the parameters in a using ﬁnite differences and then\ncompute a set of displacement weight images\nW =\n\u0014∂xT\n∂a\n∂x\n∂a\n\u0015−1 ∂xT\n∂a ,\n(14.31)\nwhich can be multiplied by the current error residual to produce an update step in the pa-\nrameters, δa = −W r. Matthews and Baker (2004) use their inverse compositional method,\nwhich they ﬁrst developed for parametric optical ﬂow (8.64–8.65), to further speed up active\nappearance model ﬁtting and tracking. Examples of AAMs being ﬁtted to two input images\nare shown in Figure 14.23.\nAlthough active appearance models are primarily designed to accurately capture the vari-\nability in appearance and deformation that are characteristic of faces, they can be adapted to\nface recognition by computing an identity subspace that separates variation in identity from\nother sources of variability such as lighting, pose, and expression (Costen, Cootes, Edwards\net al. 1999). The basic idea, which is modeled after similar work in eigenfaces (Belhumeur,\nHespanha, and Kriegman 1997; Moghaddam, Jebara, and Pentland 2000), is to compute sep-\narate statistics for intrapersonal and extrapersonal variation and then ﬁnd discriminating di-\nrections in these subspaces. While AAMs have sometimes been used directly for recognition\n(Blanz and Vetter 2003), their main use in the context of recognition is to align faces into\na canonical pose (Liang, Xiao, Wen et al. 2008) so that more traditional methods of face\n14.2 Face recognition\n683\nFigure 14.23\nMultiresolution model ﬁtting (search) in active appearance models (Cootes,\nEdwards, and Taylor 2001) c⃝2001 IEEE. The columns show the initial model, the results\nafter 3, 8, and 11 iterations, and the ﬁnal convergence. The rightmost column shows the input\nimage.\nrecognition (Penev and Atick 1996; Wiskott, Fellous, Kr¨uger et al. 1997; Ahonen, Hadid,\nand Pietik¨ainen 2006; Zhao and Pietik¨ainen 2007; Cao, Yin, Tang et al. 2010) can be used.\nAAMs (or, actually, their simpler version, Active Shape Models (ASMs)) can also be used to\nalign face images to perform automated morphing (Zanella and Fuentes 2004).\nActive appearance models continue to be an active research area, with enhancements to\ndeal with illumination and viewpoint variation (Gross, Baker, Matthews et al. 2005) as well\nas occlusions (Gross, Matthews, and Baker 2006). One of the most signiﬁcant extensions is\nto construct 3D models of shape (Matthews, Xiao, and Baker 2007), which are much better at\ncapturing and explaining the full variability of facial appearance across wide changes in pose.\nFigure 14.24\nHead tracking with 3D AAMs (Matthews, Xiao, and Baker 2007) c⃝2007\nSpringer. Each image shows a video frame along with the estimate yaw, pitch, and roll\nparameters and the ﬁtted 3D deformable mesh.\n684\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 14.25\nPerson detection and re-recognition using a combined face, hair, and torso\nmodel (Sivic, Zitnick, and Szeliski 2006) c⃝2006 Springer. (a) Using face detection alone,\nseveral of the heads are missed. (b) The combined face and clothing model successfully\nre-ﬁnds all the people.\nSuch models can be constructed either from monocular video sequences (Matthews, Xiao,\nand Baker 2007), as shown in Figure 14.24, or from multi-view video sequences (Ramnath,\nKoterba, Xiao et al. 2008), which provide even greater reliability and accuracy in reconstruc-\ntion and tracking. (For a recent review of progress in head pose estimation, please see the\nsurvey paper by Murphy-Chutorian and Trivedi (2009).)\n14.2.3 Application: Personal photo collections\nIn addition to digital cameras automatically ﬁnding faces to aid in auto-focusing and video\ncameras ﬁnding faces in video conferencing to center on the speaker (either mechanically\nor digitally), face detection has found its way into most consumer-level photo organization\npackages, such as iPhoto, Picasa, and Windows Live Photo Gallery. Finding faces and al-\nlowing users to tag them makes it easier to ﬁnd photos of selected people at a later date or to\nautomatically share them with friends. In fact, the ability to tag friends in photos is one of the\nmore popular features on Facebook.\nSometimes, however, faces can be hard to ﬁnd and recognize, especially if they are small,",
  "image_path": "page_705.jpg",
  "pages": [
    704,
    705,
    706
  ]
}