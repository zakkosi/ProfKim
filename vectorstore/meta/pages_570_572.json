{
  "doc_id": "pages_570_572",
  "text": "548\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nhigh-frequency areas, Birchﬁeld and Tomasi (1998) proposed a matching cost that is less sen-\nsitive to shifts in image sampling. Rather than just comparing pixel values shifted by integral\namounts (which may miss a valid match), they compare each pixel in the reference image\nagainst a linearly interpolated function of the other image. More detailed studies of these\nand additional matching costs are explored in (Szeliski and Scharstein 2004; Hirschm¨uller\nand Scharstein 2009). In particular, if you expect there to be signiﬁcant exposure or appear-\nance variation between images that you are matching, some of the more robust measures\nthat performed well in the evaluation by Hirschm¨uller and Scharstein (2009), such as the\ncensus transform (Zabih and Woodﬁll 1994), ordinal measures (Bhat and Nayar 1998), bi-\nlateral subtraction (Ansar, Castano, and Matthies 2004), or hierarchical mutual information\n(Hirschm¨uller 2008), should be used.\n11.4 Local methods\nLocal and window-based methods aggregate the matching cost by summing or averaging\nover a support region in the DSI C(x, y, d).4 A support region can be either two-dimensional\nat a ﬁxed disparity (favoring fronto-parallel surfaces), or three-dimensional in x-y-d space\n(supporting slanted surfaces). Two-dimensional evidence aggregation has been implemented\nusing square windows or Gaussian convolution (traditional), multiple windows anchored at\ndifferent points, i.e., shiftable windows (Arnold 1983; Fusiello, Roberto, and Trucco 1997;\nBobick and Intille 1999), windows with adaptive sizes (Okutomi and Kanade 1992; Kanade\nand Okutomi 1994; Kang, Szeliski, and Chai 2001; Veksler 2001, 2003), windows based on\nconnected components of constant disparity (Boykov, Veksler, and Zabih 1998), or the re-\nsults of color-based segmentation (Yoon and Kweon 2006; Tombari, Mattoccia, Di Stefano\net al. 2008). Three-dimensional support functions that have been proposed include limited\ndisparity difference (Grimson 1985), limited disparity gradient (Pollard, Mayhew, and Frisby\n1985), Prazdny’s coherence principle (Prazdny 1985), and the more recent work (which in-\ncludes visibility and occlusion reasoning) by Zitnick and Kanade (2000).\nAggregation with a ﬁxed support region can be performed using 2D or 3D convolution,\nC(x, y, d) = w(x, y, d) ∗C0(x, y, d),\n(11.6)\nor, in the case of rectangular windows, using efﬁcient moving average box-ﬁlters (Sec-\ntion 3.2.2) (Kanade, Yoshida, Oda et al. 1996; Kimura, Shinbo, Yamaguchi et al. 1999).\nShiftable windows can also be implemented efﬁciently using a separable sliding min-ﬁlter\n(Figure 11.8) (Scharstein and Szeliski 2002, Section 4.2). Selecting among windows of dif-\nferent shapes and sizes can be performed more efﬁciently by ﬁrst computing a summed area\n4 For two recent surveys and comparisons of such techniques, please see the work of Gong, Yang, Wang et al.\n(2007) and Tombari, Mattoccia, Di Stefano et al. (2008).\n11.4 Local methods\n549\nFigure 11.8 Shiftable window (Scharstein and Szeliski 2002) c⃝2002 Springer. The effect\nof trying all 3 × 3 shifted windows around the black pixel is the same as taking the minimum\nmatching score across all centered (non-shifted) windows in the same neighborhood. (For\nclarity, only three of the neighboring shifted windows are shown here.)\n(a)\n(b)\n(c)\n(d)\nFigure 11.9\nAggregation window sizes and weights adapted to image content (Tombari,\nMattoccia, Di Stefano et al. 2008) c⃝2008 IEEE: (a) original image with selected evaluation\npoints; (b) variable windows (Veksler 2003); (c) adaptive weights (Yoon and Kweon 2006);\n(d) segmentation-based (Tombari, Mattoccia, and Di Stefano 2007). Notice how the adaptive\nweights and segmentation-based techniques adapt their support to similarly colored pixels.\ntable (Section 3.2.3, 3.30–3.32) (Veksler 2003). Selecting the right window is important,\nsince windows must be large enough to contain sufﬁcient texture and yet small enough so\nthat they do not straddle depth discontinuities (Figure 11.9). An alternative method for ag-\ngregation is iterative diffusion, i.e., repeatedly adding to each pixel’s cost the weighted values\nof its neighboring pixels’ costs (Szeliski and Hinton 1985; Shah 1993; Scharstein and Szeliski\n1998).\nOf the local aggregation methods compared by Gong, Yang, Wang et al. (2007) and\nTombari, Mattoccia, Di Stefano et al. (2008), the fast variable window approach of Vek-\nsler (2003) and the locally weighting approach developed by Yoon and Kweon (2006) con-\nsistently stood out as having the best tradeoff between performance and speed.5 The local\nweighting technique, in particular, is interesting because, instead of using square windows\nwith uniform weighting, each pixel within an aggregation window inﬂuences the ﬁnal match-\n5 More recent and extensive results from Tombari, Mattoccia, Di Stefano et al. (2008) can be found at http:\n//www.vision.deis.unibo.it/spe/SPEHome.aspx.\n550\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ning cost based on its color similarity and spatial distance, just as in bilinear ﬁltering (Fig-\nure 11.9c). (In fact, their aggregation step is closely related to doing a joint bilateral ﬁlter\non the color/disparity image, except that it is done symmetrically in both reference and target\nimages.) The segmentation-based aggregation method of Tombari, Mattoccia, and Di Stefano\n(2007) did even better, although a fast implementation of this algorithm does not yet exist.\nIn local methods, the emphasis is on the matching cost computation and cost aggregation\nsteps. Computing the ﬁnal disparities is trivial: simply choose at each pixel the disparity\nassociated with the minimum cost value. Thus, these methods perform a local “winner-\ntake-all” (WTA) optimization at each pixel. A limitation of this approach (and many other\ncorrespondence algorithms) is that uniqueness of matches is only enforced for one image\n(the reference image), while points in the other image might match multiple points, unless\ncross-checking and subsequent hole ﬁlling is used (Fua 1993; Hirschm¨uller and Scharstein\n2009).\n11.4.1 Sub-pixel estimation and uncertainty\nMost stereo correspondence algorithms compute a set of disparity estimates in some dis-\ncretized space, e.g., for integer disparities (exceptions include continuous optimization tech-\nniques such as optical ﬂow (Bergen, Anandan, Hanna et al. 1992) or splines (Szeliski and\nCoughlan 1997)). For applications such as robot navigation or people tracking, these may be\nperfectly adequate. However for image-based rendering, such quantized maps lead to very\nunappealing view synthesis results, i.e., the scene appears to be made up of many thin shear-\ning layers. To remedy this situation, many algorithms apply a sub-pixel reﬁnement stage after\nthe initial discrete correspondence stage. (An alternative is to simply start with more discrete\ndisparity levels (Szeliski and Scharstein 2004).)\nSub-pixel disparity estimates can be computed in a variety of ways, including iterative\ngradient descent and ﬁtting a curve to the matching costs at discrete disparity levels (Ryan,\nGray, and Hunt 1980; Lucas and Kanade 1981; Tian and Huhns 1986; Matthies, Kanade,\nand Szeliski 1989; Kanade and Okutomi 1994). This provides an easy way to increase the\nresolution of a stereo algorithm with little additional computation. However, to work well,\nthe intensities being matched must vary smoothly, and the regions over which these estimates\nare computed must be on the same (correct) surface.\nRecently, some questions have been raised about the advisability of ﬁtting correlation\ncurves to integer-sampled matching costs (Shimizu and Okutomi 2001). This situation may\neven be worse when sampling-insensitive dissimilarity measures are used (Birchﬁeld and\nTomasi 1998). These issues are explored in more depth by Szeliski and Scharstein (2004).\nBesides sub-pixel computations, there are other ways of post-processing the computed\ndisparities. Occluded areas can be detected using cross-checking, i.e., comparing left-to-",
  "image_path": "page_571.jpg",
  "pages": [
    570,
    571,
    572
  ]
}