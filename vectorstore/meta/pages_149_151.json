{
  "doc_id": "pages_149_151",
  "text": "3.3 More neighborhood operators\n127\nWe can thus re-write (3.34) as\nf (t+1)(i, j)\n=\nf (t)(i, j) + η P\nk,l f (t)(k, l)r(i, j, k, l)\n1 + η P\nk,l r(i, j, k, l)\n(3.40)\n=\nf (t)(i, j) +\nη\n1 + ηR\nX\nk,l\nr(i, j, k, l)[f (t)(k, l) −f (t)(i, j)],\nwhere R = P\n(k,l) r(i, j, k, l), (k, l) are the N4 neighbors of (i, j), and we have made the\niterative nature of the ﬁltering explicit.\nAs Barash (2002) notes, (3.40) is the same as the discrete anisotropic diffusion equation\nﬁrst proposed by Perona and Malik (1990b).6 Since its original introduction, anisotropic dif-\nfusion has been extended and applied to a wide range of problems (Nielsen, Florack, and De-\nriche 1997; Black, Sapiro, Marimont et al. 1998; Weickert, ter Haar Romeny, and Viergever\n1998; Weickert 1998). It has also been shown to be closely related to other adaptive smooth-\ning techniques (Saint-Marc, Chen, and Medioni 1991; Barash 2002; Barash and Comaniciu\n2004) as well as Bayesian regularization with a non-linear smoothness term that can be de-\nrived from image statistics (Scharr, Black, and Haussecker 2003).\nIn its general form, the range kernel r(i, j, k, l) = r(∥f(i, j)−f(k, l)∥), which is usually\ncalled the gain or edge-stopping function, or diffusion coefﬁcient, can be any monotonically\nincreasing function with r′(x) →0 as x →∞. Black, Sapiro, Marimont et al. (1998) show\nhow anisotropic diffusion is equivalent to minimizing a robust penalty function on the image\ngradients, which we discuss in Sections 3.7.1 and 3.7.2). Scharr, Black, and Haussecker\n(2003) show how the edge-stopping function can be derived in a principled manner from\nlocal image statistics. They also extend the diffusion neighborhood from N4 to N8, which\nallows them to create a diffusion operator that is both rotationally invariant and incorporates\ninformation about the eigenvalues of the local structure tensor.\nNote that, without a bias term towards the original image, anisotropic diffusion and itera-\ntive adaptive smoothing converge to a constant image. Unless a small number of iterations is\nused (e.g., for speed), it is usually preferable to formulate the smoothing problem as a joint\nminimization of a smoothness term and a data ﬁdelity term, as discussed in Sections 3.7.1\nand 3.7.2 and by Scharr, Black, and Haussecker (2003), which introduce such a bias in a\nprincipled manner.\n3.3.2 Morphology\nWhile non-linear ﬁlters are often used to enhance grayscale and color images, they are also\nused extensively to process binary images. Such images often occur after a thresholding\n6 The 1/(1 + ηR) factor is not present in anisotropic diffusion but becomes negligible as η →0.\n128\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 3.21\nBinary image morphology: (a) original image; (b) dilation; (c) erosion; (d)\nmajority; (e) opening; (f) closing. The structuring element for all examples is a 5 × 5 square.\nThe effects of majority are a subtle rounding of sharp corners. Opening fails to eliminate the\ndot, since it is not wide enough.\noperation,\nθ(f, t) =\n(\n1\nif f ≥t,\n0\nelse,\n(3.41)\ne.g., converting a scanned grayscale document into a binary image for further processing such\nas optical character recognition.\nThe most common binary image operations are called morphological operations, since\nthey change the shape of the underlying binary objects (Ritter and Wilson 2000, Chapter 7).\nTo perform such an operation, we ﬁrst convolve the binary image with a binary structuring\nelement and then select a binary output value depending on the thresholded result of the\nconvolution. (This is not the usual way in which these operations are described, but I ﬁnd it\na nice simple way to unify the processes.) The structuring element can be any shape, from\na simple 3 × 3 box ﬁlter, to more complicated disc structures. It can even correspond to a\nparticular shape that is being sought for in the image.\nFigure 3.21 shows a close-up of the convolution of a binary image f with a 3 × 3 struc-\nturing element s and the resulting images for the operations described below. Let\nc = f ⊗s\n(3.42)\nbe the integer-valued count of the number of 1s inside each structuring element as it is scanned\nover the image and S be the size of the structuring element (number of pixels). The standard\noperations used in binary morphology include:\n• dilation: dilate(f, s) = θ(c, 1);\n• erosion: erode(f, s) = θ(c, S);\n• majority: maj(f, s) = θ(c, S/2);\n• opening: open(f, s) = dilate(erode(f, s), s);\n3.3 More neighborhood operators\n129\n• closing: close(f, s) = erode(dilate(f, s), s).\nAs we can see from Figure 3.21, dilation grows (thickens) objects consisting of 1s, while\nerosion shrinks (thins) them. The opening and closing operations tend to leave large regions\nand smooth boundaries unaffected, while removing small objects or holes and smoothing\nboundaries.\nWhile we will not use mathematical morphology much in the rest of this book, it is a\nhandy tool to have around whenever you need to clean up some thresholded images. You\ncan ﬁnd additional details on morphology in other textbooks on computer vision and image\nprocessing (Haralick and Shapiro 1992, Section 5.2) (Bovik 2000, Section 2.2) (Ritter and\nWilson 2000, Section 7) as well as articles and books speciﬁcally on this topic (Serra 1982;\nSerra and Vincent 1992; Yuille, Vincent, and Geiger 1992; Soille 2006).\n3.3.3 Distance transforms\nThe distance transform is useful in quickly precomputing the distance to a curve or set of\npoints using a two-pass raster algorithm (Rosenfeld and Pfaltz 1966; Danielsson 1980; Borge-\nfors 1986; Paglieroni 1992; Breu, Gil, Kirkpatrick et al. 1995; Felzenszwalb and Huttenlocher\n2004a; Fabbri, Costa, Torelli et al. 2008). It has many applications, including level sets (Sec-\ntion 5.1.4), fast chamfer matching (binary image alignment) (Huttenlocher, Klanderman, and\nRucklidge 1993), feathering in image stitching and blending (Section 9.3.2), and nearest point\nalignment (Section 12.2.1).\nThe distance transform D(i, j) of a binary image b(i, j) is deﬁned as follows. Let d(k, l)\nbe some distance metric between pixel offsets. Two commonly used metrics include the city\nblock or Manhattan distance\nd1(k, l) = |k| + |l|\n(3.43)\nand the Euclidean distance\nd2(k, l) =\np\nk2 + l2.\n(3.44)\nThe distance transform is then deﬁned as\nD(i, j) =\nmin\nk,l:b(k,l)=0 d(i −k, j −l),\n(3.45)\ni.e., it is the distance to the nearest background pixel whose value is 0.\nThe D1 city block distance transform can be efﬁciently computed using a forward and\nbackward pass of a simple raster-scan algorithm, as shown in Figure 3.22. During the forward\npass, each non-zero pixel in b is replaced by the minimum of 1 + the distance of its north or\nwest neighbor. During the backward pass, the same occurs, except that the minimum is both\nover the current value D and 1 + the distance of the south and east neighbors (Figure 3.22).",
  "image_path": "page_150.jpg",
  "pages": [
    149,
    150,
    151
  ]
}