{
  "doc_id": "pages_418_420",
  "text": "396\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 8.4\nSSD surfaces corresponding to three locations (red crosses) in an image:\n(a) highly textured area, strong minimum, low uncertainty; (b) strong edge, aperture prob-\nlem, high uncertainty in one direction; (c) weak texture, no clear minimum, large uncertainty.\n8.1 Translational alignment\n397\nUncertainty modeling.\nThe reliability of a particular patch-based motion estimate can be\ncaptured more formally with an uncertainty model. The simplest such model is a covariance\nmatrix, which captures the expected variance in the motion estimate in all possible directions.\nAs discussed in Section 6.1.4 and Appendix B.6, under small amounts of additive Gaussian\nnoise, it can be shown that the covariance matrix Σu is proportional to the inverse of the\nHessian A,\nΣu = σ2\nnA−1,\n(8.44)\nwhere σ2\nn is the variance of the additive Gaussian noise (Anandan 1989; Matthies, Kanade,\nand Szeliski 1989; Szeliski 1989).\nFor larger amounts of noise, the linearization performed by the Lucas–Kanade algorithm\nin (8.35) is only approximate, so the above quantity becomes a Cramer–Rao lower bound on\nthe true covariance. Thus, the minimum and maximum eigenvalues of the Hessian A can now\nbe interpreted as the (scaled) inverse variances in the least-certain and most-certain directions\nof motion. (A more detailed analysis using a more realistic model of image noise is given by\nSteele and Jaynes (2005).) Figure 8.4 shows the local SSD surfaces for three different pixel\nlocations in an image. As you can see, the surface has a clear minimum in the highly textured\nregion and suffers from the aperture problem near the strong edge.\nBias and gain, weighting, and robust error metrics.\nThe Lucas–Kanade update rule can\nalso be applied to the bias–gain equation (8.9) to obtain\nELK−BG(u + ∆u) =\nX\ni\n[J1(xi + u)∆u + ei −αI0(xi) −β]2\n(8.45)\n(Lucas and Kanade 1981; Gennert 1988; Fuh and Maragos 1991; Baker, Gross, and Matthews\n2003). The resulting 4 × 4 system of equations can be solved to simultaneously estimate the\ntranslational displacement update ∆u and the bias and gain parameters β and α.\nA similar formulation can be derived for images (templates) that have a linear appearance\nvariation,\nI1(x + u) ≈I0(x) +\nX\nj\nλjBj(x),\n(8.46)\nwhere the Bj(x) are the basis images and the λj are the unknown coefﬁcients (Hager and\nBelhumeur 1998; Baker, Gross, Ishikawa et al. 2003; Baker, Gross, and Matthews 2003).\nPotential linear appearance variations include illumination changes (Hager and Belhumeur\n1998) and small non-rigid deformations (Black and Jepson 1998).\nA weighted (windowed) version of the Lucas–Kanade algorithm is also possible:\nELK−WSSD(u + ∆u) =\nX\ni\nw0(xi)w1(xi + u)[J1(xi + u)∆u + ei]2.\n(8.47)\n398\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nNote that here, in deriving the Lucas–Kanade update from the original weighted SSD function\n(8.5), we have neglected taking the derivative of the w1(xi + u) weighting function with\nrespect to u, which is usually acceptable in practice, especially if the weighting function is a\nbinary mask with relatively few transitions.\nBaker, Gross, Ishikawa et al. (2003) only use the w0(x) term, which is reasonable if the\ntwo images have the same extent and no (independent) cutouts in the overlap region. They\nalso discuss the idea of making the weighting proportional to ∇I(x), which helps for very\nnoisy images, where the gradient itself is noisy. Similar observations, formulated in terms\nof total least squares (Van Huffel and Vandewalle 1991; Van Huffel and Lemmerling 2002),\nhave been made by other researchers studying optical ﬂow (Weber and Malik 1995; Bab-\nHadiashar and Suter 1998b; M¨uhlich and Mester 1998). Lastly, Baker, Gross, Ishikawa et al.\n(2003) show how evaluating Equation (8.47) at just the most reliable (highest gradient) pixels\ndoes not signiﬁcantly reduce performance for large enough images, even if only 5–10% of\nthe pixels are used. (This idea was originally proposed by Dellaert and Collins (1999), who\nused a more sophisticated selection criterion.)\nThe Lucas–Kanade incremental reﬁnement step can also be applied to the robust error\nmetric introduced in Section 8.1,\nELK−SRD(u + ∆u) =\nX\ni\nρ(J1(xi + u)∆u + ei),\n(8.48)\nwhich can be solved using the iteratively reweighted least squares technique described in\nSection 6.1.4.\n8.2 Parametric motion\nMany image alignment tasks, for example image stitching with handheld cameras, require\nthe use of more sophisticated motion models, as described in Section 2.1.2. Since these\nmodels, e.g., afﬁne deformations, typically have more parameters than pure translation, a\nfull search over the possible range of values is impractical. Instead, the incremental Lucas–\nKanade algorithm can be generalized to parametric motion models and used in conjunction\nwith a hierarchical search algorithm (Lucas and Kanade 1981; Rehg and Witkin 1991; Fuh\nand Maragos 1991; Bergen, Anandan, Hanna et al. 1992; Shashua and Toelg 1997; Shashua\nand Wexler 2001; Baker and Matthews 2004).\nFor parametric motion, instead of using a single constant translation vector u, we use\na spatially varying motion ﬁeld or correspondence map, x′(x; p), parameterized by a low-\ndimensional vector p, where x′ can be any of the motion models presented in Section 2.1.2.",
  "image_path": "page_419.jpg",
  "pages": [
    418,
    419,
    420
  ]
}