{
  "doc_id": "pages_443_445",
  "text": "8.6 Additional reading\n421\nFigure 8.18 Transparent motion separation (Szeliski, Avidan, and Anandan 2000) c⃝2000\nIEEE: (a) ﬁrst image from input sequence; (b) dominant motion layer min-composite; (c) sec-\nondary motion residual layer max-composite; (d–e) ﬁnal estimated picture and reﬂection lay-\ners. Note that the reﬂected layers in (c) and (e) are doubled in intensity to better show their\nstructure.\n(Swaminathan, Kang, Szeliski et al. 2002; Criminisi, Kang, Swaminathan et al. 2005), as has\nthe extension to scenes with more complex 3D depth (Tsin, Kang, and Szeliski 2006).\n8.6 Additional reading\nSome of the earliest algorithms for motion estimation were developed for motion-compen-\nsated video coding (Netravali and Robbins 1979) and such techniques continue to be used\nin modern coding standards such as MPEG, H.263, and H.264 (Le Gall 1991; Richardson\n2003).14 In computer vision, this ﬁeld was originally called image sequence analysis (Huang\n1981). Some of the early seminal papers include the variational approaches developed by\nHorn and Schunck (1981) and Nagel and Enkelmann (1986), and the patch-based translational\nalignment technique developed by Lucas and Kanade (1981). Hierarchical (coarse-to-ﬁne)\nversions of such algorithms were developed by Quam (1984), Anandan (1989), and Bergen,\nAnandan, Hanna et al. (1992), although they have also long been used in motion estimation\nfor video coding.\nTranslational motion models were generalized to afﬁne motion by Rehg and Witkin (1991),\nFuh and Maragos (1991), and Bergen, Anandan, Hanna et al. (1992) and to quadric refer-\nence surfaces by Shashua and Toelg (1997) and Shashua and Wexler (2001)—see Baker and\nMatthews (2004) for a nice review. Such parametric motion estimation algorithms have found\nwidespread application in video summarization (Teodosio and Bender 1993; Irani and Anan-\ndan 1998), video stabilization (Hansen, Anandan, Dana et al. 1994; Srinivasan, Chellappa,\n14 http://www.itu.int/rec/T-REC-H.264.\n422\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nVeeraraghavan et al. 2005; Matsushita, Ofek, Ge et al. 2006), and video compression (Irani,\nHsu, and Anandan 1995; Lee, ge Chen, lung Bruce Lin et al. 1997). Surveys of parametric\nimage registration include those by Brown (1992), Zitov’aa and Flusser (2003), Goshtasby\n(2005), and Szeliski (2006a).\nGood general surveys and comparisons of optic ﬂow algorithms include those by Ag-\ngarwal and Nandhakumar (1988), Barron, Fleet, and Beauchemin (1994), Otte and Nagel\n(1994), Mitiche and Bouthemy (1996), Stiller and Konrad (1999), McCane, Novins, Cran-\nnitch et al. (2001), Szeliski (2006a), and Baker, Black, Lewis et al. (2007). The topic of\nmatching primitives, i.e., pre-transforming images using ﬁltering or other techniques before\nmatching, is treated in a number of papers (Anandan 1989; Bergen, Anandan, Hanna et al.\n1992; Scharstein 1994; Zabih and Woodﬁll 1994; Cox, Roy, and Hingorani 1995; Viola and\nWells III 1997; Negahdaripour 1998; Kim, Kolmogorov, and Zabih 2003; Jia and Tang 2003;\nPapenberg, Bruhn, Brox et al. 2006; Seitz and Baker 2009). Hirschm¨uller and Scharstein\n(2009) compare a number of these approaches and report on their relative performance in\nscenes with exposure differences.\nThe publication of a new benchmark for evaluating optical ﬂow algorithms (Baker, Black,\nLewis et al. 2007) has led to rapid advances in the quality of estimation algorithms, to the\npoint where new datasets may soon become necessary. According to their updated techni-\ncal report (Baker, Scharstein, Lewis et al. 2009), most of the best performing algorithms use\nrobust data and smoothness norms (often L1 TV) and continuous variational optimization\ntechniques, although some techniques use discrete optimization or segmentations (Papen-\nberg, Bruhn, Brox et al. 2006; Trobin, Pock, Cremers et al. 2008; Xu, Chen, and Jia 2008;\nLempitsky, Roth, and Rother. 2008; Werlberger, Trobin, Pock et al. 2009; Lei and Yang 2009;\nWedel, Cremers, Pock et al. 2009).\n8.7 Exercises\nEx 8.1: Correlation\nImplement and compare the performance of the following correlation\nalgorithms:\n• sum of squared differences (8.1)\n• sum of robust differences (8.2)\n• sum of absolute differences (8.3)\n• bias–gain compensated squared differences (8.9)\n• normalized cross-correlation (8.11)\n8.7 Exercises\n423\n• windowed versions of the above (8.22–8.23)\n• Fourier-based implementations of the above measures (8.18–8.20)\n• phase correlation (8.24)\n• gradient cross-correlation (Argyriou and Vlachos 2003).\nCompare a few of your algorithms on different motion sequences with different amounts of\nnoise, exposure variation, occlusion, and frequency variations (e.g., high-frequency textures,\nsuch as sand or cloth, and low-frequency images, such as clouds or motion-blurred video).\nSome datasets with illumination variation and ground truth correspondences (horizontal mo-\ntion) can be found at http://vision.middlebury.edu/stereo/data/ (the 2005 and 2006 datasets).\nSome additional ideas, variants, and questions:\n1. When do you think that phase correlation will outperform regular correlation or SSD?\nCan you show this experimentally or justify it analytically?\n2. For the Fourier-based masked or windowed correlation and sum of squared differences,\nthe results should be the same as the direct implementations. Note that you will have\nto expand (8.5) into a sum of pairwise correlations, just as in (8.22). (This is part of the\nexercise.)\n3. For the bias–gain corrected variant of squared differences (8.9), you will also have\nto expand the terms to end up with a 3 × 3 (least squares) system of equations. If\nimplementing the Fast Fourier Transform version, you will need to ﬁgure out how all\nof these entries can be evaluated in the Fourier domain.\n4. (Optional) Implement some of the additional techniques studied by Hirschm¨uller and\nScharstein (2009) and see if your results agree with theirs.\nEx 8.2: Afﬁne registration\nImplement a coarse-to-ﬁne direct method for afﬁne and pro-\njective image alignment.\n1. Does it help to use lower-order (simpler) models at coarser levels of the pyramid\n(Bergen, Anandan, Hanna et al. 1992)?\n2. (Optional) Implement patch-based acceleration (Shum and Szeliski 2000; Baker and\nMatthews 2004).\n3. See the Baker and Matthews (2004) survey for more comparisons and ideas.\nEx 8.3: Stabilization\nWrite a program to stabilize an input video sequence. You should\nimplement the following steps, as described in Section 8.2.1:",
  "image_path": "page_444.jpg",
  "pages": [
    443,
    444,
    445
  ]
}