{
  "doc_id": "pages_145_147",
  "text": "3.3 More neighborhood operators\n123\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 3.18 Median and bilateral ﬁltering: (a) original image with Gaussian noise; (b) Gaus-\nsian ﬁltered; (c) median ﬁltered; (d) bilaterally ﬁltered; (e) original image with shot noise; (f)\nGaussian ﬁltered; (g) median ﬁltered; (h) bilaterally ﬁltered. Note that the bilateral ﬁlter fails\nto remove the shot noise because the noisy pixels are too different from their neighbors.\n.\n2\n1\n0\n1\n2\n1\n2\n1\n2\n4\n1\n2\n1\n2\n4\n2\n0.1 0.3 0.4 0.3 0.1\n0.0 0.0 0.0 0.0 0.2\n2\n1\n3\n5\n8\n2\n1\n3\n5\n8\n1\n0.3 0.6 0.8 0.6 0.3\n0.0 0.0 0.0 0.4 0.8\n1\n3\n7\n6\n9\n1\n3\n7\n6\n9\n0\n0.4 0.8 1.0 0.8 0.4\n0.0 0.0 1.0 0.8 0.4\n3\n4\n8\n6\n7\n3\n4\n8\n6\n7\n1\n0.3 0.6 0.8 0.6 0.3\n0.0 0.2 0.8 0.8 1.0\n4\n5\n7\n8\n9\n4\n5\n7\n8\n9\n2\n0.1 0.3 0.4 0.3 0.1\n0.2 0.4 1.0 0.8 0.4\n(a) median =\n4\n(b) α-mean= 4.6\n(c) domain filter\n(d) range filter\nFigure 3.19 Median and bilateral ﬁltering: (a) median pixel (green); (b) selected α-trimmed\nmean pixels; (c) domain ﬁlter (numbers along edge are pixel distances); (d) range ﬁlter.\n124\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nnoise, rather than being Gaussian, is shot noise, i.e., it occasionally has very large values. In\nthis case, regular blurring with a Gaussian ﬁlter fails to remove the noisy pixels and instead\nturns them into softer (but still visible) spots (Figure 3.18f).\nMedian ﬁltering\nA better ﬁlter to use in this case is the median ﬁlter, which selects the median value from each\npixel’s neighborhood (Figure 3.19a). Median values can be computed in expected linear time\nusing a randomized select algorithm (Cormen 2001) and incremental variants have also been\ndeveloped by Tomasi and Manduchi (1998) and Bovik (2000, Section 3.2). Since the shot\nnoise value usually lies well outside the true values in the neighborhood, the median ﬁlter is\nable to ﬁlter away such bad pixels (Figure 3.18c).\nOne downside of the median ﬁlter, in addition to its moderate computational cost, is that\nsince it selects only one input pixel value to replace each output pixel, it is not as efﬁcient at\naveraging away regular Gaussian noise (Huber 1981; Hampel, Ronchetti, Rousseeuw et al.\n1986; Stewart 1999). A better choice may be the α-trimmed mean (Lee and Redner 1990)\n(Crane 1997, p. 109), which averages together all of the pixels except for the α fraction that\nare the smallest and the largest (Figure 3.19b).\nAnother possibility is to compute a weighted median, in which each pixel is used a num-\nber of times depending on its distance from the center. This turns out to be equivalent to\nminimizing the weighted objective function\nX\nk,l\nw(k, l)|f(i + k, j + l) −g(i, j)|p,\n(3.33)\nwhere g(i, j) is the desired output value and p = 1 for the weighted median. The value p = 2\nis the usual weighted mean, which is equivalent to correlation (3.12) after normalizing by the\nsum of the weights (Bovik 2000, Section 3.2) (Haralick and Shapiro 1992, Section 7.2.6).\nThe weighted mean also has deep connections to other methods in robust statistics (see Ap-\npendix B.3), such as inﬂuence functions (Huber 1981; Hampel, Ronchetti, Rousseeuw et al.\n1986).\nNon-linear smoothing has another, perhaps even more important property, especially\nsince shot noise is rare in today’s cameras. Such ﬁltering is more edge preserving, i.e., it\nhas less tendency to soften edges while ﬁltering away high-frequency noise.\nConsider the noisy image in Figure 3.18a. In order to remove most of the noise, the\nGaussian ﬁlter is forced to smooth away high-frequency detail, which is most noticeable near\nstrong edges. Median ﬁltering does better but, as mentioned before, does not do as good\na job at smoothing away from discontinuities. See (Tomasi and Manduchi 1998) for some\nadditional references to edge-preserving smoothing techniques.\n3.3 More neighborhood operators\n125\nWhile we could try to use the α-trimmed mean or weighted median, these techniques still\nhave a tendency to round sharp corners, since the majority of pixels in the smoothing area\ncome from the background distribution.\nBilateral ﬁltering\nWhat if we were to combine the idea of a weighted ﬁlter kernel with a better version of outlier\nrejection? What if instead of rejecting a ﬁxed percentage α, we simply reject (in a soft way)\npixels whose values differ too much from the central pixel value? This is the essential idea in\nbilateral ﬁltering, which was ﬁrst popularized in the computer vision community by Tomasi\nand Manduchi (1998). Chen, Paris, and Durand (2007) and Paris, Kornprobst, Tumblin et al.\n(2008) cite similar earlier work (Aurich and Weule 1995; Smith and Brady 1997) as well as\nthe wealth of subsequent applications in computer vision and computational photography.\nIn the bilateral ﬁlter, the output pixel value depends on a weighted combination of neigh-\nboring pixel values\ng(i, j) =\nP\nk,l f(k, l)w(i, j, k, l)\nP\nk,l w(i, j, k, l)\n.\n(3.34)\nThe weighting coefﬁcient w(i, j, k, l) depends on the product of a domain kernel (Figure 3.19c),\nd(i, j, k, l) = exp\n\u0012\n−(i −k)2 + (j −l)2\n2σ2\nd\n\u0013\n,\n(3.35)\nand a data-dependent range kernel (Figure 3.19d),\nr(i, j, k, l) = exp\n\u0012\n−∥f(i, j) −f(k, l)∥2\n2σ2r\n\u0013\n.\n(3.36)\nWhen multiplied together, these yield the data-dependent bilateral weight function\nw(i, j, k, l) = exp\n\u0012\n−(i −k)2 + (j −l)2\n2σ2\nd\n−∥f(i, j) −f(k, l)∥2\n2σ2r\n\u0013\n.\n(3.37)\nFigure 3.20 shows an example of the bilateral ﬁltering of a noisy step edge. Note how the do-\nmain kernel is the usual Gaussian, the range kernel measures appearance (intensity) similarity\nto the center pixel, and the bilateral ﬁlter kernel is a product of these two.\nNotice that the range ﬁlter (3.36) uses the vector distance between the center and the\nneighboring pixel. This is important in color images, since an edge in any one of the color\nbands signals a change in material and hence the need to downweight a pixel’s inﬂuence.5\n5 Tomasi and Manduchi (1998) show that using the vector distance (as opposed to ﬁltering each color band\nseparately) reduces color fringing effects. They also recommend taking the color difference in the more perceptually\nuniform CIELAB color space (see Section 2.3.2).",
  "image_path": "page_146.jpg",
  "pages": [
    145,
    146,
    147
  ]
}