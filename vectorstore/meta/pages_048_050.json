{
  "doc_id": "pages_048_050",
  "text": "26\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWeek\nMaterial\nProject\n(1.)\nChapter 2 Image formation\n2.\nChapter 3 Image processing\n3.\nChapter 4 Feature detection and matching\nP1\n4.\nChapter 6 Feature-based alignment\n5.\nChapter 9 Image stitching\nP2\n6.\nChapter 8 Dense motion estimation\n7.\nChapter 7 Structure from motion\nPP\n8.\nChapter 14 Recognition\n(9.)\nChapter 10 Computational photography\n10.\nChapter 11 Stereo correspondence\n(11.)\nChapter 12 3D reconstruction\n12.\nChapter 13 Image-based rendering\n13.\nFinal project presentations\nFP\nTable 1.1 Sample syllabi for 10-week and 13-week courses. The weeks in parentheses are\nnot used in the shorter version. P1 and P2 are two early-term mini-projects, PP is when the\n(student-selected) ﬁnal project proposals are due, and FP is the ﬁnal project presentations.\nChapter 14 describes different approaches to recognition. It begins with techniques for\ndetecting and recognizing faces (Sections 14.1 and 14.2), then looks at techniques for ﬁnding\nand recognizing particular objects (instance recognition) in Section 14.3. Next, we cover the\nmost difﬁcult variant of recognition, namely the recognition of broad categories, such as cars,\nmotorcycles, horses and other animals (Section 14.4), and the role that scene context plays in\nrecognition (Section 14.5).\nTo support the book’s use as a textbook, the appendices and associated Web site contain\nmore detailed mathematical topics and additional material. Appendix A covers linear algebra\nand numerical techniques, including matrix algebra, least squares, and iterative techniques.\nAppendix B covers Bayesian estimation theory, including maximum likelihood estimation,\nrobust statistics, Markov random ﬁelds, and uncertainty modeling. Appendix C describes the\nsupplementary material available to complement this book, including images and data sets,\npointers to software, course slides, and an on-line bibliography.\n1.4 Sample syllabus\nTeaching all of the material covered in this book in a single quarter or semester course is a\nHerculean task and likely one not worth attempting. It is better to simply pick and choose\n1.5 A note on notation\n27\ntopics related to the lecturer’s preferred emphasis and tailored to the set of mini-projects\nenvisioned for the students.\nSteve Seitz and I have successfully used a 10-week syllabus similar to the one shown in\nTable 1.1 (omitting the parenthesized weeks) as both an undergraduate and a graduate-level\ncourse in computer vision. The undergraduate course10 tends to go lighter on the mathematics\nand takes more time reviewing basics, while the graduate-level course11 dives more deeply\ninto techniques and assumes the students already have a decent grounding in either vision\nor related mathematical techniques. (See also the Introduction to Computer Vision course at\nStanford,12 which uses a similar curriculum.) Related courses have also been taught on the\ntopics of 3D photography13 and computational photography.14\nWhen Steve and I teach the course, we prefer to give the students several small program-\nming projects early in the course rather than focusing on written homework or quizzes. With\na suitable choice of topics, it is possible for these projects to build on each other. For exam-\nple, introducing feature matching early on can be used in a second assignment to do image\nalignment and stitching. Alternatively, direct (optical ﬂow) techniques can be used to do the\nalignment and more focus can be put on either graph cut seam selection or multi-resolution\nblending techniques.\nWe also ask the students to propose a ﬁnal project (we provide a set of suggested topics\nfor those who need ideas) by the middle of the course and reserve the last week of the class\nfor student presentations. With any luck, some of these ﬁnal projects can actually turn into\nconference submissions!\nNo matter how you decide to structure the course or how you choose to use this book, I\nencourage you to try at least a few small programming tasks to get a good feel for how vision\ntechniques work, and when they do not. Better yet, pick topics that are fun and can be used on\nyour own photographs, and try to push your creative boundaries to come up with surprising\nresults.\n1.5 A note on notation\nFor better or worse, the notation found in computer vision and multi-view geometry textbooks\ntends to vary all over the map (Faugeras 1993; Hartley and Zisserman 2004; Girod, Greiner,\nand Niemann 2000; Faugeras and Luong 2001; Forsyth and Ponce 2003). In this book, I\nuse the convention I ﬁrst learned in my high school physics class (and later multi-variate\n10 http://www.cs.washington.edu/education/courses/455/\n11 http://www.cs.washington.edu/education/courses/576/\n12http://vision.stanford.edu/teaching/cs223b/\n13 http://www.cs.washington.edu/education/courses/558/06sp/\n14 http://graphics.cs.cmu.edu/courses/15-463/\n28\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ncalculus and computer graphics courses), which is that vectors v are lower case bold, matrices\nM are upper case bold, and scalars (T, s) are mixed case italic. Unless otherwise noted,\nvectors operate as column vectors, i.e., they post-multiply matrices, Mv, although they are\nsometimes written as comma-separated parenthesized lists x = (x, y) instead of bracketed\ncolumn vectors x = [x y]T . Some commonly used matrices are R for rotations, K for\ncalibration matrices, and I for the identity matrix. Homogeneous coordinates (Section 2.1)\nare denoted with a tilde over the vector, e.g., ˜x = (˜x, ˜y, ˜w) = ˜w(x, y, 1) = ˜w¯x in P2. The\ncross product operator in matrix form is denoted by [ ]×.\n1.6 Additional reading\nThis book attempts to be self-contained, so that students can implement the basic assignments\nand algorithms described here without the need for outside references. However, it does pre-\nsuppose a general familiarity with basic concepts in linear algebra and numerical techniques,\nwhich are reviewed in Appendix A, and image processing, which is reviewed in Chapter 3.\nStudents who want to delve more deeply into these topics can look in (Golub and Van\nLoan 1996) for matrix algebra and (Strang 1988) for linear algebra. In image processing,\nthere are a number of popular textbooks, including (Crane 1997; Gomes and Velho 1997;\nJ¨ahne 1997; Pratt 2007; Russ 2007; Burger and Burge 2008; Gonzales and Woods 2008). For\ncomputer graphics, popular texts include (Foley, van Dam, Feiner et al. 1995; Watt 1995),\nwith (Glassner 1995) providing a more in-depth look at image formation and rendering. For\nstatistics and machine learning, Chris Bishop’s (2006) book is a wonderful and comprehen-\nsive introduction with a wealth of exercises. Students may also want to look in other textbooks\non computer vision for material that we do not cover here, as well as for additional project\nideas (Ballard and Brown 1982; Faugeras 1993; Nalwa 1993; Trucco and Verri 1998; Forsyth\nand Ponce 2003).\nThere is, however, no substitute for reading the latest research literature, both for the lat-\nest ideas and techniques and for the most up-to-date references to related literature.15 In this\nbook, I have attempted to cite the most recent work in each ﬁeld so that students can read them\ndirectly and use them as inspiration for their own work. Browsing the last few years’ con-\nference proceedings from the major vision and graphics conferences, such as CVPR, ECCV,\nICCV, and SIGGRAPH, will provide a wealth of new ideas. The tutorials offered at these\nconferences, for which slides or notes are often available on-line, are also an invaluable re-\nsource.\n15 For a comprehensive bibliography and taxonomy of computer vision research, Keith Price’s Annotated Com-\nputer Vision Bibliography http://www.visionbib.com/bibliography/contents.html is an invaluable resource.",
  "image_path": "page_049.jpg",
  "pages": [
    48,
    49,
    50
  ]
}