{
  "doc_id": "pages_599_601",
  "text": "Chapter 12\n3D reconstruction\n12.1 Shape from X . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 580\n12.1.1 Shape from shading and photometric stereo . . . . . . . . . . . . . . 580\n12.1.2 Shape from texture . . . . . . . . . . . . . . . . . . . . . . . . . . . 583\n12.1.3 Shape from focus . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584\n12.2 Active rangeﬁnding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 585\n12.2.1 Range data merging\n. . . . . . . . . . . . . . . . . . . . . . . . . . 588\n12.2.2 Application: Digital heritage . . . . . . . . . . . . . . . . . . . . . . 590\n12.3 Surface representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591\n12.3.1 Surface interpolation . . . . . . . . . . . . . . . . . . . . . . . . . . 592\n12.3.2 Surface simpliﬁcation\n. . . . . . . . . . . . . . . . . . . . . . . . . 594\n12.3.3 Geometry images . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594\n12.4 Point-based representations . . . . . . . . . . . . . . . . . . . . . . . . . . . 595\n12.5 Volumetric representations . . . . . . . . . . . . . . . . . . . . . . . . . . . 596\n12.5.1 Implicit surfaces and level sets . . . . . . . . . . . . . . . . . . . . . 596\n12.6 Model-based reconstruction . . . . . . . . . . . . . . . . . . . . . . . . . . . 598\n12.6.1 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 598\n12.6.2 Heads and faces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 601\n12.6.3 Application: Facial animation\n. . . . . . . . . . . . . . . . . . . . . 603\n12.6.4 Whole body modeling and tracking\n. . . . . . . . . . . . . . . . . . 605\n12.7 Recovering texture maps and albedos\n. . . . . . . . . . . . . . . . . . . . . 610\n12.7.1 Estimating BRDFs . . . . . . . . . . . . . . . . . . . . . . . . . . . 612\n12.7.2 Application: 3D photography\n. . . . . . . . . . . . . . . . . . . . . 613\n12.8 Additional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 614\n12.9 Exercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 616\n578\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\n(i)\nFigure 12.1 3D shape acquisition and modeling techniques: (a) shaded image (Zhang, Tsai,\nCryer et al. 1999) c⃝1999 IEEE; (b) texture gradient (Garding 1992) c⃝1992 Springer; (c)\nreal-time depth from focus (Nayar, Watanabe, and Noguchi 1996) c⃝1996 IEEE; (d) scanning\na scene with a stick shadow (Bouguet and Perona 1999) c⃝1999 Springer; (e) merging range\nmaps into a 3D model (Curless and Levoy 1996) c⃝1996 ACM; (f) point-based surface\nmodeling (Pauly, Keiser, Kobbelt et al. 2003) c⃝2003 ACM; (g) automated modeling of a\n3D building using lines and planes (Werner and Zisserman 2002) c⃝2002 Springer; (h) 3D\nface model from spacetime stereo (Zhang, Snavely, Curless et al. 2004) c⃝2004 ACM; (i)\nperson tracking (Sigal, Bhatia, Roth et al. 2004) c⃝2004 IEEE.\n12 3D reconstruction\n579\nAs we saw in the previous chapter, a variety of stereo matching techniques have been de-\nveloped to reconstruct high quality 3D models from two or more images. However, stereo\nis just one of the many potential cues that can be used to infer shape from images. In this\nchapter, we investigate a number of such techniques, which include not only visual cues such\nas shading and focus, but also techniques for merging multiple range or depth images into 3D\nmodels, as well as techniques for reconstructing specialized models, such as heads, bodies,\nor architecture.\nAmong the various cues that can be used to infer shape, the shading on a surface (Fig-\nure 12.1a) can provide a lot of information about local surface orientations and hence overall\nsurface shape (Section 12.1.1). This approach becomes even more powerful when lights\nshining from different directions can be turned on and off separately (photometric stereo).\nTexture gradients (Figure 12.1b), i.e., the foreshortening of regular patterns as the surface\nslants or bends away from the camera, can provide similar cues on local surface orientation\n(Section 12.1.2). Focus is another powerful cue to scene depth, especially when two or more\nimages with different focus settings are used (Section 12.1.3).\n3D shape can also be estimated using active illumination techniques such as light stripes\n(Figure 12.1d) or time of ﬂight range ﬁnders (Section 12.2). The partial surface models\nobtained using such techniques (or passive image-based stereo) can then be merged into more\ncoherent 3D surface models (Figure 12.1e), as discussed in Section 12.2.1. Such techniques\nhave been used to construct highly detailed and accurate models of cultural heritage such as\nhistoric sites (Section 12.2.2). The resulting surface models can then be simpliﬁed to support\nviewing at different resolutions and streaming across the Web (Section 12.3.2). An alternative\nto working with continuous surfaces is to represent 3D surfaces as dense collections of 3D\noriented points (Section 12.4) or as volumetric primitives (Section 12.5).\n3D modeling can be more efﬁcient and effective if we know something about the objects\nwe are trying to reconstruct. In Section 12.6, we look at three specialized but commonly\noccurring examples, namely architecture (Figure 12.1g), heads and faces (Figure 12.1h), and\nwhole bodies (Figure 12.1i). In addition to modeling people, we also discuss techniques for\ntracking them.\nThe last stage of shape and appearance modeling is to extract some textures to paint onto\nour 3D models (Section 12.7). Some techniques go beyond this and actually estimate full\nBRDFs (Section 12.7.1).\nBecause there exists such a large variety of techniques to perform 3D modeling, this\nchapter does not go into detail on any one of these. Readers are encouraged to ﬁnd more\ninformation in the cited references or more specialized publications and conferences de-\nvoted to these topics, e.g., the International Symposium on 3D Data Processing, Visualiza-\ntion, and Transmission (3DPVT), the International Conference on 3D Digital Imaging and\nModeling (3DIM), the International Conference on Automatic Face and Gesture Recognition",
  "image_path": "page_600.jpg",
  "pages": [
    599,
    600,
    601
  ]
}