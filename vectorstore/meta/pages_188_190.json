{
  "doc_id": "pages_188_190",
  "text": "166\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nprocedure inverseWarp(f, h, out g):\nFor every pixel x′ in g(x′)\n1. Compute the source location x = ˆh(x′)\n2. Resample f(x) at location x and copy to g(x′)\nAlgorithm 3.2 Inverse warping algorithm for creating an image g(x′) from an image f(x)\nusing the parametric transform x′ = h(x).\nf(x)\ng(x’)\nx\nx’\nx=h(x’)\n^ \nf(x)\ng(x’)\nx\nx’\nx=h(x’)\n^ \n(a)\n(b)\nFigure 3.47 Inverse warping algorithm: (a) a pixel g(x′) is sampled from its corresponding\nlocation x = ˆh(x′) in image f(x); (b) detail of the source and destination pixel locations.\nlocation of the source pixel which produced the current pixel whose ﬂow is being estimated,\nas opposed to computing the destination pixel to which it is going. Similarly, when correcting\nfor radial distortion (Section 2.1.6), we calibrate the lens by computing for each pixel in the\nﬁnal (undistorted) image the corresponding pixel location in the original (distorted) image.\nWhat kinds of interpolation ﬁlter are suitable for the resampling process? Any of the ﬁl-\nters we studied in Section 3.5.2 can be used, including nearest neighbor, bilinear, bicubic, and\nwindowed sinc functions. While bilinear is often used for speed (e.g., inside the inner loop\nof a patch-tracking algorithm, see Section 8.1.3), bicubic, and windowed sinc are preferable\nwhere visual quality is important.\nTo compute the value of f(x) at a non-integer location x, we simply apply our usual FIR\nresampling ﬁlter,\ng(x, y) =\nX\nk,l\nf(k, l)h(x −k, y −l),\n(3.89)\nwhere (x, y) are the sub-pixel coordinate values and h(x, y) is some interpolating or smooth-\ning kernel. Recall from Section 3.5.2 that when decimation is being performed, the smoothing\nkernel is stretched and re-scaled according to the downsampling rate r.\nUnfortunately, for a general (non-zoom) image transformation, the resampling rate r is\nnot well deﬁned. Consider a transformation that stretches the x dimensions while squashing\n3.6 Geometric transformations\n167\nx\ny\nx’\ny’\nx\ny\nx’\ny’\nx\ny\nx’\ny’\nay’y\nay’x\nax’x\nax’y\n(a)\n(b)\n(c)\nmajor axis\nminor axis\nFigure 3.48\nAnisotropic texture ﬁltering: (a) Jacobian of transform A and the induced\nhorizontal and vertical resampling rates {ax′x, ax′y, ay′x, ay′y}; (b) elliptical footprint of an\nEWA smoothing kernel; (c) anisotropic ﬁltering using multiple samples along the major axis.\nImage pixels lie at line intersections.\nthe y dimensions. The resampling kernel should be performing regular interpolation along\nthe x dimension and smoothing (to anti-alias the blurred image) in the y direction. This gets\neven more complicated for the case of general afﬁne or perspective transforms.\nWhat can we do? Fortunately, Fourier analysis can help. The two-dimensional general-\nization of the one-dimensional domain scaling law given in Table 3.1 is\ng(Ax) ⇔|A|−1G(A−T f).\n(3.90)\nFor all of the transforms in Table 3.5 except perspective, the matrix A is already deﬁned.\nFor perspective transformations, the matrix A is the linearized derivative of the perspective\ntransformation (Figure 3.48a), i.e., the local afﬁne approximation to the stretching induced\nby the projection (Heckbert 1986; Wolberg 1990; Gomes, Darsa, Costa et al. 1999; Akenine-\nM¨oller and Haines 2002).\nTo prevent aliasing, we need to pre-ﬁlter the image f(x) with a ﬁlter whose frequency\nresponse is the projection of the ﬁnal desired spectrum through the A−T transform (Szeliski,\nWinder, and Uyttendaele 2010). In general (for non-zoom transforms), this ﬁlter is non-\nseparable and hence is very slow to compute. Therefore, a number of approximations to this\nﬁlter are used in practice, include MIP-mapping, elliptically weighted Gaussian averaging,\nand anisotropic ﬁltering (Akenine-M¨oller and Haines 2002).\nMIP-mapping\nMIP-mapping was ﬁrst proposed by Williams (1983) as a means to rapidly pre-ﬁlter images\nbeing used for texture mapping in computer graphics. A MIP-map18 is a standard image\n18 The term ‘MIP’ stands for multi in parvo, meaning ‘many in one’.\n168\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\npyramid (Figure 3.32), where each level is pre-ﬁltered with a high-quality ﬁlter rather than\na poorer quality approximation, such as Burt and Adelson’s (1983b) ﬁve-tap binomial. To\nresample an image from a MIP-map, a scalar estimate of the resampling rate r is ﬁrst com-\nputed. For example, r can be the maximum of the absolute values in A (which suppresses\naliasing) or it can be the minimum (which reduces blurring). Akenine-M¨oller and Haines\n(2002) discuss these issues in more detail.\nOnce a resampling rate has been speciﬁed, a fractional pyramid level is computed using\nthe base 2 logarithm,\nl = log2 r.\n(3.91)\nOne simple solution is to resample the texture from the next higher or lower pyramid level,\ndepending on whether it is preferable to reduce aliasing or blur. A better solution is to re-\nsample both images and blend them linearly using the fractional component of l. Since most\nMIP-map implementations use bilinear resampling within each level, this approach is usu-\nally called trilinear MIP-mapping. Computer graphics rendering APIs, such as OpenGL and\nDirect3D, have parameters that can be used to select which variant of MIP-mapping (and of\nthe sampling rate r computation) should be used, depending on the desired tradeoff between\nspeed and quality. Exercise 3.22 has you examine some of these tradeoffs in more detail.\nElliptical Weighted Average\nThe Elliptical Weighted Average (EWA) ﬁlter invented by Greene and Heckbert (1986) is\nbased on the observation that the afﬁne mapping x = Ax′ deﬁnes a skewed two-dimensional\ncoordinate system in the vicinity of each source pixel x (Figure 3.48a). For every destina-\ntion pixel x′, the ellipsoidal projection of a small pixel grid in x′ onto x is computed (Fig-\nure 3.48b). This is then used to ﬁlter the source image g(x) with a Gaussian whose inverse\ncovariance matrix is this ellipsoid.\nDespite its reputation as a high-quality ﬁlter (Akenine-M¨oller and Haines 2002), we have\nfound in our work (Szeliski, Winder, and Uyttendaele 2010) that because a Gaussian kernel\nis used, the technique suffers simultaneously from both blurring and aliasing, compared to\nhigher-quality ﬁlters. The EWA is also quite slow, although faster variants based on MIP-\nmapping have been proposed (Szeliski, Winder, and Uyttendaele (2010) provide some addi-\ntional references).\nAnisotropic ﬁltering\nAn alternative approach to ﬁltering oriented textures, which is sometimes implemented in\ngraphics hardware (GPUs), is to use anisotropic ﬁltering (Barkans 1997; Akenine-M¨oller and\nHaines 2002). In this approach, several samples at different resolutions (fractional levels in\nthe MIP-map) are combined along the major axis of the EWA Gaussian (Figure 3.48c).",
  "image_path": "page_189.jpg",
  "pages": [
    188,
    189,
    190
  ]
}