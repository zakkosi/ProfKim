{
  "doc_id": "pages_566_568",
  "text": "544\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\nFigure 11.7 Surface reconstruction from occluding contours (Szeliski and Weiss 1998) c⃝\n2002 Springer: (a) circular arc ﬁtting in the epipolar plane; (b) synthetic example of an el-\nlipsoid with a truncated side and elliptic surface markings; (c) partially reconstructed surface\nmesh seen from an oblique and top-down view; (d) real-world image sequence of a soda can\non a turntable; (e) extracted edges; (f) partially reconstructed proﬁle curves; (g) partially re-\nconstructed surface mesh. (Partial reconstructions are shown so as not to clutter the images.)\nferring camera motion from proﬁle curve sequences. Below, we summarize the approach\ndeveloped by Szeliski and Weiss (1998), which assumes a discrete set of images, rather than\nformulating the problem in a continuous differential framework.\nLet us assume that the camera is moving smoothly enough that the local epipolar geometry\nvaries slowly, i.e., the epipolar planes induced by the successive camera centers and an edgel\nunder consideration are nearly co-planar. The ﬁrst step in the processing pipeline is to extract\nand link edges in each of the input images (Figures 11.7b and e). Next, edgels in successive\nimages are matched using pairwise epipolar geometry, proximity and (optionally) appearance.\nThis provides a linked set of edges in the spatio-temporal volume, which is sometimes called\nthe weaving wall (Baker 1989).\nTo reconstruct the 3D location of an individual edgel, along with its local in-plane normal\nand curvature, we project the viewing rays corresponding to its neighbors onto the instanta-\nneous epipolar plane deﬁned by the camera center, the viewing ray, and the camera velocity,\nas shown in Figure 11.7a. We then ﬁt an osculating circle to the projected lines, parameteriz-\n11.3 Dense correspondence\n545\ning the circle by its centerpoint c = (xc, yc) and radius r,\ncixc + siyc + r = di,\n(11.5)\nwhere ci = ˆti · ˆt0 and si = −ˆti · ˆn0 are the cosine and sine of the angle between viewing ray\ni and the central viewing ray 0, and di = (qi −q0)· ˆn0 is the perpendicular distance between\nviewing ray i and the local origin q0, which is a point chosen on the central viewing ray close\nto the line intersections (Szeliski and Weiss 1998). The resulting set of linear equations can\nbe solved using least squares, and the quality of the solution (residual error) can be used to\ncheck for erroneous correspondences.\nThe resulting set of 3D points, along with their spatial (in-image) and temporal (between-\nimage) neighbors, form a 3D surface mesh with local normal and curvature estimates (Fig-\nures 11.7c and g). Note that whenever a curve is due to a surface marking or a sharp crease\nedge, rather than a smooth surface proﬁle curve, this shows up as a 0 or small radius of curva-\nture. Such curves result in isolated 3D space curves, rather than elements of smooth surface\nmeshes, but can still be incorporated into the 3D surface model during a later stage of surface\ninterpolation (Section 12.3.1).\n11.3 Dense correspondence\nWhile sparse matching algorithms are still occasionally used, most stereo matching algo-\nrithms today focus on dense correspondence, since this is required for applications such as\nimage-based rendering or modeling. This problem is more challenging than sparse corre-\nspondence, since inferring depth values in textureless regions requires a certain amount of\nguesswork. (Think of a solid colored background seen through a picket fence. What depth\nshould it be?)\nIn this section, we review the taxonomy and categorization scheme for dense correspon-\ndence algorithms ﬁrst proposed by Scharstein and Szeliski (2002). The taxonomy consists\nof a set of algorithmic “building blocks” from which a large set of algorithms can be con-\nstructed. It is based on the observation that stereo algorithms generally perform some subset\nof the following four steps:\n1. matching cost computation;\n2. cost (support) aggregation;\n3. disparity computation and optimization; and\n4. disparity reﬁnement.\n546\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFor example, local (window-based) algorithms (Section 11.4), where the disparity com-\nputation at a given point depends only on intensity values within a ﬁnite window, usually\nmake implicit smoothness assumptions by aggregating support. Some of these algorithms\ncan cleanly be broken down into steps 1, 2, 3. For example, the traditional sum-of-squared-\ndifferences (SSD) algorithm can be described as:\n1. The matching cost is the squared difference of intensity values at a given disparity.\n2. Aggregation is done by summing the matching cost over square windows with constant\ndisparity.\n3. Disparities are computed by selecting the minimal (winning) aggregated value at each\npixel.\nSome local algorithms, however, combine steps 1 and 2 and use a matching cost that is based\non a support region, e.g. normalized cross-correlation (Hannah 1974; Bolles, Baker, and Han-\nnah 1993) and the rank transform (Zabih and Woodﬁll 1994) and other ordinal measures (Bhat\nand Nayar 1998). (This can also be viewed as a preprocessing step; see (Section 11.3.1).)\nGlobal algorithms, on the other hand, make explicit smoothness assumptions and then\nsolve a a global optimization problem (Section 11.5). Such algorithms typically do not per-\nform an aggregation step, but rather seek a disparity assignment (step 3) that minimizes a\nglobal cost function that consists of data (step 1) terms and smoothness terms. The main dis-\ntinctions among these algorithms is the minimization procedure used, e.g., simulated anneal-\ning (Marroquin, Mitter, and Poggio 1987; Barnard 1989), probabilistic (mean-ﬁeld) diffusion\n(Scharstein and Szeliski 1998), expectation maximization (EM) (Birchﬁeld, Natarajan, and\nTomasi 2007), graph cuts (Boykov, Veksler, and Zabih 2001), or loopy belief propagation\n(Sun, Zheng, and Shum 2003), to name just a few.\nIn between these two broad classes are certain iterative algorithms that do not explicitly\nspecify a global function to be minimized, but whose behavior mimics closely that of iterative\noptimization algorithms (Marr and Poggio 1976; Zitnick and Kanade 2000). Hierarchical\n(coarse-to-ﬁne) algorithms resemble such iterative algorithms, but typically operate on an\nimage pyramid where results from coarser levels are used to constrain a more local search at\nﬁner levels (Witkin, Terzopoulos, and Kass 1987; Quam 1984; Bergen, Anandan, Hanna et\nal. 1992).\n11.3.1 Similarity measures\nThe ﬁrst component of any dense stereo matching algorithm is a similarity measure that\ncompares pixel values in order to determine how likely they are to be in correspondence. In\nthis section, we brieﬂy review the similarity measures introduced in Section 8.1 and mention a",
  "image_path": "page_567.jpg",
  "pages": [
    566,
    567,
    568
  ]
}