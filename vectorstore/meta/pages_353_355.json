{
  "doc_id": "pages_353_355",
  "text": "6.3 Geometric intrinsic calibration\n331\n(a)\n(b)\nFigure 6.10\nSingle view metrology (Criminisi, Reid, and Zisserman 2000)\nc⃝2000\nSpringer: (a) input image showing the three coordinate axes computed from the two hori-\nzontal vanishing points (which can be determined from the sidings on the shed); (b) a new\nview of the 3D reconstruction.\nIn practice, however, it is more accurate to re-estimate any unknown intrinsic calibration\nparameters using non-linear least squares (6.42).\n6.3.3 Application: Single view metrology\nA fun application of vanishing point estimation and camera calibration is the single view\nmetrology system developed by Criminisi, Reid, and Zisserman (2000). Their system allows\npeople to interactively measure heights and other dimensions as well as to build piecewise-\nplanar 3D models, as shown in Figure 6.10.\nThe ﬁrst step in their system is to identify two orthogonal vanishing points on the ground\nplane and the vanishing point for the vertical direction, which can be done by drawing some\nparallel sets of lines in the image. (Alternatively, automated techniques such as those dis-\ncussed in Section 4.3.3 or by Schaffalitzky and Zisserman (2000) could be used.) The user\nthen marks a few dimensions in the image, such as the height of a reference object, and\nthe system can automatically compute the height of another object. Walls and other planar\nimpostors (geometry) can also be sketched and reconstructed.\nIn the formulation originally developed by Criminisi, Reid, and Zisserman (2000), the\nsystem produces an afﬁne reconstruction, i.e., one that is only known up to a set of indepen-\ndent scaling factors along each axis. A potentially more useful system can be constructed by\nassuming that the camera is calibrated up to an unknown focal length, which can be recov-\nered from orthogonal (ﬁnite) vanishing directions, as we just described in Section 6.3.2. Once\nthis is done, the user can indicate an origin on the ground plane and another point a known\ndistance away. From this, points on the ground plane can be directly projected into 3D and\n332\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 6.11\nFour images taken with a hand-held camera registered using a 3D rotation\nmotion model, which can be used to estimate the focal length of the camera (Szeliski and\nShum 1997) c⃝2000 ACM.\npoints above the ground plane, when paired with their ground plane projections, can also be\nrecovered. A fully metric reconstruction of the scene then becomes possible.\nExercise 6.9 has you implement such a system and then use it to model some simple\n3D scenes. Section 12.6.1 describes other, potentially multi-view, approaches to architectural\nreconstruction, including an interactive piecewise-planar modeling system that uses vanishing\npoints to establish 3D line directions and plane normals (Sinha, Steedly, Szeliski et al. 2008).\n6.3.4 Rotational motion\nWhen no calibration targets or known structures are available but you can rotate the camera\naround its front nodal point (or, equivalently, work in a large open environment where all ob-\njects are distant), the camera can be calibrated from a set of overlapping images by assuming\nthat it is undergoing pure rotational motion, as shown in Figure 6.11 (Stein 1995; Hartley\n1997b; Hartley, Hayman, de Agapito et al. 2000; de Agapito, Hayman, and Reid 2001; Kang\nand Weiss 1999; Shum and Szeliski 2000; Frahm and Koch 2003). When a full 360◦mo-\ntion is used to perform this calibration, a very accurate estimate of the focal length f can be\nobtained, as the accuracy in this estimate is proportional to the total number of pixels in the\nresulting cylindrical panorama (Section 9.1.6) (Stein 1995; Shum and Szeliski 2000).\nTo use this technique, we ﬁrst compute the homographies ˜\nHij between all overlapping\npairs of images, as explained in Equations (6.19–6.23). Then, we use the observation, ﬁrst\nmade in Equation (2.72) and explored in more detail in Section 9.1.3 (9.5), that each homog-\nraphy is related to the inter-camera rotation Rij through the (unknown) calibration matrices\n6.3 Geometric intrinsic calibration\n333\nKi and Kj,\n˜\nHij = KiRiR−1\nj K−1\nj\n= KiRijK−1\nj .\n(6.52)\nThe simplest way to obtain the calibration is to use the simpliﬁed form of the calibra-\ntion matrix (2.59), where we assume that the pixels are square and the optical center lies at\nthe center of the image, i.e., Kk = diag(fk, fk, 1). (We number the pixel coordinates ac-\ncordingly, i.e., place pixel (x, y) = (0, 0) at the center of the image.) We can then rewrite\nEquation (6.52) as\nR10 ∼K−1\n1\n˜\nH10K0 ∼\n\n\nh00\nh01\nf −1\n0 h02\nh10\nh11\nf −1\n0 h12\nf1h20\nf1h21\nf −1\n0 f1h22\n\n,\n(6.53)\nwhere hij are the elements of ˜\nH10.\nUsing the orthonormality properties of the rotation matrix R10 and the fact that the right\nhand side of (6.53) is known only up to a scale, we obtain\nh2\n00 + h2\n01 + f −2\n0 h2\n02 = h2\n10 + h2\n11 + f −2\n0 h2\n12\n(6.54)\nand\nh00h10 + h01h11 + f −2\n0 h02h12 = 0.\n(6.55)\nFrom this, we can compute estimates for f0 of\nf 2\n0 =\nh2\n12 −h2\n02\nh2\n00 + h2\n01 −h2\n10 −h2\n11\nif h2\n00 + h2\n01 ̸= h2\n10 + h2\n11\n(6.56)\nor\nf 2\n0 = −\nh02h12\nh00h10 + h01h11\nif h00h10 ̸= −h01h11.\n(6.57)\n(Note that the equations originally given by Szeliski and Shum (1997) are erroneous; the\ncorrect equations are given by Shum and Szeliski (2000).) If neither of these conditions\nholds, we can also take the dot products between the ﬁrst (or second) row and the third one.\nSimilar results can be obtained for f1 as well, by analyzing the columns of ˜\nH10. If the focal\nlength is the same for both images, we can take the geometric mean of f0 and f1 as the\nestimated focal length f = √f1f0. When multiple estimates of f are available, e.g., from\ndifferent homographies, the median value can be used as the ﬁnal estimate.\nA more general (upper-triangular) estimate of K can be obtained in the case of a ﬁxed-\nparameter camera Ki = K using the technique of Hartley (1997b). Observe from (6.52)\nthat Rij ∼K−1 ˜\nHijK and R−T\nij\n∼KT ˜\nH\n−T\nij K−T . Equating Rij = R−T\nij\nwe obtain\nK−1 ˜\nHijK ∼KT ˜\nH\n−T\nij K−T , from which we get\n˜\nHij(KKT ) ∼(KKT ) ˜\nH\n−T\nij .\n(6.58)",
  "image_path": "page_354.jpg",
  "pages": [
    353,
    354,
    355
  ]
}