{
  "doc_id": "pages_564_566",
  "text": "542\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Section 11.4.2) (Ott, Lewis, and Cox 1993; Criminisi, Shotton, Blake et al. 2003), a camera\ncentrally located between the two input cameras is preferable, since it provides the needed\nper-pixel disparities to hallucinate the virtual middle image.\nThe choice of disparity sampling, i.e., the setting of the zero parallax plane and the scaling\nof integer disparities, is also application dependent, and is usually set to bracket the range of\ninterest, i.e., the working volume, while scaling disparities to sample the image in pixel (or\nsub-pixel) shifts. For example, when using stereo vision for obstacle avoidance in robot\nnavigation, it is most convenient to set up disparity to measure per-pixel elevation above the\nground (Ivanchenko, Shen, and Coughlan 2009).\nAs each input image is warped onto the current planes parameterized by disparity d, it\ncan be stacked into a generalized disparity space image ˜I(x, y, d, k) for further processing\n(Figure 11.6b) (Szeliski and Golland 1999). In most stereo algorithms, the photoconsistency\n(e.g., sum of squared or robust differences) with respect to the reference image Ir is calculated\nand stored in the DSI\nC(x, y, d) =\nX\nk\nρ(˜I(x, y, d, k) −Ir(x, y)).\n(11.4)\nHowever, it is also possible to compute alternative statistics such as robust variance, focus,\nor entropy (Section 11.3.1) (Vaish, Szeliski, Zitnick et al. 2006) or to use this representation\nto reason about occlusions (Szeliski and Golland 1999; Kang and Szeliski 2004). The gen-\neralized DSI will come in particularly handy when we come back to the topic of multi-view\nstereo in Section 11.6.\nOf course, planes are not the only surfaces that can be used to deﬁne a 3D sweep through\nthe space of interest. Cylindrical surfaces, especially when coupled with panoramic photog-\nraphy (Chapter 9), are often used (Ishiguro, Yamamoto, and Tsuji 1992; Kang and Szeliski\n1997; Shum and Szeliski 1999; Li, Shum, Tang et al. 2004; Zheng, Kang, Cohen et al. 2007).\nIt is also possible to deﬁne other manifold topologies, e.g., ones where the camera rotates\naround a ﬁxed axis (Seitz 2001).\nOnce the DSI has been computed, the next step in most stereo correspondence algorithms\nis to produce a univalued function in disparity space d(x, y) that best describes the shape of\nthe surfaces in the scene. This can be viewed as ﬁnding a surface embedded in the disparity\nspace image that has some optimality property, such as lowest cost and best (piecewise)\nsmoothness (Yang, Yuille, and Lu 1993). Figure 11.5 shows examples of slices through a\ntypical DSI. More ﬁgures of this kind can be found in the paper by Bobick and Intille (1999).\n11.2 Sparse correspondence\n543\n11.2 Sparse correspondence\nEarly stereo matching algorithms were feature-based, i.e., they ﬁrst extracted a set of poten-\ntially matchable image locations, using either interest operators or edge detectors, and then\nsearched for corresponding locations in other images using a patch-based metric (Hannah\n1974; Marr and Poggio 1979; Mayhew and Frisby 1980; Baker and Binford 1981; Arnold\n1983; Grimson 1985; Ohta and Kanade 1985; Bolles, Baker, and Marimont 1987; Matthies,\nKanade, and Szeliski 1989; Hsieh, McKeown, and Perlant 1992; Bolles, Baker, and Hannah\n1993). This limitation to sparse correspondences was partially due to computational resource\nlimitations, but was also driven by a desire to limit the answers produced by stereo algorithms\nto matches with high certainty. In some applications, there was also a desire to match scenes\nwith potentially very different illuminations, where edges might be the only stable features\n(Collins 1996). Such sparse 3D reconstructions could later be interpolated using surface ﬁt-\nting algorithms such as those discussed in Sections 3.7.1 and 12.3.1.\nMore recent work in this area has focused on ﬁrst extracting highly reliable features and\nthen using these as seeds to grow additional matches (Zhang and Shan 2000; Lhuillier and\nQuan 2002). Similar approaches have also been extended to wide baseline multi-view stereo\nproblems and combined with 3D surface reconstruction (Lhuillier and Quan 2005; Strecha,\nTuytelaars, and Van Gool 2003; Goesele, Snavely, Curless et al. 2007) or free-space reasoning\n(Taylor 2003), as described in more detail in Section 11.6.\n11.2.1 3D curves and proﬁles\nAnother example of sparse correspondence is the matching of proﬁle curves (or occluding\ncontours), which occur at the boundaries of objects (Figure 11.7) and at interior self occlu-\nsions, where the surface curves away from the camera viewpoint.\nThe difﬁculty in matching proﬁle curves is that in general, the locations of proﬁle curves\nvary as a function of camera viewpoint. Therefore, matching curves directly in two images\nand then triangulating these matches can lead to erroneous shape measurements. Fortunately,\nif three or more closely spaced frames are available, it is possible to ﬁt a local circular arc to\nthe locations of corresponding edgels (Figure 11.7a) and therefore obtain semi-dense curved\nsurface meshes directly from the matches (Figures 11.7c and g). Another advantage of match-\ning such curves is that they can be used to reconstruct surface shape for untextured surfaces,\nso long as there is a visible difference between foreground and background colors.\nOver the years, a number of different techniques have been developed for reconstructing\nsurface shape from proﬁle curves (Giblin and Weiss 1987; Cipolla and Blake 1992; Vaillant\nand Faugeras 1992; Zheng 1994; Boyer and Berger 1997; Szeliski and Weiss 1998). Cipolla\nand Giblin (2000) describe many of these techniques, as well as related topics such as in-\n544\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\nFigure 11.7 Surface reconstruction from occluding contours (Szeliski and Weiss 1998) c⃝\n2002 Springer: (a) circular arc ﬁtting in the epipolar plane; (b) synthetic example of an el-\nlipsoid with a truncated side and elliptic surface markings; (c) partially reconstructed surface\nmesh seen from an oblique and top-down view; (d) real-world image sequence of a soda can\non a turntable; (e) extracted edges; (f) partially reconstructed proﬁle curves; (g) partially re-\nconstructed surface mesh. (Partial reconstructions are shown so as not to clutter the images.)\nferring camera motion from proﬁle curve sequences. Below, we summarize the approach\ndeveloped by Szeliski and Weiss (1998), which assumes a discrete set of images, rather than\nformulating the problem in a continuous differential framework.\nLet us assume that the camera is moving smoothly enough that the local epipolar geometry\nvaries slowly, i.e., the epipolar planes induced by the successive camera centers and an edgel\nunder consideration are nearly co-planar. The ﬁrst step in the processing pipeline is to extract\nand link edges in each of the input images (Figures 11.7b and e). Next, edgels in successive\nimages are matched using pairwise epipolar geometry, proximity and (optionally) appearance.\nThis provides a linked set of edges in the spatio-temporal volume, which is sometimes called\nthe weaving wall (Baker 1989).\nTo reconstruct the 3D location of an individual edgel, along with its local in-plane normal\nand curvature, we project the viewing rays corresponding to its neighbors onto the instanta-\nneous epipolar plane deﬁned by the camera center, the viewing ray, and the camera velocity,\nas shown in Figure 11.7a. We then ﬁt an osculating circle to the projected lines, parameteriz-",
  "image_path": "page_565.jpg",
  "pages": [
    564,
    565,
    566
  ]
}