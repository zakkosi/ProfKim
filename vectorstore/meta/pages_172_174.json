{
  "doc_id": "pages_172_174",
  "text": "150\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n-0.2\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\nLinear\nBinomial\nCubic a=-1\nCubic a=-0.5\nWind. sinc\nQMF-9\nJPEG 2000\nFigure 3.31\nFrequency response for some 2× decimation ﬁlters. The cubic a = −1 ﬁlter\nhas the sharpest fall-off but also a bit of ringing; the wavelet analysis ﬁlters (QMF-9 and\nJPEG 2000), while useful for compression, have more aliasing.\n• a cosine-windowed sinc function (Table 3.2);\n• the QMF-9 ﬁlter of Simoncelli and Adelson (1990b) is used for wavelet denoising and\naliases a fair amount (note that the original ﬁlter coefﬁcients are normalized to\n√\n2 gain\nso they can be “self-inverting”);\n• the 9/7 analysis ﬁlter from JPEG 2000 (Taubman and Marcellin 2002).\nPlease see the original papers for the full-precision values of some of these coefﬁcients.\n3.5.3 Multi-resolution representations\nNow that we have described interpolation and decimation algorithms, we can build a complete\nimage pyramid (Figure 3.32). As we mentioned before, pyramids can be used to accelerate\ncoarse-to-ﬁne search algorithms, to look for objects or patterns at different scales, and to per-\nform multi-resolution blending operations. They are also widely used in computer graphics\nhardware and software to perform fractional-level decimation using the MIP-map, which we\ncover in Section 3.6.\nThe best known (and probably most widely used) pyramid in computer vision is Burt\nand Adelson’s (1983a) Laplacian pyramid. To construct the pyramid, we ﬁrst blur and sub-\nsample the original image by a factor of two and store this in the next level of the pyramid\n(Figure 3.33). Because adjacent levels in the pyramid are related by a sampling rate r = 2,\nthis kind of pyramid is known as an octave pyramid. Burt and Adelson originally proposed a\n3.5 Pyramids and wavelets\n151\nfine\nmedium\ncoarse\nl = 0\nl = 1\nl = 2\nFigure 3.32\nA traditional image pyramid: each level has half the resolution (width and\nheight), and hence a quarter of the pixels, of its parent level.\nﬁve-tap kernel of the form\nc\nb\na\nb\nc ,\n(3.82)\nwith b = 1/4 and c = 1/4−a/2. In practice, a = 3/8, which results in the familiar binomial\nkernel,\n1\n16 1\n4\n6\n4\n1 ,\n(3.83)\nwhich is particularly easy to implement using shifts and adds. (This was important in the days\nwhen multipliers were expensive.) The reason they call their resulting pyramid a Gaussian\npyramid is that repeated convolutions of the binomial kernel converge to a Gaussian.16\nTo compute the Laplacian pyramid, Burt and Adelson ﬁrst interpolate a lower resolu-\ntion image to obtain a reconstructed low-pass version of the original image (Figure 3.34b).\nThey then subtract this low-pass version from the original to yield the band-pass “Laplacian”\nimage, which can be stored away for further processing. The resulting pyramid has perfect\nreconstruction, i.e., the Laplacian images plus the base-level Gaussian (L2 in Figure 3.34b)\nare sufﬁcient to exactly reconstruct the original image. Figure 3.33 shows the same com-\nputation in one dimension as a signal processing diagram, which completely captures the\ncomputations being performed during the analysis and re-synthesis stages.\nBurt and Adelson also describe a variant on the Laplacian pyramid, where the low-pass\nimage is taken from the original blurred image rather than the reconstructed pyramid (piping\nthe output of the L box directly to the subtraction in Figure 3.34b). This variant has less\n16 Then again, this is true for any smoothing kernel (Wells 1986).\n152\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n¼\n⅜\n¼\n16\n1\n16\n1\n¼\n⅜\n¼\n16\n1\n16\n1\n½\n¾\n½\n½\n¾\n½\n⅛\n⅛\n⅛\n⅛\n(a)\n(b)\nFigure 3.33 The Gaussian pyramid shown as a signal processing diagram: The (a) analysis\nand (b) re-synthesis stages are shown as using similar computations. The white circles in-\ndicate zero values inserted by the ↑2 upsampling operation. Notice how the reconstruction\nﬁlter coefﬁcients are twice the analysis coefﬁcients. The computation is shown as ﬂowing\ndown the page, regardless of whether we are going from coarse to ﬁne or vice versa.\naliasing, since it avoids one downsampling and upsampling round-trip, but it is not self-\ninverting, since the Laplacian images are no longer adequate to reproduce the original image.\nAs with the Gaussian pyramid, the term Laplacian is a bit of a misnomer, since their\nband-pass images are really differences of (approximate) Gaussians, or DoGs,\nDoG{I; σ1, σ2} = Gσ1 ∗I −Gσ2 ∗I = (Gσ1 −Gσ2) ∗I.\n(3.84)\nA Laplacian of Gaussian (which we saw in (3.26)) is actually its second derivative,\nLoG{I; σ} = ∇2(Gσ ∗I) = (∇2Gσ) ∗I,\n(3.85)\nwhere\n∇2 = ∂2\n∂x2 + ∂2\n∂y2\n(3.86)\nis the Laplacian (operator) of a function. Figure 3.35 shows how the Differences of Gaussian\nand Laplacians of Gaussian look in both space and frequency.\nLaplacians of Gaussian have elegant mathematical properties, which have been widely\nstudied in the scale-space community (Witkin 1983; Witkin, Terzopoulos, and Kass 1986;\nLindeberg 1990; Nielsen, Florack, and Deriche 1997) and can be used for a variety of appli-\ncations including edge detection (Marr and Hildreth 1980; Perona and Malik 1990b), stereo\nmatching (Witkin, Terzopoulos, and Kass 1987), and image enhancement (Nielsen, Florack,\nand Deriche 1997).\nA less widely used variant is half-octave pyramids, shown in Figure 3.36a. These were\nﬁrst introduced to the vision community by Crowley and Stern (1984), who call them Dif-\nference of Low-Pass (DOLP) transforms. Because of the small scale change between adja-",
  "image_path": "page_173.jpg",
  "pages": [
    172,
    173,
    174
  ]
}