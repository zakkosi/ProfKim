{
  "doc_id": "pages_639_641",
  "text": "12.9 Exercises\n617\n1. Set up two background planes behind the object of interest and calculate their orienta-\ntion relative to the viewer, e.g., with ﬁducial marks.\n2. Cast a moving shadow with a stick across the scene; record the video or capture the\ndata with a webcam.\n3. Estimate each light plane equation from the projections of the cast shadow against the\ntwo backgrounds.\n4. Triangulate to the remaining points on each curve to get a 3D stripe and display the\nstripes using a 3D graphics engine.\n5. (Optional) remove the requirement for a known second (vertical) plane and infer its\nlocation (or that of the light source) using the techniques described by Bouguet and\nPerona (1999). The techniques from Exercise 10.9 may also be helpful here.\nEx 12.3: Range data registration\nRegister two or more 3D datasets using either iterated\nclosest points (ICP) (Besl and McKay 1992; Zhang 1994; Gold, Rangarajan, Lu et al. 1998)\nor octree signed distance ﬁelds (Szeliski and Lavall´ee 1996) (Section 12.2.1).\nApply your technique to narrow-baseline stereo pairs, e.g., obtained by moving a cam-\nera around an object, using structure from motion to recover the camera poses, and using a\nstandard stereo matching algorithm.\nEx 12.4: Range data merging\nMerge the datasets that you registered in the previous exer-\ncise using signed distance ﬁelds (Curless and Levoy 1996; Hilton, Stoddart, Illingworth et al.\n1996). You can optionally use an octree to represent and compress this ﬁeld if you already\nimplemented it in the previous registration step.\nExtract a meshed surface model from the signed distance ﬁeld using marching cubes and\ndisplay the resulting model.\nEx 12.5: Surface simpliﬁcation\nUse progressive meshes (Hoppe 1996) or some other tech-\nnique from Section 12.3.2 to create a hierarchical simpliﬁcation of your surface model.\nEx 12.6: Architectural modeler\nBuild a 3D interior or exterior model of some architec-\ntural structure, such as your house, from a series of handheld wide-angle photographs.\n1. Extract lines and vanishing points (Exercises 4.11–4.15) to estimate the dominant di-\nrections in each image.\n2. Use structure from motion to recover all of the camera poses and match up the vanish-\ning points.\n618\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n3. Let the user sketch the locations of the walls by drawing lines corresponding to wall\nbottoms, tops, and horizontal extents onto the images (Sinha, Steedly, Szeliski et al.\n2008)—see also Exercise 6.9. Do something similar for openings (doors and windows)\nand simple furniture (tables and countertops).\n4. Convert the resulting polygonal meshes into a 3D model (e.g., VRML) and optionally\ntexture-map these surfaces from the images.\nEx 12.7: Body tracker\nDownload the video sequences from the HumanEva Web site.16\nEither implement a human motion tracker from scratch or extend the code on that Web site\n(Sigal, Balan, and Black 2010) in some interesting way.\nEx 12.8: 3D photography\nCombine all of your previously developed techniques to pro-\nduce a system that takes a series of photographs or a video and constructs a photorealistic\ntexture-mapped 3D model.\n16 http://vision.cs.brown.edu/humaneva/.\nChapter 13\nImage-based rendering\n13.1 View interpolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621\n13.1.1 View-dependent texture maps\n. . . . . . . . . . . . . . . . . . . . . 623\n13.1.2 Application: Photo Tourism\n. . . . . . . . . . . . . . . . . . . . . . 624\n13.2 Layered depth images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 626\n13.2.1 Impostors, sprites, and layers . . . . . . . . . . . . . . . . . . . . . . 626\n13.3 Light ﬁelds and Lumigraphs\n. . . . . . . . . . . . . . . . . . . . . . . . . . 628\n13.3.1 Unstructured Lumigraph . . . . . . . . . . . . . . . . . . . . . . . . 632\n13.3.2 Surface light ﬁelds . . . . . . . . . . . . . . . . . . . . . . . . . . . 632\n13.3.3 Application: Concentric mosaics . . . . . . . . . . . . . . . . . . . . 634\n13.4 Environment mattes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 634\n13.4.1 Higher-dimensional light ﬁelds . . . . . . . . . . . . . . . . . . . . . 636\n13.4.2 The modeling to rendering continuum . . . . . . . . . . . . . . . . . 637\n13.5 Video-based rendering\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 638\n13.5.1 Video-based animation . . . . . . . . . . . . . . . . . . . . . . . . . 639\n13.5.2 Video textures\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 640\n13.5.3 Application: Animating pictures . . . . . . . . . . . . . . . . . . . . 643\n13.5.4 3D Video . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 643\n13.5.5 Application: Video-based walkthroughs . . . . . . . . . . . . . . . . 645\n13.6 Additional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 648\n13.7 Exercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 650",
  "image_path": "page_640.jpg",
  "pages": [
    639,
    640,
    641
  ]
}