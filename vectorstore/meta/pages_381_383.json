{
  "doc_id": "pages_381_383",
  "text": "7.3 Factorization\n359\nwhere M j is the upper 2 × 3 portion of the projection matrix P j and pi = (Xi, Yi, Zi). We\ncan concatenate all of these measurement equations into one large matrix\nˆ\nX =\n\n\n˜x11 · · · ˜x1i · · · ˜x1N\n...\n...\n...\n˜xj1 · · · ˜xji · · · ˜xjN\n...\n...\n...\n˜xM1 · · · ˜xMi · · · ˜xMN\n\n\n=\n\n\nM 1\n...\nM j\n...\nM M\n\n\nh\np1 · · · pi · · · pN\ni\n= ˆ\nM ˆS.\n(7.43)\nˆ\nX is called the measurement matrix and ˆ\nM and ( ˆS are the motion) and structure matrices,\nrespectively (Tomasi and Kanade 1992).\nBecause the motion matrix ˆ\nM is 2M × 3 and the structure matrix ˆS is 3 × N, an SVD\napplied to ˆ\nX has only three non-zero singular values. In the case where the measurements in\nˆ\nX are noisy, SVD returns the rank-three factorization of ˆ\nX that is the closest to ˆ\nX in a least\nsquares sense (Tomasi and Kanade 1992; Golub and Van Loan 1996; Hartley and Zisserman\n2004).\nIt would be nice if the SVD of ˆ\nX = UΣV T directly returned the matrices ˆ\nM and ˆS,\nbut it does not. Instead, we can write the relationship\nˆ\nX = UΣV T = [UQ][Q−1ΣV T ]\n(7.44)\nand set ˆ\nM = UQ and ˆS = Q−1ΣV T .11\nHow can we recover the values of the 3×3 matrix Q? This depends on the motion model\nbeing used. In the case of orthographic projection (2.47), the entries in M j are the ﬁrst two\nrows of rotation matrices Rj, so we have\nmj0 · mj0 =\nu2jQQT uT\n2j\n= 1,\nmj0 · mj1 =\nu2jQQT uT\n2j+1\n= 0,\nmj1 · mj1 =\nu2j+1QQT uT\n2j+1\n= 1,\n(7.45)\nwhere uk are the 3 × 1 rows of the matrix U. This gives us a large set of equations for the\nentries in the matrix QQT , from which the matrix Q can be recovered using a matrix square\nroot (Appendix A.1.4). If we have scaled orthography (2.48), i.e., M j = sjRj, the ﬁrst and\nthird equations are equal to sj and can be set equal to each other.\nNote that even once Q has been recovered, there still exists a bas-relief ambiguity, i.e.,\nwe can never be sure if the object is rotating left to right or if its depth reversed version is\nmoving the other way. (This can be seen in the classic rotating Necker Cube visual illusion.)\n11 Tomasi and Kanade (1992) ﬁrst take the square root of Σ and distribute this to U and V , but there is no\nparticular reason to do this.\n360\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nAdditional cues, such as the appearance and disappearance of points, or perspective effects,\nboth of which are discussed below, can be used to remove this ambiguity.\nFor motion models other than pure orthography, e.g., for scaled orthography or para-\nperspective, the approach above must be extended in the appropriate manner. Such tech-\nniques are relatively straightforward to derive from ﬁrst principles; more details can be found\nin papers that extend the basic factorization approach to these more ﬂexible models (Poel-\nman and Kanade 1997). Additional extensions of the original factorization algorithm include\nmulti-body rigid motion (Costeira and Kanade 1995), sequential updates to the factorization\n(Morita and Kanade 1997), the addition of lines and planes (Morris and Kanade 1998), and\nre-scaling the measurements to incorporate individual location uncertainties (Anandan and\nIrani 2002).\nA disadvantage of factorization approaches is that they require a complete set of tracks,\ni.e., each point must be visible in each frame, in order for the factorization approach to work.\nTomasi and Kanade (1992) deal with this problem by ﬁrst applying factorization to smaller\ndenser subsets and then using known camera (motion) or point (structure) estimates to hallu-\ncinate additional missing values, which allows them to incrementally incorporate more fea-\ntures and cameras. Huynh, Hartley, and Heyden (2003) extend this approach to view missing\ndata as special cases of outliers. Buchanan and Fitzgibbon (2005) develop fast iterative al-\ngorithms for performing large matrix factorizations with missing data. The general topic of\nprincipal component analysis (PCA) with missing data also appears in other computer vision\nproblems (Shum, Ikeuchi, and Reddy 1995; De la Torre and Black 2003; Gross, Matthews,\nand Baker 2006; Torresani, Hertzmann, and Bregler 2008; Vidal, Ma, and Sastry 2010).\n7.3.1 Perspective and projective factorization\nAnother disadvantage of regular factorization is that it cannot deal with perspective cameras.\nOne way to get around this problem is to perform an initial afﬁne (e.g., orthographic) recon-\nstruction and to then correct for the perspective effects in an iterative manner (Christy and\nHoraud 1996).\nObserve that the object-centered projection model (2.76)\nxji\n=\nsj\nrxj · pi + txj\n1 + ηjrzj · pi\n(7.46)\nyji\n=\nsj\nryj · pi + tyj\n1 + ηjrzj · pi\n(7.47)\ndiffers from the scaled orthographic projection model (7.40) by the inclusion of the denomi-\nnator terms (1 + ηjrzj · pi).12\n12 Assuming that the optical center (cx, cy) lies at (0, 0) and that pixels are square.\n7.3 Factorization\n361\nIf we knew the correct values of ηj = t−1\nzj and the structure and motion parameters Rj and\npi, we could cross-multiply the left hand side (visible point measurements xji and yji) by the\ndenominator and get corrected values, for which the bilinear projection model (7.40) is exact.\nIn practice, after an initial reconstruction, the values of ηj can be estimated independently\nfor each frame by comparing reconstructed and sensed point positions. (The third row of the\nrotation matrix rzj is always available as the cross-product of the ﬁrst two rows.) Note that\nsince the ηj are determined from the image measurements, the cameras do not have to be\npre-calibrated, i.e., their focal lengths can be recovered from fj = sj/ηj.\nOnce the ηj have been estimated, the feature locations can then be corrected before apply-\ning another round of factorization. Note that because of the initial depth reversal ambiguity,\nboth reconstructions have to be tried while calculating ηj. (The incorrect reconstruction will\nresult in a negative ηj, which is not physically meaningful.) Christy and Horaud (1996) report\nthat their algorithm usually converges in three to ﬁve iterations, with the majority of the time\nspent in the SVD computation.\nAn alternative approach, which does not assume partially calibrated cameras (known op-\ntical center, square pixels, and zero skew) is to perform a fully projective factorization (Sturm\nand Triggs 1996; Triggs 1996). In this case, the inclusion of the third row of the camera\nmatrix in (7.40) is equivalent to multiplying each reconstructed measurement xji = M jpi\nby its inverse (projective) depth ηji = d−1\nji = 1/(P j2pi) or, equivalently, multiplying each\nmeasured position by its projective depth dji,\nˆ\nX =\n\n\nd11˜x11\n· · ·\nd1i˜x1i\n· · ·\nd1N ˜x1N\n...\n...\n...\ndj1˜xj1\n· · ·\ndji˜xji\n· · ·\ndjN ˜xjN\n...\n...\n...\ndM1˜xM1 · · · dMi˜xMi · · · dMN ˜xMN\n\n\n= ˆ\nM ˆS.\n(7.48)\nIn the original paper by Sturm and Triggs (1996), the projective depths dji are obtained from\ntwo-frame reconstructions, while in later work (Triggs 1996; Oliensis and Hartley 2007), they\nare initialized to dji = 1 and updated after each iteration. Oliensis and Hartley (2007) present\nan update formula that is guaranteed to converge to a ﬁxed point. None of these authors\nsuggest actually estimating the third row of P j as part of the projective depth computations.\nIn any case, it is unclear when a fully projective reconstruction would be preferable to a\npartially calibrated one, especially if they are being used to initialize a full bundle adjustment\nof all the parameters.\nOne of the attractions of factorization methods is that they provide a “closed form” (some-\ntimes called a “linear”) method to initialize iterative techniques such as bundle adjustment.\nAn alternative initialization technique is to estimate the homographies corresponding to some",
  "image_path": "page_382.jpg",
  "pages": [
    381,
    382,
    383
  ]
}