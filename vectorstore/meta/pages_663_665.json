{
  "doc_id": "pages_663_665",
  "text": "13.5 Video-based rendering\n641\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\n(i)\nFigure 13.13\nVideo textures (Sch¨odl, Szeliski, Salesin et al. 2000) c⃝2000 ACM: (a) a\nclock pendulum, with correctly matched direction of motion; (b) a candle ﬂame, showing\ntemporal transition arcs; (c) the ﬂag is generated using morphing at jumps; (d) a bonﬁre\nuses longer cross-dissolves; (e) a waterfall cross-dissolves several sequences at once; (f) a\nsmiling animated face; (g) two swinging children are animated separately; (h) the balloons\nare automatically segmented into separate moving regions; (i) a synthetic ﬁsh tank consisting\nof bubbles, plants, and ﬁsh. Videos corresponding to these images can be found at http:\n//www.cc.gatech.edu/gvu/perception/projects/videotexture/.\n642\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nﬁnite impulse response (FIR) ﬁltering of each match sequence can be used to emphasize\nsubsequences that match well.\nThe results of this match computation gives us a jump table or, equivalently, a transition\nprobability between any two frames in the original video. This is shown schematically as\nred arcs in Figure 13.13b, where the red bar indicates which video frame is currently be-\ning displayed, and arcs light up as a forward or backward transition is taken. We can view\nthese transition probabilities as encoding the hidden Markov model (HMM) that underlies a\nstochastic video generation process.\nSometimes, it is not possible to ﬁnd exactly matching subsequences in the original video.\nIn this case, morphing, i.e., warping and blending frames during transitions (Section 3.6.3)\ncan be used to hide the visual differences (Figure 13.13c). If the motion is chaotic enough,\nas in a bonﬁre or a waterfall (Figures 13.13d–e), simple blending (extended cross-dissolves)\nmay be sufﬁcient. Improved transitions can also be obtained by performing 3D graph cuts on\nthe spatio-temporal volume around a transition (Kwatra, Sch¨odl, Essa et al. 2003).\nVideo textures need not be restricted to chaotic random phenomena such as ﬁre, wind,\nand water. Pleasing video textures can be created of people, e.g., a smiling face (as in Fig-\nure 13.13f) or someone running on a treadmill (Sch¨odl, Szeliski, Salesin et al. 2000). When\nmultiple people or objects are moving independently, as in Figures 13.13g–h, we must ﬁrst\nsegment the video into independently moving regions and animate each region separately.\nIt is also possible to create large panoramic video textures from a slowly panning camera\n(Agarwala, Zheng, Pal et al. 2005).\nInstead of just playing back the original frames in a stochastic (random) manner, video\ntextures can also be used to create scripted or interactive animations. If we extract individual\nelements, such as ﬁsh in a ﬁshtank (Figure 13.13i) into separate video sprites, we can animate\nthem along pre-speciﬁed paths (by matching the path direction with the original sprite motion)\nto make our video elements move in a desired fashion (Sch¨odl and Essa 2002). In fact, work\non video textures inspired research on systems that re-synthesize new motion sequences from\nmotion capture data, which some people refer to as “mocap soup” (Arikan and Forsyth 2002;\nKovar, Gleicher, and Pighin 2002; Lee, Chai, Reitsma et al. 2002; Li, Wang, and Shum 2002;\nPullen and Bregler 2002).\nWhile video textures primarily analyze the video as a sequence of frames (or regions) that\ncan be re-arranged in time, temporal textures (Szummer and Picard 1996; Bar-Joseph, El-\nYaniv, Lischinski et al. 2001) and dynamic textures (Doretto, Chiuso, Wu et al. 2003; Yuan,\nWen, Liu et al. 2004; Doretto and Soatto 2006) treat the video as a 3D spatio-temporal volume\nwith textural properties, which can be described using auto-regressive temporal models.\n13.5 Video-based rendering\n643\n    displacement map\n...\n(a)\n(b)\n(c)\n(d)\n(e)\n...\n...\n=\n=\n=\n=\n=\n \nL1\nL2\nLl-2\nLl-1\nLl\nL  (t)\n1\nL  (t)\n2\nL    (t)\nl-2\nL    (t)\nl-1\nL (t)\nl\n    displacement map\n    displacement map\n    displacement map\n    displacement map\nd    (t)\n l-1\nd (t)\n l\nd    (t)\n l-2\nd  (t)\n 2\nd  (t)\n 1\ntype=“boat”\ntype=“still”\ntype=“tree”\ntype=“cloud”\ntype=“water”\nFigure 13.14 Animating still pictures (Chuang, Goldman, Zheng et al. 2005) c⃝2005 ACM.\n(a) The input still image is manually segmented into (b) several layers. (c) Each layer is\nthen animated with a different stochastic motion texture (d) The animated layers are then\ncomposited to produce (e) the ﬁnal animation\n13.5.3 Application: Animating pictures\nWhile video textures can turn a short video clip into an inﬁnitely long video, can the same\nthing be done with a single still image? The answer is yes, if you are willing to ﬁrst segment\nthe image into different layers and then animate each layer separately.\nChuang, Goldman, Zheng et al. (2005) describe how an image can be decomposed into\nseparate layers using interactive matting techniques. Each layer is then animated using a\nclass-speciﬁc synthetic motion. As shown in Figure 13.14, boats rock back and forth, trees\nsway in the wind, clouds move horizontally, and water ripples, using a shaped noise displace-\nment map. All of these effects can be tied to some global control parameters, such as the\nvelocity and direction of a virtual wind. After being individually animated, the layers can be\ncomposited to create a ﬁnal dynamic rendering.\n13.5.4 3D Video\nIn recent years, the popularity of 3D movies has grown dramatically, with recent releases\nranging from Hannah Montana, through U2’s 3D concert movie, to James Cameron’s Avatar.\nCurrently, such releases are ﬁlmed using stereoscopic camera rigs and displayed in theaters\n(or at home) to viewers wearing polarized glasses.8 In the future, however, home audiences\nmay wish to view such movies with multi-zone auto-stereoscopic displays, where each person\ngets his or her own customized stereo stream and can move around a scene to see it from\n8 http://www.3d-summit.com/.",
  "image_path": "page_664.jpg",
  "pages": [
    663,
    664,
    665
  ]
}