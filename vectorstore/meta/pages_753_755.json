{
  "doc_id": "pages_753_755",
  "text": "Chapter 15\nConclusion\nIn this book, we have covered a broad range of computer vision topics. Starting with image\nformation, we have seen how images can be pre-processed to remove noise or blur, segmented\ninto regions, or converted into feature descriptors. Multiple images can be matched and\nregistered, with the results used to estimate motion, track people, reconstruct 3D models,\nor merge images into more attractive and interesting composites and renderings. Images can\nalso be analyzed to produce semantic descriptions of their content. However, the gap between\ncomputer and human performance in this area is still large and is likely to remain so for many\nyears.\nOur study has also exposed us to a wide range of mathematical techniques. These include\ncontinuous mathematics, such as signal processing, variational approaches, three-dimensional\nand projective geometry, linear algebra, and least squares. We have also studied topics in\ndiscrete mathematics and computer science, such as graph algorithms, combinatorial opti-\nmization, and even database techniques for information retrieval. Since many problems in\ncomputer vision are inverse problems that involve estimating unknown quantities from noisy\ninput data, we have also looked at Bayesian statistical inference techniques, as well as ma-\nchine learning techniques to learn probabilistic models from large amounts of training data.\nAs the availability of partially labeled visual imagery on the Internet continues to increase\nexponentially, this latter approach will continue to have a major impact on our ﬁeld.\nYou may ask: why is our ﬁeld so broad and aren’t there any unifying principles that can\nbe used to simplify our study? Part of the answer lies in the expansive deﬁnition of com-\nputer vision, which is the analysis of images and video, as well as the incredible complexity\ninherent in the formation of visual imagery. In some ways, our ﬁeld is as complex as the\nstudy of automotive engineering, which requires an understanding of internal combustion,\nmechanics, aerodynamics, ergonomics, electrical circuitry, and control systems, among other\n732\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ntopics. Computer vision similarly draws on a wide variety of sub-disciplines, which makes it\nchallenging to cover in a one-semester course, let alone to achieve mastery during a course\nof graduate studies. Conversely, the incredible breadth and technical complexity of computer\nvision problems is what draws many people to this research ﬁeld.\nBecause of this richness and the difﬁculty in making and measuring progress, I have at-\ntempted to instill in my students and in readers of this book a discipline founded on principles\nfrom engineering, science, and statistics.\nThe engineering approach to problem solving is to ﬁrst carefully deﬁne the overall prob-\nlem being tackled and to question the basic assumptions and goals inherent in this process.\nOnce this has been done, a number of alternative solutions or approaches are implemented\nand carefully tested, paying attention to issues such as reliability and computational cost.\nFinally, one or more solutions are deployed and evaluated in real-world settings. For this\nreason, this book contains many different alternatives for solving vision problems, many of\nwhich are sketched out in the exercises for students to implement and test on their own.\nThe scientiﬁc approach builds upon a basic understanding of physical principles. In the\ncase of computer vision, this includes the physics of man-made and natural structures, image\nformation, including lighting and atmospheric effects, optics, and noisy sensors. The task is to\nthen invert this formation using stable and efﬁcient algorithms to obtain reliable descriptions\nof the scene and other quantities of interest. The scientiﬁc approach also encourages us to\nformulate and test hypotheses, which is similar to the extensive testing and evaluation inherent\nin engineering disciplines.\nLastly, because so much about the image formation process is inherently uncertain and\nambiguous, a statistical approach that models both uncertainty in the world (e.g., the number\nand types of animals in a picture) and noise in the image formation process, is often essential.\nBayesian inference techniques can then be used to combine prior and measurement models\nto estimate the unknowns and to model their uncertainty. Machine learning techniques can\nbe used to create the probabilistic models in the ﬁrst place. Efﬁcient learning and inference\nalgorithms, such as dynamic programming, graph cuts, and belief propagation, often play a\ncrucial role in this process.\nGiven the breadth of material we have covered in this book, what new developments are\nwe likely to see in the future? As I have mentioned before, one of the recent trends in com-\nputer vision is using the massive amounts of partially labeled visual data on the Internet as\nsources for learning visual models of scenes and objects. We have already seen data-driven\napproaches succeed in related ﬁelds such as speech recognition, machine translation, speech\nand music synthesis, and even computer graphics (both in image-based rendering and anima-\ntion from motion capture). A similar process has been occurring in computer vision, with\nsome of the most exciting new work occurring at the intersection of the object recognition\nand machine learning ﬁelds.\n15 Conclusion\n733\nMore traditional quantitative techniques in computer vision such as motion estimation,\nstereo correspondence, and image enhancement, all beneﬁt from better prior models for im-\nages, motions, and disparities, as well as efﬁcient statistical inference techniques such as\nthose for inhomogeneous and higher-order Markov random ﬁelds. Some techniques, such as\nfeature matching and structure from motion, have matured to where they can be applied to\nalmost arbitrary collections of images of static scenes. This has resulted in an explosion of\nwork in 3D modeling from Internet datasets, which again is related to visual recognition from\nmassive amounts of data.\nWhile these are all encouraging developments, the gap between human and machine per-\nformance in semantic scene understanding remains large. It may be many years before com-\nputers can name and outline all of the objects in a photograph with the same skill as a two-\nyear-old child. However, we have to remember that human performance is often the result of\nmany years of training and familiarity and often works best in special ecologically important\nsituations. For example, while humans appear to be experts at face recognition, our actual\nperformance when shown people we do not know well is not that good. Combining vision\nalgorithms with general inference techniques that reason about the real world will likely lead\nto more breakthroughs, although some of the problems may turn out to be “AI-complete”, in\nthe sense that a full emulation of human experience and intelligence may be necessary.\nWhatever the outcome of these research endeavors, computer vision is already having\na tremendous impact in many areas, including digital photography, visual effects, medical\nimaging, safety and surveillance, and Web-based search. The breadth of the problems and\ntechniques inherent in this ﬁeld, combined with the richness of the mathematics and the\nutility of the resulting algorithms, will ensure that this remains an exciting area of study for\nyears to come.",
  "image_path": "page_754.jpg",
  "pages": [
    753,
    754,
    755
  ]
}