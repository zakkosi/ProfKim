{
  "doc_id": "pages_787_789",
  "text": "B.5 Markov random ﬁelds\n765\npossible. For example, 2D grids can be enhanced with the addition of diagonal connections\n(an N8 neighborhood) or even larger numbers of pairwise terms (Boykov and Kolmogorov\n2003; Rother, Kolmogorov, Lempitsky et al. 2007). 3D grids can be used to compute glob-\nally optimal segmentations in 3D volumetric medical images (Boykov and Funka-Lea 2006)\n(Section 5.5.1). Higher-order cliques can also be used to develop more sophisticated models\n(Potetz and Lee 2008; Kohli, Ladick´y, and Torr 2009; Kohli, Kumar, and Torr 2009).\nOne of the biggest challenges in using MRF models is to develop efﬁcient inference algo-\nrithms that will ﬁnd low-energy solutions (Veksler 1999; Boykov, Veksler, and Zabih 2001;\nKohli 2007; Kumar 2008). Over the years, a large variety of such algorithms have been de-\nveloped, including simulated annealing, graph cuts, and loopy belief propagation. The choice\nof inference technique can greatly affect the overall performance of a vision system. For\nexample, most of the top-performing algorithms on the Middlebury Stereo Evaluation page\neither use belief propagation or graph cuts.\nIn the next few subsections, we review some of the more widely used MRF inference\ntechniques. More in-depth descriptions of most of these algorithms can be found in a re-\ncently published book on advances in MRF techniques (Blake, Kohli, and Rother 2010).\nExperimental comparisons, along with test datasets and reference software, are provided by\nSzeliski, Zabih, Scharstein et al. (2008).6\nB.5.1 Gradient descent and simulated annealing\nThe simplest optimization technique is gradient descent, which minimizes the energy by\nchanging independent subsets of nodes to take on lower-energy conﬁgurations. Such tech-\nniques go under a variety of names, including contextual classiﬁcation (Kittler and F¨oglein\n1984) and iterated conditional modes (ICM) (Besag 1986).7 Variables can either be updated\nsequentially, e.g., in raster scan, or in parallel, e.g., using red–black coloring on a checker-\nboard. Chou and Brown (1990) suggests using highest conﬁdence ﬁrst (HCF), i.e., choosing\nvariables based on how large a difference they make in reducing the energy.\nThe problem with gradient descent is that it is prone to getting stuck in local minima,\nwhich is almost always the case with MRF problems. One way around this is to use stochastic\ngradient descent or Markov chain Monte Carlo (MCMC) (Metropolis, Rosenbluth, Rosen-\nbluth et al. 1953), i.e., to randomly take occasional uphill steps in order to get out of such\nminima. One popular update rule is the Gibbs sampler (Geman and Geman 1984); rather\nthan choosing the lowest energy state for a variable being updated, it chooses the state with\n6 http://vision.middlebury.edu/MRF/.\n7 The name comes from iteratively setting variables to the mode (most likely, i.e., lowest energy) state conditioned\non its currently ﬁxed neighbors.\n766\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nprobability\np(x) ∝e−E(x)/T ,\n(B.25)\nwhere T is called the temperature and controls how likely the system is to choose a more\nrandom update. Stochastic gradient descent is usually combined with simulated annealing\n(Kirkpatrick, Gelatt, and Vecchi 1983), which starts at a relatively high temperature, thereby\nrandomly exploring a large part of the state space, and gradually cools (anneals) the tem-\nperature to ﬁnd a good local minimum. During the late 1980s, simulated annealing was the\nmethod of choice for solving MRF inference problems (Szeliski 1986; Marroquin, Mitter,\nand Poggio 1985; Barnard 1989).\nAnother variant on simulated annealing is the Swendsen–Wang algorithm (Swendsen and\nWang 1987; Barbu and Zhu 2003, 2005). Here, instead of “ﬂipping” (changing) single vari-\nables, a connected subset of variables, chosen using a random walk based on MRF connec-\ntively strengths, is selected as the basic update unit. This can sometimes help make larger\nstate changes, and hence ﬁnd better-quality solutions in less time.\nWhile simulated annealing has largely been superseded by the newer graph cuts and loopy\nbelief propagation techniques, it still occasionally ﬁnds use, especially in highly connected\nand highly non-submodular graphs (Rother, Kolmogorov, Lempitsky et al. 2007).\nB.5.2 Dynamic programming\nDynamic programming (DP) is an efﬁcient inference procedure that works for any tree-\nstructured graphical model, i.e., one that does not have any cycles. Given such a tree, pick\nany node as the root r and ﬁguratively pick up the tree by its root. The depth or distance of all\nthe other nodes from this root induces a partial ordering over the vertices, from which a total\nordering can be obtained by arbitrarily breaking ties. Let us now lay out this graph as a tree\nwith the root on the right and indices increasing from left to right, as shown in Figure B.2a.\nBefore describing the DP algorithm, let us re-write the potential function of Equation (B.24)\nin a more general but succinct form,\nE(x) =\nX\n(i,j)∈N\nVi,j(xi, xj) +\nX\ni\nVi(xi),\n(B.26)\nwhere instead of using pixel indices (i, j) and (k, l), we just use scalar index variables i\nand j. We also replace the function value f(i, j) with the more succinct notation xi, with\nthe {xi} variables making up the state vector x. We can simplify this function even further\nby adding dummy nodes (vertices) i−for every node that has a non-zero Vi(xi) and setting\nVi,i−(xi, xi−) = Vi(xi), which lets us drop the Vi terms from (B.26).\nDynamic programming proceeds by computing partial sums in a left-to-right fashion, i.e.,\nin order of increasing variable index. Let Ck be the children of k, i.e., i < k, (i, k) ∈N).\nB.5 Markov random ﬁelds\n767\nxk\nVik\nxj\nxi\nVjk\n...\n...\n...\nxr\nVij\nxk\nVijk\nxj\nxi\n...\n...\n...\n(a)\n(b)\nFigure B.2\nDynamic programming over a tree drawn as a factor graph. (a) To compute\nthe lowest energy solution ˆEk(xk) at node xk conditioned on the best solutions to the left\nof this node, we enumerate all possible values of ˆEi(xi) + Vik(xi, xk) and pick the smallest\none (and similarly for j). (b) For higher-order cliques, we need to try all combinations of\n(xi, xj) in order to select the best possible conﬁguration. The arrows show the basic ﬂow\nof the computation. The lightly shaded factor Vij in (a) shows an additional connection that\nturns the tree into a cyclic graph, for which exact inference cannot be efﬁciently computed.\nThen, deﬁne\n˜Ek(x) =\nX\ni<k, j≤k\nVi,j(xi, xj) =\nX\ni∈Ck\nh\nVi,k(xi, xk) + ˜Ei(x)\ni\n,\n(B.27)\nas a partial sum of (B.26) over all variables up to and including k, i.e., over all parts of the\ngraph shown in Figure B.2a to the left of xk. This sum depends on the state of all the unknown\nvariables in x with i ≤k.\nNow suppose we wish to ﬁnd the setting for all variables i < k that minimizes this sum.\nIt turns out that we can use a simple recursive formula\nˆEk(xk) =\nmin\n{xi, i<k}\n˜Ek(x) =\nX\ni∈Ck\nmin\nxi\nh\nVi,k(xi, xk) + ˆEi(xi)\ni\n(B.28)\nto ﬁnd this minimum. Visually, this is easy to understand. Looking at Figure B.2a, associate\nan energy ˆEk(xk) with each node k and each possible setting of its value xk that is based on\nthe best possible setting of variables to the left of that node. It is easy to convince yourself\nthat in this ﬁgure, you only need to know ˆEi(xi) and ˆEj(xj) in order to compute this value.\nOnce the ﬂow of information in the tree has been processed from left to right, the min-\nimum value of ˆEr(xr) at the root gives the MAP (lowest-energy) solution for E(x). The\nroot node is set to the choice of xr that minimizes this function, and other nodes are set in a\nbackward chaining pass by selecting the values of child nodes i ∈Ck that were minimal in\nthe original recursion (B.28).",
  "image_path": "page_788.jpg",
  "pages": [
    787,
    788,
    789
  ]
}