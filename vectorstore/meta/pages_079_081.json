{
  "doc_id": "pages_079_081",
  "text": "2.1 Geometric primitives and transformations\n57\nThe other special case where we do not need to know depth to perform inter-camera\nmapping is when the camera is undergoing pure rotation (Section 9.1.3), i.e., when t0 = t1.\nIn this case, we can write\n˜x1 ∼K1R1R−1\n0 K−1\n0 ˜x0 = K1R10K−1\n0 ˜x0,\n(2.72)\nwhich again can be represented with a 3 × 3 homography. If we assume that the calibration\nmatrices have known aspect ratios and centers of projection (2.59), this homography can be\nparameterized by the rotation amount and the two unknown focal lengths. This particular\nformulation is commonly used in image-stitching applications (Section 9.1.3).\nObject-centered projection\nWhen working with long focal length lenses, it often becomes difﬁcult to reliably estimate\nthe focal length from image measurements alone. This is because the focal length and the\ndistance to the object are highly correlated and it becomes difﬁcult to tease these two effects\napart. For example, the change in scale of an object viewed through a zoom telephoto lens\ncan either be due to a zoom change or a motion towards the user. (This effect was put to\ndramatic use in some of Alfred Hitchcock’s ﬁlm Vertigo, where the simultaneous change of\nzoom and camera motion produces a disquieting effect.)\nThis ambiguity becomes clearer if we write out the projection equation corresponding to\nthe simple calibration matrix K (2.59),\nxs\n=\nf rx · p + tx\nrz · p + tz\n+ cx\n(2.73)\nys\n=\nf ry · p + ty\nrz · p + tz\n+ cy,\n(2.74)\nwhere rx, ry, and rz are the three rows of R. If the distance to the object center tz ≫∥p∥\n(the size of the object), the denominator is approximately tz and the overall scale of the\nprojected object depends on the ratio of f to tz. It therefore becomes difﬁcult to disentangle\nthese two quantities.\nTo see this more clearly, let ηz = t−1\nz\nand s = ηzf. We can then re-write the above\nequations as\nxs\n=\ns rx · p + tx\n1 + ηzrz · p + cx\n(2.75)\nys\n=\ns ry · p + ty\n1 + ηzrz · p + cy\n(2.76)\n(Szeliski and Kang 1994; Pighin, Hecker, Lischinski et al. 1998). The scale of the projection\ns can be reliably estimated if we are looking at a known object (i.e., the 3D coordinates p\n58\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nare known). The inverse distance ηz is now mostly decoupled from the estimates of s and\ncan be estimated from the amount of foreshortening as the object rotates. Furthermore, as\nthe lens becomes longer, i.e., the projection model becomes orthographic, there is no need to\nreplace a perspective imaging model with an orthographic one, since the same equation can\nbe used, with ηz →0 (as opposed to f and tz both going to inﬁnity). This allows us to form\na natural link between orthographic reconstruction techniques such as factorization and their\nprojective/perspective counterparts (Section 7.3).\n2.1.6 Lens distortions\nThe above imaging models all assume that cameras obey a linear projection model where\nstraight lines in the world result in straight lines in the image. (This follows as a natural\nconsequence of linear matrix operations being applied to homogeneous coordinates.) Unfor-\ntunately, many wide-angle lenses have noticeable radial distortion, which manifests itself as\na visible curvature in the projection of straight lines. (See Section 2.2.3 for a more detailed\ndiscussion of lens optics, including chromatic aberration.) Unless this distortion is taken into\naccount, it becomes impossible to create highly accurate photorealistic reconstructions. For\nexample, image mosaics constructed without taking radial distortion into account will often\nexhibit blurring due to the mis-registration of corresponding features before pixel blending\n(Chapter 9).\nFortunately, compensating for radial distortion is not that difﬁcult in practice. For most\nlenses, a simple quartic model of distortion can produce good results. Let (xc, yc) be the\npixel coordinates obtained after perspective division but before scaling by focal length f and\nshifting by the optical center (cx, cy), i.e.,\nxc\n=\nrx · p + tx\nrz · p + tz\nyc\n=\nry · p + ty\nrz · p + tz\n.\n(2.77)\nThe radial distortion model says that coordinates in the observed images are displaced away\n(barrel distortion) or towards (pincushion distortion) the image center by an amount propor-\ntional to their radial distance (Figure 2.13a–b).3\nThe simplest radial distortion models use\nlow-order polynomials, e.g.,\nˆxc\n=\nxc(1 + κ1r2\nc + κ2r4\nc)\nˆyc\n=\nyc(1 + κ1r2\nc + κ2r4\nc),\n(2.78)\n3 Anamorphic lenses, which are widely used in feature ﬁlm production, do not follow this radial distortion model.\nInstead, they can be thought of, to a ﬁrst approximation, as inducing different vertical and horizontal scalings, i.e.,\nnon-square pixels.\n2.1 Geometric primitives and transformations\n59\n(a)\n(b)\n(c)\nFigure 2.13 Radial lens distortions: (a) barrel, (b) pincushion, and (c) ﬁsheye. The ﬁsheye\nimage spans almost 180◦from side-to-side.\nwhere r2\nc = x2\nc + y2\nc and κ1 and κ2 are called the radial distortion parameters.4 After the\nradial distortion step, the ﬁnal pixel coordinates can be computed using\nxs\n=\nfx′\nc + cx\nys\n=\nfy′\nc + cy.\n(2.79)\nA variety of techniques can be used to estimate the radial distortion parameters for a given\nlens, as discussed in Section 6.3.5.\nSometimes the above simpliﬁed model does not model the true distortions produced by\ncomplex lenses accurately enough (especially at very wide angles). A more complete ana-\nlytic model also includes tangential distortions and decentering distortions (Slama 1980), but\nthese distortions are not covered in this book.\nFisheye lenses (Figure 2.13c) require a model that differs from traditional polynomial\nmodels of radial distortion. Fisheye lenses behave, to a ﬁrst approximation, as equi-distance\nprojectors of angles away from the optical axis (Xiong and Turkowski 1997), which is the\nsame as the polar projection described by Equations (9.22–9.24). Xiong and Turkowski\n(1997) describe how this model can be extended with the addition of an extra quadratic cor-\nrection in φ and how the unknown parameters (center of projection, scaling factor s, etc.)\ncan be estimated from a set of overlapping ﬁsheye images using a direct (intensity-based)\nnon-linear minimization algorithm.\nFor even larger, less regular distortions, a parametric distortion model using splines may\nbe necessary (Goshtasby 1989). If the lens does not have a single center of projection, it\n4 Sometimes the relationship between xc and ˆxc is expressed the other way around, i.e., xc = ˆxc(1 + κ1ˆr2\nc +\nκ2ˆr4\nc). This is convenient if we map image pixels into (warped) rays by dividing through by f. We can then undistort\nthe rays and have true 3D rays in space.",
  "image_path": "page_080.jpg",
  "pages": [
    79,
    80,
    81
  ]
}