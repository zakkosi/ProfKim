{
  "doc_id": "pages_241_243",
  "text": "4.1 Points and patches\n219\nFigure 4.12\nA dominant orientation estimate can be computed by creating a histogram of\nall the gradient orientations (weighted by their magnitudes or after thresholding out small\ngradients) and then ﬁnding the signiﬁcant peaks in this distribution (Lowe 2004) c⃝2004\nSpringer.\nA better method is to estimate a dominant orientation at each detected keypoint. Once\nthe local orientation and scale of a keypoint have been estimated, a scaled and oriented patch\naround the detected point can be extracted and used to form a feature descriptor (Figures 4.10\nand 4.17).\nThe simplest possible orientation estimate is the average gradient within a region around\nthe keypoint. If a Gaussian weighting function is used (Brown, Szeliski, and Winder 2005),\nthis average gradient is equivalent to a ﬁrst-order steerable ﬁlter (Section 3.2.3), i.e., it can be\ncomputed using an image convolution with the horizontal and vertical derivatives of Gaus-\nsian ﬁlter (Freeman and Adelson 1991). In order to make this estimate more reliable, it is\nusually preferable to use a larger aggregation window (Gaussian kernel size) than detection\nwindow (Brown, Szeliski, and Winder 2005). The orientations of the square boxes shown in\nFigure 4.10 were computed using this technique.\nSometimes, however, the averaged (signed) gradient in a region can be small and therefore\nan unreliable indicator of orientation. A more reliable technique is to look at the histogram\nof orientations computed around the keypoint. Lowe (2004) computes a 36-bin histogram\nof edge orientations weighted by both gradient magnitude and Gaussian distance to the cen-\nter, ﬁnds all peaks within 80% of the global maximum, and then computes a more accurate\norientation estimate using a three-bin parabolic ﬁt (Figure 4.12).\nAfﬁne invariance\nWhile scale and rotation invariance are highly desirable, for many applications such as wide\nbaseline stereo matching (Pritchett and Zisserman 1998; Schaffalitzky and Zisserman 2002)\nor location recognition (Chum, Philbin, Sivic et al. 2007), full afﬁne invariance is preferred.\n220\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 4.13\nAfﬁne region detectors used to match two images taken from dramatically\ndifferent viewpoints (Mikolajczyk and Schmid 2004) c⃝2004 Springer.\nx0 →\nA−1/2\n0\nx′\n0\nx′\n0 →\nRx′\n1\nA−1/2\n1\nx′\n1\n←x1\nFigure 4.14\nAfﬁne normalization using the second moment matrices, as described by Miko-\nlajczyk, Tuytelaars, Schmid et al. (2005) c⃝2005 Springer. After image coordinates are trans-\nformed using the matrices A−1/2\n0\nand A−1/2\n1\n, they are related by a pure rotation R, which\ncan be estimated using a dominant orientation technique.\nAfﬁne-invariant detectors not only respond at consistent locations after scale and orientation\nchanges, they also respond consistently across afﬁne deformations such as (local) perspective\nforeshortening (Figure 4.13). In fact, for a small enough patch, any continuous image warping\ncan be well approximated by an afﬁne deformation.\nTo introduce afﬁne invariance, several authors have proposed ﬁtting an ellipse to the auto-\ncorrelation or Hessian matrix (using eigenvalue analysis) and then using the principal axes\nand ratios of this ﬁt as the afﬁne coordinate frame (Lindeberg and Garding 1997; Baumberg\n2000; Mikolajczyk and Schmid 2004; Mikolajczyk, Tuytelaars, Schmid et al. 2005; Tuyte-\nlaars and Mikolajczyk 2007). Figure 4.14 shows how the square root of the moment matrix\ncan be used to transform local patches into a frame which is similar up to rotation.\nAnother important afﬁne invariant region detector is the maximally stable extremal region\n(MSER) detector developed by Matas, Chum, Urban et al. (2004). To detect MSERs, binary\nregions are computed by thresholding the image at all possible gray levels (the technique\ntherefore only works for grayscale images). This operation can be performed efﬁciently by\nﬁrst sorting all pixels by gray value and then incrementally adding pixels to each connected\ncomponent as the threshold is changed (Nist´er and Stew´enius 2008). As the threshold is\nchanged, the area of each component (region) is monitored; regions whose rate of change of\narea with respect to the threshold is minimal are deﬁned as maximally stable. Such regions\n4.1 Points and patches\n221\nFigure 4.15\nMaximally stable extremal regions (MSERs) extracted and matched from a\nnumber of images (Matas, Chum, Urban et al. 2004) c⃝2004 Elsevier.\nFigure 4.16\nFeature matching: how can we extract local descriptors that are invariant\nto inter-image variations and yet still discriminative enough to establish correct correspon-\ndences?\nare therefore invariant to both afﬁne geometric and photometric (linear bias-gain or smooth\nmonotonic) transformations (Figure 4.15). If desired, an afﬁne coordinate frame can be ﬁt to\neach detected region using its moment matrix.\nThe area of feature point detectors continues to be very active, with papers appearing ev-\nery year at major computer vision conferences (Xiao and Shah 2003; Koethe 2003; Carneiro\nand Jepson 2005; Kenney, Zuliani, and Manjunath 2005; Bay, Tuytelaars, and Van Gool 2006;\nPlatel, Balmachnova, Florack et al. 2006; Rosten and Drummond 2006). Mikolajczyk, Tuyte-\nlaars, Schmid et al. (2005) survey a number of popular afﬁne region detectors and provide\nexperimental comparisons of their invariance to common image transformations such as scal-\ning, rotations, noise, and blur. These experimental results, code, and pointers to the surveyed\npapers can be found on their Web site at http://www.robots.ox.ac.uk/∼vgg/research/afﬁne/.\nOf course, keypoints are not the only features that can be used for registering images.\nZoghlami, Faugeras, and Deriche (1997) use line segments as well as point-like features to\nestimate homographies between pairs of images, whereas Bartoli, Coquerelle, and Sturm\n(2004) use line segments with local correspondences along the edges to extract 3D structure\nand motion. Tuytelaars and Van Gool (2004) use afﬁne invariant regions to detect corre-\nspondences for wide baseline stereo matching, whereas Kadir, Zisserman, and Brady (2004)\ndetect salient regions where patch entropy and its rate of change with scale are locally max-\nimal. Corso and Hager (2005) use a related technique to ﬁt 2D oriented Gaussian kernels\nto homogeneous regions. More details on techniques for ﬁnding and matching curves, lines,\nand regions can be found later in this chapter.",
  "image_path": "page_242.jpg",
  "pages": [
    241,
    242,
    243
  ]
}