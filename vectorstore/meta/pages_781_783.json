{
  "doc_id": "pages_781_783",
  "text": "B.2 Maximum likelihood estimation and least squares\n759\nNotice that the inverse covariance Ci = Σ−1\ni\nplays the role of a weight on each of the\nmeasurement error residuals, i.e., the difference between the contaminated measurement yi\nand its uncontaminated (predicted) value f i(x). In fact, the inverse covariance is often called\nthe (Fisher) information matrix (Bishop 2006), since it tells us how much information is\ncontained in a given measurement, i.e., how well it constrains the ﬁnal estimate. We can also\nthink of this matrix as denoting the amount of conﬁdence to associate with each measurement\n(hence the letter C).\nIn this formulation, it is quite acceptable for some information matrices to be singular\n(of degenerate rank) or even zero (if the measurement is missing altogether). Rank-deﬁcient\nmeasurements often occur, for example, when using a line feature or edge to measure a 3D\nedge-like feature, since its exact position along the edge is unknown (of inﬁnite or extremely\nlarge variance) §8.1.3.\nIn order to make the distinction between the noise contaminated measurement and its\nexpected value for a particular setting of x more explicit, we adopt the notation ˜y for the\nformer (think of the tilde as the approximate or noisy value) and ˆy = f i(x) for the latter\n(think of the hat as the predicted or expected value). We can then write the negative log\nlikelihood as\nE = −log L =\nX\ni\n∥˜yi −ˆyi∥Σ\n−1\ni\n+ k.\n(B.13)\nB.2 Maximum likelihood estimation and least squares\nNow that we have presented the likelihood and log likelihood functions, how can we ﬁnd the\noptimal value for our state estimate x? One plausible choice might be to select the value of x\nthat maximizes L = p(y|x). In fact, in the absence of any prior model for x (Appendix B.4),\nwe have\nL = p(y|x) = p(y, x) = p(x|y).\nTherefore, choosing the value of x that maximizes the likelihood is equivalent to choosing\nthe maximum of our probability density estimate for x.\nWhen might this be a good idea? If the data (measurements) constrain the possible values\nof x so that they all cluster tightly around one value (e.g., if the distribution p(x|y) is a\nunimodal Gaussian), the maximum likelihood estimate is the optimal one in that it is both\nunbiased and has the least possible variance. In many other cases, e.g., if a single estimate\nis all that is required, it is still often the best estimate.3 However, if the probability is multi-\nmodal, i.e., it has several local minima in the log likelihood (Figure 5.7), much more care\n3 According to the Gauss-Markov theorem, least squares produces the best linear unbiased estimator (BLUE) for\na linear measurement model regardless of the actual noise distribution, assuming that the noise is zero mean and\nuncorrelated.\n760\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nmay be required. In particular, it might be necessary to defer certain decisions (such as the\nultimate position of an object being tracked) until more measurements have been taken. The\nCONDENSATION algorithm presented in Section 5.1.2 is one possible method for modeling\nand updating such multi-modal distributions but is just one example of more general particle\nﬁltering and Markov Chain Monte Carlo (MCMC) techniques (Andrieu, de Freitas, Doucet\net al. 2003; Bishop 2006; Koller and Friedman 2009).\nAnother possible way to choose the best estimate is to maximize the expected utility\n(or, conversely, to minimize the expected risk or loss) associated with obtaining the correct\nestimate, i.e., by minimizing\nEloss(x, y) =\nZ\nl(x −z)p(z|y)dz.\n(B.14)\nFor example, if a robot wants to avoid hitting a wall at all costs, the loss function will be\nhigh whenever the estimate underestimates the true distance to the wall. When l(x −y) =\nδ(x −y), we obtain the maximum likelihood estimate, whereas when l(x −y) = ∥x −y∥2,\nwe obtain the mean square error (MSE) or expected value estimate. The explicit modeling of\na utility or loss function is what characterizes statistical decision theory (Berger 1993; Hastie,\nTibshirani, and Friedman 2001; Bishop 2006; Robert 2007).\nHow do we ﬁnd the maximum likelihood estimate? If the measurement noise is Gaussian,\nwe can minimize the quadratic objective function (B.13). This becomes even simpler if the\nmeasurement equations are linear, i.e.,\nf i(x) = Hix,\n(B.15)\nwhere H is the measurement matrix relating unknown state variables x to measurements ˜y.\nIn this case, (B.13) becomes\nE =\nX\ni\n∥˜yi −Hix∥Σ\n−1\ni\n=\nX\ni\n(˜yi −Hix)T Ci(˜yi −Hix),\n(B.16)\nwhich is a simple quadratic form in x, which can be solved using linear least squares (Ap-\npendix A.2). When the measurements are non-linear, the system must be solved iteratively\nusing non-linear least squares (Appendix A.3).\nB.3 Robust statistics\nIn Appendix B.1.1, we assumed that the noise being added to each measurement (B.5) was\nmultivariate Gaussian (B.7). This is an appropriate model if the noise is the result of lots of\ntiny errors being added together, e.g., from thermal noise in a silicon imager. In most cases,\nhowever, measurements can be contaminated with larger outliers, i.e., gross failures in the\nB.3 Robust statistics\n761\nmeasurement process. Examples of such outliers include bad feature matches (Section 6.1.4),\nocclusions in stereo matching (Chapter 11), and discontinuities in an otherwise smooth image,\ndepth map, or label image (Sections 3.7.1 and 3.7.2).\nIn such cases, it makes more sense to model the measurement noise with a long-tailed\ncontaminated noise model such as a Laplacian. The negative log likelihood in this case,\nrather than being quadratic in the measurement residuals (B.12–B.16), has a slower growth\nin the penalty function to account for the increased likelihood of large errors.\nThis formulation of the inference problem is called an M-estimator in the robust statistics\nliterature (Huber 1981; Hampel, Ronchetti, Rousseeuw et al. 1986; Black and Rangarajan\n1996; Stewart 1999) and involves applying a robust penalty function ρ(r) to the residuals\nERLS(∆p) =\nX\ni\nρ(∥ri∥)\n(B.17)\ninstead of squaring them.\nAs we mentioned in Section 6.1.4, we can take the derivative of this function with respect\nto p and set it to 0,\nX\ni\nψ(∥ri∥)∂∥ri∥\n∂p\n=\nX\ni\nψ(∥ri∥)\n∥ri∥\nrT\ni\n∂ri\n∂p = 0,\n(B.18)\nwhere ψ(r) = ρ′(r) is the derivative of ρ and is called the inﬂuence function. If we introduce a\nweight function, w(r) = Ψ(r)/r, we observe that ﬁnding the stationary point of (B.17) using\n(B.18) is equivalent to minimizing the iteratively re-weighted least squares (IRLS) problem\nEIRLS =\nX\ni\nw(∥ri∥)∥ri∥2,\n(B.19)\nwhere the w(∥ri∥) play the same local weighting role as Ci = Σ−1\ni\nin (B.12). Black and\nAnandan (1996) describe a variety of robust penalty functions and their corresponding inﬂu-\nence and weighting function.\nThe IRLS algorithm alternates between computing the inﬂuence functions w(∥ri∥) and\nsolving the resulting weighted least squares problem (with ﬁxed w values). Alternative in-\ncremental robust least squares algorithms can be found in the work of Sawhney and Ayer\n(1996); Black and Anandan (1996); Black and Rangarajan (1996); Baker, Gross, Ishikawa et\nal. (2003) and textbooks and tutorials on robust statistics (Huber 1981; Hampel, Ronchetti,\nRousseeuw et al. 1986; Rousseeuw and Leroy 1987; Stewart 1999). It is also possible to ap-\nply general optimization techniques (Appendix A.3) directly to the non-linear cost function\ngiven in Equation (B.19), which may sometimes have better convergence properties.\nMost robust penalty functions involve a scale parameter, which should typically be set to\nthe variance (or standard deviation, depending on the formulation) of the non-contaminated",
  "image_path": "page_782.jpg",
  "pages": [
    781,
    782,
    783
  ]
}