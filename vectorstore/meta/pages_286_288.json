{
  "doc_id": "pages_286_288",
  "text": "264\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n7. (Optional) Prove that the constant phase component corresponds to the temporal shift\nin s, while the linear component corresponds to rotation.\nOf course, feel free to try any other curve descriptor and matching technique from the com-\nputer vision literature (Tek and Kimia 2003; Sebastian and Kimia 2005).\nEx 4.10: Jigsaw puzzle solver—challenging\nWrite a program to automatically solve a jig-\nsaw puzzle from a set of scanned puzzle pieces. Your software may include the following\ncomponents:\n1. Scan the pieces (either face up or face down) on a ﬂatbed scanner with a distinctively\ncolored background.\n2. (Optional) Scan in the box top to use as a low-resolution reference image.\n3. Use color-based thresholding to isolate the pieces.\n4. Extract the contour of each piece using edge ﬁnding and linking.\n5. (Optional) Re-represent each contour using an arc-length or some other re-parameterization.\nBreak up the contours into meaningful matchable pieces. (Is this hard?)\n6. (Optional) Associate color values with each contour to help in the matching.\n7. (Optional) Match pieces to the reference image using some rotationally invariant fea-\nture descriptors.\n8. Solve a global optimization or (backtracking) search problem to snap pieces together\nand place them in the correct location relative to the reference image.\n9. Test your algorithm on a succession of more difﬁcult puzzles and compare your results\nwith those of others.\nEx 4.11: Successive approximation line detector\nImplement a line simpliﬁcation algorithm\n(Section 4.3.1) (Ramer 1972; Douglas and Peucker 1973) to convert a hand-drawn curve (or\nlinked edge image) into a small set of polylines.\n(Optional) Re-render this curve using either an approximating or interpolating spline or\nBezier curve (Szeliski and Ito 1986; Bartels, Beatty, and Barsky 1987; Farin 1996).\nEx 4.12: Hough transform line detector\nImplement a Hough transform for ﬁnding lines\nin images:\n4.5 Exercises\n265\n1. Create an accumulator array of the appropriate user-speciﬁed size and clear it. The user\ncan specify the spacing in degrees between orientation bins and in pixels between dis-\ntance bins. The array can be allocated as integer (for simple counts), ﬂoating point (for\nweighted counts), or as an array of vectors for keeping back pointers to the constituent\nedges.\n2. For each detected edgel at location (x, y) and orientation θ = tan−1 ny/nx, compute\nthe value of\nd = xnx + yny\n(4.33)\nand increment the accumulator corresponding to (θ, d).\n(Optional) Weight the vote of each edge by its length (see Exercise 4.7) or the strength\nof its gradient.\n3. (Optional) Smooth the scalar accumulator array by adding in values from its immediate\nneighbors. This can help counteract the discretization effect of voting for only a single\nbin—see Exercise 3.7.\n4. Find the largest peaks (local maxima) in the accumulator corresponding to lines.\n5. (Optional) For each peak, re-ﬁt the lines to the constituent edgels, using total least\nsquares (Appendix A.2). Use the original edgel lengths or strength weights to weight\nthe least squares ﬁt, as well as the agreement between the hypothesized line orienta-\ntion and the edgel orientation. Determine whether these heuristics help increase the\naccuracy of the ﬁt.\n6. After ﬁtting each peak, zero-out or eliminate that peak and its adjacent bins in the array,\nand move on to the next largest peak.\nTest out your Hough transform on a variety of images taken indoors and outdoors, as well\nas checkerboard calibration patterns.\nFor checkerboard patterns, you can modify your Hough transform by collapsing antipodal\nbins (θ ± 180◦, −d) with (θ, d) to ﬁnd lines that do not care about polarity changes. Can you\nthink of examples in real-world images where this might be desirable as well?\nEx 4.13: Line ﬁtting uncertainty\nEstimate the uncertainty (covariance) in your line ﬁt us-\ning uncertainty analysis.\n1. After determining which edgels belong to the line segment (using either successive\napproximation or Hough transform), re-ﬁt the line segment using total least squares\n(Van Huffel and Vandewalle 1991; Van Huffel and Lemmerling 2002), i.e., ﬁnd the\nmean or centroid of the edgels and then use eigenvalue analysis to ﬁnd the dominant\norientation.\n266\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n2. Compute the perpendicular errors (deviations) to the line and robustly estimate the\nvariance of the ﬁtting noise using an estimator such as MAD (Appendix B.3).\n3. (Optional) re-ﬁt the line parameters by throwing away outliers or using a robust norm\nor inﬂuence function.\n4. Estimate the error in the perpendicular location of the line segment and its orientation.\nEx 4.14: Vanishing points\nCompute the vanishing points in an image using one of the tech-\nniques described in Section 4.3.3 and optionally reﬁne the original line equations associated\nwith each vanishing point. Your results can be used later to track a target (Exercise 6.5) or\nreconstruct architecture (Section 12.6.1).\nEx 4.15: Vanishing point uncertainty\nPerform an uncertainty analysis on your estimated\nvanishing points. You will need to decide how to represent your vanishing point, e.g., homo-\ngeneous coordinates on a sphere, to handle vanishing points near inﬁnity.\nSee the discussion of Bingham distributions by Collins and Weiss (1990) for some ideas.",
  "image_path": "page_287.jpg",
  "pages": [
    286,
    287,
    288
  ]
}