{
  "doc_id": "pages_793_795",
  "text": "B.5 Markov random ﬁelds\n771\n  Object\nterminal\n  terminal\nBackground \np\nq\nr\nw\nv\nS\nT\nBackground \n  Object\n  terminal\nterminal\np\nq\nr\nw\nv\nS\nT\ncut\n(a)\n(b)\nFigure B.3 Graph cuts for minimizing binary sub-modular MRF energies (Boykov and Jolly\n2001) c⃝2001 IEEE: (a) energy function encoded as a max ﬂow problem; (b) the minimum\ncut determines the region boundary.\nVeksler, and Zabih 2010; Ishikawa and Veksler 2010).\nThe simplest example of an MRF graph cut is the polynomial-time algorithm for perform-\ning exact minimization of a binary MRF originally developed by Greig, Porteous, and Seheult\n(1989) and brought to the attention of the computer vision community by Boykov, Veksler,\nand Zabih (2001) and Boykov and Jolly (2001). The basic construction of the min-cut graph\nfrom an MRF energy function is shown in Figure B.3 and described in Sections 3.7.2 and\n5.5. In brief, the nodes in an MRF are connected to special source and sink nodes, and the\nminimum cut between these two nodes, whose cost is exactly that of the MRF energy un-\nder a binary assignment of labels, is computed using a polynomial-time max ﬂow algorithm\n(Goldberg and Tarjan 1988; Boykov and Kolmogorov 2004).\nAs discussed in Section 5.5, important extensions of this basic algorithm have been made\nfor the case of directed edges (Kolmogorov and Boykov 2005), larger neighborhoods (Boykov\nand Kolmogorov 2003; Kolmogorov and Boykov 2005), connectivity priors (Vicente, Kol-\nmogorov, and Rother 2008), and shape priors (Lempitsky and Boykov 2007; Lempitsky,\nBlake, and Rother 2008). Kolmogorov and Zabih (2004) formally characterize the class\nof binary energy potentials (regularity conditions) for which these algorithms ﬁnd the global\nminimum. Komodakis, Tziritas, and Paragios (2008) and Rother, Kolmogorov, Lempitsky et\nal. (2007) provide good algorithms for the cases when they do not.\nBinary MRF problems can also be approximately solved by turning them into continuous\n[0, 1] problems, solving them either as linear systems (Grady 2006; Sinop and Grady 2007;\nGrady and Alvino 2008; Grady 2008; Grady and Ali 2008; Singaraju, Grady, and Vidal 2008;\nCouprie, Grady, Najman et al. 2009) (the random walker model) or by computing geodesic\n772\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ndistances (Bai and Sapiro 2009; Criminisi, Sharp, and Blake 2008) and then thresholding the\nresults. More details on these techniques are provided in Section 5.5 and a nice review can\nbe found in the work of Singaraju, Grady, Sinop et al. (2010). A different connection to\ncontinuous segmentation techniques, this time to the literature on level sets (Section 5.1.4),\nis made by Boykov, Kolmogorov, Cremers et al. (2006), who develop an approach to solving\nsurface propagation PDEs based on combinatorial graph cut algorithms—Boykov and Funka-\nLea (2006) discuss this and related techniques.\nMulti-valued MRF inference problems usually require solving a series of related binary\nMRF problems (Boykov, Veksler, and Zabih 2001), although for special cases, such as some\nconvex functions, a single graph cut may sufﬁce (Ishikawa 2003; Schlesinger and Flach\n2006). The seminal work in this area is that of Boykov, Veksler, and Zabih (2001), who intro-\nduced two algorithms, called the swap move and the expansion move, which are sketched in\nFigure B.4. The α–β-swap move selects two labels (usually by cycling through all possible\npairings) and then formulates a binary MRF problem that allows any pixels currently labeled\nas either α or β to optionally switch their values to the other label. The α-expansion move\nallows any pixel in the MRF to take on the α label or to keep its current identity. It is easy\nto see by inspection that both of these moves result in binary MRFs with well-deﬁned energy\nfunctions.\nBecause these algorithms use a binary MRF optimization inside their inner loop, they\nare subject to the constraints on the energy functions that occur in the binary labeling case\n(Kolmogorov and Zabih 2004). However, more recent algorithms such as those developed by\nKomodakis, Tziritas, and Paragios (2008) and Rother, Kolmogorov, Lempitsky et al. (2007)\ncan be used to provide approximate solutions for more general energy functions. Efﬁcient\nalgorithms for re-using previous solutions (ﬂow- and cut-recycling) have been developed for\non-line applications such as dynamic MRFs (Kohli and Torr 2005; Juan and Boykov 2006;\nAlahari, Kohli, and Torr 2011) and coarse-to-ﬁne banded graph cuts (Agarwala, Zheng, Pal et\nal. 2005; Lombaert, Sun, Grady et al. 2005; Juan and Boykov 2006). It is also now possible to\nminimize the number of labels used as part of the alpha-expansion process (Delong, Osokin,\nIsack et al. 2010).\nIn experimental comparisons, α-expansions usually converge faster to a good solution\nthan α–β-swaps (Szeliski, Zabih, Scharstein et al. 2008), especially for problems that in-\nvolve large regions of identical labels, such as the labeling of source imagery in image stitch-\ning (Figure 3.60). For truncated convex energy functions deﬁned over ordinal values, more\naccurate algorithms that consider complete ranges of labels inside each min-cut and often\nproduce lower energies have been developed (Veksler 2007; Kumar and Torr 2008; Kumar,\nVeksler, and Torr 2010). The whole ﬁeld of efﬁcient MRF inference algorithms is rapidly\ndeveloping, as witnessed by a recent special journal issue (Kohli and Torr 2008; Komodakis,\nTziritas, and Paragios 2008; Olsson, Eriksson, and Kahl 2008; Potetz and Lee 2008), articles\nB.5 Markov random ﬁelds\n773\n(a) initial labeling\n(b) standard move\n(c) α-β-swap\n(d) α-expansion\nFigure B.4 Multi-level graph optimization from (Boykov, Veksler, and Zabih 2001) c⃝2001\nIEEE: (a) initial problem conﬁguration; (b) the standard move changes only one pixel; (c)\nthe α–β-swap optimally exchanges all α- and β-labeled pixels; (d) the α-expansion move\noptimally selects among current pixel values and the α label.\n(Alahari, Kohli, and Torr 2011), and a forthcoming book (Blake, Kohli, and Rother 2010).\nB.5.5 Linear programming\n8 Many successful algorithms for MRF optimization are based on the linear programming\n(LP) relaxation of the energy function (Weiss, Yanover, and Meltzer 2010). For some prac-\ntical MRF problems, LP-based techniques can produce globally minimal solutions (Meltzer,\nYanover, and Weiss 2005), even though MRF inference is in general NP-hard. In order to\ndescribe this relaxation, let us ﬁrst rewrite the energy function (B.26) as\nE(x)\n=\nX\n(i,j)∈N\nVi,j(xi, xj) +\nX\ni\nVi(xi)\n(B.35)\n=\nX\ni,j,α,β\nVi,j(α, β)xi,j;α,β +\nX\ni,α\nVi(α)xi;α\n(B.36)\nsubject to\nxi;α\n=\nX\nβ\nxi,j;α,β\n∀(i, j) ∈N, α,\n(B.37)\nxj;β\n=\nX\nα\nxi,j;α,β\n∀(i, j) ∈N, β,\nand\n(B.38)\nxi,α, xi,j;α,β\n∈\n{0, 1}.\n(B.39)\nHere, α and β range over label values and xi;α = δ(xi −α) and xij;αβ = δ(xi −α)δ(xj −β)\nare indicator variables of assignments xi = α and (xi, xj) = (α, β), respectively. The LP\nrelaxation is obtained by replacing the discreteness constraints (B.39) with linear constraints\nxij;αβ ∈[0, 1]. It is easy to show that the optimal value of (B.36) is a lower bound on (B.26).\n8 This section was contributed by Vladimir Kolmogorov. Thanks!",
  "image_path": "page_794.jpg",
  "pages": [
    793,
    794,
    795
  ]
}