{
  "doc_id": "pages_140_142",
  "text": "118\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nunsharp masking.\nSince blurring the image reduces high frequencies, adding some of the\ndifference between the original and the blurred image makes it sharper,\ngsharp = f + γ(f −hblur ∗f).\n(3.22)\nIn fact, before the advent of digital photography, this was the standard way to sharpen images\nin the darkroom: create a blurred (“positive”) negative from the original negative by mis-\nfocusing, then overlay the two negatives before printing the ﬁnal image, which corresponds\nto\ngunsharp = f(1 −γhblur ∗f).\n(3.23)\nThis is no longer a linear ﬁlter but it still works well.\nLinear ﬁltering can also be used as a pre-processing stage to edge extraction (Section 4.2)\nand interest point detection (Section 4.1) algorithms. Figure 3.14d shows a simple 3 × 3 edge\nextractor called the Sobel operator, which is a separable combination of a horizontal central\ndifference (so called because the horizontal derivative is centered on the pixel) and a vertical\ntent ﬁlter (to smooth the results). As you can see in the image below the kernel, this ﬁlter\neffectively emphasizes horizontal edges.\nThe simple corner detector (Figure 3.14e) looks for simultaneous horizontal and vertical\nsecond derivatives. As you can see however, it responds not only to the corners of the square,\nbut also along diagonal edges. Better corner detectors, or at least interest point detectors that\nare more rotationally invariant, are described in Section 4.1.\n3.2.3 Band-pass and steerable ﬁlters\nThe Sobel and corner operators are simple examples of band-pass and oriented ﬁlters. More\nsophisticated kernels can be created by ﬁrst smoothing the image with a (unit area) Gaussian\nﬁlter,\nG(x, y; σ) =\n1\n2πσ2 e−x2+y2\n2σ2 ,\n(3.24)\nand then taking the ﬁrst or second derivatives (Marr 1982; Witkin 1983; Freeman and Adelson\n1991). Such ﬁlters are known collectively as band-pass ﬁlters, since they ﬁlter out both low\nand high frequencies.\nThe (undirected) second derivative of a two-dimensional image,\n∇2f = ∂2f\n∂x2 + ∂2y\n∂y2 ,\n(3.25)\nis known as the Laplacian operator. Blurring an image with a Gaussian and then taking its\nLaplacian is equivalent to convolving directly with the Laplacian of Gaussian (LoG) ﬁlter,\n∇2G(x, y; σ) =\n\u0012x2 + y2\nσ4\n−2\nσ2\n\u0013\nG(x, y; σ),\n(3.26)\n3.2 Linear ﬁltering\n119\n(a)\n(b)\n(c)\nFigure 3.15 Second-order steerable ﬁlter (Freeman 1992) c⃝1992 IEEE: (a) original image\nof Einstein; (b) orientation map computed from the second-order oriented energy; (c) original\nimage with oriented structures enhanced.\nwhich has certain nice scale-space properties (Witkin 1983; Witkin, Terzopoulos, and Kass\n1986). The ﬁve-point Laplacian is just a compact approximation to this more sophisticated\nﬁlter.\nLikewise, the Sobel operator is a simple approximation to a directional or oriented ﬁlter,\nwhich can obtained by smoothing with a Gaussian (or some other ﬁlter) and then taking a\ndirectional derivative ∇ˆu =\n∂\n∂ˆu, which is obtained by taking the dot product between the\ngradient ﬁeld ∇and a unit direction ˆu = (cos θ, sin θ),\nˆu · ∇(G ∗f) = ∇ˆu(G ∗f) = (∇ˆuG) ∗f.\n(3.27)\nThe smoothed directional derivative ﬁlter,\nGˆu = uGx + vGy = u∂G\n∂x + v ∂G\n∂y ,\n(3.28)\nwhere ˆu = (u, v), is an example of a steerable ﬁlter, since the value of an image convolved\nwith Gˆu can be computed by ﬁrst convolving with the pair of ﬁlters (Gx, Gy) and then\nsteering the ﬁlter (potentially locally) by multiplying this gradient ﬁeld with a unit vector ˆu\n(Freeman and Adelson 1991). The advantage of this approach is that a whole family of ﬁlters\ncan be evaluated with very little cost.\nHow about steering a directional second derivative ﬁlter ∇ˆu · ∇ˆuGˆu, which is the result\nof taking a (smoothed) directional derivative and then taking the directional derivative again?\nFor example, Gxx is the second directional derivative in the x direction.\nAt ﬁrst glance, it would appear that the steering trick will not work, since for every di-\nrection ˆu, we need to compute a different ﬁrst directional derivative. Somewhat surprisingly,\nFreeman and Adelson (1991) showed that, for directional Gaussian derivatives, it is possible\n120\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 3.16\nFourth-order steerable ﬁlter (Freeman and Adelson 1991) c⃝1991 IEEE: (a)\ntest image containing bars (lines) and step edges at different orientations; (b) average oriented\nenergy; (c) dominant orientation; (d) oriented energy as a function of angle (polar plot).\nto steer any order of derivative with a relatively small number of basis functions. For example,\nonly three basis functions are required for the second-order directional derivative,\nGˆuˆu = u2Gxx + 2uvGxy + v2Gyy.\n(3.29)\nFurthermore, each of the basis ﬁlters, while not itself necessarily separable, can be computed\nusing a linear combination of a small number of separable ﬁlters (Freeman and Adelson\n1991).\nThis remarkable result makes it possible to construct directional derivative ﬁlters of in-\ncreasingly greater directional selectivity, i.e., ﬁlters that only respond to edges that have\nstrong local consistency in orientation (Figure 3.15). Furthermore, higher order steerable\nﬁlters can respond to potentially more than a single edge orientation at a given location, and\nthey can respond to both bar edges (thin lines) and the classic step edges (Figure 3.16). In\norder to do this, however, full Hilbert transform pairs need to be used for second-order and\nhigher ﬁlters, as described in (Freeman and Adelson 1991).\nSteerable ﬁlters are often used to construct both feature descriptors (Section 4.1.3) and\nedge detectors (Section 4.2). While the ﬁlters developed by Freeman and Adelson (1991)\nare best suited for detecting linear (edge-like) structures, more recent work by Koethe (2003)\nshows how a combined 2 × 2 boundary tensor can be used to encode both edge and junction\n(“corner”) features. Exercise 3.12 has you implement such steerable ﬁlters and apply them to\nﬁnding both edge and corner features.\nSummed area table (integral image)\nIf an image is going to be repeatedly convolved with different box ﬁlters (and especially ﬁlters\nof different sizes at different locations), you can precompute the summed area table (Crow",
  "image_path": "page_141.jpg",
  "pages": [
    140,
    141,
    142
  ]
}