{
  "doc_id": "pages_755_757",
  "text": "15 Conclusion\n733\nMore traditional quantitative techniques in computer vision such as motion estimation,\nstereo correspondence, and image enhancement, all beneﬁt from better prior models for im-\nages, motions, and disparities, as well as efﬁcient statistical inference techniques such as\nthose for inhomogeneous and higher-order Markov random ﬁelds. Some techniques, such as\nfeature matching and structure from motion, have matured to where they can be applied to\nalmost arbitrary collections of images of static scenes. This has resulted in an explosion of\nwork in 3D modeling from Internet datasets, which again is related to visual recognition from\nmassive amounts of data.\nWhile these are all encouraging developments, the gap between human and machine per-\nformance in semantic scene understanding remains large. It may be many years before com-\nputers can name and outline all of the objects in a photograph with the same skill as a two-\nyear-old child. However, we have to remember that human performance is often the result of\nmany years of training and familiarity and often works best in special ecologically important\nsituations. For example, while humans appear to be experts at face recognition, our actual\nperformance when shown people we do not know well is not that good. Combining vision\nalgorithms with general inference techniques that reason about the real world will likely lead\nto more breakthroughs, although some of the problems may turn out to be “AI-complete”, in\nthe sense that a full emulation of human experience and intelligence may be necessary.\nWhatever the outcome of these research endeavors, computer vision is already having\na tremendous impact in many areas, including digital photography, visual effects, medical\nimaging, safety and surveillance, and Web-based search. The breadth of the problems and\ntechniques inherent in this ﬁeld, combined with the richness of the mathematics and the\nutility of the resulting algorithms, will ensure that this remains an exciting area of study for\nyears to come.\n734\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nAppendix A\nLinear algebra and numerical\ntechniques\nA.1\nMatrix decompositions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 736\nA.1.1\nSingular value decomposition\n. . . . . . . . . . . . . . . . . . . . . 736\nA.1.2\nEigenvalue decomposition . . . . . . . . . . . . . . . . . . . . . . . 737\nA.1.3\nQR factorization\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 740\nA.1.4\nCholesky factorization . . . . . . . . . . . . . . . . . . . . . . . . . 741\nA.2\nLinear least squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 742\nA.2.1\nTotal least squares\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 744\nA.3\nNon-linear least squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 746\nA.4\nDirect sparse matrix techniques . . . . . . . . . . . . . . . . . . . . . . . . . 747\nA.4.1\nVariable reordering . . . . . . . . . . . . . . . . . . . . . . . . . . . 748\nA.5\nIterative techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 748\nA.5.1\nConjugate gradient . . . . . . . . . . . . . . . . . . . . . . . . . . . 749\nA.5.2\nPreconditioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 751\nA.5.3\nMultigrid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 753",
  "image_path": "page_756.jpg",
  "pages": [
    755,
    756,
    757
  ]
}