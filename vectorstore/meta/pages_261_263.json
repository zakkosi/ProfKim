{
  "doc_id": "pages_261_263",
  "text": "4.2 Edges\n239\nFigure 4.31 Human boundary detection (Martin, Fowlkes, and Malik 2004) c⃝2004 IEEE.\nThe darkness of the edges corresponds to how many human subjects marked an object bound-\nary at that location.\nintensity variation.3 Think of an image as a height ﬁeld. On such a surface, edges occur\nat locations of steep slopes, or equivalently, in regions of closely packed contour lines (on a\ntopographic map).\nA mathematical way to deﬁne the slope and direction of a surface is through its gradient,\nJ(x) = ∇I(x) = (∂I\n∂x, ∂I\n∂y )(x).\n(4.19)\nThe local gradient vector J points in the direction of steepest ascent in the intensity function.\nIts magnitude is an indication of the slope or strength of the variation, while its orientation\npoints in a direction perpendicular to the local contour.\nUnfortunately, taking image derivatives accentuates high frequencies and hence ampliﬁes\nnoise, since the proportion of noise to signal is larger at high frequencies. It is therefore\nprudent to smooth the image with a low-pass ﬁlter prior to computing the gradient. Because\nwe would like the response of our edge detector to be independent of orientation, a circularly\nsymmetric smoothing ﬁlter is desirable. As we saw in Section 3.2, the Gaussian is the only\nseparable circularly symmetric ﬁlter and so it is used in most edge detection algorithms.\nCanny (1986) discusses alternative ﬁlters and a number of researcher review alternative edge\ndetection algorithms and compare their performance (Davis 1975; Nalwa and Binford 1986;\nNalwa 1987; Deriche 1987; Freeman and Adelson 1991; Nalwa 1993; Heath, Sarkar, Sanocki\net al. 1998; Crane 1997; Ritter and Wilson 2000; Bowyer, Kranenburg, and Dougherty 2001;\nArbel´aez, Maire, Fowlkes et al. 2010).\nBecause differentiation is a linear operation, it commutes with other linear ﬁltering oper-\n3 We defer the topic of edge detection in color images.\n240\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nations. The gradient of the smoothed image can therefore be written as\nJσ(x) = ∇[Gσ(x) ∗I(x)] = [∇Gσ](x) ∗I(x),\n(4.20)\ni.e., we can convolve the image with the horizontal and vertical derivatives of the Gaussian\nkernel function,\n∇Gσ(x) = (∂Gσ\n∂x , ∂Gσ\n∂y )(x) = [−x −y] 1\nσ3 exp\n\u0012\n−x2 + y2\n2σ2\n\u0013\n(4.21)\n(The parameter σ indicates the width of the Gaussian.) This is the same computation that\nis performed by Freeman and Adelson’s (1991) ﬁrst-order steerable ﬁlter, which we already\ncovered in Section 3.2.3.\nFor many applications, however, we wish to thin such a continuous gradient image to\nonly return isolated edges, i.e., as single pixels at discrete locations along the edge contours.\nThis can be achieved by looking for maxima in the edge strength (gradient magnitude) in a\ndirection perpendicular to the edge orientation, i.e., along the gradient direction.\nFinding this maximum corresponds to taking a directional derivative of the strength ﬁeld\nin the direction of the gradient and then looking for zero crossings. The desired directional\nderivative is equivalent to the dot product between a second gradient operator and the results\nof the ﬁrst,\nSσ(x) = ∇· Jσ(x) = [∇2Gσ](x) ∗I(x)].\n(4.22)\nThe gradient operator dot product with the gradient is called the Laplacian. The convolution\nkernel\n∇2Gσ(x) = 1\nσ3\n\u0012\n2 −x2 + y2\n2σ2\n\u0013\nexp\n\u0012\n−x2 + y2\n2σ2\n\u0013\n(4.23)\nis therefore called the Laplacian of Gaussian (LoG) kernel (Marr and Hildreth 1980). This\nkernel can be split into two separable parts,\n∇2Gσ(x) = 1\nσ3\n\u0012\n1 −x2\n2σ2\n\u0013\nGσ(x)Gσ(y) + 1\nσ3\n\u0012\n1 −y2\n2σ2\n\u0013\nGσ(y)Gσ(x)\n(4.24)\n(Wiejak, Buxton, and Buxton 1985), which allows for a much more efﬁcient implementation\nusing separable ﬁltering (Section 3.2.1).\nIn practice, it is quite common to replace the Laplacian of Gaussian convolution with a\nDifference of Gaussian (DoG) computation, since the kernel shapes are qualitatively similar\n(Figure 3.35). This is especially convenient if a “Laplacian pyramid” (Section 3.5) has already\nbeen computed.4\n4 Recall that Burt and Adelson’s (1983a) “Laplacian pyramid” actually computed differences of Gaussian-ﬁltered\nlevels.\n4.2 Edges\n241\nIn fact, it is not strictly necessary to take differences between adjacent levels when com-\nputing the edge ﬁeld. Think about what a zero crossing in a “generalized” difference of\nGaussians image represents. The ﬁner (smaller kernel) Gaussian is a noise-reduced version\nof the original image. The coarser (larger kernel) Gaussian is an estimate of the average in-\ntensity over a larger region. Thus, whenever the DoG image changes sign, this corresponds\nto the (slightly blurred) image going from relatively darker to relatively lighter, as compared\nto the average intensity in that neighborhood.\nOnce we have computed the sign function S(x), we must ﬁnd its zero crossings and\nconvert these into edge elements (edgels). An easy way to detect and represent zero crossings\nis to look for adjacent pixel locations xi and xj where the sign changes value, i.e., [S(xi) >\n0] ̸= [S(xj) > 0].\nThe sub-pixel location of this crossing can be obtained by computing the “x-intercept” of\nthe “line” connecting S(xi) and S(xj),\nxz = xiS(xj) −xjS(xi)\nS(xj) −S(xi)\n.\n(4.25)\nThe orientation and strength of such edgels can be obtained by linearly interpolating the\ngradient values computed on the original pixel grid.\nAn alternative edgel representation can be obtained by linking adjacent edgels on the\ndual grid to form edgels that live inside each square formed by four adjacent pixels in the\noriginal pixel grid.5 The (potential) advantage of this representation is that the edgels now\nlive on a grid offset by half a pixel from the original pixel grid and are thus easier to store\nand access.\nAs before, the orientations and strengths of the edges can be computed by\ninterpolating the gradient ﬁeld or estimating these values from the difference of Gaussian\nimage (see Exercise 4.7).\nIn applications where the accuracy of the edge orientation is more important, higher-order\nsteerable ﬁlters can be used (Freeman and Adelson 1991) (see Section 3.2.3). Such ﬁlters are\nmore selective for more elongated edges and also have the possibility of better modeling curve\nintersections because they can represent multiple orientations at the same pixel (Figure 3.16).\nTheir disadvantage is that they are more expensive to compute and the directional derivative\nof the edge strength does not have a simple closed form solution.6",
  "image_path": "page_262.jpg",
  "pages": [
    261,
    262,
    263
  ]
}