{
  "doc_id": "pages_046_048",
  "text": "24\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ntures. This chapter begins with the easier problem of 3D point triangulation (Section 7.1),\nwhich is the 3D reconstruction of points from matched features when the camera positions\nare known. It then describes two-frame structure from motion (Section 7.2), for which al-\ngebraic techniques exist, as well as robust sampling techniques such as RANSAC that can\ndiscount erroneous feature matches. The second half of Chapter 7 describes techniques for\nmulti-frame structure from motion, including factorization (Section 7.3), bundle adjustment\n(Section 7.4), and constrained motion and structure models (Section 7.5). It also presents\napplications in view morphing, sparse 3D model construction, and match move.\nIn Chapter 8, we go back to a topic that deals directly with image intensities (as op-\nposed to feature tracks), namely dense intensity-based motion estimation (optical ﬂow). We\nstart with the simplest possible motion models, translational motion (Section 8.1), and cover\ntopics such as hierarchical (coarse-to-ﬁne) motion estimation, Fourier-based techniques, and\niterative reﬁnement. We then present parametric motion models, which can be used to com-\npensate for camera rotation and zooming, as well as afﬁne or planar perspective motion (Sec-\ntion 8.2). This is then generalized to spline-based motion models (Section 8.3) and ﬁnally\nto general per-pixel optical ﬂow (Section 8.4), including layered and learned motion models\n(Section 8.5). Applications of these techniques include automated morphing, frame interpo-\nlation (slow motion), and motion-based user interfaces.\nChapter 9 is devoted to image stitching, i.e., the construction of large panoramas and com-\nposites. While stitching is just one example of computation photography (see Chapter 10),\nthere is enough depth here to warrant a separate chapter. We start by discussing various pos-\nsible motion models (Section 9.1), including planar motion and pure camera rotation. We\nthen discuss global alignment (Section 9.2), which is a special (simpliﬁed) case of general\nbundle adjustment, and then present panorama recognition, i.e., techniques for automatically\ndiscovering which images actually form overlapping panoramas. Finally, we cover the topics\nof image compositing and blending (Section 9.3), which involve both selecting which pixels\nfrom which images to use and blending them together so as to disguise exposure differences.\nImage stitching is a wonderful application that ties together most of the material covered\nin earlier parts of this book. It also makes for a good mid-term course project that can build\non previously developed techniques such as image warping and feature detection and match-\ning. Chapter 9 also presents more specialized variants of stitching such as whiteboard and\ndocument scanning, video summarization, panography, full 360◦spherical panoramas, and\ninteractive photomontage for blending repeated action shots together.\nChapter 10 presents additional examples of computational photography, which is the pro-\ncess of creating new images from one or more input photographs, often based on the careful\nmodeling and calibration of the image formation process (Section 10.1). Computational pho-\ntography techniques include merging multiple exposures to create high dynamic range images\n(Section 10.2), increasing image resolution through blur removal and super-resolution (Sec-\n1.3 Book overview\n25\ntion 10.3), and image editing and compositing operations (Section 10.4). We also cover the\ntopics of texture analysis, synthesis and inpainting (hole ﬁlling) in Section 10.5, as well as\nnon-photorealistic rendering (Section 10.5.2).\nIn Chapter 11, we turn to the issue of stereo correspondence, which can be thought of\nas a special case of motion estimation where the camera positions are already known (Sec-\ntion 11.1). This additional knowledge enables stereo algorithms to search over a much smaller\nspace of correspondences and, in many cases, to produce dense depth estimates that can\nbe converted into visible surface models (Section 11.3). We also cover multi-view stereo\nalgorithms that build a true 3D surface representation instead of just a single depth map\n(Section 11.6). Applications of stereo matching include head and gaze tracking, as well as\ndepth-based background replacement (Z-keying).\nChapter 12 covers additional 3D shape and appearance modeling techniques. These in-\nclude classic shape-from-X techniques such as shape from shading, shape from texture, and\nshape from focus (Section 12.1), as well as shape from smooth occluding contours (Sec-\ntion 11.2.1) and silhouettes (Section 12.5). An alternative to all of these passive computer\nvision techniques is to use active rangeﬁnding (Section 12.2), i.e., to project patterned light\nonto scenes and recover the 3D geometry through triangulation. Processing all of these 3D\nrepresentations often involves interpolating or simplifying the geometry (Section 12.3), or\nusing alternative representations such as surface point sets (Section 12.4).\nThe collection of techniques for going from one or more images to partial or full 3D\nmodels is often called image-based modeling or 3D photography. Section 12.6 examines\nthree more specialized application areas (architecture, faces, and human bodies), which can\nuse model-based reconstruction to ﬁt parameterized models to the sensed data. Section 12.7\nexamines the topic of appearance modeling, i.e., techniques for estimating the texture maps,\nalbedos, or even sometimes complete bi-directional reﬂectance distribution functions (BRDFs)\nthat describe the appearance of 3D surfaces.\nIn Chapter 13, we discuss the large number of image-based rendering techniques that\nhave been developed in the last two decades, including simpler techniques such as view in-\nterpolation (Section 13.1), layered depth images (Section 13.2), and sprites and layers (Sec-\ntion 13.2.1), as well as the more general framework of light ﬁelds and Lumigraphs (Sec-\ntion 13.3) and higher-order ﬁelds such as environment mattes (Section 13.4). Applications of\nthese techniques include navigating 3D collections of photographs using photo tourism and\nviewing 3D models as object movies.\nIn Chapter 13, we also discuss video-based rendering, which is the temporal extension of\nimage-based rendering. The topics we cover include video-based animation (Section 13.5.1),\nperiodic video turned into video textures (Section 13.5.2), and 3D video constructed from\nmultiple video streams (Section 13.5.4). Applications of these techniques include video de-\nnoising, morphing, and tours based on 360◦video.\n26\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWeek\nMaterial\nProject\n(1.)\nChapter 2 Image formation\n2.\nChapter 3 Image processing\n3.\nChapter 4 Feature detection and matching\nP1\n4.\nChapter 6 Feature-based alignment\n5.\nChapter 9 Image stitching\nP2\n6.\nChapter 8 Dense motion estimation\n7.\nChapter 7 Structure from motion\nPP\n8.\nChapter 14 Recognition\n(9.)\nChapter 10 Computational photography\n10.\nChapter 11 Stereo correspondence\n(11.)\nChapter 12 3D reconstruction\n12.\nChapter 13 Image-based rendering\n13.\nFinal project presentations\nFP\nTable 1.1 Sample syllabi for 10-week and 13-week courses. The weeks in parentheses are\nnot used in the shorter version. P1 and P2 are two early-term mini-projects, PP is when the\n(student-selected) ﬁnal project proposals are due, and FP is the ﬁnal project presentations.\nChapter 14 describes different approaches to recognition. It begins with techniques for\ndetecting and recognizing faces (Sections 14.1 and 14.2), then looks at techniques for ﬁnding\nand recognizing particular objects (instance recognition) in Section 14.3. Next, we cover the\nmost difﬁcult variant of recognition, namely the recognition of broad categories, such as cars,\nmotorcycles, horses and other animals (Section 14.4), and the role that scene context plays in\nrecognition (Section 14.5).\nTo support the book’s use as a textbook, the appendices and associated Web site contain\nmore detailed mathematical topics and additional material. Appendix A covers linear algebra\nand numerical techniques, including matrix algebra, least squares, and iterative techniques.\nAppendix B covers Bayesian estimation theory, including maximum likelihood estimation,\nrobust statistics, Markov random ﬁelds, and uncertainty modeling. Appendix C describes the\nsupplementary material available to complement this book, including images and data sets,\npointers to software, course slides, and an on-line bibliography.\n1.4 Sample syllabus\nTeaching all of the material covered in this book in a single quarter or semester course is a\nHerculean task and likely one not worth attempting. It is better to simply pick and choose",
  "image_path": "page_047.jpg",
  "pages": [
    46,
    47,
    48
  ]
}