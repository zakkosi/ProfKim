{
  "doc_id": "pages_421_423",
  "text": "8.2 Parametric motion\n399\nThe parametric incremental motion update rule now becomes\nELK−PM(p + ∆p)\n=\nX\ni\n[I1(x′(xi; p + ∆p)) −I0(xi)]2\n(8.49)\n≈\nX\ni\n[I1(x′\ni) + J1(x′\ni)∆p −I0(xi)]2\n(8.50)\n=\nX\ni\n[J1(x′\ni)∆p + ei]2,\n(8.51)\nwhere the Jacobian is now\nJ1(x′\ni) = ∂I1\n∂p = ∇I1(x′\ni)∂x′\n∂p (xi),\n(8.52)\ni.e., the product of the image gradient ∇I1 with the Jacobian of the correspondence ﬁeld,\nJx′ = ∂x′/∂p.\nThe motion Jacobians Jx′ for the 2D planar transformations introduced in Section 2.1.2\nand Table 2.1 are given in Table 6.1. Note how we have re-parameterized the motion matrices\nso that they are always the identity at the origin p = 0. This becomes useful later, when we\ntalk about the compositional and inverse compositional algorithms. (It also makes it easier to\nimpose priors on the motions.)\nFor parametric motion, the (Gauss–Newton) Hessian and gradient-weighted residual vec-\ntor become\nA =\nX\ni\nJTx′(xi)[∇IT\n1 (x′\ni)∇I1(x′\ni)]Jx′(xi)\n(8.53)\nand\nb = −\nX\ni\nJTx′(xi)[ei∇IT\n1 (x′\ni)].\n(8.54)\nNote how the expressions inside the square brackets are the same ones evaluated for the\nsimpler translational motion case (8.40–8.41).\nPatch-based approximation.\nThe computation of the Hessian and residual vectors for\nparametric motion can be signiﬁcantly more expensive than for the translational case. For\nparametric motion with n parameters and N pixels, the accumulation of A and b takes\nO(n2N) operations (Baker and Matthews 2004). One way to reduce this by a signiﬁcant\namount is to divide the image up into smaller sub-blocks (patches) Pj and to only accumulate\nthe simpler 2 × 2 quantities inside the square brackets at the pixel level (Shum and Szeliski\n2000),\nAj\n=\nX\ni∈Pj\n∇IT\n1 (x′\ni)∇I1(x′\ni)\n(8.55)\nbj\n=\nX\ni∈Pj\nei∇IT\n1 (x′\ni).\n(8.56)\n400\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nThe full Hessian and residual can then be approximated as\nA ≈\nX\nj\nJTx′(ˆxj)[\nX\ni∈Pj\n∇IT\n1 (x′\ni)∇I1(x′\ni)]Jx′(ˆxj) =\nX\nj\nJTx′(ˆxj)AjJx′(ˆxj)\n(8.57)\nand\nb ≈−\nX\nj\nJTx′(ˆxj)[\nX\ni∈Pj\nei∇IT\n1 (x′\ni)] = −\nX\nj\nJTx′(ˆxj)bj,\n(8.58)\nwhere ˆxj is the center of each patch Pj (Shum and Szeliski 2000). This is equivalent to\nreplacing the true motion Jacobian with a piecewise-constant approximation. In practice,\nthis works quite well. The relationship of this approximation to feature-based registration is\ndiscussed in Section 9.2.4.\nCompositional approach.\nFor a complex parametric motion such as a homography, the\ncomputation of the motion Jacobian becomes complicated and may involve a per-pixel divi-\nsion. Szeliski and Shum (1997) observed that this can be simpliﬁed by ﬁrst warping the target\nimage I1 according to the current motion estimate x′(x; p),\n˜I1(x) = I1(x′(x; p)),\n(8.59)\nand then comparing this warped image against the template I0(x),\nELK−SS(∆p)\n=\nX\ni\n[˜I1(˜x(xi; ∆p)) −I0(xi)]2\n(8.60)\n≈\nX\ni\n[ ˜J1(xi)∆p + ei]2\n(8.61)\n=\nX\ni\n[∇˜I1(xi)J ˜x(xi)∆p + ei]2.\n(8.62)\nNote that since the two images are assumed to be fairly similar, only an incremental para-\nmetric motion is required, i.e., the incremental motion can be evaluated around p = 0, which\ncan lead to considerable simpliﬁcations. For example, the Jacobian of the planar projective\ntransform (6.19) now becomes\nJ ˜x = ∂˜x\n∂p\n\f\f\f\fp=0\n=\n\"\nx\ny\n1\n0\n0\n0\n−x2\n−xy\n0\n0\n0\nx\ny\n1\n−xy\n−y2\n#\n.\n(8.63)\nOnce the incremental motion ˜x has been computed, it can be prepended to the previously\nestimated motion, which is easy to do for motions represented with transformation matrices,\nsuch as those given in Tables 2.1 and 6.1. Baker and Matthews (2004) call this the forward\ncompositional algorithm, since the target image is being re-warped and the ﬁnal motion esti-\nmates are being composed.\n8.2 Parametric motion\n401\nIf the appearance of the warped and template images is similar enough, we can replace\nthe gradient of ˜I1(x) with the gradient of I0(x), as suggested previously (8.43). This has po-\ntentially a big advantage in that it allows the pre-computation (and inversion) of the Hessian\nmatrix A given in Equation (8.53). The residual vector b (8.54) can also be partially precom-\nputed, i.e., the steepest descent images ∇I0(x)J ˜x(x) can precomputed and stored for later\nmultiplication with the e(x) = ˜I1(x)−I0(x) error images (Baker and Matthews 2004). This\nidea was ﬁrst suggested by Hager and Belhumeur (1998) in what Baker and Matthews (2004)\ncall a inverse additive scheme.\nBaker and Matthews (2004) introduce one more variant they call the inverse composi-\ntional algorithm. Rather than (conceptually) re-warping the warped target image ˜I1(x), they\ninstead warp the template image I0(x) and minimize\nELK−BM(∆p)\n=\nX\ni\n[˜I1(xi) −I0(˜x(xi; ∆p))]2\n(8.64)\n≈\nX\ni\n[∇I0(xi)J ˜x(xi)∆p −ei]2.\n(8.65)\nThis is identical to the forward warped algorithm (8.62) with the gradients ∇˜I1(x) replaced\nby the gradients ∇I0(x), except for the sign of ei. The resulting update ∆p is the negative of\nthe one computed by the modiﬁed Equation (8.62) and hence the inverse of the incremental\ntransformation must be prepended to the current transform. Because the inverse composi-\ntional algorithm has the potential of pre-computing the inverse Hessian and the steepest de-\nscent images, this makes it the preferred approach of those surveyed by Baker and Matthews\n(2004). Figure 8.5 (Baker, Gross, Ishikawa et al. 2003) beautifully shows all of the steps\nrequired to implement the inverse compositional algorithm.\nBaker and Matthews (2004) also discuss the advantage of using Gauss–Newton iteration\n(i.e., the ﬁrst-order expansion of the least squares, as above) compared to other approaches\nsuch as steepest descent and Levenberg–Marquardt. Subsequent parts of the series (Baker,\nGross, Ishikawa et al. 2003; Baker, Gross, and Matthews 2003, 2004) discuss more advanced\ntopics such as per-pixel weighting, pixel selection for efﬁciency, a more in-depth discussion of\nrobust metrics and algorithms, linear appearance variations, and priors on parameters. They\nmake for invaluable reading for anyone interested in implementing a highly tuned imple-\nmentation of incremental image registration. Evangelidis and Psarakis (2008) provide some\ndetailed experimental evaluations of these and other related approaches.\n8.2.1 Application: Video stabilization\nVideo stabilization is one of the most widely used applications of parametric motion esti-\nmation (Hansen, Anandan, Dana et al. 1994; Irani, Rousso, and Peleg 1997; Morimoto and",
  "image_path": "page_422.jpg",
  "pages": [
    421,
    422,
    423
  ]
}