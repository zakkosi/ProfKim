{
  "doc_id": "pages_476_478",
  "text": "454\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 9.14\nFinal composites computed by a variety of algorithms (Szeliski 2006a): (a)\naverage, (b) median, (c) feathered average, (d) p-norm p = 10, (e) Voronoi, (f) weighted\nROD vertex cover with feathering, (g) graph cut seams with Poisson blending and (h) with\npyramid blending.\n9.3 Compositing\n455\nAgrawala et al. 2004) can sometimes be used to retain multiple copies of a moving object\n(Figure 9.17).\nA better approach to averaging is to weight pixels near the center of the image more\nheavily and to down-weight pixels near the edges. When an image has some cutout regions,\ndown-weighting pixels near the edges of both cutouts and the image is preferable. This can\nbe done by computing a distance map or grassﬁre transform,\nwk(x) = arg min\ny {∥y∥| ˜Ik(x + y) is invalid },\n(9.38)\nwhere each valid pixel is tagged with its Euclidean distance to the nearest invalid pixel (Sec-\ntion 3.3.3). The Euclidean distance map can be efﬁciently computed using a two-pass raster\nalgorithm (Danielsson 1980; Borgefors 1986).\nWeighted averaging with a distance map is often called feathering (Szeliski and Shum\n1997; Chen and Klette 1999; Uyttendaele, Eden, and Szeliski 2001) and does a reasonable job\nof blending over exposure differences. However, blurring and ghosting can still be problems\n(Figure 9.14c). Note that weighted averaging is not the same as compositing the individual\nimages with the classic over operation (Porter and Duff 1984; Blinn 1994a), even when using\nthe weight values (normalized to sum up to one) as alpha (translucency) channels. This is\nbecause the over operation attenuates the values from more distant surfaces and, hence, is not\nequivalent to a direct sum.\nOne way to improve feathering is to raise the distance map values to some large power,\ni.e., to use wp\nk(x) in Equation (9.37). The weighted averages then become dominated by\nthe larger values, i.e., they act somewhat like a p-norm. The resulting composite can often\nprovide a reasonable tradeoff between visible exposure differences and blur (Figure 9.14d).\nIn the limit as p →∞, only the pixel with the maximum weight is selected,\nC(x) = ˜Il(x)(x),\n(9.39)\nwhere\nl = arg max\nk\nwk(x)\n(9.40)\nis the label assignment or pixel selection function that selects which image to use at each\npixel. This hard pixel selection process produces a visibility mask-sensitive variant of the fa-\nmiliar Voronoi diagram, which assigns each pixel to the nearest image center in the set (Wood,\nFinkelstein, Hughes et al. 1997; Peleg, Rousso, Rav-Acha et al. 2000). The resulting com-\nposite, while useful for artistic guidance and in high-overlap panoramas (manifold mosaics)\ntends to have very hard edges with noticeable seams when the exposures vary (Figure 9.14e).\nXiong and Turkowski (1998) use this Voronoi idea (local maximum of the grassﬁre trans-\nform) to select seams for Laplacian pyramid blending (which is discussed below). However,\n456\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.15\nComputation of regions of difference (RODs) (Uyttendaele, Eden, and Szeliski\n2001) c⃝2001 IEEE: (a) three overlapping images with a moving face; (b) corresponding\nRODs; (c) graph of coincident RODs.\nsince the seam selection is performed sequentially as new images are added in, some artifacts\ncan occur.\nOptimal seam selection.\nComputing the Voronoi diagram is one way to select the seams\nbetween regions where different images contribute to the ﬁnal composite. However, Voronoi\nimages totally ignore the local image structure underlying the seam.\nA better approach is to place the seams in regions where the images agree, so that tran-\nsitions from one source to another are not visible. In this way, the algorithm avoids “cutting\nthrough” moving objects where a seam would look unnatural (Davis 1998). For a pair of\nimages, this process can be formulated as a simple dynamic program starting from one edge\nof the overlap region and ending at the other (Milgram 1975, 1977; Davis 1998; Efros and\nFreeman 2001).\nWhen multiple images are being composited, the dynamic program idea does not readily\ngeneralize. (For square texture tiles being composited sequentially, Efros and Freeman (2001)\nrun a dynamic program along each of the four tile sides.)\nTo overcome this problem, Uyttendaele, Eden, and Szeliski (2001) observed that, for\nwell-registered images, moving objects produce the most visible artifacts, namely translu-\ncent looking ghosts. Their system therefore decides which objects to keep and which ones\nto erase. First, the algorithm compares all overlapping input image pairs to determine re-\ngions of difference (RODs) where the images disagree. Next, a graph is constructed with the\nRODs as vertices and edges representing ROD pairs that overlap in the ﬁnal composite (Fig-\nure 9.15). Since the presence of an edge indicates an area of disagreement, vertices (regions)\nmust be removed from the ﬁnal composite until no edge spans a pair of remaining vertices.\nThe smallest such set can be computed using a vertex cover algorithm. Since several such\ncovers may exist, a weighted vertex cover is used instead, where the vertex weights are com-\nputed by summing the feather weights in the ROD (Uyttendaele, Eden, and Szeliski 2001).\nThe algorithm therefore prefers removing regions that are near the edge of the image, which\nreduces the likelihood that partially visible objects will appear in the ﬁnal composite. (It is",
  "image_path": "page_477.jpg",
  "pages": [
    476,
    477,
    478
  ]
}