{
  "doc_id": "pages_705_707",
  "text": "14.2 Face recognition\n683\nFigure 14.23\nMultiresolution model ﬁtting (search) in active appearance models (Cootes,\nEdwards, and Taylor 2001) c⃝2001 IEEE. The columns show the initial model, the results\nafter 3, 8, and 11 iterations, and the ﬁnal convergence. The rightmost column shows the input\nimage.\nrecognition (Penev and Atick 1996; Wiskott, Fellous, Kr¨uger et al. 1997; Ahonen, Hadid,\nand Pietik¨ainen 2006; Zhao and Pietik¨ainen 2007; Cao, Yin, Tang et al. 2010) can be used.\nAAMs (or, actually, their simpler version, Active Shape Models (ASMs)) can also be used to\nalign face images to perform automated morphing (Zanella and Fuentes 2004).\nActive appearance models continue to be an active research area, with enhancements to\ndeal with illumination and viewpoint variation (Gross, Baker, Matthews et al. 2005) as well\nas occlusions (Gross, Matthews, and Baker 2006). One of the most signiﬁcant extensions is\nto construct 3D models of shape (Matthews, Xiao, and Baker 2007), which are much better at\ncapturing and explaining the full variability of facial appearance across wide changes in pose.\nFigure 14.24\nHead tracking with 3D AAMs (Matthews, Xiao, and Baker 2007) c⃝2007\nSpringer. Each image shows a video frame along with the estimate yaw, pitch, and roll\nparameters and the ﬁtted 3D deformable mesh.\n684\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 14.25\nPerson detection and re-recognition using a combined face, hair, and torso\nmodel (Sivic, Zitnick, and Szeliski 2006) c⃝2006 Springer. (a) Using face detection alone,\nseveral of the heads are missed. (b) The combined face and clothing model successfully\nre-ﬁnds all the people.\nSuch models can be constructed either from monocular video sequences (Matthews, Xiao,\nand Baker 2007), as shown in Figure 14.24, or from multi-view video sequences (Ramnath,\nKoterba, Xiao et al. 2008), which provide even greater reliability and accuracy in reconstruc-\ntion and tracking. (For a recent review of progress in head pose estimation, please see the\nsurvey paper by Murphy-Chutorian and Trivedi (2009).)\n14.2.3 Application: Personal photo collections\nIn addition to digital cameras automatically ﬁnding faces to aid in auto-focusing and video\ncameras ﬁnding faces in video conferencing to center on the speaker (either mechanically\nor digitally), face detection has found its way into most consumer-level photo organization\npackages, such as iPhoto, Picasa, and Windows Live Photo Gallery. Finding faces and al-\nlowing users to tag them makes it easier to ﬁnd photos of selected people at a later date or to\nautomatically share them with friends. In fact, the ability to tag friends in photos is one of the\nmore popular features on Facebook.\nSometimes, however, faces can be hard to ﬁnd and recognize, especially if they are small,\n14.3 Instance recognition\n685\nFigure 14.26 Recognizing objects in a cluttered scene (Lowe 2004) c⃝2004 Springer. Two\nof the training images in the database are shown on the left. They are matched to the cluttered\nscene in the middle using SIFT features, shown as small squares in the right image. The afﬁne\nwarp of each recognized database image onto the scene is shown as a larger parallelogram in\nthe right image.\nturned away from the camera, or otherwise occluded. In such cases, combining face recog-\nnition with person detection and clothes recognition can be very effective, as illustrated in\nFigure 14.25 (Sivic, Zitnick, and Szeliski 2006). Combining person recognition with other\nkinds of context, such as location recognition (Section 14.3.3) or activity or event recognition,\ncan also help boost performance (Lin, Kapoor, Hua et al. 2010).\n14.3 Instance recognition\nGeneral object recognition falls into two broad categories, namely instance recognition and\nclass recognition. The former involves re-recognizing a known 2D or 3D rigid object, poten-\ntially being viewed from a novel viewpoint, against a cluttered background, and with partial\nocclusions. The latter, which is also known as category-level or generic object recognition\n(Ponce, Hebert, Schmid et al. 2006), is the much more challenging problem of recognizing\nany instance of a particular general class such as “cat”, “car”, or “bicycle”.\nOver the years, many different algorithms have been developed for instance recognition.\nMundy (2006) surveys earlier approaches, which focused on extracting lines, contours, or\n3D surfaces from images and matching them to known 3D object models. Another popu-\nlar approach was to acquire images from a large set of viewpoints and illuminations and to\nrepresent them using an eigenspace decomposition (Murase and Nayar 1995). More recent\napproaches (Lowe 2004; Rothganger, Lazebnik, Schmid et al. 2006; Ferrari, Tuytelaars, and\nVan Gool 2006b; Gordon and Lowe 2006; Obdrˇz´alek and Matas 2006; Sivic and Zisserman\n2009) tend to use viewpoint-invariant 2D features, such as those we saw in Section 4.1.2. Af-",
  "image_path": "page_706.jpg",
  "pages": [
    705,
    706,
    707
  ]
}