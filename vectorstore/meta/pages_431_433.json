{
  "doc_id": "pages_431_433",
  "text": "8.4 Optical ﬂow\n409\n(a)\n(b)\n(c)\nFigure 8.11 Octree spline-based image registration of two vertebral surface models (Szeliski\nand Lavall´ee 1996) c⃝1996 Springer: (a) after initial rigid alignment; (b) after elastic align-\nment; (c) a cross-section through the adapted octree spline deformation ﬁeld.\nmatic mode but more accurate results can be obtained by locating a few key landmarks. More\nrecent papers on deformable medical image registration, including performance evaluations,\ninclude (Klein, Staring, and Pluim 2007; Glocker, Komodakis, Tziritas et al. 2008).\nAs with other applications, regular volumetric splines can be enhanced using selective\nreﬁnement. In the case of 3D volumetric image or surface registration, these are known as\noctree splines (Szeliski and Lavall´ee 1996) and have been used to register medical surface\nmodels such as vertebrae and faces from different patients (Figure 8.11).\n8.4 Optical ﬂow\nThe most general (and challenging) version of motion estimation is to compute an indepen-\ndent estimate of motion at each pixel, which is generally known as optical (or optic) ﬂow. As\nwe mentioned in the previous section, this generally involves minimizing the brightness or\ncolor difference between corresponding pixels summed over the image,\nESSD−OF({ui}) =\nX\ni\n[I1(xi + ui) −I0(xi)]2.\n(8.69)\nSince the number of variables {ui} is twice the number of measurements, the problem is\nunderconstrained. The two classic approaches to this problem are to perform the summa-\ntion locally over overlapping regions (the patch-based or window-based approach) or to\nadd smoothness terms on the {ui} ﬁeld using regularization or Markov random ﬁelds (Sec-\ntion 3.7) and to search for a global minimum.\nThe patch-based approach usually involves using a Taylor series expansion of the dis-\nplaced image function (8.35) in order to obtain sub-pixel estimates (Lucas and Kanade 1981).\n410\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nAnandan (1989) shows how a series of local discrete search steps can be interleaved with\nLucas–Kanade incremental reﬁnement steps in a coarse-to-ﬁne pyramid scheme, which al-\nlows the estimation of large motions, as described in Section 8.1.1. He also analyzes how the\nuncertainty in local motion estimates is related to the eigenvalues of the local Hessian matrix\nAi (8.44), as shown in Figures 8.3–8.4.\nBergen, Anandan, Hanna et al. (1992) develop a uniﬁed framework for describing both\nparametric (Section 8.2) and patch-based optic ﬂow algorithms and provide a nice introduc-\ntion to this topic. After each iteration of optic ﬂow estimation in a coarse-to-ﬁne pyramid,\nthey re-warp one of the images so that only incremental ﬂow estimates are computed (Sec-\ntion 8.1.1). When overlapping patches are used, an efﬁcient implementation is to ﬁrst com-\npute the outer products of the gradients and intensity errors (8.40–8.41) at every pixel and\nthen perform the overlapping window sums using a moving average ﬁlter.11\nInstead of solving for each motion (or motion update) independently, Horn and Schunck\n(1981) develop a regularization-based framework where (8.69) is simultaneously minimized\nover all ﬂow vectors {ui}. In order to constrain the problem, smoothness constraints, i.e.,\nsquared penalties on ﬂow derivatives, are added to the basic per-pixel error metric. Because\nthe technique was originally developed for small motions in a variational (continuous func-\ntion) framework, the linearized brightness constancy constraint corresponding to (8.35), i.e.,\n(8.38), is more commonly written as an analytic integral\nEHS =\nZ\n(Ixu + Iyv + It)2 dx dy,\n(8.70)\nwhere (Ix, Iy) = ∇I1 = J1 and It = ei is the temporal derivative, i.e., the brightness\nchange between images. The Horn and Schunck model can also be viewed as the limiting\ncase of spline-based motion estimation as the splines become 1x1 pixel patches.\nIt is also possible to combine ideas from local and global ﬂow estimation into a single\nframework by using a locally aggregated (as opposed to single-pixel) Hessian as the bright-\nness constancy term (Bruhn, Weickert, and Schn¨orr 2005). Consider the discrete analog\n(8.35) to the analytic global energy (8.70),\nEHSD =\nX\ni\nuT\ni [JiJT\ni ]ui + 2eiJT\ni ui + e2\ni .\n(8.71)\nIf we replace the per-pixel (rank 1) Hessians Ai = [JiJT\ni ] and residuals bi = Jiei with area-\naggregated versions (8.40–8.41), we obtain a global minimization algorithm where region-\nbased brightness constraints are used.\nAnother extension to the basic optic ﬂow model is to use a combination of global (para-\nmetric) and local motion models. For example, if we know that the motion is due to a camera\n11Other smoothing or aggregation ﬁlters can also be used at this stage (Bruhn, Weickert, and Schn¨orr 2005).\n8.4 Optical ﬂow\n411\nmoving in a static scene (rigid motion), we can re-formulate the problem as the estimation of\na per-pixel depth along with the parameters of the global camera motion (Adiv 1989; Hanna\n1991; Bergen, Anandan, Hanna et al. 1992; Szeliski and Coughlan 1997; Nir, Bruckstein,\nand Kimmel 2008; Wedel, Cremers, Pock et al. 2009). Such techniques are closely related to\nstereo matching (Chapter 11). Alternatively, we can estimate either per-image or per-segment\nafﬁne motion models combined with per-pixel residual corrections (Black and Jepson 1996;\nJu, Black, and Jepson 1996; Chang, Tekalp, and Sezan 1997; M´emin and P´erez 2002). We\nrevisit this topic in Section 8.5.\nOf course, image brightness may not always be an appropriate metric for measuring ap-\npearance consistency, e.g., when the lighting in an image is varying. As discussed in Sec-\ntion 8.1, matching gradients, ﬁltered images, or other metrics such as image Hessians (sec-\nond derivative measures) may be more appropriate. It is also possible to locally compute the\nphase of steerable ﬁlters in the image, which is insensitive to both bias and gain transforma-\ntions (Fleet and Jepson 1990). Papenberg, Bruhn, Brox et al. (2006) review and explore such\nconstraints and also provide a detailed analysis and justiﬁcation for iteratively re-warping\nimages during incremental ﬂow computation.\nBecause the brightness constancy constraint is evaluated at each pixel independently,\nrather than being summed over patches where the constant ﬂow assumption may be violated,\nglobal optimization approaches tend to perform better near motion discontinuities. This is\nespecially true if robust metrics are used in the smoothness constraint (Black and Anandan\n1996; Bab-Hadiashar and Suter 1998a).12 One popular choice for robust metrics in the L1\nnorm, also known as total variation (TV), which results in a convex energy whose global\nminimum can be found (Bruhn, Weickert, and Schn¨orr 2005; Papenberg, Bruhn, Brox et\nal. 2006). Anisotropic smoothness priors, which apply a different smoothness in the direc-\ntions parallel and perpendicular to the image gradient, are another popular choice (Nagel and\nEnkelmann 1986; Sun, Roth, Lewis et al. 2008; Werlberger, Trobin, Pock et al. 2009). It\nis also possible to learn a set of better smoothness constraints (derivative ﬁlters and robust\nfunctions) from a set of paired ﬂow and intensity images (Sun, Roth, Lewis et al. 2008). Ad-\nditional details on some of these techniques are given by Baker, Black, Lewis et al. (2007)\nand Baker, Scharstein, Lewis et al. (2009).\nBecause of the large, two-dimensional search space in estimating ﬂow, most algorithms\nuse variations of gradient descent and coarse-to-ﬁne continuation methods to minimize the\nglobal energy function. This contrasts starkly with stereo matching (which is an “easier”\none-dimensional disparity estimation problem), where combinatorial optimization techniques\nhave been the method of choice for the last decade.\nFortunately, combinatorial optimization methods based on Markov random ﬁelds are be-\n12 Robust brightness metrics (Section 8.1, (8.2)) can also help improve the performance of window-based ap-\nproaches (Black and Anandan 1996).",
  "image_path": "page_432.jpg",
  "pages": [
    431,
    432,
    433
  ]
}