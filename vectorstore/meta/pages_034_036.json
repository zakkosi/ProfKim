{
  "doc_id": "pages_034_036",
  "text": "12\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.7\nSome early (1970s) examples of computer vision algorithms: (a) line label-\ning (Nalwa 1993) c⃝1993 Addison-Wesley, (b) pictorial structures (Fischler and Elschlager\n1973) c⃝1973 IEEE, (c) articulated body model (Marr 1982) c⃝1982 David Marr, (d) intrin-\nsic images (Barrow and Tenenbaum 1981) c⃝1973 IEEE, (e) stereo correspondence (Marr\n1982) c⃝1982 David Marr, (f) optical ﬂow (Nagel and Enkelmann 1986) c⃝1986 IEEE.\nan active area of research; a nice survey of contemporaneous work can be found in (Davis\n1975).\nThree-dimensional modeling of non-polyhedral objects was also being studied (Baum-\ngart 1974; Baker 1977). One popular approach used generalized cylinders, i.e., solids of\nrevolution and swept closed curves (Agin and Binford 1976; Nevatia and Binford 1977), of-\nten arranged into parts relationships7 (Hinton 1977; Marr 1982) (Figure 1.7c). Fischler and\nElschlager (1973) called such elastic arrangements of parts pictorial structures (Figure 1.7b).\nThis is currently one of the favored approaches being used in object recognition (see Sec-\ntion 14.4 and Felzenszwalb and Huttenlocher 2005).\nA qualitative approach to understanding intensities and shading variations and explaining\nthem by the effects of image formation phenomena, such as surface orientation and shadows,\nwas championed by Barrow and Tenenbaum (1981) in their paper on intrinsic images (Fig-\nure 1.7d), along with the related 2 1/2 -D sketch ideas of Marr (1982). This approach is again\nseeing a bit of a revival in the work of Tappen, Freeman, and Adelson (2005).\nMore quantitative approaches to computer vision were also developed at the time, in-\ncluding the ﬁrst of many feature-based stereo correspondence algorithms (Figure 1.7e) (Dev\n7 In robotics and computer animation, these linked-part graphs are often called kinematic chains.\n1.2 A brief history\n13\n1974; Marr and Poggio 1976; Moravec 1977; Marr and Poggio 1979; Mayhew and Frisby\n1981; Baker 1982; Barnard and Fischler 1982; Ohta and Kanade 1985; Grimson 1985; Pol-\nlard, Mayhew, and Frisby 1985; Prazdny 1985) and intensity-based optical ﬂow algorithms\n(Figure 1.7f) (Horn and Schunck 1981; Huang 1981; Lucas and Kanade 1981; Nagel 1986).\nThe early work in simultaneously recovering 3D structure and camera motion (see Chapter 7)\nalso began around this time (Ullman 1979; Longuet-Higgins 1981).\nA lot of the philosophy of how vision was believed to work at the time is summarized\nin David Marr’s (1982) book.8 In particular, Marr introduced his notion of the three levels\nof description of a (visual) information processing system. These three levels, very loosely\nparaphrased according to my own interpretation, are:\n• Computational theory: What is the goal of the computation (task) and what are the\nconstraints that are known or can be brought to bear on the problem?\n• Representations and algorithms: How are the input, output, and intermediate infor-\nmation represented and which algorithms are used to calculate the desired result?\n• Hardware implementation: How are the representations and algorithms mapped onto\nactual hardware, e.g., a biological vision system or a specialized piece of silicon? Con-\nversely, how can hardware constraints be used to guide the choice of representation\nand algorithm? With the increasing use of graphics chips (GPUs) and many-core ar-\nchitectures for computer vision (see Section C.2), this question is again becoming quite\nrelevant.\nAs I mentioned earlier in this introduction, it is my conviction that a careful analysis of the\nproblem speciﬁcation and known constraints from image formation and priors (the scientiﬁc\nand statistical approaches) must be married with efﬁcient and robust algorithms (the engineer-\ning approach) to design successful vision algorithms. Thus, it seems that Marr’s philosophy\nis as good a guide to framing and solving problems in our ﬁeld today as it was 25 years ago.\n1980s.\nIn the 1980s, a lot of attention was focused on more sophisticated mathematical\ntechniques for performing quantitative image and scene analysis.\nImage pyramids (see Section 3.5) started being widely used to perform tasks such as im-\nage blending (Figure 1.8a) and coarse-to-ﬁne correspondence search (Rosenfeld 1980; Burt\nand Adelson 1983a,b; Rosenfeld 1984; Quam 1984; Anandan 1989). Continuous versions\nof pyramids using the concept of scale-space processing were also developed (Witkin 1983;\nWitkin, Terzopoulos, and Kass 1986; Lindeberg 1990). In the late 1980s, wavelets (see Sec-\ntion 3.5.4) started displacing or augmenting regular image pyramids in some applications\n8 More recent developments in visual perception theory are covered in (Palmer 1999; Livingstone 2008).\n14\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.8 Examples of computer vision algorithms from the 1980s: (a) pyramid blending\n(Burt and Adelson 1983b) c⃝1983 ACM, (b) shape from shading (Freeman and Adelson\n1991) c⃝1991 IEEE, (c) edge detection (Freeman and Adelson 1991) c⃝1991 IEEE, (d)\nphysically based models (Terzopoulos and Witkin 1988) c⃝1988 IEEE, (e) regularization-\nbased surface reconstruction (Terzopoulos 1988) c⃝1988 IEEE, (f) range data acquisition\nand merging (Banno, Masuda, Oishi et al. 2008) c⃝2008 Springer.\n(Adelson, Simoncelli, and Hingorani 1987; Mallat 1989; Simoncelli and Adelson 1990a,b;\nSimoncelli, Freeman, Adelson et al. 1992).\nThe use of stereo as a quantitative shape cue was extended by a wide variety of shape-\nfrom-X techniques, including shape from shading (Figure 1.8b) (see Section 12.1.1 and Horn\n1975; Pentland 1984; Blake, Zimmerman, and Knowles 1985; Horn and Brooks 1986, 1989),\nphotometric stereo (see Section 12.1.1 and Woodham 1981), shape from texture (see Sec-\ntion 12.1.2 and Witkin 1981; Pentland 1984; Malik and Rosenholtz 1997), and shape from\nfocus (see Section 12.1.3 and Nayar, Watanabe, and Noguchi 1995). Horn (1986) has a nice\ndiscussion of most of these techniques.\nResearch into better edge and contour detection (Figure 1.8c) (see Section 4.2) was also\nactive during this period (Canny 1986; Nalwa and Binford 1986), including the introduc-\ntion of dynamically evolving contour trackers (Section 5.1.1) such as snakes (Kass, Witkin,\nand Terzopoulos 1988), as well as three-dimensional physically based models (Figure 1.8d)\n(Terzopoulos, Witkin, and Kass 1987; Kass, Witkin, and Terzopoulos 1988; Terzopoulos and\nFleischer 1988; Terzopoulos, Witkin, and Kass 1988).\nResearchers noticed that a lot of the stereo, ﬂow, shape-from-X, and edge detection al-",
  "image_path": "page_035.jpg",
  "pages": [
    34,
    35,
    36
  ]
}