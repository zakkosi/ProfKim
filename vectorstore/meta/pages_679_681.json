{
  "doc_id": "pages_679_681",
  "text": "14 Recognition\n657\nOf all the visual tasks we might ask a computer to perform, analyzing a scene and recog-\nnizing all of the constituent objects remains the most challenging. While computers excel at\naccurately reconstructing the 3D shape of a scene from images taken from different views,\nthey cannot name all the objects and animals present in a picture, even at the level of a two-\nyear-old child. There is not even any consensus among researchers on when this level of\nperformance might be achieved.\nWhy is recognition so hard? The real world is made of a jumble of objects, which all oc-\nclude one another and appear in different poses. Furthermore, the variability intrinsic within\na class (e.g., dogs), due to complex non-rigid articulation and extreme variations in shape and\nappearance (e.g., between different breeds), makes it unlikely that we can simply perform\nexhaustive matching against a database of exemplars.1\nThe recognition problem can be broken down along several axes. For example, if we\nknow what we are looking for, the problem is one of object detection (Section 14.1), which\ninvolves quickly scanning an image to determine where a match may occur (Figure 14.1c). If\nwe have a speciﬁc rigid object we are trying to recognize (instance recognition, Section 14.3),\nwe can search for characteristic feature points (Section 4.1) and verify that they align in a\ngeometrically plausible way (Section 14.3.1) (Figure 14.1d).\nThe most challenging version of recognition is general category (or class) recognition\n(Section 14.4), which may involve recognizing instances of extremely varied classes such\nas animals or furniture. Some techniques rely purely on the presence of features (known\nas a “bag of words” model—see Section 14.4.1), their relative positions (part-based models\n(Section 14.4.2)), Figure 14.1e, while others involve segmenting the image into semantically\nmeaningful regions (Section 14.4.3) (Figure 14.1f). In many instances, recognition depends\nheavily on the context of surrounding objects and scene elements (Section 14.5). Woven into\nall of these techniques is the topic of learning (Section 14.5.1), since hand-crafting speciﬁc\nobject recognizers seems like a futile approach given the complexity of the problem.\nGiven the extremely rich and complex nature of this topic, this chapter is structured to\nbuild from simpler concepts to more complex ones. We begin with a discussion of face and\nobject detection (Section 14.1), where we introduce a number of machine-learning techniques\nsuch as boosting, neural networks, and support vector machines. Next, we study face recogni-\ntion (Section 14.2), which is one of the more widely known applications of recognition. This\ntopic serves as an introduction to subspace (PCA) models and Bayesian approaches to recog-\nnition and classiﬁcation. We then present techniques for instance recognition (Section 14.3),\nbuilding upon earlier topics in this book, such as feature detection, matching, and geomet-\nric alignment (Section 14.3.1). We introduce topics from the information and document re-\ntrieval communities, such as frequency vectors, feature quantization, and inverted indices\n1 However, some recent research suggests that direct image matching may be feasible for large enough databases\n(Russell, Torralba, Liu et al. 2007; Malisiewicz and Efros 2008; Torralba, Freeman, and Fergus 2008).\n658\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Section 14.3.2). We also present applications of location recognition (Section 14.3.3).\nIn the second half of the chapter, we address the most challenging variant of recognition,\nnamely the problem of category recognition (Section 14.4). This includes approaches that use\nbags of features (Section 14.4.1), parts (Section 14.4.2), and segmentation (Section 14.4.3).\nWe show how such techniques can be used to automate photo editing tasks, such as 3D mod-\neling, scene completion, and creating collages (Section 14.4.4). Next, we discuss the role\nthat context can play in both individual object recognition and more holistic scene under-\nstanding (Section 14.5). We close this chapter with a discussion of databases and test sets for\nconstructing and evaluating recognition systems (Section 14.6).\nWhile there is no comprehensive reference on object recognition, an excellent set of notes\ncan be found in the ICCV 2009 short course (Fei-Fei, Fergus, and Torralba 2009), Antonio\nTorralba’s more comprehensive MIT course (Torralba 2008), and two recent collections of\npapers (Ponce, Hebert, Schmid et al. 2006; Dickinson, Leonardis, Schiele et al. 2007) and a\nsurvey on object categorization (Pinz 2005). An evaluation of some of the best performing\nrecognition algorithms can be found on the PASCAL Visual Object Classes (VOC) Challenge\nWeb site at http://pascallin.ecs.soton.ac.uk/challenges/VOC/.\n14.1 Object detection\nIf we are given an image to analyze, such as the group portrait in Figure 14.2, we could try to\napply a recognition algorithm to every possible sub-window in this image. Such algorithms\nare likely to be both slow and error-prone. Instead, it is more effective to construct special-\npurpose detectors, whose job it is to rapidly ﬁnd likely regions where particular objects might\noccur.\nWe begin this section with face detectors, which are some of the more successful examples\nof recognition. For example, such algorithms are built into most of today’s digital cameras to\nenhance auto-focus and into video conferencing systems to control pan-tilt heads. We then\nlook at pedestrian detectors, as an example of more general methods for object detection.\nSuch detectors can be used in automotive safety applications, e.g., detecting pedestrians and\nother cars from moving vehicles (Leibe, Cornelis, Cornelis et al. 2007).\n14.1.1 Face detection\nBefore face recognition can be applied to a general image, the locations and sizes of any faces\nmust ﬁrst be found (Figures 14.1c and 14.2). In principle, we could apply a face recognition\nalgorithm at every pixel and scale (Moghaddam and Pentland 1997) but such a process would\nbe too slow in practice.\n14.1 Object detection\n659\nFigure 14.2\nFace detection results produced by Rowley, Baluja, and Kanade (1998a) c⃝\n1998 IEEE. Can you ﬁnd the one false positive (a box around a non-face) among the 57 true\npositive results?\nOver the years, a wide variety of fast face detection algorithms have been developed.\nYang, Kriegman, and Ahuja (2002) provide a comprehensive survey of earlier work in this\nﬁeld; Yang’s ICPR 2004 tutorial2 and the Torralba (2007) short course provide more recent\nreviews.3\nAccording to the taxonomy of Yang, Kriegman, and Ahuja (2002), face detection tech-\nniques can be classiﬁed as feature-based, template-based, or appearance-based. Feature-\nbased techniques attempt to ﬁnd the locations of distinctive image features such as the eyes,\nnose, and mouth, and then verify whether these features are in a plausible geometrical ar-\nrangement. These techniques include some of the early approaches to face recognition (Fis-\nchler and Elschlager 1973; Kanade 1977; Yuille 1991), as well as more recent approaches\nbased on modular eigenspaces (Moghaddam and Pentland 1997), local ﬁlter jets (Leung,\nBurl, and Perona 1995; Penev and Atick 1996; Wiskott, Fellous, Kr¨uger et al. 1997), support\nvector machines (Heisele, Ho, Wu et al. 2003; Heisele, Serre, and Poggio 2007), and boosting\n(Schneiderman and Kanade 2004).\nTemplate-based approaches, such as active appearance models (AAMs) (Section 14.2.2),\ncan deal with a wide range of pose and expression variability. Typically, they require good\ninitialization near a real face and are therefore not suitable as fast face detectors.\n2 http://vision.ai.uiuc.edu/mhyang/face-detection-survey.html.\n3 An alternative approach to detecting faces is to look for regions of skin color in the image (Forsyth and Fleck\n1999; Jones and Rehg 2001). See Exercise 2.8 for some additional discussion and references.",
  "image_path": "page_680.jpg",
  "pages": [
    679,
    680,
    681
  ]
}