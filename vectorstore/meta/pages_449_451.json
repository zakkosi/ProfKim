{
  "doc_id": "pages_449_451",
  "text": "Chapter 9\nImage stitching\n9.1\nMotion models\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430\n9.1.1\nPlanar perspective motion\n. . . . . . . . . . . . . . . . . . . . . . . 431\n9.1.2\nApplication: Whiteboard and document scanning . . . . . . . . . . . 432\n9.1.3\nRotational panoramas . . . . . . . . . . . . . . . . . . . . . . . . . . 433\n9.1.4\nGap closing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435\n9.1.5\nApplication: Video summarization and compression\n. . . . . . . . . 436\n9.1.6\nCylindrical and spherical coordinates\n. . . . . . . . . . . . . . . . . 438\n9.2\nGlobal alignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n9.2.1\nBundle adjustment . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n9.2.2\nParallax removal . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445\n9.2.3\nRecognizing panoramas\n. . . . . . . . . . . . . . . . . . . . . . . . 446\n9.2.4\nDirect vs. feature-based alignment . . . . . . . . . . . . . . . . . . . 450\n9.3\nCompositing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450\n9.3.1\nChoosing a compositing surface . . . . . . . . . . . . . . . . . . . . 451\n9.3.2\nPixel selection and weighting (de-ghosting) . . . . . . . . . . . . . . 453\n9.3.3\nApplication: Photomontage\n. . . . . . . . . . . . . . . . . . . . . . 459\n9.3.4\nBlending\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 459\n9.4\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462\n9.5\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463\n428\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 9.1\nImage stitching: (a) portion of a cylindrical panorama and (b) a spherical\npanorama constructed from 54 photographs (Szeliski and Shum 1997) c⃝1997 ACM; (c) a\nmulti-image panorama automatically assembled from an unordered photo collection; a multi-\nimage stitch (d) without and (e) with moving object removal (Uyttendaele, Eden, and Szeliski\n2001) c⃝2001 IEEE.\n9 Image stitching\n429\nAlgorithms for aligning images and stitching them into seamless photo-mosaics are among\nthe oldest and most widely used in computer vision (Milgram 1975; Peleg 1981). image\nstitching algorithms create the high-resolution photo-mosaics used to produce today’s digital\nmaps and satellite photos. They also come bundled with most digital cameras and can be used\nto create beautiful ultra wide-angle panoramas.\nimage stitching originated in the photogrammetry community, where more manually in-\ntensive methods based on surveyed ground control points or manually registered tie points\nhave long been used to register aerial photos into large-scale photo-mosaics (Slama 1980).\nOne of the key advances in this community was the development of bundle adjustment al-\ngorithms (Section 7.4), which could simultaneously solve for the locations of all of the cam-\nera positions, thus yielding globally consistent solutions (Triggs, McLauchlan, Hartley et al.\n1999). Another recurring problem in creating photo-mosaics is the elimination of visible\nseams, for which a variety of techniques have been developed over the years (Milgram 1975,\n1977; Peleg 1981; Davis 1998; Agarwala, Dontcheva, Agrawala et al. 2004)\nIn ﬁlm photography, special cameras were developed in the 1990s to take ultra-wide-\nangle panoramas, often by exposing the ﬁlm through a vertical slit as the camera rotated on its\naxis (Meehan 1990). In the mid-1990s, image alignment techniques started being applied to\nthe construction of wide-angle seamless panoramas from regular hand-held cameras (Mann\nand Picard 1994; Chen 1995; Szeliski 1996). More recent work in this area has addressed\nthe need to compute globally consistent alignments (Szeliski and Shum 1997; Sawhney and\nKumar 1999; Shum and Szeliski 2000), to remove “ghosts” due to parallax and object move-\nment (Davis 1998; Shum and Szeliski 2000; Uyttendaele, Eden, and Szeliski 2001; Agarwala,\nDontcheva, Agrawala et al. 2004), and to deal with varying exposures (Mann and Picard 1994;\nUyttendaele, Eden, and Szeliski 2001; Levin, Zomet, Peleg et al. 2004; Agarwala, Dontcheva,\nAgrawala et al. 2004; Eden, Uyttendaele, and Szeliski 2006; Kopf, Uyttendaele, Deussen et\nal. 2007).1 These techniques have spawned a large number of commercial stitching products\n(Chen 1995; Sawhney, Kumar, Gendel et al. 1998), of which reviews and comparisons can\nbe found on the Web.2\nWhile most of the earlier techniques worked by directly minimizing pixel-to-pixel dis-\nsimilarities, more recent algorithms usually extract a sparse set of features and match them\nto each other, as described in Chapter 4. Such feature-based approaches to image stitching\nhave the advantage of being more robust against scene movement and are potentially faster,\nif implemented the right way. Their biggest advantage, however, is the ability to “recognize\npanoramas”, i.e., to automatically discover the adjacency (overlap) relationships among an\nunordered set of images, which makes them ideally suited for fully automated stitching of\n1 A collection of some of these papers was compiled by Benosman and Kang (2001) and they are surveyed by\nSzeliski (2006a).\n2 The Photosynth Web site, http://photosynth.net, allows people to create and upload panoramas for free.",
  "image_path": "page_450.jpg",
  "pages": [
    449,
    450,
    451
  ]
}