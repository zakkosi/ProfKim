{
  "doc_id": "pages_210_212",
  "text": "188\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 3.61\nImage segmentation (Boykov and Funka-Lea 2006) c⃝2006 Springer: The user\ndraws a few red strokes in the foreground object and a few blue ones in the background. The\nsystem computes color distributions for the foreground and background and solves a binary\nMRF. The smoothness weights are modulated by the intensity gradients (edges), which makes\nthis a conditional random ﬁeld (CRF).\nthe compatibility Vp,q(lp, lq) may depend on the values of the underlying pixels Ilp(p) and\nIlq(q).\nConsider, for example, where one image I0 is all sky blue, i.e., I0(p) = I0(q) = B, while\nthe other image I1 has a transition from sky blue, I1(p) = B, to forest green, I1(q) = G.\nI0 :\np\nq\np\nq\n: I1\nIn this case, Vp,q(1, 0) = 0 (the colors agree), while Vp,q(0, 1) > 0 (the colors disagree).\nConditional random ﬁelds\nIn a classic Bayesian model (3.106–3.108),\np(x|y) ∝p(y|x)p(x),\n(3.117)\nthe prior distribution p(x) is independent of the observations y. Sometimes, however, it is\nuseful to modify our prior assumptions, say about the smoothness of the ﬁeld we are trying\nto estimate, in response to the sensed data. Whether this makes sense from a probability\nviewpoint is something we discuss once we have explained the new model.\nConsider the interactive image segmentation problem shown in Figure 3.61 (Boykov and\nFunka-Lea 2006). In this application, the user draws foreground (red) and background (blue)\nstrokes, and the system then solves a binary MRF labeling problem to estimate the extent of\nthe foreground object. In addition to minimizing a data term, which measures the pointwise\nsimilarity between pixel colors and the inferred region distributions (Section 5.5), the MRF\n3.7 Global optimization\n189\nf (i, j)\nsx(i, j)\nf (i, j+1)\nsy(i, j)\nw(i, j)\nd (i, j)\nf (i+1, j)\nf (i+1, j+1)\nFigure 3.62\nGraphical model for a conditional random ﬁeld (CRF). The additional green\nedges show how combinations of sensed data inﬂuence the smoothness in the underlying\nMRF prior model, i.e., sx(i, j) and sy(i, j) in (3.113) depend on adjacent d(i, j) values.\nThese additional links (factors) enable the smoothness to depend on the input data. However,\nthey make sampling from this MRF more complex.\nis modiﬁed so that the smoothness terms sx(x, y) and sy(x, y) in Figure 3.56 and (3.113)\ndepend on the magnitude of the gradient between adjacent pixels.25\nSince the smoothness term now depends on the data, Bayes’ Rule (3.117) no longer ap-\nplies. Instead, we use a direct model for the posterior distribution p(x|y), whose negative log\nlikelihood can be written as\nE(x|y)\n=\nEd(x, y) + Es(x, y)\n=\nX\np\nVp(xp, y) +\nX\n(p,q)∈N\nVp,q(xp, xq, y),\n(3.118)\nusing the notation introduced in (3.116). The resulting probability distribution is called a\nconditional random ﬁeld (CRF) and was ﬁrst introduced to the computer vision ﬁeld by Ku-\nmar and Hebert (2003), based on earlier work in text modeling by Lafferty, McCallum, and\nPereira (2001).\nFigure 3.62 shows a graphical model where the smoothness terms depend on the data\nvalues. In this particular model, each smoothness term depends only on its adjacent pair of\ndata values, i.e., terms are of the form Vp,q(xp, xq, yp, yq) in (3.118).\nThe idea of modifying smoothness terms in response to input data is not new. For ex-\nample, Boykov and Jolly (2001) used this idea for interactive segmentation, as shown in\nFigure 3.61, and it is now widely used in image segmentation (Section 5.5) (Blake, Rother,\n25 An alternative formulation that also uses detected edges to modulate the smoothness of a depth or motion ﬁeld\nand hence to integrate multiple lower level vision modules is presented by Poggio, Gamble, and Little (1988).\n190\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nf (i, j)\nsx(i, j)\nf (i, j+1)\nsy(i, j)\nw(i, j)\nd (i, j)\nf (i+1, j)\nf (i+1, j+1)\nd (i, j+1)\nFigure 3.63\nGraphical model for a discriminative random ﬁeld (DRF). The additional green\nedges show how combinations of sensed data, e.g., d(i, j + 1), inﬂuence the data term for\nf(i, j). The generative model is therefore more complex, i.e., we cannot just apply a simple\nfunction to the unknown variables and add noise.\nBrown et al. 2004; Rother, Kolmogorov, and Blake 2004), denoising (Tappen, Liu, Freeman\net al. 2007), and object recognition (Section 14.4.3) (Winn and Shotton 2006; Shotton, Winn,\nRother et al. 2009).\nIn stereo matching, the idea of encouraging disparity discontinuities to coincide with\nintensity edges goes back even further to the early days of optimization and MRF-based\nalgorithms (Poggio, Gamble, and Little 1988; Fua 1993; Bobick and Intille 1999; Boykov,\nVeksler, and Zabih 2001) and is discussed in more detail in (Section 11.5).\nIn addition to using smoothness terms that adapt to the input data, Kumar and Hebert\n(2003) also compute a neighborhood function over the input data for each Vp(xp, y) term,\nas illustrated in Figure 3.63, instead of using the classic unary MRF data term Vp(xp, yp)\nshown in Figure 3.56.26 Because such neighborhood functions can be thought of as dis-\ncriminant functions (a term widely used in machine learning (Bishop 2006)), they call the\nresulting graphical model a discriminative random ﬁeld (DRF). In their paper, Kumar and\nHebert (2006) show that DRFs outperform similar CRFs on a number of applications, such\nas structure detection (Figure 3.64) and binary image denoising.\nHere again, one could argue that previous stereo correspondence algorithms also look at\na neighborhood of input data, either explicitly, because they compute correlation measures\n(Criminisi, Cross, Blake et al. 2006) as data terms, or implicitly, because even pixel-wise\ndisparity costs look at several pixels in either the left or right image (Barnard 1989; Boykov,\nVeksler, and Zabih 2001).\n26 Kumar and Hebert (2006) call the unary potentials Vp(xp, y) association potentials and the pairwise potentials\nVp,q(xp, yq, y) interaction potentials.",
  "image_path": "page_211.jpg",
  "pages": [
    210,
    211,
    212
  ]
}