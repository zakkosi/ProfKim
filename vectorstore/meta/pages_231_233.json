{
  "doc_id": "pages_231_233",
  "text": "4.1 Points and patches\n209\nFigure 4.3\nImage pairs with extracted patches below. Notice how some patches can be\nlocalized or matched with higher accuracy than others.\nfeature matching stage (Section 4.1.3) efﬁciently searches for likely matching candidates in\nother images. The feature tracking stage (Section 4.1.4) is an alternative to the third stage\nthat only searches a small neighborhood around each detected feature and is therefore more\nsuitable for video processing.\nA wonderful example of all of these stages can be found in David Lowe’s (2004) paper,\nwhich describes the development and reﬁnement of his Scale Invariant Feature Transform\n(SIFT). Comprehensive descriptions of alternative techniques can be found in a series of\nsurvey and evaluation papers covering both feature detection (Schmid, Mohr, and Bauck-\nhage 2000; Mikolajczyk, Tuytelaars, Schmid et al. 2005; Tuytelaars and Mikolajczyk 2007)\nand feature descriptors (Mikolajczyk and Schmid 2005). Shi and Tomasi (1994) and Triggs\n(2004) also provide nice reviews of feature detection techniques.\n4.1.1 Feature detectors\nHow can we ﬁnd image locations where we can reliably ﬁnd correspondences with other\nimages, i.e., what are good features to track (Shi and Tomasi 1994; Triggs 2004)? Look again\nat the image pair shown in Figure 4.3 and at the three sample patches to see how well they\nmight be matched or tracked. As you may notice, textureless patches are nearly impossible\nto localize. Patches with large contrast changes (gradients) are easier to localize, although\nstraight line segments at a single orientation suffer from the aperture problem (Horn and\nSchunck 1981; Lucas and Kanade 1981; Anandan 1989), i.e., it is only possible to align\nthe patches along the direction normal to the edge direction (Figure 4.4b). Patches with\n210\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nxi\nxi+u\nu\ni\n(a)\n(b)\n(c)\nFigure 4.4\nAperture problems for different image patches: (a) stable (“corner-like”) ﬂow;\n(b) classic aperture problem (barber-pole illusion); (c) textureless region. The two images I0\n(yellow) and I1 (red) are overlaid. The red vector u indicates the displacement between the\npatch centers and the w(xi) weighting function (patch window) is shown as a dark circle.\ngradients in at least two (signiﬁcantly) different orientations are the easiest to localize, as\nshown schematically in Figure 4.4a.\nThese intuitions can be formalized by looking at the simplest possible matching criterion\nfor comparing two image patches, i.e., their (weighted) summed square difference,\nEWSSD(u) =\nX\ni\nw(xi)[I1(xi + u) −I0(xi)]2,\n(4.1)\nwhere I0 and I1 are the two images being compared, u = (u, v) is the displacement vector,\nw(x) is a spatially varying weighting (or window) function, and the summation i is over all\nthe pixels in the patch. Note that this is the same formulation we later use to estimate motion\nbetween complete images (Section 8.1).\nWhen performing feature detection, we do not know which other image locations the\nfeature will end up being matched against. Therefore, we can only compute how stable this\nmetric is with respect to small variations in position ∆u by comparing an image patch against\nitself, which is known as an auto-correlation function or surface\nEAC(∆u) =\nX\ni\nw(xi)[I0(xi + ∆u) −I0(xi)]2\n(4.2)\n(Figure 4.5).1 Note how the auto-correlation surface for the textured ﬂower bed (Figure 4.5b\nand the red cross in the lower right quadrant of Figure 4.5a) exhibits a strong minimum,\nindicating that it can be well localized. The correlation surface corresponding to the roof\nedge (Figure 4.5c) has a strong ambiguity along one direction, while the correlation surface\ncorresponding to the cloud region (Figure 4.5d) has no stable minimum.\n1 Strictly speaking, a correlation is the product of two patches (3.12); I’m using the term here in a more qualitative\nsense. The weighted sum of squared differences is often called an SSD surface (Section 8.1).\n4.1 Points and patches\n211\n(a)\n(b)\n(c)\n(d)\nFigure 4.5 Three auto-correlation surfaces EAC(∆u) shown as both grayscale images and\nsurface plots: (a) The original image is marked with three red crosses to denote where the\nauto-correlation surfaces were computed; (b) this patch is from the ﬂower bed (good unique\nminimum); (c) this patch is from the roof edge (one-dimensional aperture problem); and (d)\nthis patch is from the cloud (no good peak). Each grid point in ﬁgures b–d is one value of\n∆u.",
  "image_path": "page_232.jpg",
  "pages": [
    231,
    232,
    233
  ]
}