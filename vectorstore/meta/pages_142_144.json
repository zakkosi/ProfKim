{
  "doc_id": "pages_142_144",
  "text": "120\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 3.16\nFourth-order steerable ﬁlter (Freeman and Adelson 1991) c⃝1991 IEEE: (a)\ntest image containing bars (lines) and step edges at different orientations; (b) average oriented\nenergy; (c) dominant orientation; (d) oriented energy as a function of angle (polar plot).\nto steer any order of derivative with a relatively small number of basis functions. For example,\nonly three basis functions are required for the second-order directional derivative,\nGˆuˆu = u2Gxx + 2uvGxy + v2Gyy.\n(3.29)\nFurthermore, each of the basis ﬁlters, while not itself necessarily separable, can be computed\nusing a linear combination of a small number of separable ﬁlters (Freeman and Adelson\n1991).\nThis remarkable result makes it possible to construct directional derivative ﬁlters of in-\ncreasingly greater directional selectivity, i.e., ﬁlters that only respond to edges that have\nstrong local consistency in orientation (Figure 3.15). Furthermore, higher order steerable\nﬁlters can respond to potentially more than a single edge orientation at a given location, and\nthey can respond to both bar edges (thin lines) and the classic step edges (Figure 3.16). In\norder to do this, however, full Hilbert transform pairs need to be used for second-order and\nhigher ﬁlters, as described in (Freeman and Adelson 1991).\nSteerable ﬁlters are often used to construct both feature descriptors (Section 4.1.3) and\nedge detectors (Section 4.2). While the ﬁlters developed by Freeman and Adelson (1991)\nare best suited for detecting linear (edge-like) structures, more recent work by Koethe (2003)\nshows how a combined 2 × 2 boundary tensor can be used to encode both edge and junction\n(“corner”) features. Exercise 3.12 has you implement such steerable ﬁlters and apply them to\nﬁnding both edge and corner features.\nSummed area table (integral image)\nIf an image is going to be repeatedly convolved with different box ﬁlters (and especially ﬁlters\nof different sizes at different locations), you can precompute the summed area table (Crow\n3.2 Linear ﬁltering\n121\n3\n2\n7\n2\n3\n3\n5\n12\n14\n17\n3\n5\n12 14\n17\n1\n5\n1\n3\n4\n4\n11\n19\n24\n31\n4\n11\n19\n24\n31\n5\n1\n3\n5\n1\n9\n17\n28\n38\n46\n9\n17\n28\n38\n46\n4\n3\n2\n1\n6\n13\n24\n37\n48\n62\n13\n24\n37\n48\n62\n2\n4\n1\n4\n8\n15\n30\n44\n59\n81\n15\n30\n44\n59\n81\n (a)  S = 24\n (b)  s =\n28\n (c)  S = 24\nFigure 3.17 Summed area tables: (a) original image; (b) summed area table; (c) computation\nof area sum. Each value in the summed area table s(i, j) (red) is computed recursively from\nits three adjacent (blue) neighbors (3.31). Area sums S (green) are computed by combining\nthe four values at the rectangle corners (purple) (3.32). Positive values are shown in bold and\nnegative values in italics.\n1984), which is just the running sum of all the pixel values from the origin,\ns(i, j) =\ni\nX\nk=0\nj\nX\nl=0\nf(k, l).\n(3.30)\nThis can be efﬁciently computed using a recursive (raster-scan) algorithm,\ns(i, j) = s(i −1, j) + s(i, j −1) −s(i −1, j −1) + f(i, j).\n(3.31)\nThe image s(i, j) is also often called an integral image (see Figure 3.17) and can actually be\ncomputed using only two additions per pixel if separate row sums are used (Viola and Jones\n2004). To ﬁnd the summed area (integral) inside a rectangle [i0, i1] × [j0, j1], we simply\ncombine four samples from the summed area table,\nS(i0 . . . i1, j0 . . . j1) =\ni1\nX\ni=i0\nj1\nX\nj=j0\ns(i1, j1) −s(i1, j0 −1) −s(i0 −1, j1) + s(i0 −1, j0 −1).\n(3.32)\nA potential disadvantage of summed area tables is that they require log M + log N extra bits\nin the accumulation image compared to the original image, where M and N are the image\nwidth and height. Extensions of summed area tables can also be used to approximate other\nconvolution kernels (Wolberg (1990, Section 6.5.2) contains a review).\nIn computer vision, summed area tables have been used in face detection (Viola and\nJones 2004) to compute simple multi-scale low-level features. Such features, which consist of\nadjacent rectangles of positive and negative values, are also known as boxlets (Simard, Bottou,\n122\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nHaffner et al. 1998). In principle, summed area tables could also be used to compute the sums\nin the sum of squared differences (SSD) stereo and motion algorithms (Section 11.4). In\npractice, separable moving average ﬁlters are usually preferred (Kanade, Yoshida, Oda et al.\n1996), unless many different window shapes and sizes are being considered (Veksler 2003).\nRecursive ﬁltering\nThe incremental formula (3.31) for the summed area is an example of a recursive ﬁlter, i.e.,\none whose values depends on previous ﬁlter outputs. In the signal processing literature, such\nﬁlters are known as inﬁnite impulse response (IIR), since the output of the ﬁlter to an impulse\n(single non-zero value) goes on forever. For example, for a summed area table, an impulse\ngenerates an inﬁnite rectangle of 1s below and to the right of the impulse. The ﬁlters we have\npreviously studied in this chapter, which involve the image with a ﬁnite extent kernel, are\nknown as ﬁnite impulse response (FIR).\nTwo-dimensional IIR ﬁlters and recursive formulas are sometimes used to compute quan-\ntities that involve large area interactions, such as two-dimensional distance functions (Sec-\ntion 3.3.3) and connected components (Section 3.3.4).\nMore commonly, however, IIR ﬁlters are used inside one-dimensional separable ﬁltering\nstages to compute large-extent smoothing kernels, such as efﬁcient approximations to Gaus-\nsians and edge ﬁlters (Deriche 1990; Nielsen, Florack, and Deriche 1997).\nPyramid-based\nalgorithms (Section 3.5) can also be used to perform such large-area smoothing computations.\n3.3 More neighborhood operators\nAs we have just seen, linear ﬁlters can perform a wide variety of image transformations.\nHowever non-linear ﬁlters, such as edge-preserving median or bilateral ﬁlters, can sometimes\nperform even better. Other examples of neighborhood operators include morphological oper-\nators that operate on binary images, as well as semi-global operators that compute distance\ntransforms and ﬁnd connected components in binary images (Figure 3.11f–h).\n3.3.1 Non-linear ﬁltering\nThe ﬁlters we have looked at so far have all been linear, i.e., their response to a sum of two\nsignals is the same as the sum of the individual responses. This is equivalent to saying that\neach output pixel is a weighted summation of some number of input pixels (3.19). Linear\nﬁlters are easier to compose and are amenable to frequency response analysis (Section 3.4).\nIn many cases, however, better performance can be obtained by using a non-linear com-\nbination of neighboring pixels. Consider for example the image in Figure 3.18e, where the",
  "image_path": "page_143.jpg",
  "pages": [
    142,
    143,
    144
  ]
}