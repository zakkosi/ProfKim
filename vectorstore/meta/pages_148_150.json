{
  "doc_id": "pages_148_150",
  "text": "126\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 3.20\nBilateral ﬁltering (Durand and Dorsey 2002) c⃝2002 ACM: (a) noisy step\nedge input; (b) domain ﬁlter (Gaussian); (c) range ﬁlter (similarity to center pixel value); (d)\nbilateral ﬁlter; (e) ﬁltered step edge output; (f) 3D distance between pixels.\nSince bilateral ﬁltering is quite slow compared to regular separable ﬁltering, a number\nof acceleration techniques have been developed (Durand and Dorsey 2002; Paris and Durand\n2006; Chen, Paris, and Durand 2007; Paris, Kornprobst, Tumblin et al. 2008). Unfortunately,\nthese techniques tend to use more memory than regular ﬁltering and are hence not directly\napplicable to ﬁltering full-color images.\nIterated adaptive smoothing and anisotropic diffusion\nBilateral (and other) ﬁlters can also be applied in an iterative fashion, especially if an appear-\nance more like a “cartoon” is desired (Tomasi and Manduchi 1998). When iterated ﬁltering\nis applied, a much smaller neighborhood can often be used.\nConsider, for example, using only the four nearest neighbors, i.e., restricting |k −i|+|l −\nj| ≤1 in (3.34). Observe that\nd(i, j, k, l)\n=\nexp\n\u0012\n−(i −k)2 + (j −l)2\n2σ2\nd\n\u0013\n(3.38)\n=\n(\n1,\n|k −i| + |l −j| = 0,\nλ = e−1/2σ2\nd,\n|k −i| + |l −j| = 1.\n(3.39)\n3.3 More neighborhood operators\n127\nWe can thus re-write (3.34) as\nf (t+1)(i, j)\n=\nf (t)(i, j) + η P\nk,l f (t)(k, l)r(i, j, k, l)\n1 + η P\nk,l r(i, j, k, l)\n(3.40)\n=\nf (t)(i, j) +\nη\n1 + ηR\nX\nk,l\nr(i, j, k, l)[f (t)(k, l) −f (t)(i, j)],\nwhere R = P\n(k,l) r(i, j, k, l), (k, l) are the N4 neighbors of (i, j), and we have made the\niterative nature of the ﬁltering explicit.\nAs Barash (2002) notes, (3.40) is the same as the discrete anisotropic diffusion equation\nﬁrst proposed by Perona and Malik (1990b).6 Since its original introduction, anisotropic dif-\nfusion has been extended and applied to a wide range of problems (Nielsen, Florack, and De-\nriche 1997; Black, Sapiro, Marimont et al. 1998; Weickert, ter Haar Romeny, and Viergever\n1998; Weickert 1998). It has also been shown to be closely related to other adaptive smooth-\ning techniques (Saint-Marc, Chen, and Medioni 1991; Barash 2002; Barash and Comaniciu\n2004) as well as Bayesian regularization with a non-linear smoothness term that can be de-\nrived from image statistics (Scharr, Black, and Haussecker 2003).\nIn its general form, the range kernel r(i, j, k, l) = r(∥f(i, j)−f(k, l)∥), which is usually\ncalled the gain or edge-stopping function, or diffusion coefﬁcient, can be any monotonically\nincreasing function with r′(x) →0 as x →∞. Black, Sapiro, Marimont et al. (1998) show\nhow anisotropic diffusion is equivalent to minimizing a robust penalty function on the image\ngradients, which we discuss in Sections 3.7.1 and 3.7.2). Scharr, Black, and Haussecker\n(2003) show how the edge-stopping function can be derived in a principled manner from\nlocal image statistics. They also extend the diffusion neighborhood from N4 to N8, which\nallows them to create a diffusion operator that is both rotationally invariant and incorporates\ninformation about the eigenvalues of the local structure tensor.\nNote that, without a bias term towards the original image, anisotropic diffusion and itera-\ntive adaptive smoothing converge to a constant image. Unless a small number of iterations is\nused (e.g., for speed), it is usually preferable to formulate the smoothing problem as a joint\nminimization of a smoothness term and a data ﬁdelity term, as discussed in Sections 3.7.1\nand 3.7.2 and by Scharr, Black, and Haussecker (2003), which introduce such a bias in a\nprincipled manner.\n3.3.2 Morphology\nWhile non-linear ﬁlters are often used to enhance grayscale and color images, they are also\nused extensively to process binary images. Such images often occur after a thresholding\n6 The 1/(1 + ηR) factor is not present in anisotropic diffusion but becomes negligible as η →0.\n128\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 3.21\nBinary image morphology: (a) original image; (b) dilation; (c) erosion; (d)\nmajority; (e) opening; (f) closing. The structuring element for all examples is a 5 × 5 square.\nThe effects of majority are a subtle rounding of sharp corners. Opening fails to eliminate the\ndot, since it is not wide enough.\noperation,\nθ(f, t) =\n(\n1\nif f ≥t,\n0\nelse,\n(3.41)\ne.g., converting a scanned grayscale document into a binary image for further processing such\nas optical character recognition.\nThe most common binary image operations are called morphological operations, since\nthey change the shape of the underlying binary objects (Ritter and Wilson 2000, Chapter 7).\nTo perform such an operation, we ﬁrst convolve the binary image with a binary structuring\nelement and then select a binary output value depending on the thresholded result of the\nconvolution. (This is not the usual way in which these operations are described, but I ﬁnd it\na nice simple way to unify the processes.) The structuring element can be any shape, from\na simple 3 × 3 box ﬁlter, to more complicated disc structures. It can even correspond to a\nparticular shape that is being sought for in the image.\nFigure 3.21 shows a close-up of the convolution of a binary image f with a 3 × 3 struc-\nturing element s and the resulting images for the operations described below. Let\nc = f ⊗s\n(3.42)\nbe the integer-valued count of the number of 1s inside each structuring element as it is scanned\nover the image and S be the size of the structuring element (number of pixels). The standard\noperations used in binary morphology include:\n• dilation: dilate(f, s) = θ(c, 1);\n• erosion: erode(f, s) = θ(c, S);\n• majority: maj(f, s) = θ(c, S/2);\n• opening: open(f, s) = dilate(erode(f, s), s);",
  "image_path": "page_149.jpg",
  "pages": [
    148,
    149,
    150
  ]
}