{
  "doc_id": "pages_223_225",
  "text": "3.9 Exercises\n201\n3. Multiply each Laplacian image by its corresponding mask and sum the images (see\nFigure 3.43).\n4. Reconstruct the ﬁnal image from the blended Laplacian pyramid.\nGeneralize your algorithm to input n images and a label image with values 1 . . . n (the value\n0 can be reserved for “no input”). Discuss whether the weighted summation stage (step 3)\nneeds to keep track of the total weight for renormalization, or whether the math just works\nout. Use your algorithm either to blend two differently exposed image (to avoid under- and\nover-exposed regions) or to make a creative blend of two different scenes.\nEx 3.21: Wavelet construction and applications\nImplement one of the wavelet families\ndescribed in Section 3.5.4 or by Simoncelli and Adelson (1990b), as well as the basic Lapla-\ncian pyramid (Exercise 3.19). Apply the resulting representations to one of the following two\ntasks:\n• Compression: Compute the entropy in each band for the different wavelet implemen-\ntations, assuming a given quantization level (say, 1/4 gray level, to keep the rounding\nerror acceptable). Quantize the wavelet coefﬁcients and reconstruct the original im-\nages. Which technique performs better? (See (Simoncelli and Adelson 1990b) or any\nof the multitude of wavelet compression papers for some typical results.)\n• Denoising. After computing the wavelets, suppress small values using coring, i.e., set\nsmall values to zero using a piecewise linear or other C0 function. Compare the results\nof your denoising using different wavelet and pyramid representations.\nEx 3.22: Parametric image warping\nWrite the code to do afﬁne and perspective image\nwarps (optionally bilinear as well). Try a variety of interpolants and report on their visual\nquality. In particular, discuss the following:\n• In a MIP-map, selecting only the coarser level adjacent to the computed fractional\nlevel will produce a blurrier image, while selecting the ﬁner level will lead to aliasing.\nExplain why this is so and discuss whether blending an aliased and a blurred image\n(tri-linear MIP-mapping) is a good idea.\n• When the ratio of the horizontal and vertical resampling rates becomes very different\n(anisotropic), the MIP-map performs even worse. Suggest some approaches to reduce\nsuch problems.\nEx 3.23: Local image warping\nOpen an image and deform its appearance in one of the\nfollowing ways:\n202\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n1. Click on a number of pixels and move (drag) them to new locations. Interpolate the\nresulting sparse displacement ﬁeld to obtain a dense motion ﬁeld (Sections 3.6.2 and\n3.5.1).\n2. Draw a number of lines in the image. Move the endpoints of the lines to specify their\nnew positions and use the Beier–Neely interpolation algorithm (Beier and Neely 1992),\ndiscussed in Section 3.6.2, to get a dense motion ﬁeld.\n3. Overlay a spline control grid and move one grid point at a time (optionally select the\nlevel of the deformation).\n4. Have a dense per-pixel ﬂow ﬁeld and use a soft “paintbrush” to design a horizontal and\nvertical velocity ﬁeld.\n5. (Optional): Prove whether the Beier–Neely warp does or does not reduce to a sparse\npoint-based deformation as the line segments become shorter (reduce to points).\nEx 3.24: Forward warping\nGiven a displacement ﬁeld from the previous exercise, write a\nforward warping algorithm:\n1. Write a forward warper using splatting, either nearest neighbor or soft accumulation\n(Section 3.6.1).\n2. Write a two-pass algorithm, which forward warps the displacement ﬁeld, ﬁlls in small\nholes, and then uses inverse warping (Shade, Gortler, He et al. 1998).\n3. Compare the quality of these two algorithms.\nEx 3.25: Feature-based morphing\nExtend the warping code you wrote in Exercise 3.23\nto import two different images and specify correspondences (point, line, or mesh-based) be-\ntween the two images.\n1. Create a morph by partially warping the images towards each other and cross-dissolving\n(Section 3.6.3).\n2. Try using your morphing algorithm to perform an image rotation and discuss whether\nit behaves the way you want it to.\nEx 3.26: 2D image editor\nExtend the program you wrote in Exercise 2.2 to import images\nand let you create a “collage” of pictures. You should implement the following steps:\n1. Open up a new image (in a separate window).\n3.9 Exercises\n203\nFigure 3.66 There is a faint image of a rainbow visible in the right hand side of this picture.\nCan you think of a way to enhance it (Exercise 3.29)?\n2. Shift drag (rubber-band) to crop a subregion (or select whole image).\n3. Paste into the current canvas.\n4. Select the deformation mode (motion model): translation, rigid, similarity, afﬁne, or\nperspective.\n5. Drag any corner of the outline to change its transformation.\n6. (Optional) Change the relative ordering of the images and which image is currently\nbeing manipulated.\nThe user should see the composition of the various images’ pieces on top of each other.\nThis exercise should be built on the image transformation classes supported in the soft-\nware library. Persistence of the created representation (save and load) should also be sup-\nported (for each image, save its transformation).\nEx 3.27: 3D texture-mapped viewer\nExtend the viewer you created in Exercise 2.3 to in-\nclude texture-mapped polygon rendering. Augment each polygon with (u, v, w) coordinates\ninto an image.\nEx 3.28: Image denoising\nImplement at least two of the various image denoising tech-\nniques described in this chapter and compare them on both synthetically noised image se-\nquences and real-world (low-light) sequences. Does the performance of the algorithm de-\npend on the correct choice of noise level estimate? Can you draw any conclusions as to\nwhich techniques work better?",
  "image_path": "page_224.jpg",
  "pages": [
    223,
    224,
    225
  ]
}