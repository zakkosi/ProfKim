{
  "doc_id": "pages_524_526",
  "text": "502\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.33 Recognition-based super-resolution (Baker and Kanade 2002) c⃝2002 IEEE.\nThe Hallucinated column shows the results of the recognition-based algorithm compared to\nthe regularization-based approach of Hardie, Barnard, and Armstrong (1997).\nestimate depth and reduce blur (Levin, Fergus, Durand et al. 2007; Zhou, Lin, and Nayar\n2009).\n10.3.1 Color image demosaicing\nA special case of super-resolution, which is used daily in most digital still cameras, is the\nprocess of demosaicing samples from a color ﬁlter array (CFA) into a full-color RGB image.\nFigure 10.34 shows the most commonly used CFA known as the Bayer pattern, which has\ntwice as many green (G) sensors as red and blue sensors.\nThe process of going from the known CFA pixels values to the full RGB image is quite\nchallenging. Unlike regular super-resolution, where small errors in guessing unknown values\nusually show up as blur or aliasing, demosaicing artifacts often produce spurious colors or\nhigh-frequency patterned zippering, which are quite visible to the eye (Figure 10.35b).\nOver the years, a variety of techniques have been developed for image demosaicing (Kim-\nmel 1999). Bennett, Uyttendaele, Zitnick et al. (2006) present a recently developed algorithm\nalong with some good references, while Longere, Delahunt, Zhang et al. (2002) and Tappen,\nRussell, and Freeman (2003) compare some previously developed techniques using percep-\ntually motivated metrics. To reduce the zippering effect, most techniques use the edge or\n10.3 Super-resolution and blur removal\n503\n(a)\n(b)\nrgB\nrGb\nrgB\nrGb\nrGb\nRgb\nrGb\nRgb\nrgB\nrGb\nrgB\nrGb\nrGb\nRgb\nrGb\nRgb\nB\nG\nB\nG\nG\nR\nG\nR\nG\nB\nG\nR\nG\nR\nB\nG\nFigure 10.34 Bayer RGB pattern: (a) color ﬁlter array layout; (b) interpolated pixel values,\nwith unknown (guessed) values shown as lower case.\n(a)\n(b)\n(c)\n(d)\nFigure 10.35 CFA demosaicing results (Bennett, Uyttendaele, Zitnick et al. 2006) c⃝2006\nSpringer: (a) original full-resolution image (a color subsampled version is used as the input\nto the algorithms); (b) bilinear interpolation results, showing color fringing near the tip of the\nblue crayon and zippering near its left (vertical) edge; (c) the high-quality linear interpolation\nresults of Malvar, He, and Cutler (2004) (note the strong halo/checkerboard artifacts on the\nyellow crayon); (d) using the local two-color prior of Bennett, Uyttendaele, Zitnick et al.\n(2006).\n504\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.36\nTwo-color model computed from a collection of local 5 × 5 neighborhoods\n(Bennett, Uyttendaele, Zitnick et al. 2006) c⃝2006 Springer. After two-means clustering\nand reprojection along the line joining the two dominant colors (red dots), the majority of the\npixels fall near the ﬁtted line. The distribution along the line, projected along the RGB axes,\nis peaked at 0 and 1, the two dominant colors.\ngradient information from the green channel, which is more reliable because it is sampled\nmore densely, to infer plausible values for the red and blue channels, which are more sparsely\nsampled.\nTo reduce color fringing, some techniques perform a color space analysis, e.g., using\nmedian ﬁltering on color opponent channels (Longere, Delahunt, Zhang et al. 2002). The\napproach of Bennett, Uyttendaele, Zitnick et al. (2006) locally forms a two-color model from\nan initial demosaicing result, using a moving 5 × 5 window to ﬁnd the two dominant colors\n(Figure 10.36).21\nOnce the local color model has been estimated at each pixel, a Bayesian approach is\nthen used to encourage pixel values to lie along each color line and to cluster around the\ndominant color values, which reduces halos (Figure 10.35d). The Bayesian approach also\nsupports the simultaneous application of demosaicing and super-resolution, i.e., multiple CFA\ninputs can be merged into a higher-quality full-color image, which becomes more important\nas additional processing becomes incorporated into today’s cameras.\n10.3.2 Application: Colorization\nAlthough not strictly an example of super-resolution, the process of colorization, i.e., manu-\nally adding colors to a “black and white” (grayscale) image, is another example of a sparse\ninterpolation problem. In most applications of colorization, the user draws some scribbles in-\ndicating the desired colors in certain regions (Figure 10.37a) and the system interpolates the\n21 Previous work on locally linear color models (Klinker, Shafer, and Kanade 1990; Omer and Werman 2004)\nfocuses on color and illumination variation within a single material, whereas Bennett, Uyttendaele, Zitnick et al.\n(2006) use the two-color model to describe variations across color (material) edges.",
  "image_path": "page_525.jpg",
  "pages": [
    524,
    525,
    526
  ]
}