{
  "doc_id": "pages_151_153",
  "text": "3.3 More neighborhood operators\n129\n• closing: close(f, s) = erode(dilate(f, s), s).\nAs we can see from Figure 3.21, dilation grows (thickens) objects consisting of 1s, while\nerosion shrinks (thins) them. The opening and closing operations tend to leave large regions\nand smooth boundaries unaffected, while removing small objects or holes and smoothing\nboundaries.\nWhile we will not use mathematical morphology much in the rest of this book, it is a\nhandy tool to have around whenever you need to clean up some thresholded images. You\ncan ﬁnd additional details on morphology in other textbooks on computer vision and image\nprocessing (Haralick and Shapiro 1992, Section 5.2) (Bovik 2000, Section 2.2) (Ritter and\nWilson 2000, Section 7) as well as articles and books speciﬁcally on this topic (Serra 1982;\nSerra and Vincent 1992; Yuille, Vincent, and Geiger 1992; Soille 2006).\n3.3.3 Distance transforms\nThe distance transform is useful in quickly precomputing the distance to a curve or set of\npoints using a two-pass raster algorithm (Rosenfeld and Pfaltz 1966; Danielsson 1980; Borge-\nfors 1986; Paglieroni 1992; Breu, Gil, Kirkpatrick et al. 1995; Felzenszwalb and Huttenlocher\n2004a; Fabbri, Costa, Torelli et al. 2008). It has many applications, including level sets (Sec-\ntion 5.1.4), fast chamfer matching (binary image alignment) (Huttenlocher, Klanderman, and\nRucklidge 1993), feathering in image stitching and blending (Section 9.3.2), and nearest point\nalignment (Section 12.2.1).\nThe distance transform D(i, j) of a binary image b(i, j) is deﬁned as follows. Let d(k, l)\nbe some distance metric between pixel offsets. Two commonly used metrics include the city\nblock or Manhattan distance\nd1(k, l) = |k| + |l|\n(3.43)\nand the Euclidean distance\nd2(k, l) =\np\nk2 + l2.\n(3.44)\nThe distance transform is then deﬁned as\nD(i, j) =\nmin\nk,l:b(k,l)=0 d(i −k, j −l),\n(3.45)\ni.e., it is the distance to the nearest background pixel whose value is 0.\nThe D1 city block distance transform can be efﬁciently computed using a forward and\nbackward pass of a simple raster-scan algorithm, as shown in Figure 3.22. During the forward\npass, each non-zero pixel in b is replaced by the minimum of 1 + the distance of its north or\nwest neighbor. During the backward pass, the same occurs, except that the minimum is both\nover the current value D and 1 + the distance of the south and east neighbors (Figure 3.22).\n130\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n.\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n2\n0\n0\n0\n0\n1\n1\n2\n0\n0\n0\n0\n1\n1\n1\n0\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n2\n2\n3\n1\n0\n0\n1\n2\n2\n3\n1\n0\n0\n1\n2\n2\n2\n1\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n2\n3\n0\n1\n2\n2\n1\n1\n0\n0\n1\n2\n2\n1\n1\n0\n0\n1\n1\n1\n0\n0\n0\n0\n1\n2\n1\n0\n0\n0\n0\n1\n2\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n(a)\n(b)\n(c)\n(d)\nFigure 3.22\nCity block distance transform: (a) original binary image; (b) top to bottom\n(forward) raster sweep: green values are used to compute the orange value; (c) bottom to top\n(backward) raster sweep: green values are merged with old orange value; (d) ﬁnal distance\ntransform.\nEfﬁciently computing the Euclidean distance transform is more complicated. Here, just\nkeeping the minimum scalar distance to the boundary during the two passes is not sufﬁcient.\nInstead, a vector-valued distance consisting of both the x and y coordinates of the distance\nto the boundary must be kept and compared using the squared distance (hypotenuse) rule. As\nwell, larger search regions need to be used to obtain reasonable results. Rather than explaining\nthe algorithm (Danielsson 1980; Borgefors 1986) in more detail, we leave it as an exercise\nfor the motivated reader (Exercise 3.13).\nFigure 3.11g shows a distance transform computed from a binary image. Notice how\nthe values grow away from the black (ink) regions and form ridges in the white area of the\noriginal image. Because of this linear growth from the starting boundary pixels, the distance\ntransform is also sometimes known as the grassﬁre transform, since it describes the time at\nwhich a ﬁre starting inside the black region would consume any given pixel, or a chamfer,\nbecause it resembles similar shapes used in woodworking and industrial design. The ridges\nin the distance transform become the skeleton (or medial axis transform (MAT)) of the region\nwhere the transform is computed, and consist of pixels that are of equal distance to two (or\nmore) boundaries (Tek and Kimia 2003; Sebastian and Kimia 2005).\nA useful extension of the basic distance transform is the signed distance transform, which\ncomputes distances to boundary pixels for all the pixels (Lavall´ee and Szeliski 1995). The\nsimplest way to create this is to compute the distance transforms for both the original bi-\nnary image and its complement and to negate one of them before combining. Because such\ndistance ﬁelds tend to be smooth, it is possible to store them more compactly (with mini-\nmal loss in relative accuracy) using a spline deﬁned over a quadtree or octree data structure\n(Lavall´ee and Szeliski 1995; Szeliski and Lavall´ee 1996; Frisken, Perry, Rockwood et al.\n2000). Such precomputed signed distance transforms can be extremely useful in efﬁciently\naligning and merging 2D curves and 3D surfaces (Huttenlocher, Klanderman, and Rucklidge\n3.3 More neighborhood operators\n131\n(a)\n(b)\n(c)\nFigure 3.23 Connected component computation: (a) original grayscale image; (b) horizontal\nruns (nodes) connected by vertical (graph) edges (dashed blue)—runs are pseudocolored with\nunique colors inherited from parent nodes; (c) re-coloring after merging adjacent segments.\n1993; Szeliski and Lavall´ee 1996; Curless and Levoy 1996), especially if the vectorial version\nof the distance transform, i.e., a pointer from each pixel or voxel to the nearest boundary or\nsurface element, is stored and interpolated. Signed distance ﬁelds are also an essential com-\nponent of level set evolution (Section 5.1.4), where they are called characteristic functions.\n3.3.4 Connected components\nAnother useful semi-global image operation is ﬁnding connected components, which are de-\nﬁned as regions of adjacent pixels that have the same input value (or label). (In the remainder\nof this section, consider pixels to be adjacent if they are immediate N4 neighbors and they\nhave the same input value.) Connected components can be used in a variety of applications,\nsuch as ﬁnding individual letters in a scanned document or ﬁnding objects (say, cells) in a\nthresholded image and computing their area statistics.\nConsider the grayscale image in Figure 3.23a. There are four connected components in\nthis ﬁgure: the outermost set of white pixels, the large ring of gray pixels, the white enclosed\nregion, and the single gray pixel. These are shown pseudocolored in Figure 3.23c as pink,\ngreen, blue, and brown.\nTo compute the connected components of an image, we ﬁrst (conceptually) split the image\ninto horizontal runs of adjacent pixels, and then color the runs with unique labels, re-using\nthe labels of vertically adjacent runs whenever possible. In a second phase, adjacent runs of\ndifferent colors are then merged.\nWhile this description is a little sketchy, it should be enough to enable a motivated stu-\ndent to implement this algorithm (Exercise 3.14). Haralick and Shapiro (1992, Section 2.3)\ngive a much longer description of various connected component algorithms, including ones",
  "image_path": "page_152.jpg",
  "pages": [
    151,
    152,
    153
  ]
}