{
  "doc_id": "pages_741_743",
  "text": "14.6 Recognition databases and test sets\n719\nName / URL\nExtents\nContents / Reference\nFace and person recognition\nYale face database\nCentered face images\nFrontal faces\nhttp://www1.cs.columbia.edu/∼belhumeur/\nBelhumeur, Hespanha, and Kriegman (1997)\nResources for face detection\nVarious databases\nFaces in various poses\nhttp://vision.ai.uiuc.edu/mhyang/face-detection-survey.html\nYang, Kriegman, and Ahuja (2002)\nFERET\nCentered face images\nFrontal faces\nhttp://www.frvt.org/FERET\nPhillips, Moon, Rizvi et al. (2000)\nFRVT\nCentered face images\nFaces in various poses\nhttp://www.frvt.org/\nPhillips, Scruggs, O’Toole et al. (2010)\nCMU PIE database\nCentered face image\nFaces in various poses\nhttp://www.ri.cmu.edu/projects/project 418.html\nSim, Baker, and Bsat (2003)\nCMU Multi-PIE database\nCentered face image\nFaces in various poses\nhttp://multipie.org\nGross, Matthews, Cohn et al. (2010)\nFaces in the Wild\nInternet images\nFaces in various poses\nhttp://vis-www.cs.umass.edu/lfw/\nHuang, Ramesh, Berg et al. (2007)\nConsumer image person DB\nComplete images\nPeople\nhttp://chenlab.ece.cornell.edu/people/Andy/GallagherDataset.html\nGallagher and Chen (2008)\nObject recognition\nCaltech 101\nSegmentation masks\n101 categories\nhttp://www.vision.caltech.edu/Image Datasets/Caltech101/\nFei-Fei, Fergus, and Perona (2006)\nCaltech 256\nCentered objects\n256 categories and clutter\nhttp://www.vision.caltech.edu/Image Datasets/Caltech256/\nGrifﬁn, Holub, and Perona (2007)\nCOIL-100\nCentered objects\n100 instances\nhttp://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php\nNene, Nayar, and Murase (1996)\nETH-80\nCentered objects\n8 instances, 10 views\nhttp://www.mis.tu-darmstadt.de/datasets\nLeibe and Schiele (2003)\nInstance recognition benchmark\nObjects in various poses\n2550 objects\nhttp://vis.uky.edu/∼stewe/ukbench/\nNist´er and Stew´enius (2006)\nOxford buildings dataset\nPictures of buildings\n5062 images\nhttp://www.robots.ox.ac.uk/∼vgg/data/oxbuildings/\nPhilbin, Chum, Isard et al. (2007)\nNORB\nBounding box\n50 toys\nhttp://www.cs.nyu.edu/∼ylclab/data/norb-v1.0/\nLeCun, Huang, and Bottou (2004)\nTiny images\nComplete images\n75,000 (Wordnet) things\nhttp://people.csail.mit.edu/torralba/tinyimages/\nTorralba, Freeman, and Fergus (2008)\nImageNet\nComplete images\n14,000 (Wordnet) things\nhttp://www.image-net.org/\nDeng, Dong, Socher et al. (2009)\nTable 14.1\nImage databases for recognition, adapted and expanded from Fei-Fei, Fergus,\nand Torralba (2009).\n720\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nName / URL\nExtents\nContents / Reference\nObject detection / localization\nCMU frontal faces\nPatches\nFrontal faces\nhttp://vasc.ri.cmu.edu/idb/html/face/frontal images\nRowley, Baluja, and Kanade (1998a)\nMIT frontal faces\nPatches\nFrontal faces\nhttp://cbcl.mit.edu/software-datasets/FaceData2.html\nSung and Poggio (1998)\nCMU face detection databases\nMultiple faces\nFaces in various poses\nhttp://www.ri.cmu.edu/research project detail.html?project id=419\nSchneiderman and Kanade (2004)\nUIUC Image DB\nBounding boxes\nCars\nhttp://l2r.cs.uiuc.edu/∼cogcomp/Data/Car/\nAgarwal and Roth (2002)\nCaltech Pedestrian Dataset\nBounding boxes\nPedestrians\nhttp://www.vision.caltech.edu/Image Datasets/CaltechPedestrians/\nDoll`ar, Wojek, Schiele et al. (2009)\nGraz-02 Database\nSegmentation masks\nBikes, cars, people\nhttp://www.emt.tugraz.at/∼pinz/data/GRAZ 02/\nOpelt, Pinz, Fussenegger et al. (2006)\nETHZ Toys\nCluttered images\nToys, boxes, magazines\nhttp://www.vision.ee.ethz.ch/∼calvin/datasets.html\nFerrari, Tuytelaars, and Van Gool (2006b)\nTU Darmstadt DB\nSegmentation masks\nMotorbikes, cars, cows\nhttp://www.vision.ee.ethz.ch/∼bleibe/data/datasets.html\nLeibe, Leonardis, and Schiele (2008)\nMSR Cambridge\nSegmentation masks\n23 classes\nhttp://research.microsoft.com/en-us/projects/objectclassrecognition/\nShotton, Winn, Rother et al. (2009)\nLabelMe dataset\nPolygonal boundary\n>500 categories\nhttp://labelme.csail.mit.edu/\nRussell, Torralba, Murphy et al. (2008)\nLotus Hill\nSegmentation masks\nScenes and hierarchies\nhttp://www.imageparsing.com/\nYao, Yang, Lin et al. (2010)\nOn-line annotation tools\nESP game\nImage descriptions\nWeb images\nhttp://www.gwap.com/gwap/\nvon Ahn and Dabbish (2004)\nPeekaboom\nLabeled regions\nWeb images\nhttp://www.gwap.com/gwap/\nvon Ahn, Liu, and Blum (2006)\nLabelMe\nPolygonal boundary\nHigh-resolution images\nhttp://labelme.csail.mit.edu/\nRussell, Torralba, Murphy et al. (2008)\nCollections of challenges\nPASCAL\nSegmentation, boxes\nVarious\nhttp://pascallin.ecs.soton.ac.uk/challenges/VOC/\nEveringham, Van Gool, Williams et al. (2010)\nTable 14.2 Image databases for detection and localization, adapted and expanded from Fei-\nFei, Fergus, and Torralba (2009).\n14.6 Recognition databases and test sets\n721\nairplane\nbicycle\nbird\nboat\nbottle\nbus\ncar\ncat\nchair\ncow\ndiningtable\ndog\nhorse\nmotorbike\nperson\npottedplant\nsheep\nsofa\ntrain\ntvmonitor\nFigure 14.54\nSample images from the PASCAL Visual Object Classes Challenge 2008\n(VOC2008) database (Everingham, Van Gool, Williams et al. 2008). The original images\nwere obtained from ﬂickr (http://www.ﬂickr.com/) and the database rights are explained on\nhttp://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2008/.\n“serious” volunteer effort is the LabelMe database, in which vision researchers contribute\nmanual polygonal region annotations in return for gaining access to the database (Russell,\nTorralba, Murphy et al. 2008).\nThe use of computer vision algorithms for collecting recognition databases dates back to\nthe work of Fergus, Fei-Fei, Perona et al. (2005), who cluster the results returned by Google\nimage search using an extension of PLSA and then select the clusters associated with the\nhighest ranked results. More recent examples of related techniques include the work of Berg\nand Forsyth (2006) and Li and Fei-Fei (2010).\nWhatever methods are used to collect and validate recognition databases, they will con-\ntinue to grow in size, utility, and difﬁculty from year to year. They will also continue to be\nan essential component of research into the recognition and scene understanding problems,\nwhich remain, as always, the grand challenges of computer vision.",
  "image_path": "page_742.jpg",
  "pages": [
    741,
    742,
    743
  ]
}