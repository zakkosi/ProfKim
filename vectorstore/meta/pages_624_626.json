{
  "doc_id": "pages_624_626",
  "text": "602\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 12.17\n3D model ﬁtting to a collection of images: (Pighin, Hecker, Lischinski et\nal. 1998) c⃝1998 ACM: (a) set of ﬁve input images along with user-selected keypoints; (b)\nthe complete set of keypoints and curves; (c) three meshes—the original, adapted after 13\nkeypoints, and after an additional 99 keypoints; (d) the partition of the image into separately\nanimatable regions.\n(a)\n(b)\nFigure 12.18\nHead and expression tracking and re-animation using deformable 3D models.\n(a) Models ﬁt directly to ﬁve input video streams (Pighin, Szeliski, and Salesin 2002) c⃝\n2002 Springer: The bottom row shows the results of re-animating a synthetic texture-mapped\n3D model with pose and expression parameters ﬁtted to the input images in the top row. (b)\nModels ﬁt to frame-rate spacetime stereo surface models (Zhang, Snavely, Curless et al. 2004)\nc⃝2004 ACM: The top row shows the input images with synthetic green markers overlaid,\nwhile the bottom row shows the ﬁtted 3D surface model.\n12.6 Model-based reconstruction\n603\nuse such models for a variety of animation and visual effects (Blanz and Vetter 1999). It is\nalso possible to design stereo matching algorithms that optimize directly for the head model\nparameters (Shan, Liu, and Zhang 2001; Kang and Jones 2002) or to use the output of real-\ntime stereo with active illumination (Zhang, Snavely, Curless et al. 2004) (Figures 12.7 and\n12.18b).\nAs the sophistication of 3D facial capture systems evolves, so does the detail and realism\nin the reconstructed models. Newer systems can capture (in real-time) not only surface details\nsuch as wrinkles and creases, but also accurate models of skin reﬂection, translucency, and\nsub-surface scattering (Weyrich, Matusik, Pﬁster et al. 2006; Golovinskiy, Matusik, ster et al.\n2006; Bickel, Botsch, Angst et al. 2007; Igarashi, Nishino, and Nayar 2007).\nOnce a 3D head model has been constructed, it can be used in a variety of applications,\nsuch as head tracking (Toyama 1998; Lepetit, Pilet, and Fua 2004; Matthews, Xiao, and Baker\n2007), as shown in Figures 4.29 and 14.24, and face transfer, i.e., replacing one person’s\nface with another in a video (Bregler, Covell, and Slaney 1997; Vlasic, Brand, Pﬁster et al.\n2005). Additional applications include face beautiﬁcation by warping face images toward a\nmore attractive “standard” (Leyvand, Cohen-Or, Dror et al. 2008), face de-identiﬁcation for\nprivacy protection (Gross, Sweeney, De la Torre et al. 2008), and face swapping (Bitouk,\nKumar, Dhillon et al. 2008).\n12.6.3 Application: Facial animation\nPerhaps the most widely used application of 3D head modeling is facial animation. Once\na parameterized 3D model of shape and appearance (surface texture) has been constructed,\nit can be used directly to track a person’s facial motions (Figure 12.18a) and to animate a\ndifferent character with these same motions and expressions (Pighin, Szeliski, and Salesin\n2002).\nAn improved version of such a system can be constructed by ﬁrst applying principal com-\nponent analysis (PCA) to the space of possible head shapes and facial appearances. Blanz\nand Vetter (1999) describe a system where they ﬁrst capture a set of 200 colored range scans\nof faces (Figure 12.19a), which can be represented as a large collection of (X, Y, Z, R, G, B)\nsamples (vertices).9 In order for 3D morphing to be meaningful, corresponding vertices in\ndifferent people’s scans must ﬁrst be put into correspondence (Pighin, Hecker, Lischinski et\nal. 1998). Once this is done, PCA can be applied to more naturally parameterize the 3D mor-\nphable model. The ﬂexibility of this model can be increased by performing separate analyses\nin different subregions, such as the eyes, nose, and mouth, just as in modular eigenspaces\n(Moghaddam and Pentland 1997).\n9 A cylindrical coordinate system provides a natural two-dimensional embedding for this collection, but such an\nembedding is not necessary to perform PCA.\n604\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 12.19\n3D morphable face model (Blanz and Vetter 1999) c⃝1999 ACM: (a) orig-\ninal 3D face model with the addition of shape and texture variations in speciﬁc directions:\ndeviation from the mean (caricature), gender, expression, weight, and nose shape; (b) a 3D\nmorphable model is ﬁt to a single image, after which its weight or expression can be manip-\nulated; (c) another example of a 3D reconstruction along with a different set of 3D manipula-\ntions such as lighting and pose change.",
  "image_path": "page_625.jpg",
  "pages": [
    624,
    625,
    626
  ]
}