{
  "doc_id": "pages_791_793",
  "text": "B.5 Markov random ﬁelds\n769\nwhere\nφi,j(xi, xj) = e−Vi,j(xi,xj)\n(B.30)\nare the pairwise interaction potentials. We can rewrite (B.27) as\n˜pk(x) =\nY\ni<k, j≤k\nφi,j(xi, xj) =\nY\ni∈Ck\n˜pi,k(x),\n(B.31)\nwhere\n˜pi,k(x) = φi,k(xi, xk)˜pi(x).\n(B.32)\nWe can therefore rewrite (B.28) as\nˆpk(xk) =\nmax\n{xi, i<k} ˜pk(x) =\nY\ni∈Ck\nˆpi,k(x),\n(B.33)\nwith\nˆpi,k(x) = max\nxi φi,k(xi, xk)ˆpi(x).\n(B.34)\nEquation (B.34) is the max update rule evaluated at all square box factors in Figure B.2a,\nwhile (B.33) is the product rule evaluated at the nodes. The probability distribution ˆpi,k(x)\nis often interpreted as a message passing information about child i to parent k and is hence\nwritten as mi,k(xk) (Yedidia, Freeman, and Weiss 2001) or µi→k(xk) (Bishop 2006).\nThe max-product rule can be used to compute the MAP estimate in a tree using the same\nkind of forward and backward sweep as in dynamic programming (which is sometimes called\nthe max-sum algorithm (Bishop 2006)). An alternative rule, known as the sum–product, sums\nover all possible values in (B.34) rather than taking the maximum, in essence computing\nthe expected distribution rather than the maximum likelihood distribution. This produces a\nset of probability estimates that can be used to compute the marginal distributions bi(xi) =\nP\nx\\xi p(x) (Pearl 1988; Yedidia, Freeman, and Weiss 2001; Bishop 2006).\nBelief propagation may not produce optimal estimates for cyclic graphs for the same\nreason that dynamic programming fails to work, i.e., because a node with multiple parents\nmay take on different optimal values for each of the parents, i.e., there is no unique elim-\nination ordering. Early algorithms for extending belief propagation to graphs with cycles,\ndubbed loopy belief propagation, performed the updates in parallel over the graph, i.e., us-\ning synchronous updates (Frey and MacKay 1997; Freeman, Pasztor, and Carmichael 2000;\nYedidia, Freeman, and Weiss 2001; Weiss and Freeman 2001a,b; Yuille 2002; Sun, Zheng,\nand Shum 2003; Felzenszwalb and Huttenlocher 2006).\nFor example, Felzenszwalb and Huttenlocher (2006) split an N4 graph into its red and\nblack (checkerboard) components and alternate between sending messages from the red nodes\nto the black and vice versa. They also use multi-grid (coarser level) updates to speed up the\nconvergence. As discussed previously, to reduce the complexity of the basic max-product\n770\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nupdate rule (B.28) from O(l2) to O(l), they develop specialized update algorithms for sev-\neral cost functions Vi,k(xi, xk), including the Potts model (delta function), absolute values\n(total variation), and quadratic (Gaussian MRF). A related algorithm, mean ﬁeld diffusion\n(Scharstein and Szeliski 1998), also uses synchronous updates between nodes to compute\nmarginal distributions. Yuille (2010) discusses the relationships between mean ﬁeld theory\nand loopy belief propagation.\nMore recent loopy belief propagation algorithms and their variants use sequential scans\nthrough the graph (Szeliski, Zabih, Scharstein et al. 2008). For example, Tappen and Free-\nman (2003) pass messages from left to right along each row and then reverse the direction\nonce they reach the end. This is similar to treating each row as an independent tree (chain),\nexcept that messages from nodes above and below the row are also incorporated. They then\nperform similar computations along columns. These sequential updates allow the information\nto propagate much more quickly across the image than synchronous updates.\nThe other belief propagation variant tested by Szeliski, Zabih, Scharstein et al. (2008),\nwhich they call BP-S or TRW-S, is based on Kolmogorov’s (2006) sequential extension of\nthe tree-reweighted message passing of Wainwright, Jaakkola, and Willsky (2005). TRW\nﬁrst selects a set of trees from the neighborhood graph and computes a set of probability\ndistributions over each tree. These are then used to reweight the messages being passed\nduring loopy belief propagation. The sequential version of TRW, called TRW-S, processed\nnodes in scan-line order, with a forward and backward pass. In the forward pass, each node\nsends messages to its right and bottom neighbors. In the backward pass, messages are sent\nto the left and upper neighbors. TRW-S also computes a lower bound on the energy, which\nis used by Szeliski, Zabih, Scharstein et al. (2008) to estimate how close to the best possible\nsolution all of the MRF inference algorithms being evaluated get.\nAs with dynamic programming, belief propagation techniques also become less efﬁcient\nas the order of each factor clique increases. Potetz and Lee (2008) shows how this complex-\nity can be reduced back to linear in the clique order for continuous-valued problems where\nthe factors involve linear summations followed by a non-linearity, which is typical of more\nsophisticated MRF models such as ﬁelds of experts (Roth and Black 2009) and steerable ran-\ndom ﬁelds (Roth and Black 2007b). Kohli, Kumar, and Torr (2009) and Alahari, Kohli, and\nTorr (2011) develop alternative ways for dealing with higher-order cliques in the context of\ngraph cut algorithms.\nB.5.4 Graph cuts\nThe computer vision community has adopted “graph cuts” as an informal name to describe\na large family of MRF inference algorithms based on solving one or more min-cut or max-\nﬂow problems (Boykov, Veksler, and Zabih 2001; Boykov and Kolmogorov 2010; Boykov,\nB.5 Markov random ﬁelds\n771\n  Object\nterminal\n  terminal\nBackground \np\nq\nr\nw\nv\nS\nT\nBackground \n  Object\n  terminal\nterminal\np\nq\nr\nw\nv\nS\nT\ncut\n(a)\n(b)\nFigure B.3 Graph cuts for minimizing binary sub-modular MRF energies (Boykov and Jolly\n2001) c⃝2001 IEEE: (a) energy function encoded as a max ﬂow problem; (b) the minimum\ncut determines the region boundary.\nVeksler, and Zabih 2010; Ishikawa and Veksler 2010).\nThe simplest example of an MRF graph cut is the polynomial-time algorithm for perform-\ning exact minimization of a binary MRF originally developed by Greig, Porteous, and Seheult\n(1989) and brought to the attention of the computer vision community by Boykov, Veksler,\nand Zabih (2001) and Boykov and Jolly (2001). The basic construction of the min-cut graph\nfrom an MRF energy function is shown in Figure B.3 and described in Sections 3.7.2 and\n5.5. In brief, the nodes in an MRF are connected to special source and sink nodes, and the\nminimum cut between these two nodes, whose cost is exactly that of the MRF energy un-\nder a binary assignment of labels, is computed using a polynomial-time max ﬂow algorithm\n(Goldberg and Tarjan 1988; Boykov and Kolmogorov 2004).\nAs discussed in Section 5.5, important extensions of this basic algorithm have been made\nfor the case of directed edges (Kolmogorov and Boykov 2005), larger neighborhoods (Boykov\nand Kolmogorov 2003; Kolmogorov and Boykov 2005), connectivity priors (Vicente, Kol-\nmogorov, and Rother 2008), and shape priors (Lempitsky and Boykov 2007; Lempitsky,\nBlake, and Rother 2008). Kolmogorov and Zabih (2004) formally characterize the class\nof binary energy potentials (regularity conditions) for which these algorithms ﬁnd the global\nminimum. Komodakis, Tziritas, and Paragios (2008) and Rother, Kolmogorov, Lempitsky et\nal. (2007) provide good algorithms for the cases when they do not.\nBinary MRF problems can also be approximately solved by turning them into continuous\n[0, 1] problems, solving them either as linear systems (Grady 2006; Sinop and Grady 2007;\nGrady and Alvino 2008; Grady 2008; Grady and Ali 2008; Singaraju, Grady, and Vidal 2008;\nCouprie, Grady, Najman et al. 2009) (the random walker model) or by computing geodesic",
  "image_path": "page_792.jpg",
  "pages": [
    791,
    792,
    793
  ]
}