{
  "doc_id": "pages_025_027",
  "text": "1.1 What is computer vision?\n3\n1.1 What is computer vision?\nAs humans, we perceive the three-dimensional structure of the world around us with apparent\nease. Think of how vivid the three-dimensional percept is when you look at a vase of ﬂowers\nsitting on the table next to you. You can tell the shape and translucency of each petal through\nthe subtle patterns of light and shading that play across its surface and effortlessly segment\neach ﬂower from the background of the scene (Figure 1.1). Looking at a framed group por-\ntrait, you can easily count (and name) all of the people in the picture and even guess at their\nemotions from their facial appearance. Perceptual psychologists have spent decades trying to\nunderstand how the visual system works and, even though they can devise optical illusions1\nto tease apart some of its principles (Figure 1.3), a complete solution to this puzzle remains\nelusive (Marr 1982; Palmer 1999; Livingstone 2008).\nResearchers in computer vision have been developing, in parallel, mathematical tech-\nniques for recovering the three-dimensional shape and appearance of objects in imagery. We\nnow have reliable techniques for accurately computing a partial 3D model of an environment\nfrom thousands of partially overlapping photographs (Figure 1.2a). Given a large enough\nset of views of a particular object or fac¸ade, we can create accurate dense 3D surface mod-\nels using stereo matching (Figure 1.2b). We can track a person moving against a complex\nbackground (Figure 1.2c). We can even, with moderate success, attempt to ﬁnd and name\nall of the people in a photograph using a combination of face, clothing, and hair detection\nand recognition (Figure 1.2d). However, despite all of these advances, the dream of having a\ncomputer interpret an image at the same level as a two-year old (for example, counting all of\nthe animals in a picture) remains elusive.\nWhy is vision so difﬁcult? In part, it is because\nvision is an inverse problem, in which we seek to recover some unknowns given insufﬁcient\ninformation to fully specify the solution. We must therefore resort to physics-based and prob-\nabilistic models to disambiguate between potential solutions. However, modeling the visual\nworld in all of its rich complexity is far more difﬁcult than, say, modeling the vocal tract that\nproduces spoken sounds.\nThe forward models that we use in computer vision are usually developed in physics (ra-\ndiometry, optics, and sensor design) and in computer graphics. Both of these ﬁelds model\nhow objects move and animate, how light reﬂects off their surfaces, is scattered by the at-\nmosphere, refracted through camera lenses (or human eyes), and ﬁnally projected onto a ﬂat\n(or curved) image plane. While computer graphics are not yet perfect (no fully computer-\nanimated movie with human characters has yet succeeded at crossing the uncanny valley2\nthat separates real humans from android robots and computer-animated humans), in limited\n1 http://www.michaelbach.de/ot/sze muelue\n2 The term uncanny valley was originally coined by roboticist Masahiro Mori as applied to robotics (Mori 1970).\nIt is also commonly applied to computer-animated ﬁlms such as Final Fantasy and Polar Express (Geller 2008).\n4\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nX\nX\nX\nX\nX\nX\nX\nO\nX\nO\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nO\nX\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nO\nO\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nO\nX\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nX\nO\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nO\nO\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nO\nX\nX\nX\nO\nX\n(c)\n(d)\nFigure 1.3 Some common optical illusions and what they might tell us about the visual sys-\ntem: (a) The classic M¨uller-Lyer illusion, where the length of the two horizontal lines appear\ndifferent, probably due to the imagined perspective effects. (b) The “white” square B in the\nshadow and the “black” square A in the light actually have the same absolute intensity value.\nThe percept is due to brightness constancy, the visual system’s attempt to discount illumi-\nnation when interpreting colors. Image courtesy of Ted Adelson, http://web.mit.edu/persci/\npeople/adelson/checkershadow illusion.html. (c) A variation of the Hermann grid illusion,\ncourtesy of Hany Farid, http://www.cs.dartmouth.edu/∼farid/illusions/hermann.html. As you\nmove your eyes over the ﬁgure, gray spots appear at the intersections. (d) Count the red Xs\nin the left half of the ﬁgure. Now count them in the right half. Is it signiﬁcantly harder?\nThe explanation has to do with a pop-out effect (Treisman 1985), which tells us about the\noperations of parallel perception and integration pathways in the brain.\n1.1 What is computer vision?\n5\ndomains, such as rendering a still scene composed of everyday objects or animating extinct\ncreatures such as dinosaurs, the illusion of reality is perfect.\nIn computer vision, we are trying to do the inverse, i.e., to describe the world that we see\nin one or more images and to reconstruct its properties, such as shape, illumination, and color\ndistributions. It is amazing that humans and animals do this so effortlessly, while computer\nvision algorithms are so error prone. People who have not worked in the ﬁeld often under-\nestimate the difﬁculty of the problem. (Colleagues at work often ask me for software to ﬁnd\nand name all the people in photos, so they can get on with the more “interesting” work.) This\nmisperception that vision should be easy dates back to the early days of artiﬁcial intelligence\n(see Section 1.2), when it was initially believed that the cognitive (logic proving and plan-\nning) parts of intelligence were intrinsically more difﬁcult than the perceptual components\n(Boden 2006).\nThe good news is that computer vision is being used today in a wide variety of real-world\napplications, which include:\n• Optical character recognition (OCR): reading handwritten postal codes on letters\n(Figure 1.4a) and automatic number plate recognition (ANPR);\n• Machine inspection: rapid parts inspection for quality assurance using stereo vision\nwith specialized illumination to measure tolerances on aircraft wings or auto body parts\n(Figure 1.4b) or looking for defects in steel castings using X-ray vision;\n• Retail: object recognition for automated checkout lanes (Figure 1.4c);\n• 3D model building (photogrammetry): fully automated construction of 3D models\nfrom aerial photographs used in systems such as Bing Maps;\n• Medical imaging: registering pre-operative and intra-operative imagery (Figure 1.4d)\nor performing long-term studies of people’s brain morphology as they age;\n• Automotive safety: detecting unexpected obstacles such as pedestrians on the street,\nunder conditions where active vision techniques such as radar or lidar do not work\nwell (Figure 1.4e; see also Miller, Campbell, Huttenlocher et al. (2008); Montemerlo,\nBecker, Bhat et al. (2008); Urmson, Anhalt, Bagnell et al. (2008) for examples of fully\nautomated driving);\n• Match move: merging computer-generated imagery (CGI) with live action footage by\ntracking feature points in the source video to estimate the 3D camera motion and shape\nof the environment. Such techniques are widely used in Hollywood (e.g., in movies\nsuch as Jurassic Park) (Roble 1999; Roble and Zafar 2009); they also require the use of\nprecise matting to insert new elements between foreground and background elements\n(Chuang, Agarwala, Curless et al. 2002).",
  "image_path": "page_026.jpg",
  "pages": [
    25,
    26,
    27
  ]
}