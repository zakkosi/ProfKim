{
  "doc_id": "pages_124_126",
  "text": "102\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 3.2 Some local image processing operations: (a) original image along with its three\ncolor (per-channel) histograms; (b) brightness increased (additive offset, b = 16); (c) contrast\nincreased (multiplicative gain, a = 1.1); (d) gamma (partially) linearized (γ = 1.2); (e) full\nhistogram equalization; (f) partial histogram equalization.\n3.1 Point operators\n103\n45\n60\n98\n127 132 133 137 133\n46\n65\n98\n123 126 128 131 133\n47\n65\n96\n115 119 123 135 137\n47\n63\n91\n107 113 122 138 134\n50\n59\n80\n97\n110 123 133 134\n49\n53\n68\n83\n97\n113 128 133\n50\n50\n58\n70\n84\n102 116 126\n50\n50\n52\n58\n69\n86\n101 120\n1\n3\n5\n7\n9\n11\n13\n15\nS1\nS2\nS3\nS4\nS5\nS6\nS7\nS8\nS9\nS10\nS11\nS12\nS13\nS14\nS15\nS16\n0\n20\n40\n60\n80\n100\n120\n140\n160\nrange\ndomain\ndomain\n(a)\n(b)\n(c)\n(d)\nFigure 3.3 Visualizing image data: (a) original image; (b) cropped portion and scanline plot\nusing an image inspection tool; (c) grid of numbers; (d) surface plot. For ﬁgures (c)–(d), the\nimage was ﬁrst converted to grayscale.\nscaling and image addition. Next, we discuss how colors in images can be manipulated.\nWe then present image compositing and matting operations, which play an important role\nin computational photography (Chapter 10) and computer graphics applications. Finally, we\ndescribe the more global process of histogram equalization. We close with an example appli-\ncation that manipulates tonal values (exposure and contrast) to improve image appearance.\n3.1.1 Pixel transforms\nA general image processing operator is a function that takes one or more input images and\nproduces an output image. In the continuous domain, this can be denoted as\ng(x) = h(f(x)) or g(x) = h(f0(x), . . . , fn(x)),\n(3.1)\nwhere x is in the D-dimensional domain of the functions (usually D = 2 for images) and the\nfunctions f and g operate over some range, which can either be scalar or vector-valued, e.g.,\nfor color images or 2D motion. For discrete (sampled) images, the domain consists of a ﬁnite\nnumber of pixel locations, x = (i, j), and we can write\ng(i, j) = h(f(i, j)).\n(3.2)\nFigure 3.3 shows how an image can be represented either by its color (appearance), as a grid\nof numbers, or as a two-dimensional function (surface plot).\nTwo commonly used point processes are multiplication and addition with a constant,\ng(x) = af(x) + b.\n(3.3)\nThe parameters a > 0 and b are often called the gain and bias parameters; sometimes these\nparameters are said to control contrast and brightness, respectively (Figures 3.2b–c).1 The\n1 An image’s luminance characteristics can also be summarized by its key (average luminanance) and range\n(Kopf, Uyttendaele, Deussen et al. 2007).\n104\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nbias and gain parameters can also be spatially varying,\ng(x) = a(x)f(x) + b(x),\n(3.4)\ne.g., when simulating the graded density ﬁlter used by photographers to selectively darken\nthe sky or when modeling vignetting in an optical system.\nMultiplicative gain (both global and spatially varying) is a linear operation, since it obeys\nthe superposition principle,\nh(f0 + f1) = h(f0) + h(f1).\n(3.5)\n(We will have more to say about linear shift invariant operators in Section 3.2.) Operators\nsuch as image squaring (which is often used to get a local estimate of the energy in a band-\npass ﬁltered signal, see Section 3.5) are not linear.\nAnother commonly used dyadic (two-input) operator is the linear blend operator,\ng(x) = (1 −α)f0(x) + αf1(x).\n(3.6)\nBy varying α from 0 →1, this operator can be used to perform a temporal cross-dissolve\nbetween two images or videos, as seen in slide shows and ﬁlm production, or as a component\nof image morphing algorithms (Section 3.6.3).\nOne highly used non-linear transform that is often applied to images before further pro-\ncessing is gamma correction, which is used to remove the non-linear mapping between input\nradiance and quantized pixel values (Section 2.3.2).\nTo invert the gamma mapping applied\nby the sensor, we can use\ng(x) = [f(x)]1/γ ,\n(3.7)\nwhere a gamma value of γ ≈2.2 is a reasonable ﬁt for most digital cameras.\n3.1.2 Color transforms\nWhile color images can be treated as arbitrary vector-valued functions or collections of inde-\npendent bands, it usually makes sense to think about them as highly correlated signals with\nstrong connections to the image formation process (Section 2.2), sensor design (Section 2.3),\nand human perception (Section 2.3.2). Consider, for example, brightening a picture by adding\na constant value to all three channels, as shown in Figure 3.2b. Can you tell if this achieves the\ndesired effect of making the image look brighter? Can you see any undesirable side-effects\nor artifacts?\nIn fact, adding the same value to each color channel not only increases the apparent in-\ntensity of each pixel, it can also affect the pixel’s hue and saturation. How can we deﬁne and\nmanipulate such quantities in order to achieve the desired perceptual effects?",
  "image_path": "page_125.jpg",
  "pages": [
    124,
    125,
    126
  ]
}