{
  "doc_id": "pages_214_216",
  "text": "192\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ntion may be preferable. Thus, as with most computer vision algorithms, a careful analysis of\nthe problem at hand and desired robustness and computation constraints may be required to\nchoose the best technique.\nPerhaps the biggest advantage of CRFs and DRFs, as argued by Kumar and Hebert (2006),\nTappen, Liu, Freeman et al. (2007) and Blake, Rother, Brown et al. (2004), is that learning the\nmodel parameters is sometimes easier. While learning parameters in MRFs and their variants\nis not a topic that we cover in this book, interested readers can ﬁnd more details in recently\npublished articles (Kumar and Hebert 2006; Roth and Black 2007a; Tappen, Liu, Freeman et\nal. 2007; Tappen 2007; Li and Huttenlocher 2008).\n3.7.3 Application: Image restoration\nIn Section 3.4.4, we saw how two-dimensional linear and non-linear ﬁlters can be used to\nremove noise or enhance sharpness in images. Sometimes, however, images are degraded by\nlarger problems, such as scratches and blotches (Kokaram 2004). In this case, Bayesian meth-\nods such as MRFs, which can model spatially varying per-pixel measurement noise, can be\nused instead. An alternative is to use hole ﬁlling or inpainting techniques (Bertalmio, Sapiro,\nCaselles et al. 2000; Bertalmio, Vese, Sapiro et al. 2003; Criminisi, P´erez, and Toyama 2004),\nas discussed in Sections 5.1.4 and 10.5.1.\nFigure 3.57 shows an example of image denoising and inpainting (hole ﬁlling) using a\nMarkov random ﬁeld. The original image has been corrupted by noise and a portion of the\ndata has been removed. In this case, the loopy belief propagation algorithm computes a\nslightly lower energy and also a smoother image than the alpha-expansion graph cut algo-\nrithm.\n3.8 Additional reading\nIf you are interested in exploring the topic of image processing in more depth, some popular\ntextbooks have been written by Lim (1990); Crane (1997); Gomes and Velho (1997); J¨ahne\n(1997); Pratt (2007); Russ (2007); Burger and Burge (2008); Gonzales and Woods (2008).\nThe pre-eminent conference and journal in this ﬁeld are the IEEE Conference on Image Pro-\ncesssing and the IEEE Transactions on Image Processing.\nFor image compositing operators, the seminal reference is by Porter and Duff (1984)\nwhile Blinn (1994a,b) provides a more detailed tutorial. For image compositing, Smith and\nBlinn (1996) were the ﬁrst to bring this topic to the attention of the graphics community,\nwhile Wang and Cohen (2007a) provide a recent in-depth survey.\nIn the realm of linear ﬁltering, Freeman and Adelson (1991) provide a great introduc-\ntion to separable and steerable oriented band-pass ﬁlters, while Perona (1995) shows how to\n3.8 Additional reading\n193\napproximate any ﬁlter as a sum of separable components.\nThe literature on non-linear ﬁltering is quite wide and varied; it includes such topics as\nbilateral ﬁltering (Tomasi and Manduchi 1998; Durand and Dorsey 2002; Paris and Durand\n2006; Chen, Paris, and Durand 2007; Paris, Kornprobst, Tumblin et al. 2008), related itera-\ntive algorithms (Saint-Marc, Chen, and Medioni 1991; Nielsen, Florack, and Deriche 1997;\nBlack, Sapiro, Marimont et al. 1998; Weickert, ter Haar Romeny, and Viergever 1998; Weick-\nert 1998; Barash 2002; Scharr, Black, and Haussecker 2003; Barash and Comaniciu 2004),\nand variational approaches (Chan, Osher, and Shen 2001; Tschumperl´e and Deriche 2005;\nTschumperl´e 2006; Kaftory, Schechner, and Zeevi 2007).\nGood references to image morphology include (Haralick and Shapiro 1992, Section 5.2;\nBovik 2000, Section 2.2; Ritter and Wilson 2000, Section 7; Serra 1982; Serra and Vincent\n1992; Yuille, Vincent, and Geiger 1992; Soille 2006).\nThe classic papers for image pyramids and pyramid blending are by Burt and Adelson\n(1983a,b). Wavelets were ﬁrst introduced to the computer vision community by Mallat (1989)\nand good tutorial and review papers and books are available (Strang 1989; Simoncelli and\nAdelson 1990b; Rioul and Vetterli 1991; Chui 1992; Meyer 1993; Sweldens 1997). Wavelets\nare widely used in the computer graphics community to perform multi-resolution geomet-\nric processing (Stollnitz, DeRose, and Salesin 1996) and have been used in computer vision\nfor similar applications (Szeliski 1990b; Pentland 1994; Gortler and Cohen 1995; Yaou and\nChang 1994; Lai and Vemuri 1997; Szeliski 2006b), as well as for multi-scale oriented ﬁlter-\ning (Simoncelli, Freeman, Adelson et al. 1992) and denoising (Portilla, Strela, Wainwright et\nal. 2003).\nWhile image pyramids (Section 3.5.3) are usually constructed using linear ﬁltering op-\nerators, some recent work has started investigating non-linear ﬁlters, since these can better\npreserve details and other salient features. Some representative papers in the computer vision\nliterature are by Gluckman (2006a,b); Lyu and Simoncelli (2008) and in computational pho-\ntography by Bae, Paris, and Durand (2006); Farbman, Fattal, Lischinski et al. (2008); Fattal\n(2009).\nHigh-quality algorithms for image warping and resampling are covered both in the im-\nage processing literature (Wolberg 1990; Dodgson 1992; Gomes, Darsa, Costa et al. 1999;\nSzeliski, Winder, and Uyttendaele 2010) and in computer graphics (Williams 1983; Heckbert\n1986; Barkans 1997; Akenine-M¨oller and Haines 2002), where they go under the name of\ntexture mapping. Combination of image warping and image blending techniques are used to\nenable morphing between images, which is covered in a series of seminal papers and books\n(Beier and Neely 1992; Gomes, Darsa, Costa et al. 1999).\nThe regularization approach to computer vision problems was ﬁrst introduced to the vi-\nsion community by Poggio, Torre, and Koch (1985) and Terzopoulos (1986a,b, 1988) and\ncontinues to be a popular framework for formulating and solving low-level vision problems\n194\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Ju, Black, and Jepson 1996; Nielsen, Florack, and Deriche 1997; Nordstr¨om 1990; Brox,\nBruhn, Papenberg et al. 2004; Levin, Lischinski, and Weiss 2008). More detailed mathe-\nmatical treatment and additional applications can be found in the applied mathematics and\nstatistics literature (Tikhonov and Arsenin 1977; Engl, Hanke, and Neubauer 1996).\nThe literature on Markov random ﬁelds is truly immense, with publications in related\nﬁelds such as optimization and control theory of which few vision practitioners are even\naware. A good guide to the latest techniques is the book edited by Blake, Kohli, and Rother\n(2010). Other recent articles that contain nice literature reviews or experimental compar-\nisons include (Boykov and Funka-Lea 2006; Szeliski, Zabih, Scharstein et al. 2008; Kumar,\nVeksler, and Torr 2010).\nThe seminal paper on Markov random ﬁelds is the work of Geman and Geman (1984),\nwho introduced this formalism to computer vision researchers and also introduced the no-\ntion of line processes, additional binary variables that control whether smoothness penalties\nare enforced or not. Black and Rangarajan (1996) showed how independent line processes\ncould be replaced with robust pairwise potentials; Boykov, Veksler, and Zabih (2001) devel-\noped iterative binary, graph cut algorithms for optimizing multi-label MRFs; Kolmogorov\nand Zabih (2004) characterized the class of binary energy potentials required for these tech-\nniques to work; and Freeman, Pasztor, and Carmichael (2000) popularized the use of loopy\nbelief propagation for MRF inference. Many more additional references can be found in\nSections 3.7.2 and 5.5, and Appendix B.5.\n3.9 Exercises\nEx 3.1: Color balance\nWrite a simple application to change the color balance of an image\nby multiplying each color value by a different user-speciﬁed constant. If you want to get\nfancy, you can make this application interactive, with sliders.\n1. Do you get different results if you take out the gamma transformation before or after\ndoing the multiplication? Why or why not?\n2. Take the same picture with your digital camera using different color balance settings\n(most cameras control the color balance from one of the menus). Can you recover what\nthe color balance ratios are between the different settings? You may need to put your\ncamera on a tripod and align the images manually or automatically to make this work.\nAlternatively, use a color checker chart (Figure 10.3b), as discussed in Sections 2.3 and\n10.1.1.\n3. If you have access to the RAW image for the camera, perform the demosaicing yourself\n(Section 10.3.1) or downsample the image resolution to get a “true” RGB image. Does",
  "image_path": "page_215.jpg",
  "pages": [
    214,
    215,
    216
  ]
}