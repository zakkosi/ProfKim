{
  "doc_id": "pages_526_528",
  "text": "504\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.36\nTwo-color model computed from a collection of local 5 × 5 neighborhoods\n(Bennett, Uyttendaele, Zitnick et al. 2006) c⃝2006 Springer. After two-means clustering\nand reprojection along the line joining the two dominant colors (red dots), the majority of the\npixels fall near the ﬁtted line. The distribution along the line, projected along the RGB axes,\nis peaked at 0 and 1, the two dominant colors.\ngradient information from the green channel, which is more reliable because it is sampled\nmore densely, to infer plausible values for the red and blue channels, which are more sparsely\nsampled.\nTo reduce color fringing, some techniques perform a color space analysis, e.g., using\nmedian ﬁltering on color opponent channels (Longere, Delahunt, Zhang et al. 2002). The\napproach of Bennett, Uyttendaele, Zitnick et al. (2006) locally forms a two-color model from\nan initial demosaicing result, using a moving 5 × 5 window to ﬁnd the two dominant colors\n(Figure 10.36).21\nOnce the local color model has been estimated at each pixel, a Bayesian approach is\nthen used to encourage pixel values to lie along each color line and to cluster around the\ndominant color values, which reduces halos (Figure 10.35d). The Bayesian approach also\nsupports the simultaneous application of demosaicing and super-resolution, i.e., multiple CFA\ninputs can be merged into a higher-quality full-color image, which becomes more important\nas additional processing becomes incorporated into today’s cameras.\n10.3.2 Application: Colorization\nAlthough not strictly an example of super-resolution, the process of colorization, i.e., manu-\nally adding colors to a “black and white” (grayscale) image, is another example of a sparse\ninterpolation problem. In most applications of colorization, the user draws some scribbles in-\ndicating the desired colors in certain regions (Figure 10.37a) and the system interpolates the\n21 Previous work on locally linear color models (Klinker, Shafer, and Kanade 1990; Omer and Werman 2004)\nfocuses on color and illumination variation within a single material, whereas Bennett, Uyttendaele, Zitnick et al.\n(2006) use the two-color model to describe variations across color (material) edges.\n10.4 Image matting and compositing\n505\n(a)\n(b)\n(c)\nFigure 10.37 Colorization using optimization (Levin, Lischinski, and Weiss 2004) c⃝2004\nACM: (a) grayscale image some color scribbles overlaid; (b) resulting colorized image; (c)\noriginal color image from which the grayscale image and the chrominance values for the\nscribbles were derived. Original photograph by Rotem Weiss.\nspeciﬁed chrominance (u, v) values to the whole image, which are then re-combined with the\ninput luminance channel to produce a ﬁnal colorized image, as shown in Figure 10.37b. In the\nsystem developed by Levin, Lischinski, and Weiss (2004), the interpolation is performed us-\ning locally weighted regularization (3.100), where the local smoothness weights are inversely\nproportional to luminance gradients. This approach to locally weighted regularization has\ninspired later algorithms for high dynamic range tone mapping (Lischinski, Farbman, Uyt-\ntendaele et al. 2006a), see Section 10.2.1, as well as other applications of the weighted least\nsquares (WLS) formulation (Farbman, Fattal, Lischinski et al. 2008). An alternative approach\nto performing the sparse chrominance interpolation based on geodesic (edge-aware) distance\nfunctions has been developed by Yatziv and Sapiro (2006).\n10.4 Image matting and compositing\nImage matting and compositing is the process of cutting a foreground object out of one image\nand pasting it against a new background (Smith and Blinn 1996; Wang and Cohen 2007a).\nIt is commonly used in television and ﬁlm production to composite a live actor in front of\ncomputer-generated imagery such as weather maps or 3D virtual characters and scenery\n(Wright 2006; Brinkmann 2008).\nWe have already seen a number of tools for interactively segmenting objects in an image,\nincluding snakes (Section 5.1.1), scissors (Section 5.1.3), and GrabCut segmentation (Sec-\ntion 5.5). While these techniques can generate reasonable pixel-accurate segmentations, they\nfail to capture the subtle interplay of foreground and background colors at mixed pixels along\nthe boundary (Szeliski and Golland 1999) (Figure 10.38a).\nIn order to successfully copy a foreground object from one image to another without\n506\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.38\nSoftening a hard segmentation boundary (border matting) (Rother, Kol-\nmogorov, and Blake 2004) c⃝2004 ACM: (a) the region surrounding a segmentation bound-\nary where pixels of mixed foreground and background colors are visible; (b) pixel values\nalong the boundary are used to compute a soft alpha matte; (c) at each point along the curve\nt, a displacement ∆and a width σ are estimated.\nvisible discretization artifacts, we need to pull a matte, i.e., to estimate a soft opacity channel\nα and the uncontaminated foreground colors F from the input composite image C. Recall\nfrom Section 3.1.3 (Figure 3.4) that the compositing equation (3.8) can be written as\nC = (1 −α)B + αF.\n(10.30)\nThis operator attenuates the inﬂuence of the background image B by a factor (1 −α) and\nthen adds in the (partial) color values corresponding to the foreground element F.\nWhile the compositing operation is easy to implement, the reverse matting operation of\nestimating F, α, and B given an input image C is much more challenging (Figure 10.39).\nTo see why, observe that while the composite pixel color C provides three measurements,\nthe F, α, and B unknowns have a total of seven degrees of freedom. Devising techniques to\nestimate these unknowns despite the underconstrained nature of the problem is the essence of\nimage matting.\nIn this section, we review a number of image matting techniques. We begin with blue\nscreen matting, which assumes that the background is a constant known color, and discuss its\nvariants, two-screen matting (when multiple backgrounds can be used) and difference matting\n(where the known background is arbitrary). We then discuss local variants of natural image\nmatting, where both the foreground and background are unknown. In these applications, it is\nusual to ﬁrst specify a trimap, i.e., a three-way labeling of the image into foreground, back-\nground, and unknown regions (Figure 10.39b). Next, we present some global optimization\napproaches to natural image matting. Finally, we discuss variants on the matting problem,\nincluding shadow matting, ﬂash matting, and environment matting.",
  "image_path": "page_527.jpg",
  "pages": [
    526,
    527,
    528
  ]
}