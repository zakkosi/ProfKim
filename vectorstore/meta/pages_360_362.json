{
  "doc_id": "pages_360_362",
  "text": "338\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n10. (Optional) Write down a different least squares problem that involves pairwise match-\ning of images. Discuss why this might be better or worse than the global matching\nformula given in (6.12).\nEx 6.3: 2D rigid/Euclidean matching\nSeveral alternative approaches are given in Section 6.1.3\nfor estimating a 2D rigid (Euclidean) alignment.\n1. Implement the various alternatives and compare their accuracy on synthetic data, i.e.,\nrandom 2D point clouds with noisy feature positions.\n2. One approach is to estimate the translations from the centroids and then estimate ro-\ntation in polar coordinates. Do you need to weight the angles obtained from a polar\ndecomposition in some way to get the statistically correct estimate?\n3. How can you modify your techniques to take into account either scalar (6.10) or full\ntwo-dimensional point covariance weightings (6.11)? Do all of the previously devel-\noped “shortcuts” still work or does full weighting require iterative optimization?\nEx 6.4: 2D match move/augmented reality\nReplace a picture in a magazine or a book\nwith a different image or video.\n1. With a webcam, take a picture of a magazine or book page.\n2. Outline a ﬁgure or picture on the page with a rectangle, i.e., draw over the four sides as\nthey appear in the image.\n3. Match features in this area with each new image frame.\n4. Replace the original image with an “advertising” insert, warping the new image with\nthe appropriate homography.\n5. Try your approach on a clip from a sporting event (e.g., indoor or outdoor soccer) to\nimplement a billboard replacement.\nEx 6.5: 3D joystick\nTrack a Rubik’s cube to implement a 3D joystick/mouse control.\n1. Get out an old Rubik’s cube (or get one from your parents).\n2. Write a program to detect the center of each colored square.\n3. Group these centers into lines and then ﬁnd the vanishing points for each face.\n4. Estimate the rotation angle and focal length from the vanishing points.\n6.5 Exercises\n339\n5. Estimate the full 3D pose (including translation) by ﬁnding one or more 3×3 grids and\nrecovering the plane’s full equation from this known homography using the technique\ndeveloped by Zhang (2000).\n6. Alternatively, since you already know the rotation, simply estimate the unknown trans-\nlation from the known 3D corner points on the cube and their measured 2D locations\nusing either linear or non-linear least squares.\n7. Use the 3D rotation and position to control a VRML or 3D game viewer.\nEx 6.6: Rotation-based calibration\nTake an outdoor or indoor sequence from a rotating\ncamera with very little parallax and use it to calibrate the focal length of your camera using\nthe techniques described in Section 6.3.4 or Sections 9.1.3–9.2.1.\n1. Take out any radial distortion in the images using one of the techniques from Exer-\ncises 6.10–6.11 or using parameters supplied for a given camera by your instructor.\n2. Detect and match feature points across neighboring frames and chain them into feature\ntracks.\n3. Compute homographies between overlapping frames and use Equations (6.56–6.57) to\nget an estimate of the focal length.\n4. Compute a full 360◦panorama and update your focal length estimate to close the gap\n(Section 9.1.4).\n5. (Optional) Perform a complete bundle adjustment in the rotation matrices and focal\nlength to obtain the highest quality estimate (Section 9.2.1).\nEx 6.7: Target-based calibration\nUse a three-dimensional target to calibrate your camera.\n1. Construct a three-dimensional calibration pattern with known 3D locations. It is not\neasy to get high accuracy unless you use a machine shop, but you can get close using\nheavy plywood and printed patterns.\n2. Find the corners, e.g, using a line ﬁnder and intersecting the lines.\n3. Implement one of the iterative calibration and pose estimation algorithms described\nin Tsai (1987); Bogart (1991); Gleicher and Witkin (1992) or the system described in\nSection 6.2.2.\n4. Take many pictures at different distances and orientations relative to the calibration\ntarget and report on both your re-projection errors and accuracy. (To do the latter, you\nmay need to use simulated data.)\n340\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 6.8: Calibration accuracy\nCompare the three calibration techniques (plane-based, rotation-\nbased, and 3D-target-based).\nOne approach is to have a different student implement each one and to compare the results.\nAnother approach is to use synthetic data, potentially re-using the software you developed\nfor Exercise 2.3. The advantage of using synthetic data is that you know the ground truth\nfor the calibration and pose parameters, you can easily run lots of experiments, and you can\nsynthetically vary the noise in your measurements.\nHere are some possible guidelines for constructing your test sets:\n1. Assume a medium-wide focal length (say, 50◦ﬁeld of view).\n2. For the plane-based technique, generate a 2D grid target and project it at different\ninclinations.\n3. For a 3D target, create an inner cube corner and position it so that it ﬁlls most of ﬁeld\nof view.\n4. For the rotation technique, scatter points uniformly on a sphere until you get a similar\nnumber of points as for other techniques.\nBefore comparing your techniques, predict which one will be the most accurate (normalize\nyour results by the square root of the number of points used).\nAdd varying amounts of noise to your measurements and describe the noise sensitivity of\nyour various techniques.\nEx 6.9: Single view metrology\nImplement a system to measure dimensions and reconstruct\na 3D model from a single image of a man-made scene using visible vanishing directions (Sec-\ntion 6.3.3) (Criminisi, Reid, and Zisserman 2000).\n1. Find the three orthogonal vanishing points from parallel lines and use them to establish\nthe three coordinate axes (rotation matrix R of the camera relative to the scene). If\ntwo of the vanishing points are ﬁnite (not at inﬁnity), use them to compute the focal\nlength, assuming a known optical center. Otherwise, ﬁnd some other way to calibrate\nyour camera; you could use some of the techniques described by Schaffalitzky and\nZisserman (2000).\n2. Click on a ground plane point to establish your origin and click on a point a known\ndistance away to establish the scene scale. This lets you compute the translation t\nbetween the camera and the scene. As an alternative, click on a pair of points, one\non the ground plane and one above it, and use the known height to establish the scene\nscale.",
  "image_path": "page_361.jpg",
  "pages": [
    360,
    361,
    362
  ]
}