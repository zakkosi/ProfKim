{
  "doc_id": "pages_636_638",
  "text": "614\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nstructure from motion recovery,15 dense depth map estimation, 3D model building, and tex-\nture map recovery. A complete Web-based system for automatically performing all of these\ntasks, called ARC3D, is described by Vergauwen and Van Gool (2006) and Moons, Van Gool,\nand Vergauwen (2010). The latter paper provides not only an in-depth survey of this whole\nﬁeld but also a detailed description of their complete end-to-end system.\nAn alternative to such fully automated systems is to put the user in the loop in what is\nsometimes called interactive computer vision. van den Hengel, Dick, Thormhlen et al. (2007)\ndescribe their VideoTrace system, which performs automated point tracking and 3D structure\nrecovery from video and then lets the user draw triangles and surfaces on top of the resulting\npoint cloud, as well as interactively adjusting the locations of model vertices. Sinha, Steedly,\nSzeliski et al. (2008) describe a related system that uses matched vanishing points in multiple\nimages (Figure 4.45) to infer 3D line orientations and plane normals. These are then used to\nguide the user drawing axis-aligned planes, which are automatically ﬁtted to the recovered\n3D point cloud. Fully automated variants on these ideas are described by Zebedin, Bauer,\nKarner et al. (2008), Furukawa, Curless, Seitz et al. (2009a), Furukawa, Curless, Seitz et al.\n(2009b), Miˇcuˇs´ık and Koˇseck´a (2009), and Sinha, Steedly, and Szeliski (2009).\nAs the sophistication and reliability of these techniques continues to improve, we can ex-\npect to see even more user-friendly applications for photorealistic 3D modeling from images\n(Exercise 12.8).\n12.8 Additional reading\nShape from shading is one of the classic problems in computer vision (Horn 1975). Some\nrepresentative papers in this area include those by Horn (1977), Ikeuchi and Horn (1981),\nPentland (1984), Horn and Brooks (1986), Horn (1990), Szeliski (1991a), Mancini and Wolff\n(1992), Dupuis and Oliensis (1994), and Fua and Leclerc (1995). The collection of papers\nedited by Horn and Brooks (1989) is a great source of information on this topic, especially\nthe chapter on variational approaches. The survey by Zhang, Tsai, Cryer et al. (1999) not\nonly reviews more recent techniques but also provides some comparative results.\nWoodham (1981) wrote the seminal paper of photometric stereo. Shape from texture\ntechniques include those by Witkin (1981), Ikeuchi (1981), Blostein and Ahuja (1987), Gard-\ning (1992), Malik and Rosenholtz (1997), Liu, Collins, and Tsin (2004), Liu, Lin, and Hays\n(2004), Hays, Leordeanu, Efros et al. (2006), Lin, Hays, Wu et al. (2006), Lobay and Forsyth\n(2006), White and Forsyth (2006), White, Crane, and Forsyth (2007), and Park, Brockle-\nhurst, Collins et al. (2009). Good papers and books on depth from defocus have been written\nby Pentland (1987), Nayar and Nakagawa (1994), Nayar, Watanabe, and Noguchi (1996),\n15 These earlier steps are also discussed in Section 7.4.4.\n12.8 Additional reading\n615\nWatanabe and Nayar (1998), Chaudhuri and Rajagopalan (1999), and Favaro and Soatto\n(2006). Additional techniques for recovering shape from various kinds of illumination ef-\nfects, including inter-reﬂections (Nayar, Ikeuchi, and Kanade 1991), are discussed in the\nbook on shape recovery edited by Wolff, Shafer, and Healey (1992b).\nActive rangeﬁnding systems, which use laser or natural light illumination projected into\nthe scene, have been described by Besl (1989), Rioux and Bird (1993), Kang, Webb, Zit-\nnick et al. (1995), Curless and Levoy (1995), Curless and Levoy (1996), Proesmans, Van\nGool, and Defoort (1998), Bouguet and Perona (1999), Curless (1999), Hebert (2000), Id-\ndan and Yahav (2001), Goesele, Fuchs, and Seidel (2003), Scharstein and Szeliski (2003),\nDavis, Ramamoorthi, and Rusinkiewicz (2003), Zhang, Curless, and Seitz (2003), Zhang,\nSnavely, Curless et al. (2004), and Moons, Van Gool, and Vergauwen (2010). Individual\nrange scans can be aligned using 3D correspondence and distance optimization techniques\nsuch as iterated closest points and its variants (Besl and McKay 1992; Zhang 1994; Szeliski\nand Lavall´ee 1996; Johnson and Kang 1997; Gold, Rangarajan, Lu et al. 1998; Johnson\nand Hebert 1999; Pulli 1999; David, DeMenthon, Duraiswami et al. 2004; Li and Hartley\n2007; Enqvist, Josephson, and Kahl 2009). Once they have been aligned, range scans can\nbe merged using techniques that model the signed distance of surfaces to volumetric sam-\nple points (Hoppe, DeRose, Duchamp et al. 1992; Curless and Levoy 1996; Hilton, Stoddart,\nIllingworth et al. 1996; Wheeler, Sato, and Ikeuchi 1998; Kazhdan, Bolitho, and Hoppe 2006;\nLempitsky and Boykov 2007; Zach, Pock, and Bischof 2007b; Zach 2008).\nOnce constructed, 3D surfaces can be modeled and manipulated using a variety of three-\ndimensional representations, which include triangle meshes (Eck, DeRose, Duchamp et al.\n1995; Hoppe 1996), splines (Farin 1992, 1996; Lee, Wolberg, and Shin 1996), subdivision\nsurfaces (Stollnitz, DeRose, and Salesin 1996; Zorin, Schr¨oder, and Sweldens 1996; Warren\nand Weimer 2001; Peters and Reif 2008), and geometry images (Gu, Gortler, and Hoppe\n2002). Alternatively, they can be represented as collections of point samples with local ori-\nentation estimates (Hoppe, DeRose, Duchamp et al. 1992; Szeliski and Tonnesen 1992; Turk\nand O’Brien 2002; Pﬁster, Zwicker, van Baar et al. 2000; Alexa, Behr, Cohen-Or et al. 2003;\nPauly, Keiser, Kobbelt et al. 2003; Diebel, Thrun, and Br¨unig 2006; Guennebaud and Gross\n2007; Guennebaud, Germann, and Gross 2008; Oztireli, Guennebaud, and Gross 2008). They\ncan also be modeled using implicit inside–outside characteristic or signed distance functions\nsampled on regular or irregular (octree) volumetric grids (Lavall´ee and Szeliski 1995; Szeliski\nand Lavall´ee 1996; Frisken, Perry, Rockwood et al. 2000; Dinh, Turk, and Slabaugh 2002;\nKazhdan, Bolitho, and Hoppe 2006; Lempitsky and Boykov 2007; Zach, Pock, and Bischof\n2007b; Zach 2008).\nThe literature on model-based 3D reconstruction is extensive. For modeling architecture\nand urban scenes, both interactive and fully automated systems have been developed. A\nspecial journal issue devoted to the reconstruction of large-scale 3D scenes (Zhu and Kanade\n616\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n2008) is a good source of references and Robertson and Cipolla (2009) give a nice description\nof a complete system. Lots of additional references can be found in Section 12.6.1.\nFace and whole body modeling and tracking is a very active sub-ﬁeld of computer vision,\nwith its own conferences and workshops, e.g., the International Conference on Automatic\nFace and Gesture Recognition (FG), the IEEE Workshop on Analysis and Modeling of Faces\nand Gestures, and the International Workshop on Tracking Humans for the Evaluation of their\nMotion in Image Sequences (THEMIS). Recent survey articles on the topic of whole body\nmodeling and tracking include those by Forsyth, Arikan, Ikemoto et al. (2006), Moeslund,\nHilton, and Kr¨uger (2006), and Sigal, Balan, and Black (2010).\n12.9 Exercises\nEx 12.1: Shape from focus\nGrab a series of focused images with a digital SLR set to man-\nual focus (or get one that allows for programmatic focus control) and recover the depth of an\nobject.\n1. Take some calibration images, e.g., of a checkerboard, so you can compute a mapping\nbetween the amount of defocus and the focus setting.\n2. Try both a fronto-parallel planar target and one which is slanted so that it covers the\nworking range of the sensor. Which one works better?\n3. Now put a real object in the scene and perform a similar focus sweep.\n4. For each pixel, compute the local sharpness and ﬁt a parabolic curve over focus settings\nto ﬁnd the most in-focus setting.\n5. Map these focus settings to depth and compare your result to ground truth. If you are\nusing a known simple object, such as sphere or cylinder (a ball or a soda can), it’s easy\nto measure its true shape.\n6. (Optional) See if you can recover the depth map from just two or three focus settings.\n7. (Optional) Use an LCD projector to project artiﬁcial texture onto the scene. Use a pair\nof cameras to compare the accuracy of your shape from focus and shape from stereo\ntechniques.\n8. (Optional) Create an all-in-focus image using the technique of Agarwala, Dontcheva,\nAgrawala et al. (2004).\nEx 12.2: Shadow striping\nImplement the handheld shadow striping system of Bouguet\nand Perona (1999). The basic steps include the following.",
  "image_path": "page_637.jpg",
  "pages": [
    636,
    637,
    638
  ]
}