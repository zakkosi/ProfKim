{
  "doc_id": "pages_225_227",
  "text": "3.9 Exercises\n203\nFigure 3.66 There is a faint image of a rainbow visible in the right hand side of this picture.\nCan you think of a way to enhance it (Exercise 3.29)?\n2. Shift drag (rubber-band) to crop a subregion (or select whole image).\n3. Paste into the current canvas.\n4. Select the deformation mode (motion model): translation, rigid, similarity, afﬁne, or\nperspective.\n5. Drag any corner of the outline to change its transformation.\n6. (Optional) Change the relative ordering of the images and which image is currently\nbeing manipulated.\nThe user should see the composition of the various images’ pieces on top of each other.\nThis exercise should be built on the image transformation classes supported in the soft-\nware library. Persistence of the created representation (save and load) should also be sup-\nported (for each image, save its transformation).\nEx 3.27: 3D texture-mapped viewer\nExtend the viewer you created in Exercise 2.3 to in-\nclude texture-mapped polygon rendering. Augment each polygon with (u, v, w) coordinates\ninto an image.\nEx 3.28: Image denoising\nImplement at least two of the various image denoising tech-\nniques described in this chapter and compare them on both synthetically noised image se-\nquences and real-world (low-light) sequences. Does the performance of the algorithm de-\npend on the correct choice of noise level estimate? Can you draw any conclusions as to\nwhich techniques work better?\n204\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 3.29: Rainbow enhancer—challenging\nTake a picture containing a rainbow, such as\nFigure 3.66, and enhance the strength (saturation) of the rainbow.\n1. Draw an arc in the image delineating the extent of the rainbow.\n2. Fit an additive rainbow function (explain why it is additive) to this arc (it is best to work\nwith linearized pixel values), using the spectrum as the cross section, and estimating\nthe width of the arc and the amount of color being added. This is the trickiest part of\nthe problem, as you need to tease apart the (low-frequency) rainbow pattern and the\nnatural image hiding behind it.\n3. Amplify the rainbow signal and add it back into the image, re-applying the gamma\nfunction if necessary to produce the ﬁnal image.\nEx 3.30: Image deblocking—challenging\nNow that you have some good techniques to\ndistinguish signal from noise, develop a technique to remove the blocking artifacts that occur\nwith JPEG at high compression settings (Section 2.3.3). Your technique can be as simple\nas looking for unexpected edges along block boundaries, to looking at the quantization step\nas a projection of a convex region of the transform coefﬁcient space onto the corresponding\nquantized values.\n1. Does the knowledge of the compression factor, which is available in the JPEG header\ninformation, help you perform better deblocking?\n2. Because the quantization occurs in the DCT transformed YCbCr space (2.115), it may\nbe preferable to perform the analysis in this space. On the other hand, image priors\nmake more sense in an RGB space (or do they?). Decide how you will approach this\ndichotomy and discuss your choice.\n3. While you are at it, since the YCbCr conversion is followed by a chrominance subsam-\npling stage (before the DCT), see if you can restore some of the lost high-frequency\nchrominance signal using one of the better restoration techniques discussed in this\nchapter.\n4. If your camera has a RAW + JPEG mode, how close can you come to the noise-free\ntrue pixel values? (This suggestion may not be that useful, since cameras generally use\nreasonably high quality settings for their RAW + JPEG models.)\nEx 3.31: Inference in de-blurring—challenging\nWrite down the graphical model corre-\nsponding to Figure 3.59 for a non-blind image deblurring problem, i.e., one where the blur\nkernel is known ahead of time.\nWhat kind of efﬁcient inference (optimization) algorithms can you think of for solving\nsuch problems?\nChapter 4\nFeature detection and matching\n4.1\nPoints and patches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n4.1.1\nFeature detectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\n4.1.2\nFeature descriptors . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\n4.1.3\nFeature matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\n4.1.4\nFeature tracking\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\n4.1.5\nApplication: Performance-driven animation . . . . . . . . . . . . . . 237\n4.2\nEdges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n4.2.1\nEdge detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n4.2.2\nEdge linking\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\n4.2.3\nApplication: Edge editing and enhancement . . . . . . . . . . . . . . 249\n4.3\nLines\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\n4.3.1\nSuccessive approximation\n. . . . . . . . . . . . . . . . . . . . . . . 250\n4.3.2\nHough transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\n4.3.3\nVanishing points\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 254\n4.3.4\nApplication: Rectangle detection . . . . . . . . . . . . . . . . . . . . 257\n4.4\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257\n4.5\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259",
  "image_path": "page_226.jpg",
  "pages": [
    225,
    226,
    227
  ]
}