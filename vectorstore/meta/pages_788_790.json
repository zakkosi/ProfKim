{
  "doc_id": "pages_788_790",
  "text": "766\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nprobability\np(x) ∝e−E(x)/T ,\n(B.25)\nwhere T is called the temperature and controls how likely the system is to choose a more\nrandom update. Stochastic gradient descent is usually combined with simulated annealing\n(Kirkpatrick, Gelatt, and Vecchi 1983), which starts at a relatively high temperature, thereby\nrandomly exploring a large part of the state space, and gradually cools (anneals) the tem-\nperature to ﬁnd a good local minimum. During the late 1980s, simulated annealing was the\nmethod of choice for solving MRF inference problems (Szeliski 1986; Marroquin, Mitter,\nand Poggio 1985; Barnard 1989).\nAnother variant on simulated annealing is the Swendsen–Wang algorithm (Swendsen and\nWang 1987; Barbu and Zhu 2003, 2005). Here, instead of “ﬂipping” (changing) single vari-\nables, a connected subset of variables, chosen using a random walk based on MRF connec-\ntively strengths, is selected as the basic update unit. This can sometimes help make larger\nstate changes, and hence ﬁnd better-quality solutions in less time.\nWhile simulated annealing has largely been superseded by the newer graph cuts and loopy\nbelief propagation techniques, it still occasionally ﬁnds use, especially in highly connected\nand highly non-submodular graphs (Rother, Kolmogorov, Lempitsky et al. 2007).\nB.5.2 Dynamic programming\nDynamic programming (DP) is an efﬁcient inference procedure that works for any tree-\nstructured graphical model, i.e., one that does not have any cycles. Given such a tree, pick\nany node as the root r and ﬁguratively pick up the tree by its root. The depth or distance of all\nthe other nodes from this root induces a partial ordering over the vertices, from which a total\nordering can be obtained by arbitrarily breaking ties. Let us now lay out this graph as a tree\nwith the root on the right and indices increasing from left to right, as shown in Figure B.2a.\nBefore describing the DP algorithm, let us re-write the potential function of Equation (B.24)\nin a more general but succinct form,\nE(x) =\nX\n(i,j)∈N\nVi,j(xi, xj) +\nX\ni\nVi(xi),\n(B.26)\nwhere instead of using pixel indices (i, j) and (k, l), we just use scalar index variables i\nand j. We also replace the function value f(i, j) with the more succinct notation xi, with\nthe {xi} variables making up the state vector x. We can simplify this function even further\nby adding dummy nodes (vertices) i−for every node that has a non-zero Vi(xi) and setting\nVi,i−(xi, xi−) = Vi(xi), which lets us drop the Vi terms from (B.26).\nDynamic programming proceeds by computing partial sums in a left-to-right fashion, i.e.,\nin order of increasing variable index. Let Ck be the children of k, i.e., i < k, (i, k) ∈N).\nB.5 Markov random ﬁelds\n767\nxk\nVik\nxj\nxi\nVjk\n...\n...\n...\nxr\nVij\nxk\nVijk\nxj\nxi\n...\n...\n...\n(a)\n(b)\nFigure B.2\nDynamic programming over a tree drawn as a factor graph. (a) To compute\nthe lowest energy solution ˆEk(xk) at node xk conditioned on the best solutions to the left\nof this node, we enumerate all possible values of ˆEi(xi) + Vik(xi, xk) and pick the smallest\none (and similarly for j). (b) For higher-order cliques, we need to try all combinations of\n(xi, xj) in order to select the best possible conﬁguration. The arrows show the basic ﬂow\nof the computation. The lightly shaded factor Vij in (a) shows an additional connection that\nturns the tree into a cyclic graph, for which exact inference cannot be efﬁciently computed.\nThen, deﬁne\n˜Ek(x) =\nX\ni<k, j≤k\nVi,j(xi, xj) =\nX\ni∈Ck\nh\nVi,k(xi, xk) + ˜Ei(x)\ni\n,\n(B.27)\nas a partial sum of (B.26) over all variables up to and including k, i.e., over all parts of the\ngraph shown in Figure B.2a to the left of xk. This sum depends on the state of all the unknown\nvariables in x with i ≤k.\nNow suppose we wish to ﬁnd the setting for all variables i < k that minimizes this sum.\nIt turns out that we can use a simple recursive formula\nˆEk(xk) =\nmin\n{xi, i<k}\n˜Ek(x) =\nX\ni∈Ck\nmin\nxi\nh\nVi,k(xi, xk) + ˆEi(xi)\ni\n(B.28)\nto ﬁnd this minimum. Visually, this is easy to understand. Looking at Figure B.2a, associate\nan energy ˆEk(xk) with each node k and each possible setting of its value xk that is based on\nthe best possible setting of variables to the left of that node. It is easy to convince yourself\nthat in this ﬁgure, you only need to know ˆEi(xi) and ˆEj(xj) in order to compute this value.\nOnce the ﬂow of information in the tree has been processed from left to right, the min-\nimum value of ˆEr(xr) at the root gives the MAP (lowest-energy) solution for E(x). The\nroot node is set to the choice of xr that minimizes this function, and other nodes are set in a\nbackward chaining pass by selecting the values of child nodes i ∈Ck that were minimal in\nthe original recursion (B.28).\n768\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nDynamic programming is not restricted to trees with pairwise potentials. Figure B.2b\nshows an example of a three-way potential Vijk(xi, xj, xk) inside a tree. To compute the\noptimum value of ˆEk(xk), the recursion formula in (B.28) now has to evaluate the mini-\nmum over all combinations of possible state values leading into a factor node (gray box).\nFor this reason, dynamic programming is normally exponential in complexity in the order\nof the clique size, i.e., a clique of size n with l labels at each node requires the evaluation\nof ln−1 possible states (Potetz and Lee 2008; Kohli, Kumar, and Torr 2009). However, for\ncertain kinds of potential functions Vi,k(xi, xk), including the Potts model (delta function),\nabsolute values (total variation), and quadratic (Gaussian MRF), Felzenszwalb and Hutten-\nlocher (2006) show how to reduce the complexity of the min-ﬁnding step (B.28) from O(l2)\nto O(l). In Appendix B.5.3, we also discuss how Potetz and Lee (2008) reduce the complexity\nfor special kinds of higher-order clique, i.e., linear summations followed by non-linearities.\nFigure B.2a also shows what happens if we add an extra factor between nodes i and j.\nIn this case, the graph is no longer a tree, i.e., it contains a cycle. It is no longer possible\nto use the recursion formula (B.28), since ˆEi(xi) now appears in two different terms inside\nthe summation, i.e., as a child of both nodes j and k, and the same setting for xi may not\nminimize both. In other words, when loops exist, there is no ordering of the variables that\nallows the recursion (elimination) in (B.28) to be well-founded.\nIt is, however, possible to convert small loops into higher-order factors and to solve these\nas shown in Figure B.2b. However, graphs with long loops or meshes result in extremely\nlarge clique sizes and hence an amount of computation potentially exponential in the size of\nthe graph.\nB.5.3 Belief propagation\nBelief propagation is an inference technique originally developed for trees (Pearl 1988) but\nmore recently extended to “loopy” (cyclic) graphs such as MRFs (Frey and MacKay 1997;\nFreeman, Pasztor, and Carmichael 2000; Yedidia, Freeman, and Weiss 2001; Weiss and Free-\nman 2001a,b; Yuille 2002; Sun, Zheng, and Shum 2003; Felzenszwalb and Huttenlocher\n2006). It is closely related to dynamic programming, in that both techniques pass messages\nforward and backward over a tree or graph. In fact, one of the two variants of belief prop-\nagation, the max-product rule, performs the exact same computation (inference) as dynamic\nprogramming, albeit using probabilities instead of energies.\nRecall that the energy we are minimizing in MAP estimation (B.26) is the negative log\nlikelihood (B.12, B.13, and B.22) of a factored Gibbs posterior distribution,\np(x) =\nY\n(i,j)∈N\nφi,j(xi, xj),\n(B.29)",
  "image_path": "page_789.jpg",
  "pages": [
    788,
    789,
    790
  ]
}