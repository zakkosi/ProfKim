{
  "doc_id": "pages_423_425",
  "text": "8.2 Parametric motion\n401\nIf the appearance of the warped and template images is similar enough, we can replace\nthe gradient of ˜I1(x) with the gradient of I0(x), as suggested previously (8.43). This has po-\ntentially a big advantage in that it allows the pre-computation (and inversion) of the Hessian\nmatrix A given in Equation (8.53). The residual vector b (8.54) can also be partially precom-\nputed, i.e., the steepest descent images ∇I0(x)J ˜x(x) can precomputed and stored for later\nmultiplication with the e(x) = ˜I1(x)−I0(x) error images (Baker and Matthews 2004). This\nidea was ﬁrst suggested by Hager and Belhumeur (1998) in what Baker and Matthews (2004)\ncall a inverse additive scheme.\nBaker and Matthews (2004) introduce one more variant they call the inverse composi-\ntional algorithm. Rather than (conceptually) re-warping the warped target image ˜I1(x), they\ninstead warp the template image I0(x) and minimize\nELK−BM(∆p)\n=\nX\ni\n[˜I1(xi) −I0(˜x(xi; ∆p))]2\n(8.64)\n≈\nX\ni\n[∇I0(xi)J ˜x(xi)∆p −ei]2.\n(8.65)\nThis is identical to the forward warped algorithm (8.62) with the gradients ∇˜I1(x) replaced\nby the gradients ∇I0(x), except for the sign of ei. The resulting update ∆p is the negative of\nthe one computed by the modiﬁed Equation (8.62) and hence the inverse of the incremental\ntransformation must be prepended to the current transform. Because the inverse composi-\ntional algorithm has the potential of pre-computing the inverse Hessian and the steepest de-\nscent images, this makes it the preferred approach of those surveyed by Baker and Matthews\n(2004). Figure 8.5 (Baker, Gross, Ishikawa et al. 2003) beautifully shows all of the steps\nrequired to implement the inverse compositional algorithm.\nBaker and Matthews (2004) also discuss the advantage of using Gauss–Newton iteration\n(i.e., the ﬁrst-order expansion of the least squares, as above) compared to other approaches\nsuch as steepest descent and Levenberg–Marquardt. Subsequent parts of the series (Baker,\nGross, Ishikawa et al. 2003; Baker, Gross, and Matthews 2003, 2004) discuss more advanced\ntopics such as per-pixel weighting, pixel selection for efﬁciency, a more in-depth discussion of\nrobust metrics and algorithms, linear appearance variations, and priors on parameters. They\nmake for invaluable reading for anyone interested in implementing a highly tuned imple-\nmentation of incremental image registration. Evangelidis and Psarakis (2008) provide some\ndetailed experimental evaluations of these and other related approaches.\n8.2.1 Application: Video stabilization\nVideo stabilization is one of the most widely used applications of parametric motion esti-\nmation (Hansen, Anandan, Dana et al. 1994; Irani, Rousso, and Peleg 1997; Morimoto and\n402\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 8.5\nA schematic overview of the inverse compositional algorithm (copied, with\npermission, from (Baker, Gross, Ishikawa et al. 2003)). Steps 3–6 (light-colored arrows) are\nperformed once as a pre-computation. The main algorithm simply consists of iterating: image\nwarping (Step 1), image differencing (Step 2), image dot products (Step 7), multiplication\nwith the inverse of the Hessian (Step 8), and the update to the warp (Step 9). All of these\nsteps can be performed efﬁciently.\n8.2 Parametric motion\n403\nChellappa 1997; Srinivasan, Chellappa, Veeraraghavan et al. 2005). Algorithms for stabiliza-\ntion run inside both hardware devices, such as camcorders and still cameras, and software\npackages for improving the visual quality of shaky videos.\nIn their paper on full-frame video stabilization, Matsushita, Ofek, Ge et al. (2006) give\na nice overview of the three major stages of stabilization, namely motion estimation, motion\nsmoothing, and image warping. Motion estimation algorithms often use a similarity trans-\nform to handle camera translations, rotations, and zooming. The tricky part is getting these\nalgorithms to lock onto the background motion, which is a result of the camera movement,\nwithout getting distracted by independent moving foreground objects. Motion smoothing al-\ngorithms recover the low-frequency (slowly varying) part of the motion and then estimate\nthe high-frequency shake component that needs to be removed. Finally, image warping algo-\nrithms apply the high-frequency correction to render the original frames as if the camera had\nundergone only the smooth motion.\nThe resulting stabilization algorithms can greatly improve the appearance of shaky videos\nbut they often still contain visual artifacts. For example, image warping can result in missing\nborders around the image, which must be cropped, ﬁlled using information from other frames,\nor hallucinated using inpainting techniques (Section 10.5.1). Furthermore, video frames cap-\ntured during fast motion are often blurry. Their appearance can be improved either using\ndeblurring techniques (Section 10.3) or stealing sharper pixels from other frames with less\nmotion or better focus (Matsushita, Ofek, Ge et al. 2006). Exercise 8.3 has you implement\nand test some of these ideas.\nIn situations where the camera is translating a lot in 3D, e.g., when the videographer is\nwalking, an even better approach is to compute a full structure from motion reconstruction\nof the camera motion and 3D scene. A smooth 3D camera path can then be computed and\nthe original video re-rendered using view interpolation with the interpolated 3D point cloud\nserving as the proxy geometry while preserving salient features (Liu, Gleicher, Jin et al.\n2009). If you have access to a camera array instead of a single video camera, you can do even\nbetter using a light ﬁeld rendering approach (Section 13.3) (Smith, Zhang, Jin et al. 2009).\n8.2.2 Learned motion models\nAn alternative to parameterizing the motion ﬁeld with a geometric deformation such as an\nafﬁne transform is to learn a set of basis functions tailored to a particular application (Black,\nYacoob, Jepson et al. 1997). First, a set of dense motion ﬁelds (Section 8.4) is computed from\na set of training videos. Next, singular value decomposition (SVD) is applied to the stack of\nmotion ﬁelds ut(x) to compute the ﬁrst few singular vectors vk(x). Finally, for a new test\nsequence, a novel ﬂow ﬁeld is computed using a coarse-to-ﬁne algorithm that estimates the",
  "image_path": "page_424.jpg",
  "pages": [
    423,
    424,
    425
  ]
}