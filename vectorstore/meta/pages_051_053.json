{
  "doc_id": "pages_051_053",
  "text": "Chapter 2\nImage formation\n2.1\nGeometric primitives and transformations . . . . . . . . . . . . . . . . . . .\n31\n2.1.1\nGeometric primitives . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n2.1.2\n2D transformations . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n2.1.3\n3D transformations . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n2.1.4\n3D rotations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n2.1.5\n3D to 2D projections . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n2.1.6\nLens distortions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n58\n2.2\nPhotometric image formation . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n2.2.1\nLighting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n2.2.2\nReﬂectance and shading . . . . . . . . . . . . . . . . . . . . . . . .\n62\n2.2.3\nOptics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n68\n2.3\nThe digital camera\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n73\n2.3.1\nSampling and aliasing\n. . . . . . . . . . . . . . . . . . . . . . . . .\n77\n2.3.2\nColor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n80\n2.3.3\nCompression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n90\n2.4\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n93\n2.5\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n93\n30\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nn^\n(a)\n(b)\nzi=102mm\nf = 100mm\nzo=5m\nd\nG\nR\nG\nR\nB\nG\nB\nG\nG\nR\nG\nR\nB\nG\nB\nG\n(c)\n(d)\nFigure 2.1\nA few components of the image formation process: (a) perspective projection;\n(b) light scattering when hitting a surface; (c) lens optics; (d) Bayer color ﬁlter array.\n2.1 Geometric primitives and transformations\n31\nBefore we can intelligently analyze and manipulate images, we need to establish a vocabulary\nfor describing the geometry of a scene. We also need to understand the image formation\nprocess that produced a particular image given a set of lighting conditions, scene geometry,\nsurface properties, and camera optics. In this chapter, we present a simpliﬁed model of such\nan image formation process.\nSection 2.1 introduces the basic geometric primitives used throughout the book (points,\nlines, and planes) and the geometric transformations that project these 3D quantities into 2D\nimage features (Figure 2.1a). Section 2.2 describes how lighting, surface properties (Fig-\nure 2.1b), and camera optics (Figure 2.1c) interact in order to produce the color values that\nfall onto the image sensor. Section 2.3 describes how continuous color images are turned into\ndiscrete digital samples inside the image sensor (Figure 2.1d) and how to avoid (or at least\ncharacterize) sampling deﬁciencies, such as aliasing.\nThe material covered in this chapter is but a brief summary of a very rich and deep set of\ntopics, traditionally covered in a number of separate ﬁelds. A more thorough introduction to\nthe geometry of points, lines, planes, and projections can be found in textbooks on multi-view\ngeometry (Hartley and Zisserman 2004; Faugeras and Luong 2001) and computer graphics\n(Foley, van Dam, Feiner et al. 1995). The image formation (synthesis) process is traditionally\ntaught as part of a computer graphics curriculum (Foley, van Dam, Feiner et al. 1995; Glass-\nner 1995; Watt 1995; Shirley 2005) but it is also studied in physics-based computer vision\n(Wolff, Shafer, and Healey 1992a). The behavior of camera lens systems is studied in optics\n(M¨oller 1988; Hecht 2001; Ray 2002). Two good books on color theory are (Wyszecki and\nStiles 2000; Healey and Shafer 1992), with (Livingstone 2008) providing a more fun and in-\nformal introduction to the topic of color perception. Topics relating to sampling and aliasing\nare covered in textbooks on signal and image processing (Crane 1997; J¨ahne 1997; Oppen-\nheim and Schafer 1996; Oppenheim, Schafer, and Buck 1999; Pratt 2007; Russ 2007; Burger\nand Burge 2008; Gonzales and Woods 2008).\nA note to students: If you have already studied computer graphics, you may want to\nskim the material in Section 2.1, although the sections on projective depth and object-centered\nprojection near the end of Section 2.1.5 may be new to you. Similarly, physics students (as\nwell as computer graphics students) will mostly be familiar with Section 2.2. Finally, students\nwith a good background in image processing will already be familiar with sampling issues\n(Section 2.3) as well as some of the material in Chapter 3.\n2.1 Geometric primitives and transformations\nIn this section, we introduce the basic 2D and 3D primitives used in this textbook, namely\npoints, lines, and planes. We also describe how 3D features are projected into 2D features.",
  "image_path": "page_052.jpg",
  "pages": [
    51,
    52,
    53
  ]
}