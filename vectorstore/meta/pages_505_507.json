{
  "doc_id": "pages_505_507",
  "text": "10.2 High dynamic range imaging\n483\n(a)\n(b)\nFigure 10.14\nRecovered response function and radiance image for a real digital camera\n(DCS460) (Debevec and Malik 1997) c⃝1997 ACM.\nFigure 10.14 shows the recovered radiometric response function for a digital camera along\nwith select (relative) radiance values in the overall radiance map. Figure 10.15 shows the\nbracketed input images captured on color ﬁlm and the corresponding radiance map.\nWhile Debevec and Malik (1997) use a general second-order smooth curve g to parame-\nterize their response curve, Mann and Picard (1995) use a three-parameter function\nf(E) = α + βEγ,\n(10.9)\nwhile Mitsunaga and Nayar (1999) use a low-order (N ≤10) polynomial for the inverse\nresponse function g. Pal, Szeliski, Uyttendaele et al. (2004) derive a Bayesian model that\nestimates an independent smooth response function for each image, which can better model\nthe more sophisticated (and hence less predictable) automatic contrast and tone adjustment\nperformed in today’s digital cameras.\nOnce the response function has been estimated, the second step in creating high dynamic\nrange photographs is to merge the input images into a composite radiance map. If the re-\nsponse function and images were known exactly, i.e., if they were noise free, you could use\nany non-saturated pixel value to estimate the corresponding radiance by mapping it through\nthe inverse response curve E = g(z).\nUnfortunately, pixels are noisy, especially under low-light conditions when fewer photons\narrive at the sensor. To compensate for this, Mann and Picard (1995) use the derivative of\nthe response function as a weight in determining the ﬁnal radiance estimate, since “ﬂatter”\nregions of the curve tell us less about the incoming irradiance. Debevec and Malik (1997)\nuse a hat function (10.7) which accentuates mid-tone pixels while avoiding saturated values.\nMitsunaga and Nayar (1999) show that in order to maximize the signal-to-noise ratio (SNR),\n484\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.15\nBracketed set of exposures captured with a ﬁlm camera and the resulting\nradiance image displayed in pseudocolor (Debevec and Malik 1997) c⃝1997 ACM.\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 10.16\nMerging multiple exposures to create a high dynamic range composite (Kang,\nUyttendaele, Winder et al. 2003): (a–c) three different exposures; (d) merging the exposures\nusing classic algorithms (note the ghosting due to the horse’s head movement); (e) merging\nthe exposures with motion compensation.\n10.2 High dynamic range imaging\n485\n(a)\n(b)\n(c)\nFigure 10.17 HDR merging with large amounts of motion (Eden, Uyttendaele, and Szeliski\n2006) c⃝2006 IEEE: (a) registered bracketed input images; (b) results after the ﬁrst pass of\nimage selection: reference labels, image, and tone-mapped image; (c) results after the second\npass of image selection: ﬁnal labels, compressed HDR image, and tone-mapped image\nthe weighting function must emphasize both higher pixel values and larger gradients in the\ntransfer function, i.e.,\nw(z) = g(z)/g′(z),\n(10.10)\nwhere the weights w are used to form the ﬁnal irradiance estimate\nlog Ei =\nP\nj w(zij)[g(zij) −log tj]\nP\nj w(zij)\n.\n(10.11)\nExercise 10.1 has you implement one of the radiometric response function calibration tech-\nniques and then use it to create radiance maps.\nUnder real-world conditions, casually acquired images may not be perfectly registered\nand may contain moving objects. Ward (2003) uses a global (parametric) transform to align\nthe input images, while Kang, Uyttendaele, Winder et al. (2003) present an algorithm that\ncombines global registration with local motion estimation (optical ﬂow) to accurately align\nthe images before blending their radiance estimates (Figure 10.16). Since the images may",
  "image_path": "page_506.jpg",
  "pages": [
    505,
    506,
    507
  ]
}