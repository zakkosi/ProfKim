{
  "doc_id": "pages_789_791",
  "text": "B.5 Markov random ﬁelds\n767\nxk\nVik\nxj\nxi\nVjk\n...\n...\n...\nxr\nVij\nxk\nVijk\nxj\nxi\n...\n...\n...\n(a)\n(b)\nFigure B.2\nDynamic programming over a tree drawn as a factor graph. (a) To compute\nthe lowest energy solution ˆEk(xk) at node xk conditioned on the best solutions to the left\nof this node, we enumerate all possible values of ˆEi(xi) + Vik(xi, xk) and pick the smallest\none (and similarly for j). (b) For higher-order cliques, we need to try all combinations of\n(xi, xj) in order to select the best possible conﬁguration. The arrows show the basic ﬂow\nof the computation. The lightly shaded factor Vij in (a) shows an additional connection that\nturns the tree into a cyclic graph, for which exact inference cannot be efﬁciently computed.\nThen, deﬁne\n˜Ek(x) =\nX\ni<k, j≤k\nVi,j(xi, xj) =\nX\ni∈Ck\nh\nVi,k(xi, xk) + ˜Ei(x)\ni\n,\n(B.27)\nas a partial sum of (B.26) over all variables up to and including k, i.e., over all parts of the\ngraph shown in Figure B.2a to the left of xk. This sum depends on the state of all the unknown\nvariables in x with i ≤k.\nNow suppose we wish to ﬁnd the setting for all variables i < k that minimizes this sum.\nIt turns out that we can use a simple recursive formula\nˆEk(xk) =\nmin\n{xi, i<k}\n˜Ek(x) =\nX\ni∈Ck\nmin\nxi\nh\nVi,k(xi, xk) + ˆEi(xi)\ni\n(B.28)\nto ﬁnd this minimum. Visually, this is easy to understand. Looking at Figure B.2a, associate\nan energy ˆEk(xk) with each node k and each possible setting of its value xk that is based on\nthe best possible setting of variables to the left of that node. It is easy to convince yourself\nthat in this ﬁgure, you only need to know ˆEi(xi) and ˆEj(xj) in order to compute this value.\nOnce the ﬂow of information in the tree has been processed from left to right, the min-\nimum value of ˆEr(xr) at the root gives the MAP (lowest-energy) solution for E(x). The\nroot node is set to the choice of xr that minimizes this function, and other nodes are set in a\nbackward chaining pass by selecting the values of child nodes i ∈Ck that were minimal in\nthe original recursion (B.28).\n768\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nDynamic programming is not restricted to trees with pairwise potentials. Figure B.2b\nshows an example of a three-way potential Vijk(xi, xj, xk) inside a tree. To compute the\noptimum value of ˆEk(xk), the recursion formula in (B.28) now has to evaluate the mini-\nmum over all combinations of possible state values leading into a factor node (gray box).\nFor this reason, dynamic programming is normally exponential in complexity in the order\nof the clique size, i.e., a clique of size n with l labels at each node requires the evaluation\nof ln−1 possible states (Potetz and Lee 2008; Kohli, Kumar, and Torr 2009). However, for\ncertain kinds of potential functions Vi,k(xi, xk), including the Potts model (delta function),\nabsolute values (total variation), and quadratic (Gaussian MRF), Felzenszwalb and Hutten-\nlocher (2006) show how to reduce the complexity of the min-ﬁnding step (B.28) from O(l2)\nto O(l). In Appendix B.5.3, we also discuss how Potetz and Lee (2008) reduce the complexity\nfor special kinds of higher-order clique, i.e., linear summations followed by non-linearities.\nFigure B.2a also shows what happens if we add an extra factor between nodes i and j.\nIn this case, the graph is no longer a tree, i.e., it contains a cycle. It is no longer possible\nto use the recursion formula (B.28), since ˆEi(xi) now appears in two different terms inside\nthe summation, i.e., as a child of both nodes j and k, and the same setting for xi may not\nminimize both. In other words, when loops exist, there is no ordering of the variables that\nallows the recursion (elimination) in (B.28) to be well-founded.\nIt is, however, possible to convert small loops into higher-order factors and to solve these\nas shown in Figure B.2b. However, graphs with long loops or meshes result in extremely\nlarge clique sizes and hence an amount of computation potentially exponential in the size of\nthe graph.\nB.5.3 Belief propagation\nBelief propagation is an inference technique originally developed for trees (Pearl 1988) but\nmore recently extended to “loopy” (cyclic) graphs such as MRFs (Frey and MacKay 1997;\nFreeman, Pasztor, and Carmichael 2000; Yedidia, Freeman, and Weiss 2001; Weiss and Free-\nman 2001a,b; Yuille 2002; Sun, Zheng, and Shum 2003; Felzenszwalb and Huttenlocher\n2006). It is closely related to dynamic programming, in that both techniques pass messages\nforward and backward over a tree or graph. In fact, one of the two variants of belief prop-\nagation, the max-product rule, performs the exact same computation (inference) as dynamic\nprogramming, albeit using probabilities instead of energies.\nRecall that the energy we are minimizing in MAP estimation (B.26) is the negative log\nlikelihood (B.12, B.13, and B.22) of a factored Gibbs posterior distribution,\np(x) =\nY\n(i,j)∈N\nφi,j(xi, xj),\n(B.29)\nB.5 Markov random ﬁelds\n769\nwhere\nφi,j(xi, xj) = e−Vi,j(xi,xj)\n(B.30)\nare the pairwise interaction potentials. We can rewrite (B.27) as\n˜pk(x) =\nY\ni<k, j≤k\nφi,j(xi, xj) =\nY\ni∈Ck\n˜pi,k(x),\n(B.31)\nwhere\n˜pi,k(x) = φi,k(xi, xk)˜pi(x).\n(B.32)\nWe can therefore rewrite (B.28) as\nˆpk(xk) =\nmax\n{xi, i<k} ˜pk(x) =\nY\ni∈Ck\nˆpi,k(x),\n(B.33)\nwith\nˆpi,k(x) = max\nxi φi,k(xi, xk)ˆpi(x).\n(B.34)\nEquation (B.34) is the max update rule evaluated at all square box factors in Figure B.2a,\nwhile (B.33) is the product rule evaluated at the nodes. The probability distribution ˆpi,k(x)\nis often interpreted as a message passing information about child i to parent k and is hence\nwritten as mi,k(xk) (Yedidia, Freeman, and Weiss 2001) or µi→k(xk) (Bishop 2006).\nThe max-product rule can be used to compute the MAP estimate in a tree using the same\nkind of forward and backward sweep as in dynamic programming (which is sometimes called\nthe max-sum algorithm (Bishop 2006)). An alternative rule, known as the sum–product, sums\nover all possible values in (B.34) rather than taking the maximum, in essence computing\nthe expected distribution rather than the maximum likelihood distribution. This produces a\nset of probability estimates that can be used to compute the marginal distributions bi(xi) =\nP\nx\\xi p(x) (Pearl 1988; Yedidia, Freeman, and Weiss 2001; Bishop 2006).\nBelief propagation may not produce optimal estimates for cyclic graphs for the same\nreason that dynamic programming fails to work, i.e., because a node with multiple parents\nmay take on different optimal values for each of the parents, i.e., there is no unique elim-\nination ordering. Early algorithms for extending belief propagation to graphs with cycles,\ndubbed loopy belief propagation, performed the updates in parallel over the graph, i.e., us-\ning synchronous updates (Frey and MacKay 1997; Freeman, Pasztor, and Carmichael 2000;\nYedidia, Freeman, and Weiss 2001; Weiss and Freeman 2001a,b; Yuille 2002; Sun, Zheng,\nand Shum 2003; Felzenszwalb and Huttenlocher 2006).\nFor example, Felzenszwalb and Huttenlocher (2006) split an N4 graph into its red and\nblack (checkerboard) components and alternate between sending messages from the red nodes\nto the black and vice versa. They also use multi-grid (coarser level) updates to speed up the\nconvergence. As discussed previously, to reduce the complexity of the basic max-product",
  "image_path": "page_790.jpg",
  "pages": [
    789,
    790,
    791
  ]
}