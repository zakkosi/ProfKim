{
  "doc_id": "pages_032_034",
  "text": "10\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ncalled Bayesian modeling (Appendix B). It is possible to associate a risk or loss function with\nmis-estimating the answer (Section B.2) and to set up your inference algorithm to minimize\nthe expected risk. (Consider a robot trying to estimate the distance to an obstacle: it is\nusually safer to underestimate than to overestimate.) With statistical techniques, it often helps\nto gather lots of training data from which to learn probabilistic models. Finally, statistical\napproaches enable you to use proven inference techniques to estimate the best answer (or\ndistribution of answers) and to quantify the uncertainty in the resulting estimates.\nBecause so much of computer vision involves the solution of inverse problems or the esti-\nmation of unknown quantities, my book also has a heavy emphasis on algorithms, especially\nthose that are known to work well in practice. For many vision problems, it is all too easy to\ncome up with a mathematical description of the problem that either does not match realistic\nreal-world conditions or does not lend itself to the stable estimation of the unknowns. What\nwe need are algorithms that are both robust to noise and deviation from our models and rea-\nsonably efﬁcient in terms of run-time resources and space. In this book, I go into these issues\nin detail, using Bayesian techniques, where applicable, to ensure robustness, and efﬁcient\nsearch, minimization, and linear system solving algorithms to ensure efﬁciency. Most of the\nalgorithms described in this book are at a high level, being mostly a list of steps that have to\nbe ﬁlled in by students or by reading more detailed descriptions elsewhere. In fact, many of\nthe algorithms are sketched out in the exercises.\nNow that I’ve described the goals of this book and the frameworks that I use, I devote the\nrest of this chapter to two additional topics. Section 1.2 is a brief synopsis of the history of\ncomputer vision. It can easily be skipped by those who want to get to “the meat” of the new\nmaterial in this book and do not care as much about who invented what when.\nThe second is an overview of the book’s contents, Section 1.3, which is useful reading for\neveryone who intends to make a study of this topic (or to jump in partway, since it describes\nchapter inter-dependencies). This outline is also useful for instructors looking to structure\none or more courses around this topic, as it provides sample curricula based on the book’s\ncontents.\n1.2 A brief history\nIn this section, I provide a brief personal synopsis of the main developments in computer\nvision over the last 30 years (Figure 1.6); at least, those that I ﬁnd personally interesting\nand which appear to have stood the test of time. Readers not interested in the provenance\nof various ideas and the evolution of this ﬁeld should skip ahead to the book overview in\nSection 1.3.\n1.2 A brief history\n11\nDigital image processing\nBlocks world, line labeling\nGeneralized cylinders\n197\nGeneralized cylinders\nPictorial structures\nStereo correspondence\nIntrinsic images\nOptical flow\nStructure from motion\n70\nImage pyramids\nScale-space processing\nShape from shading, \ntexture, and focus\nPhysically-based  modeling\n1980\nRegularization\nMarkov Random Fields\nKalman filters\n3D range data processing\nProjective invariants\nFactorization\n1\nFactorization\nPhysics-based vision\nGraph cuts\nParticle filtering\nEnergy-based segmentation\nFace recognition and detection\n1990\nFace recognition and detection\nSubspace methods\nImage-based modeling \nand rendering\nTexture synthesis and inpainting\nComputational photography\n2000\nFeature-based  recognition\nMRF inference algorithms\nCategory recognition\nLearning\nFigure 1.6\nA rough timeline of some of the most active topics of research in computer\nvision.\n1970s.\nWhen computer vision ﬁrst started out in the early 1970s, it was viewed as the\nvisual perception component of an ambitious agenda to mimic human intelligence and to\nendow robots with intelligent behavior. At the time, it was believed by some of the early\npioneers of artiﬁcial intelligence and robotics (at places such as MIT, Stanford, and CMU)\nthat solving the “visual input” problem would be an easy step along the path to solving more\ndifﬁcult problems such as higher-level reasoning and planning. According to one well-known\nstory, in 1966, Marvin Minsky at MIT asked his undergraduate student Gerald Jay Sussman\nto “spend the summer linking a camera to a computer and getting the computer to describe\nwhat it saw” (Boden 2006, p. 781).5 We now know that the problem is slightly more difﬁcult\nthan that.6\nWhat distinguished computer vision from the already existing ﬁeld of digital image pro-\ncessing (Rosenfeld and Pfaltz 1966; Rosenfeld and Kak 1976) was a desire to recover the\nthree-dimensional structure of the world from images and to use this as a stepping stone to-\nwards full scene understanding. Winston (1975) and Hanson and Riseman (1978) provide\ntwo nice collections of classic papers from this early period.\nEarly attempts at scene understanding involved extracting edges and then inferring the\n3D structure of an object or a “blocks world” from the topological structure of the 2D lines\n(Roberts 1965). Several line labeling algorithms (Figure 1.7a) were developed at that time\n(Huffman 1971; Clowes 1971; Waltz 1975; Rosenfeld, Hummel, and Zucker 1976; Kanade\n1980). Nalwa (1993) gives a nice review of this area. The topic of edge detection was also\n5 Boden (2006) cites (Crevier 1993) as the original source. The actual Vision Memo was authored by Seymour\nPapert (1966) and involved a whole cohort of students.\n6 To see how far robotic vision has come in the last four decades, have a look at the towel-folding robot at\nhttp://rll.eecs.berkeley.edu/pr/icra10/ (Maitin-Shepard, Cusumano-Towner, Lei et al. 2010).\n12\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.7\nSome early (1970s) examples of computer vision algorithms: (a) line label-\ning (Nalwa 1993) c⃝1993 Addison-Wesley, (b) pictorial structures (Fischler and Elschlager\n1973) c⃝1973 IEEE, (c) articulated body model (Marr 1982) c⃝1982 David Marr, (d) intrin-\nsic images (Barrow and Tenenbaum 1981) c⃝1973 IEEE, (e) stereo correspondence (Marr\n1982) c⃝1982 David Marr, (f) optical ﬂow (Nagel and Enkelmann 1986) c⃝1986 IEEE.\nan active area of research; a nice survey of contemporaneous work can be found in (Davis\n1975).\nThree-dimensional modeling of non-polyhedral objects was also being studied (Baum-\ngart 1974; Baker 1977). One popular approach used generalized cylinders, i.e., solids of\nrevolution and swept closed curves (Agin and Binford 1976; Nevatia and Binford 1977), of-\nten arranged into parts relationships7 (Hinton 1977; Marr 1982) (Figure 1.7c). Fischler and\nElschlager (1973) called such elastic arrangements of parts pictorial structures (Figure 1.7b).\nThis is currently one of the favored approaches being used in object recognition (see Sec-\ntion 14.4 and Felzenszwalb and Huttenlocher 2005).\nA qualitative approach to understanding intensities and shading variations and explaining\nthem by the effects of image formation phenomena, such as surface orientation and shadows,\nwas championed by Barrow and Tenenbaum (1981) in their paper on intrinsic images (Fig-\nure 1.7d), along with the related 2 1/2 -D sketch ideas of Marr (1982). This approach is again\nseeing a bit of a revival in the work of Tappen, Freeman, and Adelson (2005).\nMore quantitative approaches to computer vision were also developed at the time, in-\ncluding the ﬁrst of many feature-based stereo correspondence algorithms (Figure 1.7e) (Dev\n7 In robotics and computer animation, these linked-part graphs are often called kinematic chains.",
  "image_path": "page_033.jpg",
  "pages": [
    32,
    33,
    34
  ]
}