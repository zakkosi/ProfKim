{
  "doc_id": "pages_584_586",
  "text": "562\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 11.17 Local (5 × 5 window-based) matching results (Kang, Szeliski, and Chai 2001)\nc⃝2001 IEEE: (a) window that is not spatially perturbed (centered); (b) spatially perturbed\nwindow; (c) using the best ﬁve of 10 neighboring frames; (d) using the better half sequence.\nNotice how the results near the tree trunk are improved using temporal selection.\nand Szeliski (2004) use soft (penalty-based) constraints to encourage multiple disparity maps\nto be consistent, Kolmogorov and Zabih (2002) show how such consistency measures can\nbe encoded as hard constraints, which guarantee that the multiple depth maps are not only\nsimilar but actually identical in overlapping regions. Newer algorithms that simultaneously\nestimate multiple disparity maps include papers by Maitre, Shinagawa, and Do (2008) and\nZhang, Jia, Wong et al. (2008).\nA closely related topic to multi-frame stereo estimation is scene ﬂow, in which multiple\ncameras are used to capture a dynamic scene. The task is then to simultaneously recover the\n3D shape of the object at every instant in time and to estimate the full 3D motion of every\nsurface point between frames. Representative papers in this area include those by Vedula,\nBaker, Rander et al. (2005), Zhang and Kambhamettu (2003), Pons, Keriven, and Faugeras\n(2007), Huguet and Devernay (2007), and Wedel, Rabe, Vaudrey et al. (2008). Figure 11.18a\nshows an image of the 3D scene ﬂow for the tango dancer shown in Figure 11.2h–j, while\nFigure 11.18b shows 3D scene ﬂows captured from a moving vehicle for the purpose of\nobstacle avoidance. In addition to supporting mensuration and safety applications, scene\nﬂow can be used to support both spatial and temporal view interpolation (Section 13.5.4), as\ndemonstrated by Vedula, Baker, and Kanade (2005).\n11.6.1 Volumetric and 3D surface reconstruction\nAccording to Seitz, Curless, Diebel et al. (2006):\nThe goal of multi-view stereo is to reconstruct a complete 3D object model from\na collection of images taken from known camera viewpoints.\nThe most challenging but potentially most useful variant of multi-view stereo reconstruc-\ntion is to create globally consistent 3D models. This topic has a long history in computer\nvision, starting with surface mesh reconstruction techniques such as the one developed by\n11.6 Multi-view stereo\n563\n(a)\n(b)\nFigure 11.18 Three-dimensional scene ﬂow: (a) computed from a multi-camera dome sur-\nrounding the dancer shown in Figure 11.2h–j (Vedula, Baker, Rander et al. 2005) c⃝2005\nIEEE; (b) computed from stereo cameras mounted on a moving vehicle (Wedel, Rabe, Vau-\ndrey et al. 2008) c⃝2008 Springer.\nFua and Leclerc (1995) (Figure 11.19a). A variety of approaches and representations have\nbeen used to solve this problem, including 3D voxel representations (Seitz and Dyer 1999;\nSzeliski and Golland 1999; De Bonet and Viola 1999; Kutulakos and Seitz 2000; Eisert, Stein-\nbach, and Girod 2000; Slabaugh, Culbertson, Slabaugh et al. 2004; Sinha and Pollefeys 2005;\nVogiatzis, Hernandez, Torr et al. 2007; Hiep, Keriven, Pons et al. 2009), level sets (Faugeras\nand Keriven 1998; Pons, Keriven, and Faugeras 2007), polygonal meshes (Fua and Leclerc\n1995; Narayanan, Rander, and Kanade 1998; Hernandez and Schmitt 2004; Furukawa and\nPonce 2009), and multiple depth maps (Kolmogorov and Zabih 2002). Figure 11.19 shows\nrepresentative examples of 3D object models reconstructed using some of these techniques.\nIn order to organize and compare all these techniques, Seitz, Curless, Diebel et al. (2006)\ndeveloped a six-point taxonomy that can help classify algorithms according to the scene rep-\nresentation, photoconsistency measure, visibility model, shape priors, reconstruction algo-\nrithm, and initialization requirements they use. Below, we summarize some of these choices\nand list a few representative papers. For more details, please consult the full survey paper\n(Seitz, Curless, Diebel et al. 2006) and the evaluation Web site, http://vision.middlebury.edu/\nmview/, which contains pointers to even more recent papers and results.\nScene representation.\nOne of the more popular 3D representations is a uniform grid of 3D\nvoxels,7 which can be reconstructed using a variety of carving (Seitz and Dyer 1999; Kutu-\nlakos and Seitz 2000) or optimization (Sinha and Pollefeys 2005; Vogiatzis, Hernandez, Torr\net al. 2007; Hiep, Keriven, Pons et al. 2009) techniques. Level set techniques (Section 5.1.4)\nalso operate on a uniform grid but, instead of representing a binary occupancy map, they\nrepresent the signed distance to the surface (Faugeras and Keriven 1998; Pons, Keriven, and\nFaugeras 2007), which can encode a ﬁner level of detail. Polygonal meshes are another pop-\n7 For outdoor scenes that go to inﬁnity, a non-uniform gridding of space may be preferable (Slabaugh, Culbertson,\nSlabaugh et al. 2004).\n564\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 11.19\nMulti-view stereo algorithms: (a) surface-based stereo (Fua and Leclerc\n1995); (b) voxel coloring (Seitz and Dyer 1999) c⃝1999 Springer; (c) depth map merg-\ning (Narayanan, Rander, and Kanade 1998); (d) level set evolution (Faugeras and Keriven\n1998) c⃝1998 IEEE; (e) silhouette and stereo fusion (Hernandez and Schmitt 2004) c⃝2004\nElsevier; (f) multi-view image matching (Pons, Keriven, and Faugeras 2005) c⃝2005 IEEE;\n(g) volumetric graph cut (Vogiatzis, Torr, and Cipolla 2005) c⃝2005 IEEE; (h) carved visual\nhulls (Furukawa and Ponce 2009) c⃝2009 Springer.\nular representation (Fua and Leclerc 1995; Narayanan, Rander, and Kanade 1998; Isidoro\nand Sclaroff 2003; Hernandez and Schmitt 2004; Furukawa and Ponce 2009; Hiep, Keriven,\nPons et al. 2009). Meshes are the standard representation used in computer graphics and\nalso readily support the computation of visibility and occlusions. Finally, as we discussed in\nthe previous section, multiple depth maps can also be used (Szeliski 1999; Kolmogorov and\nZabih 2002; Kang and Szeliski 2004). Many algorithms also use more than a single represen-\ntation, e.g., they may start by computing multiple depth maps and then merge them into a 3D\nobject model (Narayanan, Rander, and Kanade 1998; Furukawa and Ponce 2009; Goesele,\nCurless, and Seitz 2006; Goesele, Snavely, Curless et al. 2007; Furukawa, Curless, Seitz et\nal. 2010).",
  "image_path": "page_585.jpg",
  "pages": [
    584,
    585,
    586
  ]
}