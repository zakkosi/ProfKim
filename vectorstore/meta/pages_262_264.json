{
  "doc_id": "pages_262_264",
  "text": "240\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nations. The gradient of the smoothed image can therefore be written as\nJσ(x) = ∇[Gσ(x) ∗I(x)] = [∇Gσ](x) ∗I(x),\n(4.20)\ni.e., we can convolve the image with the horizontal and vertical derivatives of the Gaussian\nkernel function,\n∇Gσ(x) = (∂Gσ\n∂x , ∂Gσ\n∂y )(x) = [−x −y] 1\nσ3 exp\n\u0012\n−x2 + y2\n2σ2\n\u0013\n(4.21)\n(The parameter σ indicates the width of the Gaussian.) This is the same computation that\nis performed by Freeman and Adelson’s (1991) ﬁrst-order steerable ﬁlter, which we already\ncovered in Section 3.2.3.\nFor many applications, however, we wish to thin such a continuous gradient image to\nonly return isolated edges, i.e., as single pixels at discrete locations along the edge contours.\nThis can be achieved by looking for maxima in the edge strength (gradient magnitude) in a\ndirection perpendicular to the edge orientation, i.e., along the gradient direction.\nFinding this maximum corresponds to taking a directional derivative of the strength ﬁeld\nin the direction of the gradient and then looking for zero crossings. The desired directional\nderivative is equivalent to the dot product between a second gradient operator and the results\nof the ﬁrst,\nSσ(x) = ∇· Jσ(x) = [∇2Gσ](x) ∗I(x)].\n(4.22)\nThe gradient operator dot product with the gradient is called the Laplacian. The convolution\nkernel\n∇2Gσ(x) = 1\nσ3\n\u0012\n2 −x2 + y2\n2σ2\n\u0013\nexp\n\u0012\n−x2 + y2\n2σ2\n\u0013\n(4.23)\nis therefore called the Laplacian of Gaussian (LoG) kernel (Marr and Hildreth 1980). This\nkernel can be split into two separable parts,\n∇2Gσ(x) = 1\nσ3\n\u0012\n1 −x2\n2σ2\n\u0013\nGσ(x)Gσ(y) + 1\nσ3\n\u0012\n1 −y2\n2σ2\n\u0013\nGσ(y)Gσ(x)\n(4.24)\n(Wiejak, Buxton, and Buxton 1985), which allows for a much more efﬁcient implementation\nusing separable ﬁltering (Section 3.2.1).\nIn practice, it is quite common to replace the Laplacian of Gaussian convolution with a\nDifference of Gaussian (DoG) computation, since the kernel shapes are qualitatively similar\n(Figure 3.35). This is especially convenient if a “Laplacian pyramid” (Section 3.5) has already\nbeen computed.4\n4 Recall that Burt and Adelson’s (1983a) “Laplacian pyramid” actually computed differences of Gaussian-ﬁltered\nlevels.\n4.2 Edges\n241\nIn fact, it is not strictly necessary to take differences between adjacent levels when com-\nputing the edge ﬁeld. Think about what a zero crossing in a “generalized” difference of\nGaussians image represents. The ﬁner (smaller kernel) Gaussian is a noise-reduced version\nof the original image. The coarser (larger kernel) Gaussian is an estimate of the average in-\ntensity over a larger region. Thus, whenever the DoG image changes sign, this corresponds\nto the (slightly blurred) image going from relatively darker to relatively lighter, as compared\nto the average intensity in that neighborhood.\nOnce we have computed the sign function S(x), we must ﬁnd its zero crossings and\nconvert these into edge elements (edgels). An easy way to detect and represent zero crossings\nis to look for adjacent pixel locations xi and xj where the sign changes value, i.e., [S(xi) >\n0] ̸= [S(xj) > 0].\nThe sub-pixel location of this crossing can be obtained by computing the “x-intercept” of\nthe “line” connecting S(xi) and S(xj),\nxz = xiS(xj) −xjS(xi)\nS(xj) −S(xi)\n.\n(4.25)\nThe orientation and strength of such edgels can be obtained by linearly interpolating the\ngradient values computed on the original pixel grid.\nAn alternative edgel representation can be obtained by linking adjacent edgels on the\ndual grid to form edgels that live inside each square formed by four adjacent pixels in the\noriginal pixel grid.5 The (potential) advantage of this representation is that the edgels now\nlive on a grid offset by half a pixel from the original pixel grid and are thus easier to store\nand access.\nAs before, the orientations and strengths of the edges can be computed by\ninterpolating the gradient ﬁeld or estimating these values from the difference of Gaussian\nimage (see Exercise 4.7).\nIn applications where the accuracy of the edge orientation is more important, higher-order\nsteerable ﬁlters can be used (Freeman and Adelson 1991) (see Section 3.2.3). Such ﬁlters are\nmore selective for more elongated edges and also have the possibility of better modeling curve\nintersections because they can represent multiple orientations at the same pixel (Figure 3.16).\nTheir disadvantage is that they are more expensive to compute and the directional derivative\nof the edge strength does not have a simple closed form solution.6\n242\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 4.32\nScale selection for edge detection (Elder and Zucker 1998) c⃝1998 IEEE:\n(a) original image; (b–c) Canny/Deriche edge detector tuned to the ﬁner (mannequin) and\ncoarser (shadow) scales; (d) minimum reliable scale for gradient estimation; (e) minimum\nreliable scale for second derivative estimation; (f) ﬁnal detected edges.\nScale selection and blur estimation\nAs we mentioned before, the derivative, Laplacian, and Difference of Gaussian ﬁlters (4.20–\n4.23) all require the selection of a spatial scale parameter σ. If we are only interested in\ndetecting sharp edges, the width of the ﬁlter can be determined from image noise characteris-\ntics (Canny 1986; Elder and Zucker 1998). However, if we want to detect edges that occur at\ndifferent resolutions (Figures 4.32b–c), a scale-space approach that detects and then selects\nedges at different scales may be necessary (Witkin 1983; Lindeberg 1994, 1998a; Nielsen,\nFlorack, and Deriche 1997).\nElder and Zucker (1998) present a principled approach to solving this problem. Given\na known image noise level, their technique computes, for every pixel, the minimum scale\nat which an edge can be reliably detected (Figure 4.32d). Their approach ﬁrst computes\n5 This algorithm is a 2D version of the 3D marching cubes isosurface extraction algorithm (Lorensen and Cline\n1987).\n6 In fact, the edge orientation can have a 180◦ambiguity for “bar edges”, which makes the computation of zero\ncrossings in the derivative more tricky.",
  "image_path": "page_263.jpg",
  "pages": [
    262,
    263,
    264
  ]
}