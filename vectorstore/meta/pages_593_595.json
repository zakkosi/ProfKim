{
  "doc_id": "pages_593_595",
  "text": "11.8 Exercises\n571\nare discussed in Section 11.4 and surveyed by Gong, Yang, Wang et al. (2007) and Tombari,\nMattoccia, Di Stefano et al. (2008). More commonly, global optimization frameworks are\nused to compute the best disparity ﬁeld, as described in Section 11.5. These techniques\ninclude dynamic programming and truly global optimization algorithms, such as graph cuts\nand loopy belief propagation. Because the literature on this is so extensive, it is described in\nmore detail in Section 11.5. A good place to ﬁnd pointers to the latest results in this ﬁeld is\nthe Middlebury Stereo Vision Page at http://vision.middlebury.edu/stereo.\nAlgorithms for multi-view stereo typically fall into two categories. The ﬁrst include al-\ngorithms that compute traditional depth maps using several images for computing photocon-\nsistency measures (Okutomi and Kanade 1993; Kang, Webb, Zitnick et al. 1995; Nakamura,\nMatsuura, Satoh et al. 1996; Szeliski and Golland 1999; Kang, Szeliski, and Chai 2001;\nVaish, Szeliski, Zitnick et al. 2006; Gallup, Frahm, Mordohai et al. 2008). Optionally, some\nof these techniques compute multiple depth maps and use additional constraints to encourage\nthe different depth maps to be consistent (Szeliski 1999; Kolmogorov and Zabih 2002; Kang\nand Szeliski 2004; Maitre, Shinagawa, and Do 2008; Zhang, Jia, Wong et al. 2008).\nThe second category consists of papers that compute true 3D volumetric or surface-based\nobject models. Again, because of the large number of papers published on this topic, rather\nthan citing them here, we refer you to the material in Section 11.6.1, the survey by Seitz,\nCurless, Diebel et al. (2006), and the on-line evaluation Web site at http://vision.middlebury.\nedu/mview/.\n11.8 Exercises\nEx 11.1: Stereo pair rectiﬁcation\nImplement the following simple algorithm (Section 11.1.1):\n1. Rotate both cameras so that they are looking perpendicular to the line joining the two\ncamera centers c0 and c1. The smallest rotation can be computed from the cross prod-\nuct between the original and desired optical axes.\n2. Twist the optical axes so that the horizontal axis of each camera looks in the direction\nof the other camera. (Again, the cross product between the current x-axis after the ﬁrst\nrotation and the line joining the cameras gives the rotation.)\n3. If needed, scale up the smaller (less detailed) image so that it has the same resolution\n(and hence line-to-line correspondence) as the other image.\nNow compare your results to the algorithm proposed by Loop and Zhang (1999). Can you\nthink of situations where their approach may be preferable?\n572\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 11.2: Rigid direct alignment\nModify your spline-based or optical ﬂow motion estima-\ntor from Exercise 8.4 to use epipolar geometry, i.e. to only estimate disparity.\n(Optional) Extend your algorithm to simultaneously estimate the epipolar geometry (with-\nout ﬁrst using point correspondences) by estimating a base homography corresponding to a\nreference plane for the dominant motion and then an epipole for the residual parallax (mo-\ntion).\nEx 11.3: Shape from proﬁles\nReconstruct a surface model from a series of edge images\n(Section 11.2.1).\n1. Extract edges and link them (Exercises 4.7–4.8).\n2. Based on previously computed epipolar geometry, match up edges in triplets (or longer\nsets) of images.\n3. Reconstruct the 3D locations of the curves using osculating circles (11.5).\n4. Render the resulting 3D surface model as a sparse mesh, i.e., drawing the reconstructed\n3D proﬁle curves and links between 3D points in neighboring images with similar\nosculating circles.\nEx 11.4: Plane sweep\nImplement a plane sweep algorithm (Section 11.1.2).\nIf the images are already pre-rectiﬁed, this consists simply of shifting images relative to\neach other and comparing pixels. If the images are not pre-rectiﬁed, compute the homography\nthat resamples the target image into the reference image’s coordinate system for each plane.\nEvaluate a subset of the following similarity measures (Section 11.3.1) and compare their\nperformance by visualizing the disparity space image (DSI), which should be dark for pixels\nat correct depths:\n• squared difference (SD);\n• absolute difference (AD);\n• truncated or robust measures;\n• gradient differences;\n• rank or census transform (the latter usually performs better);\n• mutual information from a pre-computed joint density function.\nConsider using the Birchﬁeld and Tomasi (1998) technique of comparing ranges between\nneighboring pixels (different shifted or warped images). Also, try pre-compensating images\nfor bias or gain variations using one or more of the techniques discussed in Section 11.3.1.\n11.8 Exercises\n573\nEx 11.5: Aggregation and window-based stereo\nImplement one or more of the matching\ncost aggregation strategies described in Section 11.4:\n• convolution with a box or Gaussian kernel;\n• shifting window locations by applying a min ﬁlter (Scharstein and Szeliski 2002);\n• picking a window that maximizes some match-reliability metric (Veksler 2001, 2003);\n• weighting pixels by their similarity to the central pixel (Yoon and Kweon 2006).\nOnce you have aggregated the costs in the DSI, pick the winner at each pixel (winner-take-\nall), and then optionally perform one or more of the following post-processing steps:\n1. compute matches both ways and pick only the reliable matches (draw the others in\nanother color);\n2. tag matches that are unsure (whose conﬁdence is too low);\n3. ﬁll in the matches that are unsure from neighboring values;\n4. reﬁne your matches to sub-pixel disparity by either ﬁtting a parabola to the DSI values\naround the winner or by using an iteration of Lukas–Kanade.\nEx 11.6: Optimization-based stereo\nCompute the disparity space image (DSI) volume us-\ning one of the techniques you implemented in Exercise 11.4 and then implement one (or more)\nof the global optimization techniques described in Section 11.5 to compute the depth map.\nPotential choices include:\n• dynamic programming or scanline optimization (relatively easy);\n• semi-global optimization (Hirschm¨uller 2008), which is a simple extension of scanline\noptimization and performs well;\n• graph cuts using alpha expansions (Boykov, Veksler, and Zabih 2001), for which you\nwill need to ﬁnd a max-ﬂow or min-cut algorithm (http://vision.middlebury.edu/stereo);\n• loopy belief propagation (Appendix B.5.3).\nEvaluate your algorithm by running it on the Middlebury stereo data sets.\nHow well does your algorithm do against local aggregation (Yoon and Kweon 2006)?\nCan you think of some extensions or modiﬁcations to make it even better?",
  "image_path": "page_594.jpg",
  "pages": [
    593,
    594,
    595
  ]
}