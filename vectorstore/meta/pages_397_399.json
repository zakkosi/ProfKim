{
  "doc_id": "pages_397_399",
  "text": "7.5 Constrained structure and motion\n375\nFigure 7.14 Two images of a toy house along with their matched 3D line segments (Schmid\nand Zisserman 1997) c⃝1997 Springer.\ncommon line segment intersection.20 In their system, the epipolar geometry is assumed to be\nknown, e.g., computed from point matches. For wide baselines, all possible homographies\ncorresponding to planes passing through the 3D line are used to warp pixels and the maximum\ncorrelation score is used. For triplets of images, the trifocal tensor is used to verify that\nthe lines are in geometric correspondence before evaluating the correlations between line\nsegments. Figure 7.14 shows the results of using their system.\nBartoli and Sturm (2003) describe a complete system for extending three view relations\n(trifocal tensors) computed from manual line correspondences to a full bundle adjustment of\nall the line and camera parameters. The key to their approach is to use the Pl¨ucker coor-\ndinates (2.12) to parameterize lines and to directly minimize reprojection errors. It is also\npossible to represent 3D line segments by their endpoints and to measure either the reprojec-\ntion error perpendicular to the detected 2D line segments in each image or the 2D errors using\nan elongated uncertainty ellipse aligned with the line segment direction (Szeliski and Kang\n1994).\nInstead of reconstructing 3D lines, Bay, Ferrari, and Van Gool (2005) use RANSAC to\ngroup lines into likely coplanar subsets. Four lines are chosen at random to compute a homog-\nraphy, which is then veriﬁed for these and other plausible line segment matches by evaluating\ncolor histogram-based correlation scores. The 2D intersection points of lines belonging to the\nsame plane are then used as virtual measurements to estimate the epipolar geometry, which\nis more accurate than using the homographies directly.\nAn alternative to grouping lines into coplanar subsets is to group lines by parallelism.\nWhenever three or more 2D lines share a common vanishing point, there is a good likelihood\nthat they are parallel in 3D. By ﬁnding multiple vanishing points in an image (Section 4.3.3)\nand establishing correspondences between such vanishing points in different images, the rel-\native rotations between the various images (and often the camera intrinsics) can be directly\nestimated (Section 6.3.2).\n20 Because lines often occur at depth or orientation discontinuities, it may be preferable to compute correlation\nscores (or to match color histograms (Bay, Ferrari, and Van Gool 2005)) separately on each side of the line.\n376\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nShum, Han, and Szeliski (1998) describe a 3D modeling system which ﬁrst constructs\ncalibrated panoramas from multiple images (Section 7.4) and then has the user draw vertical\nand horizontal lines in the image to demarcate the boundaries of planar regions. The lines\nare initially used to establish an absolute rotation for each panorama and are later used (along\nwith the inferred vertices and planes) to infer a 3D structure, which can be recovered up to\nscale from one or more images (Figure 12.15).\nA fully automated approach to line-based structure from motion is presented vy Werner\nand Zisserman (2002). In their system, they ﬁrst ﬁnd lines and group them by common van-\nishing points in each image (Section 4.3.3). The vanishing points are then used to calibrate the\ncamera, i.e., to performa a “metric upgrade” (Section 6.3.2). Lines corresponding to common\nvanishing points are then matched using both appearance (Schmid and Zisserman 1997) and\ntrifocal tensors. The resulting set of 3D lines, color coded by common vanishing directions\n(3D orientations) is shown in Figure 12.16a. These lines are then used to infer planes and a\nblock-structured model for the scene, as described in more detail in Section 12.6.1.\n7.5.2 Plane-based techniques\nIn scenes that are rich in planar structures, e.g., in architecture and certain kinds of manu-\nfactured objects such as furniture, it is possible to directly estimate homographies between\ndifferent planes, using either feature-based or intensity-based methods. In principle, this in-\nformation can be used to simultaneously infer the camera poses and the plane equations, i.e.,\nto compute plane-based structure from motion.\nLuong and Faugeras (1996) show how a fundamental matrix can be directly computed\nfrom two or more homographies using algebraic manipulations and least squares. Unfortu-\nnately, this approach often performs poorly, since the algebraic errors do not correspond to\nmeaningful reprojection errors (Szeliski and Torr 1998).\nA better approach is to hallucinate virtual point correspondences within the areas from\nwhich each homography was computed and to feed them into a standard structure from mo-\ntion algorithm (Szeliski and Torr 1998). An even better approach is to use full bundle adjust-\nment with explicit plane equations, as well as additional constraints to force reconstructed\nco-planar features to lie exactly on their corresponding planes. (A principled way to do this\nis to establish a coordinate frame for each plane, e.g., at one of the feature points, and to use\n2D in-plane parameterizations for the other points.) The system developed by Shum, Han,\nand Szeliski (1998) shows an example of such an approach, where the directions of lines and\nnormals for planes in the scene are pre-speciﬁed by the user.\n7.6 Additional reading\n377\n7.6 Additional reading\nThe topic of structure from motion is extensively covered in books and review articles on\nmulti-view geometry (Faugeras and Luong 2001; Hartley and Zisserman 2004; Moons, Van\nGool, and Vergauwen 2010). For two-frame reconstruction, Hartley (1997a) wrote a highly\ncited paper on the “eight-point algorithm” for computing an essential or fundamental ma-\ntrix with reasonable point normalization. When the cameras are calibrated, the ﬁve-point\nalgorithm of Nist´er (2004) can be used in conjunction with RANSAC to obtain initial recon-\nstructions from the minimum number of points. When the cameras are uncalibrated, various\nself-calibration techniques can be found in work by Hartley and Zisserman (2004); Moons,\nVan Gool, and Vergauwen (2010)—I only brieﬂy mention one of the simplest techniques, the\nKruppa equations (7.35).\nIn applications where points are being tracked from frame to frame, factorization tech-\nniques, based on either orthographic camera models (Tomasi and Kanade 1992; Poelman\nand Kanade 1997; Costeira and Kanade 1995; Morita and Kanade 1997; Morris and Kanade\n1998; Anandan and Irani 2002) or projective extensions (Christy and Horaud 1996; Sturm\nand Triggs 1996; Triggs 1996; Oliensis and Hartley 2007), can be used.\nTriggs, McLauchlan, Hartley et al. (1999) provide a good tutorial and survey on bundle\nadjustment, while Lourakis and Argyros (2009) and Engels, Stew´enius, and Nist´er (2006)\nprovide tips on implementation and effective practices. Bundle adjustment is also covered\nin textbooks and surveys on multi-view geometry (Faugeras and Luong 2001; Hartley and\nZisserman 2004; Moons, Van Gool, and Vergauwen 2010). Techniques for handling larger\nproblems are described by Snavely, Seitz, and Szeliski (2008b); Agarwal, Snavely, Simon\net al. (2009); Jeong, Nist´er, Steedly et al. (2010); Agarwal, Snavely, Seitz et al. (2010).\nWhile bundle adjustment is often called as an inner loop inside incremental reconstruction\nalgorithms (Snavely, Seitz, and Szeliski 2006), hierarchical (Fitzgibbon and Zisserman 1998;\nFarenzena, Fusiello, and Gherardi 2009) and global (Rother and Carlsson 2002; Martinec and\nPajdla 2007) approaches for initialization are also possible and perhaps even preferable.\nAs structure from motion starts being applied to dynamic scenes, the topic of non-rigid\nstructure from motion (Torresani, Hertzmann, and Bregler 2008), which we do not cover in\nthis book, will become more important.\n7.7 Exercises\nEx 7.1: Triangulation\nUse the calibration pattern you built and tested in Exercise 6.7 to\ntest your triangulation accuracy. As an alternative, generate synthetic 3D points and cameras\nand add noise to the 2D point measurements.",
  "image_path": "page_398.jpg",
  "pages": [
    397,
    398,
    399
  ]
}