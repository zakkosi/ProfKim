{
  "doc_id": "pages_811_813",
  "text": "C.3 Slides and lectures\n789\nIn practice, for eight-bit color channels, this bit reverse can be stored in a table or a complete\ntable mapping from labels to pseudocolors (say with 4092 entries) can be pre-computed.\nFigure 8.16 shows an example of such a pseudo-color mapping.\nGPU implementation\nThe advent of programmable GPUs with capabilities such as pixel shaders and compute\nshaders has led to the development of fast computer vision algorithms for real-time appli-\ncations such as segmentation, tracking, stereo, and motion estimation (Pock, Unger, Cremers\net al. 2008; Vineet and Narayanan 2008; Zach, Gallup, and Frahm 2008). A good source\nfor learning about such algorithms is the CVPR 2008 workshop on Visual Computer Vision\non GPUs (CVGPU), http://www.cs.unc.edu/∼jmf/Workshop on Computer Vision on GPU.\nhtml, whose papers can be found on the CVPR 2008 proceedings DVD. Additional sources\nfor GPU algorithms include the GPGPU Web site and workshops, http://gpgpu.org/, and the\nOpenVIDIA Web site, http://openvidia.sourceforge.net/index.php/OpenVIDIA.\nC.3 Slides and lectures\nAs I mentioned in the preface, I hope to post slides corresponding to the material in the book.\nUntil these are ready, your best bet is to look at the slides from the courses I have co-taught\nat the University of Washington, as well as related courses that have used a similar syllabus.\nHere is a partial list of such courses:\nUW 455: Undergraduate Computer Vision, http://www.cs.washington.edu/education/\ncourses/455/.\nUW 576: Graduate Computer Vision, http://www.cs.washington.edu/education/courses/\n576/.\nStanford CS233B: Introduction to Computer Vision, http://vision.stanford.edu/teaching/\ncs223b/.\nMIT 6.869: Advances in Computer Vision, http://people.csail.mit.edu/torralba/courses/\n6.869/6.869.computervision.htm.\nBerkeley CS 280: Computer Vision, http://www.eecs.berkeley.edu/∼trevor/CS280.html.\nUNC COMP 776: Computer Vision, http://www.cs.unc.edu/∼lazebnik/spring10/.\nMiddlebury CS 453: Computer Vision, http://www.cs.middlebury.edu/∼schar/courses/\ncs453-s10/.\n790\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nRelated courses have also been taught on the topic of Computational Photography, e.g.,\nCMU 15-463: Computational Photography, http://graphics.cs.cmu.edu/courses/15-463/.\nMIT 6.815/6.865: Advanced Computational Photography, http://stellar.mit.edu/S/course/\n6/sp09/6.815/.\nStanford CS 448A: Computational photography on cell phones, http://graphics.stanford.\nedu/courses/cs448a-10/.\nSIGGRAPH courses on Computational Photography, http://web.media.mit.edu/∼raskar/\nphoto/.\nThere is also an excellent set of on-line lectures available on a range of computer vision\ntopics, such as belief propagation and graph cuts, at the UW-MSR Course of Vision Algo-\nrithms http://www.cs.washington.edu/education/courses/577/04sp/.\nC.4 Bibliography\nWhile a bibliography (BibTex .bib ﬁle) for all of the references cited in this book is avail-\nable on the book’s Web site, a much more comprehensive partially annotated bibliography\nof nearly all computer vision publications is maintained by Keith Price at http://iris.usc.edu/\nVision-Notes/bibliography/contents.html. There is also a searchable computer graphics bibli-\nography at http://www.siggraph.org/publications/bibliography/. Additional good sources for\ntechnical papers are Google Scholar and CiteSeerx.\nReferences\nAbdel-Hakim, A. E. and Farag, A. A. (2006). CSIFT: A SIFT descriptor with color in-\nvariant characterstics. In IEEE Computer Society Conference on Computer Vision and\nPattern Recognition (CVPR’2006), pp. 1978–1983, New York City, NY.\nAdelson, E. H. and Bergen, J. (1991). The plenoptic function and the elements of early\nvision. In Computational Models of Visual Processing, pp. 3–20.\nAdelson, E. H., Simoncelli, E., and Hingorani, R. (1987). Orthogonal pyramid transforms\nfor image coding. In SPIE Vol. 845, Visual Communications and Image Processing II,\npp. 50–58, Cambridge, Massachusetts.\nAdiv, G.\n(1989).\nInherent ambiguities in recovering 3-D motion and structure from a\nnoisy ﬂow ﬁeld.\nIEEE Transactions on Pattern Analysis and Machine Intelligence,\n11(5):477–490.\nAgarwal, A. and Triggs, B. (2006). Recovering 3D human pose from monocular images.\nIEEE Transactions on Pattern Analysis and Machine Intelligence, 28(1):44–58.\nAgarwal, S. and Roth, D. (2002). Learning a sparse representation for object detection. In\nSeventh European Conference on Computer Vision (ECCV 2002), pp. 113–127, Copen-\nhagen.\nAgarwal, S., Snavely, N., Seitz, S. M., and Szeliski, R. (2010). Bundle adjustment in the\nlarge. In Eleventh European Conference on Computer Vision (ECCV 2010), Heraklion,\nCrete.\nAgarwal, S., Snavely, N., Simon, I., Seitz, S. M., and Szeliski, R. (2009). Building Rome\nin a day. In Twelfth IEEE International Conference on Computer Vision (ICCV 2009),\nKyoto, Japan.\nAgarwal, S., Furukawa, Y., Snavely, N., Curless, B., Seitz, S. M., and Szeliski, R. (2010).\nReconstructing Rome. Computer, 43(6):40–47.\nAgarwala, A. (2007). Efﬁcient gradient-domain compositing using quadtrees. ACM Trans-\nactions on Graphics, 26(3).",
  "image_path": "page_812.jpg",
  "pages": [
    811,
    812,
    813
  ]
}