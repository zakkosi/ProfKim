{
  "doc_id": "pages_430_432",
  "text": "408\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 8.10\nElastic brain registration (Kybic and Unser 2003) c⃝2003 IEEE: (a) original\nbrain atlas and patient MRI images overlaid in red–green; (b) after elastic registration with\neight user-speciﬁed landmarks (not shown); (c) a cubic B-spline deformation ﬁeld, shown as\na deformed grid.\nure 8.9b), the values of certain nodes in the reﬁned mesh, i.e., those adjacent to larger cells,\nneed to be restricted so that they depend on their parent values. This is most easily accom-\nplished using a hierarchical basis representation for the quadtree spline (Szeliski 1990b) and\nselectively setting some of the hierarchical basis functions to 0, as described in (Szeliski and\nShum 1996).\n8.3.1 Application: Medical image registration\nBecause they excel at representing smooth elastic deformation ﬁelds, spline-based motion\nmodels have found widespread use in medical image registration (Bajcsy and Kovacic 1989;\nSzeliski and Lavall´ee 1996; Christensen, Joshi, and Miller 1997).10 Registration techniques\ncan be used both to track an individual patient’s development or progress over time (a lon-\ngitudinal study) or to match different patient images together to ﬁnd commonalities and de-\ntect variations or pathologies (cross-sectional studies). When different imaging modalities\nare being registered, e.g., computed tomography (CT) scans and magnetic resonance images\n(MRI), mutual information measures of similarity are often necessary (Viola and Wells III\n1997; Maes, Collignon, Vandermeulen et al. 1997).\nKybic and Unser (2003) provide a nice literature review and describe a complete working\nsystem based on representing both the images and the deformation ﬁelds as multi-resolution\nsplines. Figure 8.10 shows an example of the Kybic and Unser system being used to register\na patient’s brain MRI with a labeled brain atlas image. The system can be run in a fully auto-\n10 In computer graphics, such elastic volumetric deformation are known as free-form deformations (Sederberg and\nParry 1986; Coquillart 1990; Celniker and Gossard 1991).\n8.4 Optical ﬂow\n409\n(a)\n(b)\n(c)\nFigure 8.11 Octree spline-based image registration of two vertebral surface models (Szeliski\nand Lavall´ee 1996) c⃝1996 Springer: (a) after initial rigid alignment; (b) after elastic align-\nment; (c) a cross-section through the adapted octree spline deformation ﬁeld.\nmatic mode but more accurate results can be obtained by locating a few key landmarks. More\nrecent papers on deformable medical image registration, including performance evaluations,\ninclude (Klein, Staring, and Pluim 2007; Glocker, Komodakis, Tziritas et al. 2008).\nAs with other applications, regular volumetric splines can be enhanced using selective\nreﬁnement. In the case of 3D volumetric image or surface registration, these are known as\noctree splines (Szeliski and Lavall´ee 1996) and have been used to register medical surface\nmodels such as vertebrae and faces from different patients (Figure 8.11).\n8.4 Optical ﬂow\nThe most general (and challenging) version of motion estimation is to compute an indepen-\ndent estimate of motion at each pixel, which is generally known as optical (or optic) ﬂow. As\nwe mentioned in the previous section, this generally involves minimizing the brightness or\ncolor difference between corresponding pixels summed over the image,\nESSD−OF({ui}) =\nX\ni\n[I1(xi + ui) −I0(xi)]2.\n(8.69)\nSince the number of variables {ui} is twice the number of measurements, the problem is\nunderconstrained. The two classic approaches to this problem are to perform the summa-\ntion locally over overlapping regions (the patch-based or window-based approach) or to\nadd smoothness terms on the {ui} ﬁeld using regularization or Markov random ﬁelds (Sec-\ntion 3.7) and to search for a global minimum.\nThe patch-based approach usually involves using a Taylor series expansion of the dis-\nplaced image function (8.35) in order to obtain sub-pixel estimates (Lucas and Kanade 1981).\n410\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nAnandan (1989) shows how a series of local discrete search steps can be interleaved with\nLucas–Kanade incremental reﬁnement steps in a coarse-to-ﬁne pyramid scheme, which al-\nlows the estimation of large motions, as described in Section 8.1.1. He also analyzes how the\nuncertainty in local motion estimates is related to the eigenvalues of the local Hessian matrix\nAi (8.44), as shown in Figures 8.3–8.4.\nBergen, Anandan, Hanna et al. (1992) develop a uniﬁed framework for describing both\nparametric (Section 8.2) and patch-based optic ﬂow algorithms and provide a nice introduc-\ntion to this topic. After each iteration of optic ﬂow estimation in a coarse-to-ﬁne pyramid,\nthey re-warp one of the images so that only incremental ﬂow estimates are computed (Sec-\ntion 8.1.1). When overlapping patches are used, an efﬁcient implementation is to ﬁrst com-\npute the outer products of the gradients and intensity errors (8.40–8.41) at every pixel and\nthen perform the overlapping window sums using a moving average ﬁlter.11\nInstead of solving for each motion (or motion update) independently, Horn and Schunck\n(1981) develop a regularization-based framework where (8.69) is simultaneously minimized\nover all ﬂow vectors {ui}. In order to constrain the problem, smoothness constraints, i.e.,\nsquared penalties on ﬂow derivatives, are added to the basic per-pixel error metric. Because\nthe technique was originally developed for small motions in a variational (continuous func-\ntion) framework, the linearized brightness constancy constraint corresponding to (8.35), i.e.,\n(8.38), is more commonly written as an analytic integral\nEHS =\nZ\n(Ixu + Iyv + It)2 dx dy,\n(8.70)\nwhere (Ix, Iy) = ∇I1 = J1 and It = ei is the temporal derivative, i.e., the brightness\nchange between images. The Horn and Schunck model can also be viewed as the limiting\ncase of spline-based motion estimation as the splines become 1x1 pixel patches.\nIt is also possible to combine ideas from local and global ﬂow estimation into a single\nframework by using a locally aggregated (as opposed to single-pixel) Hessian as the bright-\nness constancy term (Bruhn, Weickert, and Schn¨orr 2005). Consider the discrete analog\n(8.35) to the analytic global energy (8.70),\nEHSD =\nX\ni\nuT\ni [JiJT\ni ]ui + 2eiJT\ni ui + e2\ni .\n(8.71)\nIf we replace the per-pixel (rank 1) Hessians Ai = [JiJT\ni ] and residuals bi = Jiei with area-\naggregated versions (8.40–8.41), we obtain a global minimization algorithm where region-\nbased brightness constraints are used.\nAnother extension to the basic optic ﬂow model is to use a combination of global (para-\nmetric) and local motion models. For example, if we know that the motion is due to a camera\n11Other smoothing or aggregation ﬁlters can also be used at this stage (Bruhn, Weickert, and Schn¨orr 2005).",
  "image_path": "page_431.jpg",
  "pages": [
    430,
    431,
    432
  ]
}