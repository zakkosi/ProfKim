{
  "doc_id": "pages_622_624",
  "text": "600\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 12.15\nInteractive 3D modeling from panoramas (Shum, Han, and Szeliski 1998)\nc⃝1998 IEEE: (a) wide-angle view of a panorama with user-drawn vertical and horizontal\n(axis-aligned) lines; (b) single-view reconstruction of the corridors.\n2003).\nWhile earlier image-based modeling systems required some user authoring, Werner and\nZisserman (2002) present a fully automated line-based reconstruction system. As described\nin Section 7.5.1, they ﬁrst detect lines and vanishing points and use them to calibrate the\ncamera; then they establish line correspondences using both appearance matching and tri-\nfocal tensors, which enables them to reconstruct families of 3D line segments, as shown in\nFigure 12.16a. They then generate plane hypotheses, using both co-planar 3D lines and a\nplane sweep (Section 11.1.2) based on cross-correlation scores evaluated at interest points.\nIntersections of planes are used to determine the extent of each plane, i.e., an initial coarse ge-\nometry, which is then reﬁned with the addition of rectangular or wedge-shaped indentations\nand extrusions (Figure 12.16c). Note that when top-down maps of the buildings being mod-\neled are available, these can be used to further constrain the 3D modeling process (Robertson\nand Cipolla 2002, 2009). The idea of using matched 3D lines for estimating vanishing point\ndirections and dominant planes continues to be used in a number of recent fully automated\nimage-based architectural modeling systems (Zebedin, Bauer, Karner et al. 2008; Miˇcuˇs´ık\nand Koˇseck´a 2009; Furukawa, Curless, Seitz et al. 2009b; Sinha, Steedly, and Szeliski 2009).\nAnother common characteristic of architecture is the repeated use of primitives such as\nwindows, doors, and colonnades. Architectural modeling systems can be designed to search\nfor such repeated elements and to use them as part of the structure inference process (Dick,\nTorr, and Cipolla 2004; Mueller, Zeng, Wonka et al. 2007; Schindler, Krishnamurthy, Lublin-\nerman et al. 2008; Sinha, Steedly, Szeliski et al. 2008).\nThe combination of all these techniques now makes it possible to reconstruct the structure\nof large 3D scenes (Zhu and Kanade 2008). For example, the Urbanscan system of Polle-\nfeys, Nist´er, Frahm et al. (2008) reconstructs texture-mapped 3D models of city streets from\nvideos acquired with a GPS-equipped vehicle. To obtain real-time performance, they use\nboth optimized on-line structure-from-motion algorithms, as well as GPU implementations\n12.6 Model-based reconstruction\n601\n(a)\n(b)\n(c)\n(d)\nFigure 12.16\nAutomated architectural reconstruction using 3D lines and planes (Werner\nand Zisserman 2002) c⃝2002 Springer: (a) reconstructed 3D lines, color coded by their van-\nishing directions; (b) wire-frame model superimposed onto an input image; (c) triangulated\npiecewise-planar model with windows; (d) ﬁnal texture-mapped model.\nof plane-sweep stereo aligned to dominant planes and depth map fusion. Cornelis, Leibe,\nCornelis et al. (2008) present a related system that also uses plane-sweep stereo (aligned to\nvertical building fac¸ades) combined with object recognition and segmentation for vehicles.\nMiˇcuˇs´ık and Koˇseck´a (2009) build on these results using omni-directional images and super-\npixel-based stereo matching along dominant plane orientations. Reconstruction directly from\nactive range scanning data combined with color imagery that has been compensated for ex-\nposure and lighting variations is also possible (Chen and Chen 2008; Stamos, Liu, Chen et\nal. 2008; Troccoli and Allen 2008).\n12.6.2 Heads and faces\nAnother area in which specialized shape and appearance models are extremely helpful is in\nthe modeling of heads and faces. Even though the appearance of people seems at ﬁrst glance\nto be inﬁnitely variable, the actual shape of a person’s head and face can be described rea-\nsonably well using a few dozen parameters (Pighin, Hecker, Lischinski et al. 1998; Guenter,\nGrimm, Wood et al. 1998; DeCarlo, Metaxas, and Stone 1998; Blanz and Vetter 1999; Shan,\nLiu, and Zhang 2001).\nFigure 12.17 shows an example of an image-based modeling system, where user-speciﬁed\nkeypoints in several images are used to ﬁt a generic head model to a person’s face. As you\ncan see in Figure 12.17c, after specifying just over 100 keypoints, the shape of the face has\nbecome quite adapted and recognizable. Extracting a texture map from the original images\nand then applying it to the head model results in an animatable model with striking visual\nﬁdelity (Figure 12.18a).\nA more powerful system can be built by applying principal component analysis (PCA) to\na collection of 3D scanned faces, which is a topic we discuss in Section 12.6.3. As you can\nsee in Figure 12.19, it is then possible to ﬁt morphable 3D models to single images and to\n602\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 12.17\n3D model ﬁtting to a collection of images: (Pighin, Hecker, Lischinski et\nal. 1998) c⃝1998 ACM: (a) set of ﬁve input images along with user-selected keypoints; (b)\nthe complete set of keypoints and curves; (c) three meshes—the original, adapted after 13\nkeypoints, and after an additional 99 keypoints; (d) the partition of the image into separately\nanimatable regions.\n(a)\n(b)\nFigure 12.18\nHead and expression tracking and re-animation using deformable 3D models.\n(a) Models ﬁt directly to ﬁve input video streams (Pighin, Szeliski, and Salesin 2002) c⃝\n2002 Springer: The bottom row shows the results of re-animating a synthetic texture-mapped\n3D model with pose and expression parameters ﬁtted to the input images in the top row. (b)\nModels ﬁt to frame-rate spacetime stereo surface models (Zhang, Snavely, Curless et al. 2004)\nc⃝2004 ACM: The top row shows the input images with synthetic green markers overlaid,\nwhile the bottom row shows the ﬁtted 3D surface model.",
  "image_path": "page_623.jpg",
  "pages": [
    622,
    623,
    624
  ]
}