{
  "doc_id": "pages_725_727",
  "text": "14.4 Category recognition\n703\nX1\nX2\nX3\nX4\nX5\nX6\nX1\nX2\nX3\nX4\nX5\nX6\nX4\nX5\nX3\nX6\nX2\nX1\nX1\nX2\nX3\nX4\nX5\nX6\n(a)\n(b)\n(c)\n(d)\nX2\nX3\nX4\nX5\nX6\nX1\ng\nh1\nhg\nl1\nl2\nlK\nX1\nX3\nX2\nX5\nX6\nX7\n. . .\n. . .\nCenter\nPart\nSubpart\n. . .\nX1\nX2\nX3\nX4\nX5\nX6\nX1\nX2\nX3\nX4\nX5\nX6\nk=1\nk=2\n(e)\n(f)\n(g)\nFigure 14.41\nGraphical models for geometric spatial priors (Carneiro and Lowe 2006) c⃝\n2006 Springer: (a) constellation (Fergus, Perona, and Zisserman 2007); (b) star (Crandall,\nFelzenszwalb, and Huttenlocher 2005; Fergus, Perona, and Zisserman 2005); (c) k-fan (k =\n2) (Crandall, Felzenszwalb, and Huttenlocher 2005); (d) tree (Felzenszwalb and Huttenlocher\n2005); (e) bag of features (Csurka, Dance, Fan et al. 2004); (f) hierarchy (Bouchard and\nTriggs 2005); (g) sparse ﬂexible model (Carneiro and Lowe 2006).\nlated body model to a binary image obtained by background segmentation. In this application\nof pictorial structures, parts are parameterized by the locations, sizes, and orientations of their\napproximating rectangles. Unary matching potentials Vi(li) are determined by counting the\npercentage of foreground and background pixels inside and just outside the tilted rectangle\nrepresenting each part.\nOver the last decade, a large number of different graphical models have been proposed\nfor part-based recognition, as shown in Figure 14.41. Carneiro and Lowe (2006) discuss\na number of these models and propose one of their own, which they call a sparse ﬂexible\nmodel; it involves ordering the parts and having each part’s location depend on at most k of\nits ancestor locations.\nThe simplest models, which we saw in Section 14.4.1, are bags of words, where there are\nno geometric relationships between different parts or features. While such models can be very\nefﬁcient, they have a very limited capacity to express the spatial arrangement of parts. Trees\nand stars (a special case of trees where all leaf nodes are directly connected to a common root)\nare the most efﬁcient in terms of inference and hence also learning (Felzenszwalb and Hutten-\nlocher 2005; Fergus, Perona, and Zisserman 2005; Felzenszwalb, McAllester, and Ramanan\n2008). Directed acyclic graphs (Figure 14.41f–g) come next in terms of complexity and can\nstill support efﬁcient inference, although at the cost of imposing a causal structure on the\n704\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\npart model (Bouchard and Triggs 2005; Carneiro and Lowe 2006). k-fans, in which a clique\nof size k forms the root of a star-shaped model (Figure 14.41c) have inference complexity\nO(N k+1), although with distance transforms and Gaussian priors, this can be lowered to\nO(N k) (Crandall, Felzenszwalb, and Huttenlocher 2005; Crandall and Huttenlocher 2006).\nFinally, fully connected constellation models (Figure 14.41a) are the most general, but the\nassignment of features to parts becomes intractable for moderate numbers of parts P, since\nthe complexity of such an assignment is O(N P ) (Fergus, Perona, and Zisserman 2007).\nThe original constellation model was developed by Burl, Weber, and Perona (1998) and\nconsists of a number of parts whose relative positions are encoded by their mean locations\nand a full covariance matrix, which is used to denote not only positional uncertainty but also\npotential correlations (covariance) between different parts (Figure 14.42a). Weber, Welling,\nand Perona (2000) extended this technique to a weakly supervised setting, where both the\nappearance of each part and its locations are automatically learned given only whole image\nlabels. Fergus, Perona, and Zisserman (2007) further extend this approach to simultaneous\nlearning of appearance and shape models from scale-invariant keypoint detections.\nFigure 14.42a shows the shape model learned for the motorcycle class. The top ﬁgure\nshows the mean relative locations for each part along with their position covariances (inter-\npart covariances are not shown) and likelihood of occurrence. The bottom curve shows the\nGaussian PDFs for the relative log-scale of each part with respect to the “landmark” feature.\nFigure 14.42b shows the appearance model learned for each part, visualized as the patches\naround detected features in the training database that best match the appearance model. Fig-\nure 14.42c shows the features detected in the test database (pink dots) along with the corre-\nsponding parts that they were assigned to (colored circles). As you can see, the system has\nsuccessfully learned and then used a fairly complex model of motorcycle appearance.\nThe part-based approach to recognition has also been extended to learning new categories\nfrom small numbers of examples, building on recognition components developed for other\nclasses (Fei-Fei, Fergus, and Perona 2006). More complex hierarchical part-based models can\nbe developed using the concept of grammars (Bouchard and Triggs 2005; Zhu and Mumford\n2006). A simpler way to use parts is to have keypoints that are recognized as being part of\na class vote for the estimated part locations, as shown in the top row of Figure 14.43 (Leibe,\nLeonardis, and Schiele 2008). (Implicitly, this corresponds to having a star-shaped geometric\nmodel.)\n14.4.3 Recognition with segmentation\nThe most challenging version of generic object recognition is to simultaneously perform\nrecognition with accurate boundary segmentation (Fergus 2007a). For instance recognition\n(Section 14.3.1), this can sometimes be achieved by backprojecting the object model into\n14.4 Category recognition\n705\n(a)\n(b)\nCorrect\nCorrect\nINCORRECT\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nCorrect\nINCORRECT\nINCORRECT\nCorrect\nINCORRECT\nCorrect\nCorrect\nCorrect\n(c)\nFigure 14.42\nPart-based recognition (Fergus, Perona, and Zisserman 2007)\nc⃝2007\nSpringer: (a) locations and covariance ellipses for each part, along with their occurrence\nprobabilities (top) and relative log-scale densities (bottom); (b) part examples drawn from\nthe training images that best match the average appearance; (c) recognition results for the\nmotorcycle class, showing detected features (pink dots) and parts (colored circles).",
  "image_path": "page_726.jpg",
  "pages": [
    725,
    726,
    727
  ]
}