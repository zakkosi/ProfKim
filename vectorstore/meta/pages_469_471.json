{
  "doc_id": "pages_469_471",
  "text": "9.2 Global alignment\n447\n(a)\n(b)\n(c)\nFigure 9.10\nDeghosting a mosaic with motion parallax (Shum and Szeliski 2000) c⃝2000\nIEEE: (a) composite with parallax; (b) after a single deghosting step (patch size 32); (c) after\nmultiple steps (sizes 32, 16 and 8).\nmas. If the user takes images in sequence so that each image overlaps its predecessor and\nalso speciﬁes the ﬁrst and last images to be stitched, bundle adjustment combined with the\nprocess of topology inference can be used to automatically assemble a panorama (Sawhney\nand Kumar 1999). However, users often jump around when taking panoramas, e.g., they\nmay start a new row on top of a previous one, jump back to take a repeat shot, or create\n360◦panoramas where end-to-end overlaps need to be discovered. Furthermore, the ability\nto discover multiple panoramas taken by a user over an extended period of time can be a big\nconvenience.\nTo recognize panoramas, Brown and Lowe (2007) ﬁrst ﬁnd all pairwise image overlaps\nusing a feature-based method and then ﬁnd connected components in the overlap graph to\n“recognize” individual panoramas (Figure 9.11). The feature-based matching stage ﬁrst ex-\ntracts scale invariant feature transform (SIFT) feature locations and feature descriptors (Lowe\n2004) from all the input images and places them in an indexing structure, as described in Sec-\ntion 4.1.3. For each image pair under consideration, the nearest matching neighbor is found\nfor each feature in the ﬁrst image, using the indexing structure to rapidly ﬁnd candidates and\nthen comparing feature descriptors to ﬁnd the best match. RANSAC is used to ﬁnd a set of in-\nlier matches; pairs of matches are used to hypothesize similarity motion models that are then\nused to count the number of inliers. (A more recent RANSAC algorithm tailored speciﬁcally\nfor rotational panoramas is described by Brown, Hartley, and Nist´er (2007).)\nIn practice, the most difﬁcult part of getting a fully automated stitching algorithm to\nwork is deciding which pairs of images actually correspond to the same parts of the scene.\nRepeated structures such as windows (Figure 9.12) can lead to false matches when using\na feature-based approach. One way to mitigate this problem is to perform a direct pixel-\nbased comparison between the registered images to determine if they actually are different\nviews of the same scene. Unfortunately, this heuristic may fail if there are moving objects\nin the scene (Figure 9.13). While there is no magic bullet for this problem, short of full\nscene understanding, further improvements can likely be made by applying domain-speciﬁc\n448\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.11\nRecognizing panoramas (Brown, Szeliski, and Winder 2005), ﬁgures cour-\ntesy of Matthew Brown: (a) input images with pairwise matches; (b) images grouped into\nconnected components (panoramas); (c) individual panoramas registered and blended into\nstitched composites.\n9.2 Global alignment\n449\nFigure 9.12\nMatching errors (Brown, Szeliski, and Winder 2004): accidental matching of\nseveral features can lead to matches between pairs of images that do not actually overlap.\nFigure 9.13\nValidation of image matches by direct pixel error comparison can fail when the\nscene contains moving objects (Uyttendaele, Eden, and Szeliski 2001) c⃝2001 IEEE.",
  "image_path": "page_470.jpg",
  "pages": [
    469,
    470,
    471
  ]
}