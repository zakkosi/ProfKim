{
  "doc_id": "pages_226_228",
  "text": "204\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 3.29: Rainbow enhancer—challenging\nTake a picture containing a rainbow, such as\nFigure 3.66, and enhance the strength (saturation) of the rainbow.\n1. Draw an arc in the image delineating the extent of the rainbow.\n2. Fit an additive rainbow function (explain why it is additive) to this arc (it is best to work\nwith linearized pixel values), using the spectrum as the cross section, and estimating\nthe width of the arc and the amount of color being added. This is the trickiest part of\nthe problem, as you need to tease apart the (low-frequency) rainbow pattern and the\nnatural image hiding behind it.\n3. Amplify the rainbow signal and add it back into the image, re-applying the gamma\nfunction if necessary to produce the ﬁnal image.\nEx 3.30: Image deblocking—challenging\nNow that you have some good techniques to\ndistinguish signal from noise, develop a technique to remove the blocking artifacts that occur\nwith JPEG at high compression settings (Section 2.3.3). Your technique can be as simple\nas looking for unexpected edges along block boundaries, to looking at the quantization step\nas a projection of a convex region of the transform coefﬁcient space onto the corresponding\nquantized values.\n1. Does the knowledge of the compression factor, which is available in the JPEG header\ninformation, help you perform better deblocking?\n2. Because the quantization occurs in the DCT transformed YCbCr space (2.115), it may\nbe preferable to perform the analysis in this space. On the other hand, image priors\nmake more sense in an RGB space (or do they?). Decide how you will approach this\ndichotomy and discuss your choice.\n3. While you are at it, since the YCbCr conversion is followed by a chrominance subsam-\npling stage (before the DCT), see if you can restore some of the lost high-frequency\nchrominance signal using one of the better restoration techniques discussed in this\nchapter.\n4. If your camera has a RAW + JPEG mode, how close can you come to the noise-free\ntrue pixel values? (This suggestion may not be that useful, since cameras generally use\nreasonably high quality settings for their RAW + JPEG models.)\nEx 3.31: Inference in de-blurring—challenging\nWrite down the graphical model corre-\nsponding to Figure 3.59 for a non-blind image deblurring problem, i.e., one where the blur\nkernel is known ahead of time.\nWhat kind of efﬁcient inference (optimization) algorithms can you think of for solving\nsuch problems?\nChapter 4\nFeature detection and matching\n4.1\nPoints and patches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n4.1.1\nFeature detectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\n4.1.2\nFeature descriptors . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\n4.1.3\nFeature matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\n4.1.4\nFeature tracking\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\n4.1.5\nApplication: Performance-driven animation . . . . . . . . . . . . . . 237\n4.2\nEdges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n4.2.1\nEdge detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n4.2.2\nEdge linking\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\n4.2.3\nApplication: Edge editing and enhancement . . . . . . . . . . . . . . 249\n4.3\nLines\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\n4.3.1\nSuccessive approximation\n. . . . . . . . . . . . . . . . . . . . . . . 250\n4.3.2\nHough transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\n4.3.3\nVanishing points\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 254\n4.3.4\nApplication: Rectangle detection . . . . . . . . . . . . . . . . . . . . 257\n4.4\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257\n4.5\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n206\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 4.1 A variety of feature detectors and descriptors can be used to analyze, describe and\nmatch images: (a) point-like interest operators (Brown, Szeliski, and Winder 2005) c⃝2005\nIEEE; (b) region-like interest operators (Matas, Chum, Urban et al. 2004) c⃝2004 Elsevier;\n(c) edges (Elder and Goldberg 2001) c⃝2001 IEEE; (d) straight lines (Sinha, Steedly, Szeliski\net al. 2008) c⃝2008 ACM.",
  "image_path": "page_227.jpg",
  "pages": [
    226,
    227,
    228
  ]
}