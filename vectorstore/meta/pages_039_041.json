{
  "doc_id": "pages_039_041",
  "text": "1.2 A brief history\n17\nMulti-view stereo algorithms (Figure 1.9c) that produce complete 3D surfaces (see Sec-\ntion 11.6) were also an active topic of research (Seitz and Dyer 1999; Kutulakos and Seitz\n2000) that continues to be active today (Seitz, Curless, Diebel et al. 2006). Techniques for\nproducing 3D volumetric descriptions from binary silhouettes (see Section 11.6.2) continued\nto be developed (Potmesil 1987; Srivasan, Liang, and Hackwood 1990; Szeliski 1993; Lau-\nrentini 1994), along with techniques based on tracking and reconstructing smooth occluding\ncontours (see Section 11.2.1 and Cipolla and Blake 1992; Vaillant and Faugeras 1992; Zheng\n1994; Boyer and Berger 1997; Szeliski and Weiss 1998; Cipolla and Giblin 2000).\nTracking algorithms also improved a lot, including contour tracking using active contours\n(see Section 5.1), such as snakes (Kass, Witkin, and Terzopoulos 1988), particle ﬁlters (Blake\nand Isard 1998), and level sets (Malladi, Sethian, and Vemuri 1995), as well as intensity-based\n(direct) techniques (Lucas and Kanade 1981; Shi and Tomasi 1994; Rehg and Kanade 1994),\noften applied to tracking faces (Figure 1.9d) (Lanitis, Taylor, and Cootes 1997; Matthews and\nBaker 2004; Matthews, Xiao, and Baker 2007) and whole bodies (Sidenbladh, Black, and\nFleet 2000; Hilton, Fua, and Ronfard 2006; Moeslund, Hilton, and Kr¨uger 2006).\nImage segmentation (see Chapter 5) (Figure 1.9e), a topic which has been active since\nthe earliest days of computer vision (Brice and Fennema 1970; Horowitz and Pavlidis 1976;\nRiseman and Arbib 1977; Rosenfeld and Davis 1979; Haralick and Shapiro 1985; Pavlidis\nand Liow 1990), was also an active topic of research, producing techniques based on min-\nimum energy (Mumford and Shah 1989) and minimum description length (Leclerc 1989),\nnormalized cuts (Shi and Malik 2000), and mean shift (Comaniciu and Meer 2002).\nStatistical learning techniques started appearing, ﬁrst in the application of principal com-\nponent eigenface analysis to face recognition (Figure 1.9f) (see Section 14.2.1 and Turk and\nPentland 1991a) and linear dynamical systems for curve tracking (see Section 5.1.1 and Blake\nand Isard 1998).\nPerhaps the most notable development in computer vision during this decade was the\nincreased interaction with computer graphics (Seitz and Szeliski 1999), especially in the\ncross-disciplinary area of image-based modeling and rendering (see Chapter 13). The idea of\nmanipulating real-world imagery directly to create new animations ﬁrst came to prominence\nwith image morphing techniques (Figure1.5c) (see Section 3.6.3 and Beier and Neely 1992)\nand was later applied to view interpolation (Chen and Williams 1993; Seitz and Dyer 1996),\npanoramic image stitching (Figure1.5a) (see Chapter 9 and Mann and Picard 1994; Chen\n1995; Szeliski 1996; Szeliski and Shum 1997; Szeliski 2006a), and full light-ﬁeld rendering\n(Figure 1.10a) (see Section 13.3 and Gortler, Grzeszczuk, Szeliski et al. 1996; Levoy and\nHanrahan 1996; Shade, Gortler, He et al. 1998). At the same time, image-based modeling\ntechniques (Figure 1.10b) for automatically creating realistic 3D models from collections of\nimages were also being introduced (Beardsley, Torr, and Zisserman 1996; Debevec, Taylor,\nand Malik 1996; Taylor, Debevec, and Malik 1996).\n18\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.10\nRecent examples of computer vision algorithms: (a) image-based rendering\n(Gortler, Grzeszczuk, Szeliski et al. 1996), (b) image-based modeling (Debevec, Taylor, and\nMalik 1996) c⃝1996 ACM, (c) interactive tone mapping (Lischinski, Farbman, Uyttendaele\net al. 2006a) (d) texture synthesis (Efros and Freeman 2001), (e) feature-based recognition\n(Fergus, Perona, and Zisserman 2007), (f) region-based recognition (Mori, Ren, Efros et al.\n2004) c⃝2004 IEEE.\n2000s.\nThis past decade has continued to see a deepening interplay between the vision and\ngraphics ﬁelds. In particular, many of the topics introduced under the rubric of image-based\nrendering, such as image stitching (see Chapter 9), light-ﬁeld capture and rendering (see\nSection 13.3), and high dynamic range (HDR) image capture through exposure bracketing\n(Figure1.5b) (see Section 10.2 and Mann and Picard 1995; Debevec and Malik 1997), were\nre-christened as computational photography (see Chapter 10) to acknowledge the increased\nuse of such techniques in everyday digital photography. For example, the rapid adoption of\nexposure bracketing to create high dynamic range images necessitated the development of\ntone mapping algorithms (Figure 1.10c) (see Section 10.2.1) to convert such images back\nto displayable results (Fattal, Lischinski, and Werman 2002; Durand and Dorsey 2002; Rein-\nhard, Stark, Shirley et al. 2002; Lischinski, Farbman, Uyttendaele et al. 2006a). In addition to\nmerging multiple exposures, techniques were developed to merge ﬂash images with non-ﬂash\ncounterparts (Eisemann and Durand 2004; Petschnigg, Agrawala, Hoppe et al. 2004) and to\ninteractively or automatically select different regions from overlapping images (Agarwala,\n1.3 Book overview\n19\nDontcheva, Agrawala et al. 2004).\nTexture synthesis (Figure 1.10d) (see Section 10.5), quilting (Efros and Leung 1999; Efros\nand Freeman 2001; Kwatra, Sch¨odl, Essa et al. 2003) and inpainting (Bertalmio, Sapiro,\nCaselles et al. 2000; Bertalmio, Vese, Sapiro et al. 2003; Criminisi, P´erez, and Toyama 2004)\nare additional topics that can be classiﬁed as computational photography techniques, since\nthey re-combine input image samples to produce new photographs.\nA second notable trend during this past decade has been the emergence of feature-based\ntechniques (combined with learning) for object recognition (see Section 14.3 and Ponce,\nHebert, Schmid et al. 2006). Some of the notable papers in this area include the constellation\nmodel of Fergus, Perona, and Zisserman (2007) (Figure 1.10e) and the pictorial structures\nof Felzenszwalb and Huttenlocher (2005). Feature-based techniques also dominate other\nrecognition tasks, such as scene recognition (Zhang, Marszalek, Lazebnik et al. 2007) and\npanorama and location recognition (Brown and Lowe 2007; Schindler, Brown, and Szeliski\n2007). And while interest point (patch-based) features tend to dominate current research,\nsome groups are pursuing recognition based on contours (Belongie, Malik, and Puzicha 2002)\nand region segmentation (Figure 1.10f) (Mori, Ren, Efros et al. 2004).\nAnother signiﬁcant trend from this past decade has been the development of more efﬁcient\nalgorithms for complex global optimization problems (see Sections 3.7 and B.5 and Szeliski,\nZabih, Scharstein et al. 2008; Blake, Kohli, and Rother 2010). While this trend began with\nwork on graph cuts (Boykov, Veksler, and Zabih 2001; Kohli and Torr 2007), a lot of progress\nhas also been made in message passing algorithms, such as loopy belief propagation (LBP)\n(Yedidia, Freeman, and Weiss 2001; Kumar and Torr 2006).\nThe ﬁnal trend, which now dominates a lot of the visual recognition research in our com-\nmunity, is the application of sophisticated machine learning techniques to computer vision\nproblems (see Section 14.5.1 and Freeman, Perona, and Sch¨olkopf 2008). This trend coin-\ncides with the increased availability of immense quantities of partially labelled data on the\nInternet, which makes it more feasible to learn object categories without the use of careful\nhuman supervision.\n1.3 Book overview\nIn the ﬁnal part of this introduction, I give a brief tour of the material in this book, as well\nas a few notes on notation and some additional general references. Since computer vision is\nsuch a broad ﬁeld, it is possible to study certain aspects of it, e.g., geometric image formation\nand 3D structure recovery, without engaging other parts, e.g., the modeling of reﬂectance and\nshading. Some of the chapters in this book are only loosely coupled with others, and it is not\nstrictly necessary to read all of the material in sequence.",
  "image_path": "page_040.jpg",
  "pages": [
    39,
    40,
    41
  ]
}