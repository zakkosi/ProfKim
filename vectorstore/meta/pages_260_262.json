{
  "doc_id": "pages_260_262",
  "text": "238\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 4.30\nPerformance-driven, hand-drawn animation (Buck, Finkelstein, Jacobs et al.\n2000) c⃝2000 ACM: (a) eye and mouth portions of hand-drawn sketch with their overlaid\ncontrol lines; (b) an input video frame with the tracked features overlaid; (c) a different input\nvideo frame along with its (d) corresponding hand-drawn animation.\n4.2 Edges\nWhile interest points are useful for ﬁnding image locations that can be accurately matched\nin 2D, edge points are far more plentiful and often carry important semantic associations.\nFor example, the boundaries of objects, which also correspond to occlusion events in 3D, are\nusually delineated by visible contours. Other kinds of edges correspond to shadow boundaries\nor crease edges, where surface orientation changes rapidly. Isolated edge points can also be\ngrouped into longer curves or contours, as well as straight line segments (Section 4.3). It\nis interesting that even young children have no difﬁculty in recognizing familiar objects or\nanimals from such simple line drawings.\n4.2.1 Edge detection\nGiven an image, how can we ﬁnd the salient edges? Consider the color images in Figure 4.31.\nIf someone asked you to point out the most “salient” or “strongest” edges or the object bound-\naries (Martin, Fowlkes, and Malik 2004; Arbel´aez, Maire, Fowlkes et al. 2010), which ones\nwould you trace? How closely do your perceptions match the edge images shown in Fig-\nure 4.31?\nQualitatively, edges occur at boundaries between regions of different color, intensity, or\ntexture. Unfortunately, segmenting an image into coherent regions is a difﬁcult task, which\nwe address in Chapter 5. Often, it is preferable to detect edges using only purely local infor-\nmation.\nUnder such conditions, a reasonable approach is to deﬁne an edge as a location of rapid\n4.2 Edges\n239\nFigure 4.31 Human boundary detection (Martin, Fowlkes, and Malik 2004) c⃝2004 IEEE.\nThe darkness of the edges corresponds to how many human subjects marked an object bound-\nary at that location.\nintensity variation.3 Think of an image as a height ﬁeld. On such a surface, edges occur\nat locations of steep slopes, or equivalently, in regions of closely packed contour lines (on a\ntopographic map).\nA mathematical way to deﬁne the slope and direction of a surface is through its gradient,\nJ(x) = ∇I(x) = (∂I\n∂x, ∂I\n∂y )(x).\n(4.19)\nThe local gradient vector J points in the direction of steepest ascent in the intensity function.\nIts magnitude is an indication of the slope or strength of the variation, while its orientation\npoints in a direction perpendicular to the local contour.\nUnfortunately, taking image derivatives accentuates high frequencies and hence ampliﬁes\nnoise, since the proportion of noise to signal is larger at high frequencies. It is therefore\nprudent to smooth the image with a low-pass ﬁlter prior to computing the gradient. Because\nwe would like the response of our edge detector to be independent of orientation, a circularly\nsymmetric smoothing ﬁlter is desirable. As we saw in Section 3.2, the Gaussian is the only\nseparable circularly symmetric ﬁlter and so it is used in most edge detection algorithms.\nCanny (1986) discusses alternative ﬁlters and a number of researcher review alternative edge\ndetection algorithms and compare their performance (Davis 1975; Nalwa and Binford 1986;\nNalwa 1987; Deriche 1987; Freeman and Adelson 1991; Nalwa 1993; Heath, Sarkar, Sanocki\net al. 1998; Crane 1997; Ritter and Wilson 2000; Bowyer, Kranenburg, and Dougherty 2001;\nArbel´aez, Maire, Fowlkes et al. 2010).\nBecause differentiation is a linear operation, it commutes with other linear ﬁltering oper-\n3 We defer the topic of edge detection in color images.\n240\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nations. The gradient of the smoothed image can therefore be written as\nJσ(x) = ∇[Gσ(x) ∗I(x)] = [∇Gσ](x) ∗I(x),\n(4.20)\ni.e., we can convolve the image with the horizontal and vertical derivatives of the Gaussian\nkernel function,\n∇Gσ(x) = (∂Gσ\n∂x , ∂Gσ\n∂y )(x) = [−x −y] 1\nσ3 exp\n\u0012\n−x2 + y2\n2σ2\n\u0013\n(4.21)\n(The parameter σ indicates the width of the Gaussian.) This is the same computation that\nis performed by Freeman and Adelson’s (1991) ﬁrst-order steerable ﬁlter, which we already\ncovered in Section 3.2.3.\nFor many applications, however, we wish to thin such a continuous gradient image to\nonly return isolated edges, i.e., as single pixels at discrete locations along the edge contours.\nThis can be achieved by looking for maxima in the edge strength (gradient magnitude) in a\ndirection perpendicular to the edge orientation, i.e., along the gradient direction.\nFinding this maximum corresponds to taking a directional derivative of the strength ﬁeld\nin the direction of the gradient and then looking for zero crossings. The desired directional\nderivative is equivalent to the dot product between a second gradient operator and the results\nof the ﬁrst,\nSσ(x) = ∇· Jσ(x) = [∇2Gσ](x) ∗I(x)].\n(4.22)\nThe gradient operator dot product with the gradient is called the Laplacian. The convolution\nkernel\n∇2Gσ(x) = 1\nσ3\n\u0012\n2 −x2 + y2\n2σ2\n\u0013\nexp\n\u0012\n−x2 + y2\n2σ2\n\u0013\n(4.23)\nis therefore called the Laplacian of Gaussian (LoG) kernel (Marr and Hildreth 1980). This\nkernel can be split into two separable parts,\n∇2Gσ(x) = 1\nσ3\n\u0012\n1 −x2\n2σ2\n\u0013\nGσ(x)Gσ(y) + 1\nσ3\n\u0012\n1 −y2\n2σ2\n\u0013\nGσ(y)Gσ(x)\n(4.24)\n(Wiejak, Buxton, and Buxton 1985), which allows for a much more efﬁcient implementation\nusing separable ﬁltering (Section 3.2.1).\nIn practice, it is quite common to replace the Laplacian of Gaussian convolution with a\nDifference of Gaussian (DoG) computation, since the kernel shapes are qualitatively similar\n(Figure 3.35). This is especially convenient if a “Laplacian pyramid” (Section 3.5) has already\nbeen computed.4\n4 Recall that Burt and Adelson’s (1983a) “Laplacian pyramid” actually computed differences of Gaussian-ﬁltered\nlevels.",
  "image_path": "page_261.jpg",
  "pages": [
    260,
    261,
    262
  ]
}