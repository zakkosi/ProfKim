{
  "doc_id": "pages_486_488",
  "text": "464\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n6. Blend the resulting images using feathering or some other technique.\nEx 9.4: Coarse alignment\nUse FFT or phase correlation (Section 8.1.2) to estimate the\ninitial alignment between successive images. How well does this work? Over what range of\noverlaps? If it does not work, does aligning sub-sections (e.g., quarters) do better?\nEx 9.5: Automated mosaicing\nUse feature-based alignment with four-point RANSAC for\nhomographies (Section 6.1.3, Equations (6.19–6.23)) or three-point RANSAC for rotational\nmotions (Brown, Hartley, and Nist´er 2007) to match up all pairs of overlapping images.\nMerge these pairwise estimates together by ﬁnding a spanning tree of pairwise relations.\nVisualize the resulting global alignment, e.g., by displaying a blend of each image with all\nother images that overlap it.\nFor greater robustness, try multiple spanning trees (perhaps randomly sampled based on\nthe conﬁdence in pairwise alignments) to see if you can recover from bad pairwise matches\n(Zach, Klopschitz, and Pollefeys 2010). As a measure of ﬁtness, count how many pairwise\nestimates are consistent with the global alignment.\nEx 9.6: Global optimization\nUse the initialization from the previous algorithm to perform\na full bundle adjustment over all of the camera rotations and focal lengths, as described in\nSection 7.4 and by Shum and Szeliski (2000). Optionally, estimate radial distortion parame-\nters as well or support ﬁsheye lenses (Section 2.1.6).\nAs in the previous exercise, visualize the quality of your registration by creating compos-\nites of each input image with its neighbors, optionally blinking between the original image\nand the composite to better see mis-alignment artifacts.\nEx 9.7: De-ghosting\nUse the results of the previous bundle adjustment to predict the loca-\ntion of each feature in a consensus geometry. Use the difference between the predicted and\nactual feature locations to correct for small mis-registrations, as described in Section 9.2.2\n(Shum and Szeliski 2000).\nEx 9.8: Compositing surface\nChoose a compositing surface (Section 9.3.1), e.g., a single\nreference image extended to a larger plane, a sphere represented using cylindrical or spherical\ncoordinates, a stereographic “little planet” projection, or a cube map.\nProject all of your images onto this surface and blend them with equal weighting, for now\n(just to see where the original image seams are).\nEx 9.9: Feathering and blending\nCompute a feather (distance) map for each warped source\nimage and use these maps to blend the warped images.\nAlternatively, use Laplacian pyramid blending (Exercise 3.20) or gradient domain blend-\ning.\n9.5 Exercises\n465\nEx 9.10: Photomontage and object removal\nImplement a “PhotoMontage” system in which\nusers can indicate desired or unwanted regions in pre-registered images using strokes or other\nprimitives (such as bounding boxes).\n(Optional) Devise an automatic moving objects remover (or “keeper”) by analyzing which\ninconsistent regions are more or less typical given some consensus (e.g., median ﬁltering) of\nthe aligned images. Figure 9.17 shows an example where the moving object was kept. Try\nto make this work for sequences with large amounts of overlaps and consider averaging the\nimages to make the moving object look more ghosted.\n466\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)",
  "image_path": "page_487.jpg",
  "pages": [
    486,
    487,
    488
  ]
}