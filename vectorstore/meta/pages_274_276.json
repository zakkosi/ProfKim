{
  "doc_id": "pages_274_276",
  "text": "252\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nθi\nri\nθ\n(xi,yi)\n0\n360\n0\nrmax\nr\n-rmax\nx\ny\n(a)\n(b)\nFigure 4.42 Oriented Hough transform: (a) an edgel re-parameterized in polar (r, θ) coor-\ndinates, with ˆni = (cos θi, sin θi) and ri = ˆni · xi; (b) (r, θ) accumulator array, showing the\nvotes for the three edgels marked in red, green, and blue.\ny\nx\nd\nθ\nn\nl\n^\nFigure 4.43 2D line equation expressed in terms of the normal ˆn and distance to the origin\nd.\nwhere each edgel votes for a number of possible orientation or location pairs centered around\nthe estimate orientation, may be desirable in some cases.\nBefore we can vote for line hypotheses, we must ﬁrst choose a suitable representation.\nFigure 4.43 (copied from Figure 2.2a) shows the normal-distance (ˆn, d) parameterization for\na line. Since lines are made up of edge segments, we adopt the convention that the line normal\nˆn points in the same direction (i.e., has the same sign) as the image gradient J(x) = ∇I(x)\n(4.19). To obtain a minimal two-parameter representation for lines, we convert the normal\nvector into an angle\nθ = tan−1 ny/nx,\n(4.26)\nas shown in Figure 4.43. The range of possible (θ, d) values is [−180◦, 180◦] × [−\n√\n2,\n√\n2],\nassuming that we are using normalized pixel coordinates (2.61) that lie in [−1, 1]. The number\nof bins to use along each axis depends on the accuracy of the position and orientation estimate\navailable at each edgel and the expected line density, and is best set experimentally with some\ntest runs on sample imagery.\nGiven the line parameterization, the Hough transform proceeds as shown in Algorithm 4.2.\n4.3 Lines\n253\nprocedure Hough({(x, y, θ)}):\n1. Clear the accumulator array.\n2. For each detected edgel at location (x, y) and orientation θ = tan−1 ny/nx,\ncompute the value of\nd = x nx + y ny\nand increment the accumulator corresponding to (θ, d).\n3. Find the peaks in the accumulator corresponding to lines.\n4. Optionally re-ﬁt the lines to the constituent edgels.\nAlgorithm 4.2 Outline of a Hough transform algorithm based on oriented edge segments.\nNote that the original formulation of the Hough transform, which assumed no knowledge of\nthe edgel orientation θ, has an additional loop inside Step 2 that iterates over all possible\nvalues of θ and increments a whole series of accumulators.\nThere are a lot of details in getting the Hough transform to work well, but these are\nbest worked out by writing an implementation and testing it out on sample data. Exercise\n4.12 describes some of these steps in more detail, including using edge segment lengths or\nstrengths during the voting process, keeping a list of constituent edgels in the accumulator\narray for easier post-processing, and optionally combining edges of different “polarity” into\nthe same line segments.\nAn alternative to the 2D polar (θ, d) representation for lines is to use the full 3D m =\n(ˆn, d) line equation, projected onto the unit sphere. While the sphere can be parameterized\nusing spherical coordinates (2.8),\nˆm = (cos θ cos φ, sin θ cos φ, sin φ),\n(4.27)\nthis does not uniformly sample the sphere and still requires the use of trigonometry.\nAn alternative representation can be obtained by using a cube map, i.e., projecting m onto\nthe face of a unit cube (Figure 4.44a). To compute the cube map coordinate of a 3D vector\nm, ﬁrst ﬁnd the largest (absolute value) component of m, i.e., m = ± max(|nx|, |ny|, |d|),\nand use this to select one of the six cube faces. Divide the remaining two coordinates by m\nand use these as indices into the cube face. While this avoids the use of trigonometry, it does\nrequire some decision logic.\nOne advantage of using the cube map, ﬁrst pointed out by Tuytelaars, Van Gool, and\nProesmans (1997), is that all of the lines passing through a point correspond to line segments\n254\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n⇒\n(a)\n(b)\nFigure 4.44 Cube map representation for line equations and vanishing points: (a) a cube map\nsurrounding the unit sphere; (b) projecting the half-cube onto three subspaces (Tuytelaars,\nVan Gool, and Proesmans 1997) c⃝1997 IEEE.\non the cube faces, which is useful if the original (full voting) variant of the Hough transform\nis being used. In their work, they represent the line equation as ax + b + y = 0, which\ndoes not treat the x and y axes symmetrically. Note that if we restrict d ≥0 by ignoring the\npolarity of the edge orientation (gradient sign), we can use a half-cube instead, which can be\nrepresented using only three cube faces, as shown in Figure 4.44b (Tuytelaars, Van Gool, and\nProesmans 1997).\nRANSAC-based line detection.\nAnother alternative to the Hough transform is the RAN-\ndom SAmple Consensus (RANSAC) algorithm described in more detail in Section 6.1.4. In\nbrief, RANSAC randomly chooses pairs of edgels to form a line hypothesis and then tests\nhow many other edgels fall onto this line. (If the edge orientations are accurate enough, a\nsingle edgel can produce this hypothesis.) Lines with sufﬁciently large numbers of inliers\n(matching edgels) are then selected as the desired line segments.\nAn advantage of RANSAC is that no accumulator array is needed and so the algorithm can\nbe more space efﬁcient and potentially less prone to the choice of bin size. The disadvantage\nis that many more hypotheses may need to be generated and tested than those obtained by\nﬁnding peaks in the accumulator array.\nIn general, there is no clear consensus on which line estimation technique performs best.\nIt is therefore a good idea to think carefully about the problem at hand and to implement\nseveral approaches (successive approximation, Hough, and RANSAC) to determine the one\nthat works best for your application.\n4.3.3 Vanishing points\nIn many scenes, structurally important lines have the same vanishing point because they are\nparallel in 3D. Examples of such lines are horizontal and vertical building edges, zebra cross-\nings, railway tracks, the edges of furniture such as tables and dressers, and of course, the\nubiquitous calibration pattern (Figure 4.45). Finding the vanishing points common to such",
  "image_path": "page_275.jpg",
  "pages": [
    274,
    275,
    276
  ]
}