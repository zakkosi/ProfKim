{
  "doc_id": "pages_562_564",
  "text": "540\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 11.5\nSlices through a typical disparity space image (DSI) (Scharstein and Szeliski\n2002) c⃝2002 Springer: (a) original color image; (b) ground truth disparities; (c–e) three\n(x, y) slices for d = 10, 16, 21; (f) an (x, d) slice for y = 151 (the dashed line in (b)).\nVarious dark (matching) regions are visible in (c–e), e.g., the bookshelves, table and cans,\nand head statue, and three disparity levels can be seen as horizontal lines in (f). The dark\nbands in the DSIs indicate regions that match at this disparity. (Smaller dark regions are often\nthe result of textureless regions.) Additional examples of DSIs are discussed by Bobick and\nIntille (1999).\n2002).3 The task of extracting depth from a set of images then becomes one of estimating the\ndisparity map d(x, y).\nAfter rectiﬁcation, we can easily compare the similarity of pixels at corresponding lo-\ncations (x, y) and (x′, y′) = (x + d, y) and store them in a disparity space image (DSI)\nC(x, y, d) for further processing (Figure 11.5). The concept of the disparity space (x, y, d)\ndates back to early work in stereo matching (Marr and Poggio 1976), while the concept of a\ndisparity space image (volume) is generally associated with Yang, Yuille, and Lu (1993) and\nIntille and Bobick (1994).\n11.1.2 Plane sweep\nAn alternative to pre-rectifying the images before matching is to sweep a set of planes through\nthe scene and to measure the photoconsistency of different images as they are re-projected\nonto these planes (Figure 11.6). This process is commonly known as the plane sweep algo-\nrithm (Collins 1996; Szeliski and Golland 1999; Saito and Kanade 1999).\nAs we saw in Section 2.1.5, where we introduced projective depth (also known as plane\nplus parallax (Kumar, Anandan, and Hanna 1994; Sawhney 1994; Szeliski and Coughlan\n3 The term disparity was ﬁrst introduced in the human vision literature to describe the difference in location\nof corresponding features seen by the left and right eyes (Marr 1982). Horizontal disparity is the most commonly\nstudied phenomenon, but vertical disparity is possible if the eyes are verged.\n11.1 Epipolar geometry\n541\nVirtual camera\nd\nx\ny\nInput  image k\nu\nv\nHomography:\n  u = H x\nx\ny\nk\nd\nk\n(a)\n(b)\nFigure 11.6 Sweeping a set of planes through a scene (Szeliski and Golland 1999) c⃝1999\nSpringer: (a) The set of planes seen from a virtual camera induces a set of homographies in\nany other source (input) camera image. (b) The warped images from all the other cameras can\nbe stacked into a generalized disparity space volume ˜I(x, y, d, k) indexed by pixel location\n(x, y), disparity d, and camera k.\n1997)), the last row of a full-rank 4 × 4 projection matrix ˜\nP can be set to an arbitrary plane\nequation p3 = s3[ˆn0|c0]. The resulting four-dimensional projective transform (collineation)\n(2.68) maps 3D world points p = (X, Y, Z, 1) into screen coordinates xs = (xs, ys, 1, d),\nwhere the projective depth (or parallax) d (2.66) is 0 on the reference plane (Figure 2.11).\nSweeping d through a series of disparity hypotheses, as shown in Figure 11.6a, corre-\nsponds to mapping each input image into the virtual camera ˜\nP deﬁning the disparity space\nthrough a series of homographies (2.68–2.71),\n˜xk ∼˜\nP k ˜\nP\n−1xs = ˜\nHk˜x + tkd = ( ˜\nHk + tk[0 0 d])˜x,\n(11.3)\nas shown in Figure 2.12b, where ˜xk and ˜x are the homogeneous pixel coordinates in the\nsource and virtual (reference) images (Szeliski and Golland 1999). The members of the fam-\nily of homographies ˜\nHk(d) = ˜\nHk + tk[0 0 d], which are parametererized by the addition of\na rank-1 matrix, are related to each other through a planar homology (Hartley and Zisserman\n2004, A5.2).\nThe choice of virtual camera and parameterization is application dependent and is what\ngives this framework a lot of its ﬂexibility. In many applications, one of the input cameras\n(the reference camera) is used, thus computing a depth map that is registered with one of the\ninput images and which can later be used for image-based rendering (Sections 13.1 and 13.2).\nIn other applications, such as view interpolation for gaze correction in video-conferencing\n542\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(Section 11.4.2) (Ott, Lewis, and Cox 1993; Criminisi, Shotton, Blake et al. 2003), a camera\ncentrally located between the two input cameras is preferable, since it provides the needed\nper-pixel disparities to hallucinate the virtual middle image.\nThe choice of disparity sampling, i.e., the setting of the zero parallax plane and the scaling\nof integer disparities, is also application dependent, and is usually set to bracket the range of\ninterest, i.e., the working volume, while scaling disparities to sample the image in pixel (or\nsub-pixel) shifts. For example, when using stereo vision for obstacle avoidance in robot\nnavigation, it is most convenient to set up disparity to measure per-pixel elevation above the\nground (Ivanchenko, Shen, and Coughlan 2009).\nAs each input image is warped onto the current planes parameterized by disparity d, it\ncan be stacked into a generalized disparity space image ˜I(x, y, d, k) for further processing\n(Figure 11.6b) (Szeliski and Golland 1999). In most stereo algorithms, the photoconsistency\n(e.g., sum of squared or robust differences) with respect to the reference image Ir is calculated\nand stored in the DSI\nC(x, y, d) =\nX\nk\nρ(˜I(x, y, d, k) −Ir(x, y)).\n(11.4)\nHowever, it is also possible to compute alternative statistics such as robust variance, focus,\nor entropy (Section 11.3.1) (Vaish, Szeliski, Zitnick et al. 2006) or to use this representation\nto reason about occlusions (Szeliski and Golland 1999; Kang and Szeliski 2004). The gen-\neralized DSI will come in particularly handy when we come back to the topic of multi-view\nstereo in Section 11.6.\nOf course, planes are not the only surfaces that can be used to deﬁne a 3D sweep through\nthe space of interest. Cylindrical surfaces, especially when coupled with panoramic photog-\nraphy (Chapter 9), are often used (Ishiguro, Yamamoto, and Tsuji 1992; Kang and Szeliski\n1997; Shum and Szeliski 1999; Li, Shum, Tang et al. 2004; Zheng, Kang, Cohen et al. 2007).\nIt is also possible to deﬁne other manifold topologies, e.g., ones where the camera rotates\naround a ﬁxed axis (Seitz 2001).\nOnce the DSI has been computed, the next step in most stereo correspondence algorithms\nis to produce a univalued function in disparity space d(x, y) that best describes the shape of\nthe surfaces in the scene. This can be viewed as ﬁnding a surface embedded in the disparity\nspace image that has some optimality property, such as lowest cost and best (piecewise)\nsmoothness (Yang, Yuille, and Lu 1993). Figure 11.5 shows examples of slices through a\ntypical DSI. More ﬁgures of this kind can be found in the paper by Bobick and Intille (1999).",
  "image_path": "page_563.jpg",
  "pages": [
    562,
    563,
    564
  ]
}