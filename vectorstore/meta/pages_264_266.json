{
  "doc_id": "pages_264_266",
  "text": "242\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 4.32\nScale selection for edge detection (Elder and Zucker 1998) c⃝1998 IEEE:\n(a) original image; (b–c) Canny/Deriche edge detector tuned to the ﬁner (mannequin) and\ncoarser (shadow) scales; (d) minimum reliable scale for gradient estimation; (e) minimum\nreliable scale for second derivative estimation; (f) ﬁnal detected edges.\nScale selection and blur estimation\nAs we mentioned before, the derivative, Laplacian, and Difference of Gaussian ﬁlters (4.20–\n4.23) all require the selection of a spatial scale parameter σ. If we are only interested in\ndetecting sharp edges, the width of the ﬁlter can be determined from image noise characteris-\ntics (Canny 1986; Elder and Zucker 1998). However, if we want to detect edges that occur at\ndifferent resolutions (Figures 4.32b–c), a scale-space approach that detects and then selects\nedges at different scales may be necessary (Witkin 1983; Lindeberg 1994, 1998a; Nielsen,\nFlorack, and Deriche 1997).\nElder and Zucker (1998) present a principled approach to solving this problem. Given\na known image noise level, their technique computes, for every pixel, the minimum scale\nat which an edge can be reliably detected (Figure 4.32d). Their approach ﬁrst computes\n5 This algorithm is a 2D version of the 3D marching cubes isosurface extraction algorithm (Lorensen and Cline\n1987).\n6 In fact, the edge orientation can have a 180◦ambiguity for “bar edges”, which makes the computation of zero\ncrossings in the derivative more tricky.\n4.2 Edges\n243\ngradients densely over an image by selecting among gradient estimates computed at different\nscales, based on their gradient magnitudes. It then performs a similar estimate of minimum\nscale for directed second derivatives and uses zero crossings of this latter quantity to robustly\nselect edges (Figures 4.32e–f). As an optional ﬁnal step, the blur width of each edge can\nbe computed from the distance between extrema in the second derivative response minus the\nwidth of the Gaussian ﬁlter.\nColor edge detection\nWhile most edge detection techniques have been developed for grayscale images, color im-\nages can provide additional information. For example, noticeable edges between iso-luminant\ncolors (colors that have the same luminance) are useful cues but fail to be detected by grayscale\nedge operators.\nOne simple approach is to combine the outputs of grayscale detectors run on each color\nband separately.7 However, some care must be taken. For example, if we simply sum up\nthe gradients in each of the color bands, the signed gradients may actually cancel each other!\n(Consider, for example a pure red-to-green edge.) We could also detect edges independently\nin each band and then take the union of these, but this might lead to thickened or doubled\nedges that are hard to link.\nA better approach is to compute the oriented energy in each band (Morrone and Burr\n1988; Perona and Malik 1990a), e.g., using a second-order steerable ﬁlter (Section 3.2.3)\n(Freeman and Adelson 1991), and then sum up the orientation-weighted energies and ﬁnd\ntheir joint best orientation. Unfortunately, the directional derivative of this energy may not\nhave a closed form solution (as in the case of signed ﬁrst-order steerable ﬁlters), so a simple\nzero crossing-based strategy cannot be used. However, the technique described by Elder and\nZucker (1998) can be used to compute these zero crossings numerically instead.\nAn alternative approach is to estimate local color statistics in regions around each pixel\n(Ruzon and Tomasi 2001; Martin, Fowlkes, and Malik 2004). This has the advantage that\nmore sophisticated techniques (e.g., 3D color histograms) can be used to compare regional\nstatistics and that additional measures, such as texture, can also be considered. Figure 4.33\nshows the output of such detectors.\nOf course, many other approaches have been developed for detecting color edges, dating\nback to early work by Nevatia (1977). Ruzon and Tomasi (2001) and Gevers, van de Weijer,\nand Stokman (2006) provide good reviews of these approaches, which include ideas such as\nfusing outputs from multiple channels, using multidimensional gradients, and vector-based\n7 Instead of using the raw RGB space, a more perceptually uniform color space such as L*a*b* (see Section 2.3.2)\ncan be used instead. When trying to match human performance (Martin, Fowlkes, and Malik 2004), this makes sense.\nHowever, in terms of the physics of the underlying image formation and sensing, it may be a questionable strategy.\n244\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nmethods.\nCombining edge feature cues\nIf the goal of edge detection is to match human boundary detection performance (Bowyer,\nKranenburg, and Dougherty 2001; Martin, Fowlkes, and Malik 2004; Arbel´aez, Maire, Fowlkes\net al. 2010), as opposed to simply ﬁnding stable features for matching, even better detectors\ncan be constructed by combining multiple low-level cues such as brightness, color, and tex-\nture.\nMartin, Fowlkes, and Malik (2004) describe a system that combines brightness, color, and\ntexture edges to produce state-of-the-art performance on a database of hand-segmented natu-\nral color images (Martin, Fowlkes, Tal et al. 2001). First, they construct and train8 separate\noriented half-disc detectors for measuring signiﬁcant differences in brightness (luminance),\ncolor (a* and b* channels, summed responses), and texture (un-normalized ﬁlter bank re-\nsponses from the work of Malik, Belongie, Leung et al. (2001)). Some of the responses\nare then sharpened using a soft non-maximal suppression technique. Finally, the outputs of\nthe three detectors are combined using a variety of machine-learning techniques, from which\nlogistic regression is found to have the best tradeoff between speed, space and accuracy .\nThe resulting system (see Figure 4.33 for some examples) is shown to outperform previously\ndeveloped techniques. Maire, Arbelaez, Fowlkes et al. (2008) improve on these results by\ncombining the detector based on local appearance with a spectral (segmentation-based) de-\ntector (Belongie and Malik 1998). In more recent work, Arbel´aez, Maire, Fowlkes et al.\n(2010) build a hierarchical segmentation on top of this edge detector using a variant of the\nwatershed algorithm.\n4.2.2 Edge linking\nWhile isolated edges can be useful for a variety of applications, such as line detection (Sec-\ntion 4.3) and sparse stereo matching (Section 11.2), they become even more useful when\nlinked into continuous contours.\nIf the edges have been detected using zero crossings of some function, linking them up\nis straightforward, since adjacent edgels share common endpoints. Linking the edgels into\nchains involves picking up an unlinked edgel and following its neighbors in both directions.\nEither a sorted list of edgels (sorted ﬁrst by x coordinates and then by y coordinates, for\nexample) or a 2D array can be used to accelerate the neighbor ﬁnding. If edges were not\ndetected using zero crossings, ﬁnding the continuation of an edgel can be tricky. In this\ncase, comparing the orientation (and, optionally, phase) of adjacent edgels can be used for\n8 The training uses 200 labeled images and testing is performed on a different set of 100 images.",
  "image_path": "page_265.jpg",
  "pages": [
    264,
    265,
    266
  ]
}