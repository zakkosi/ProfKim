{
  "doc_id": "pages_047_049",
  "text": "1.3 Book overview\n25\ntion 10.3), and image editing and compositing operations (Section 10.4). We also cover the\ntopics of texture analysis, synthesis and inpainting (hole ﬁlling) in Section 10.5, as well as\nnon-photorealistic rendering (Section 10.5.2).\nIn Chapter 11, we turn to the issue of stereo correspondence, which can be thought of\nas a special case of motion estimation where the camera positions are already known (Sec-\ntion 11.1). This additional knowledge enables stereo algorithms to search over a much smaller\nspace of correspondences and, in many cases, to produce dense depth estimates that can\nbe converted into visible surface models (Section 11.3). We also cover multi-view stereo\nalgorithms that build a true 3D surface representation instead of just a single depth map\n(Section 11.6). Applications of stereo matching include head and gaze tracking, as well as\ndepth-based background replacement (Z-keying).\nChapter 12 covers additional 3D shape and appearance modeling techniques. These in-\nclude classic shape-from-X techniques such as shape from shading, shape from texture, and\nshape from focus (Section 12.1), as well as shape from smooth occluding contours (Sec-\ntion 11.2.1) and silhouettes (Section 12.5). An alternative to all of these passive computer\nvision techniques is to use active rangeﬁnding (Section 12.2), i.e., to project patterned light\nonto scenes and recover the 3D geometry through triangulation. Processing all of these 3D\nrepresentations often involves interpolating or simplifying the geometry (Section 12.3), or\nusing alternative representations such as surface point sets (Section 12.4).\nThe collection of techniques for going from one or more images to partial or full 3D\nmodels is often called image-based modeling or 3D photography. Section 12.6 examines\nthree more specialized application areas (architecture, faces, and human bodies), which can\nuse model-based reconstruction to ﬁt parameterized models to the sensed data. Section 12.7\nexamines the topic of appearance modeling, i.e., techniques for estimating the texture maps,\nalbedos, or even sometimes complete bi-directional reﬂectance distribution functions (BRDFs)\nthat describe the appearance of 3D surfaces.\nIn Chapter 13, we discuss the large number of image-based rendering techniques that\nhave been developed in the last two decades, including simpler techniques such as view in-\nterpolation (Section 13.1), layered depth images (Section 13.2), and sprites and layers (Sec-\ntion 13.2.1), as well as the more general framework of light ﬁelds and Lumigraphs (Sec-\ntion 13.3) and higher-order ﬁelds such as environment mattes (Section 13.4). Applications of\nthese techniques include navigating 3D collections of photographs using photo tourism and\nviewing 3D models as object movies.\nIn Chapter 13, we also discuss video-based rendering, which is the temporal extension of\nimage-based rendering. The topics we cover include video-based animation (Section 13.5.1),\nperiodic video turned into video textures (Section 13.5.2), and 3D video constructed from\nmultiple video streams (Section 13.5.4). Applications of these techniques include video de-\nnoising, morphing, and tours based on 360◦video.\n26\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWeek\nMaterial\nProject\n(1.)\nChapter 2 Image formation\n2.\nChapter 3 Image processing\n3.\nChapter 4 Feature detection and matching\nP1\n4.\nChapter 6 Feature-based alignment\n5.\nChapter 9 Image stitching\nP2\n6.\nChapter 8 Dense motion estimation\n7.\nChapter 7 Structure from motion\nPP\n8.\nChapter 14 Recognition\n(9.)\nChapter 10 Computational photography\n10.\nChapter 11 Stereo correspondence\n(11.)\nChapter 12 3D reconstruction\n12.\nChapter 13 Image-based rendering\n13.\nFinal project presentations\nFP\nTable 1.1 Sample syllabi for 10-week and 13-week courses. The weeks in parentheses are\nnot used in the shorter version. P1 and P2 are two early-term mini-projects, PP is when the\n(student-selected) ﬁnal project proposals are due, and FP is the ﬁnal project presentations.\nChapter 14 describes different approaches to recognition. It begins with techniques for\ndetecting and recognizing faces (Sections 14.1 and 14.2), then looks at techniques for ﬁnding\nand recognizing particular objects (instance recognition) in Section 14.3. Next, we cover the\nmost difﬁcult variant of recognition, namely the recognition of broad categories, such as cars,\nmotorcycles, horses and other animals (Section 14.4), and the role that scene context plays in\nrecognition (Section 14.5).\nTo support the book’s use as a textbook, the appendices and associated Web site contain\nmore detailed mathematical topics and additional material. Appendix A covers linear algebra\nand numerical techniques, including matrix algebra, least squares, and iterative techniques.\nAppendix B covers Bayesian estimation theory, including maximum likelihood estimation,\nrobust statistics, Markov random ﬁelds, and uncertainty modeling. Appendix C describes the\nsupplementary material available to complement this book, including images and data sets,\npointers to software, course slides, and an on-line bibliography.\n1.4 Sample syllabus\nTeaching all of the material covered in this book in a single quarter or semester course is a\nHerculean task and likely one not worth attempting. It is better to simply pick and choose\n1.5 A note on notation\n27\ntopics related to the lecturer’s preferred emphasis and tailored to the set of mini-projects\nenvisioned for the students.\nSteve Seitz and I have successfully used a 10-week syllabus similar to the one shown in\nTable 1.1 (omitting the parenthesized weeks) as both an undergraduate and a graduate-level\ncourse in computer vision. The undergraduate course10 tends to go lighter on the mathematics\nand takes more time reviewing basics, while the graduate-level course11 dives more deeply\ninto techniques and assumes the students already have a decent grounding in either vision\nor related mathematical techniques. (See also the Introduction to Computer Vision course at\nStanford,12 which uses a similar curriculum.) Related courses have also been taught on the\ntopics of 3D photography13 and computational photography.14\nWhen Steve and I teach the course, we prefer to give the students several small program-\nming projects early in the course rather than focusing on written homework or quizzes. With\na suitable choice of topics, it is possible for these projects to build on each other. For exam-\nple, introducing feature matching early on can be used in a second assignment to do image\nalignment and stitching. Alternatively, direct (optical ﬂow) techniques can be used to do the\nalignment and more focus can be put on either graph cut seam selection or multi-resolution\nblending techniques.\nWe also ask the students to propose a ﬁnal project (we provide a set of suggested topics\nfor those who need ideas) by the middle of the course and reserve the last week of the class\nfor student presentations. With any luck, some of these ﬁnal projects can actually turn into\nconference submissions!\nNo matter how you decide to structure the course or how you choose to use this book, I\nencourage you to try at least a few small programming tasks to get a good feel for how vision\ntechniques work, and when they do not. Better yet, pick topics that are fun and can be used on\nyour own photographs, and try to push your creative boundaries to come up with surprising\nresults.\n1.5 A note on notation\nFor better or worse, the notation found in computer vision and multi-view geometry textbooks\ntends to vary all over the map (Faugeras 1993; Hartley and Zisserman 2004; Girod, Greiner,\nand Niemann 2000; Faugeras and Luong 2001; Forsyth and Ponce 2003). In this book, I\nuse the convention I ﬁrst learned in my high school physics class (and later multi-variate\n10 http://www.cs.washington.edu/education/courses/455/\n11 http://www.cs.washington.edu/education/courses/576/\n12http://vision.stanford.edu/teaching/cs223b/\n13 http://www.cs.washington.edu/education/courses/558/06sp/\n14 http://graphics.cs.cmu.edu/courses/15-463/",
  "image_path": "page_048.jpg",
  "pages": [
    47,
    48,
    49
  ]
}