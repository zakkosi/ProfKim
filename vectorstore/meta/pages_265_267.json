{
  "doc_id": "pages_265_267",
  "text": "4.2 Edges\n243\ngradients densely over an image by selecting among gradient estimates computed at different\nscales, based on their gradient magnitudes. It then performs a similar estimate of minimum\nscale for directed second derivatives and uses zero crossings of this latter quantity to robustly\nselect edges (Figures 4.32e–f). As an optional ﬁnal step, the blur width of each edge can\nbe computed from the distance between extrema in the second derivative response minus the\nwidth of the Gaussian ﬁlter.\nColor edge detection\nWhile most edge detection techniques have been developed for grayscale images, color im-\nages can provide additional information. For example, noticeable edges between iso-luminant\ncolors (colors that have the same luminance) are useful cues but fail to be detected by grayscale\nedge operators.\nOne simple approach is to combine the outputs of grayscale detectors run on each color\nband separately.7 However, some care must be taken. For example, if we simply sum up\nthe gradients in each of the color bands, the signed gradients may actually cancel each other!\n(Consider, for example a pure red-to-green edge.) We could also detect edges independently\nin each band and then take the union of these, but this might lead to thickened or doubled\nedges that are hard to link.\nA better approach is to compute the oriented energy in each band (Morrone and Burr\n1988; Perona and Malik 1990a), e.g., using a second-order steerable ﬁlter (Section 3.2.3)\n(Freeman and Adelson 1991), and then sum up the orientation-weighted energies and ﬁnd\ntheir joint best orientation. Unfortunately, the directional derivative of this energy may not\nhave a closed form solution (as in the case of signed ﬁrst-order steerable ﬁlters), so a simple\nzero crossing-based strategy cannot be used. However, the technique described by Elder and\nZucker (1998) can be used to compute these zero crossings numerically instead.\nAn alternative approach is to estimate local color statistics in regions around each pixel\n(Ruzon and Tomasi 2001; Martin, Fowlkes, and Malik 2004). This has the advantage that\nmore sophisticated techniques (e.g., 3D color histograms) can be used to compare regional\nstatistics and that additional measures, such as texture, can also be considered. Figure 4.33\nshows the output of such detectors.\nOf course, many other approaches have been developed for detecting color edges, dating\nback to early work by Nevatia (1977). Ruzon and Tomasi (2001) and Gevers, van de Weijer,\nand Stokman (2006) provide good reviews of these approaches, which include ideas such as\nfusing outputs from multiple channels, using multidimensional gradients, and vector-based\n7 Instead of using the raw RGB space, a more perceptually uniform color space such as L*a*b* (see Section 2.3.2)\ncan be used instead. When trying to match human performance (Martin, Fowlkes, and Malik 2004), this makes sense.\nHowever, in terms of the physics of the underlying image formation and sensing, it may be a questionable strategy.\n244\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nmethods.\nCombining edge feature cues\nIf the goal of edge detection is to match human boundary detection performance (Bowyer,\nKranenburg, and Dougherty 2001; Martin, Fowlkes, and Malik 2004; Arbel´aez, Maire, Fowlkes\net al. 2010), as opposed to simply ﬁnding stable features for matching, even better detectors\ncan be constructed by combining multiple low-level cues such as brightness, color, and tex-\nture.\nMartin, Fowlkes, and Malik (2004) describe a system that combines brightness, color, and\ntexture edges to produce state-of-the-art performance on a database of hand-segmented natu-\nral color images (Martin, Fowlkes, Tal et al. 2001). First, they construct and train8 separate\noriented half-disc detectors for measuring signiﬁcant differences in brightness (luminance),\ncolor (a* and b* channels, summed responses), and texture (un-normalized ﬁlter bank re-\nsponses from the work of Malik, Belongie, Leung et al. (2001)). Some of the responses\nare then sharpened using a soft non-maximal suppression technique. Finally, the outputs of\nthe three detectors are combined using a variety of machine-learning techniques, from which\nlogistic regression is found to have the best tradeoff between speed, space and accuracy .\nThe resulting system (see Figure 4.33 for some examples) is shown to outperform previously\ndeveloped techniques. Maire, Arbelaez, Fowlkes et al. (2008) improve on these results by\ncombining the detector based on local appearance with a spectral (segmentation-based) de-\ntector (Belongie and Malik 1998). In more recent work, Arbel´aez, Maire, Fowlkes et al.\n(2010) build a hierarchical segmentation on top of this edge detector using a variant of the\nwatershed algorithm.\n4.2.2 Edge linking\nWhile isolated edges can be useful for a variety of applications, such as line detection (Sec-\ntion 4.3) and sparse stereo matching (Section 11.2), they become even more useful when\nlinked into continuous contours.\nIf the edges have been detected using zero crossings of some function, linking them up\nis straightforward, since adjacent edgels share common endpoints. Linking the edgels into\nchains involves picking up an unlinked edgel and following its neighbors in both directions.\nEither a sorted list of edgels (sorted ﬁrst by x coordinates and then by y coordinates, for\nexample) or a 2D array can be used to accelerate the neighbor ﬁnding. If edges were not\ndetected using zero crossings, ﬁnding the continuation of an edgel can be tricky. In this\ncase, comparing the orientation (and, optionally, phase) of adjacent edgels can be used for\n8 The training uses 200 labeled images and testing is performed on a different set of 100 images.\n4.2 Edges\n245\nFigure 4.33\nCombined brightness, color, texture boundary detector (Martin, Fowlkes, and\nMalik 2004) c⃝2004 IEEE. Successive rows show the outputs of the brightness gradient\n(BG), color gradient (CG), texture gradient (TG), and combined (BG+CG+TG) detectors.\nThe ﬁnal row shows human-labeled boundaries derived from a database of hand-segmented\nimages (Martin, Fowlkes, Tal et al. 2001).",
  "image_path": "page_266.jpg",
  "pages": [
    265,
    266,
    267
  ]
}