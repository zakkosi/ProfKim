{
  "doc_id": "pages_092_094",
  "text": "70\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 2.20 Regular and zoom lens depth of ﬁeld indicators.\nThe allowable depth variation in the scene that limits the circle of confusion to an accept-\nable number is commonly called the depth of ﬁeld and is a function of both the focus distance\nand the aperture, as shown diagrammatically by many lens markings (Figure 2.20). Since this\ndepth of ﬁeld depends on the aperture diameter d, we also have to know how this varies with\nthe commonly displayed f-number, which is usually denoted as f/# or N and is deﬁned as\nf/# = N = f\nd ,\n(2.97)\nwhere the focal length f and the aperture diameter d are measured in the same unit (say,\nmillimeters).\nThe usual way to write the f-number is to replace the # in f/# with the actual number,\ni.e., f/1.4, f/2, f/2.8, . . . , f/22. (Alternatively, we can say N = 1.4, etc.) An easy way to\ninterpret these numbers is to notice that dividing the focal length by the f-number gives us the\ndiameter d, so these are just formulas for the aperture diameter.8\nNotice that the usual progression for f-numbers is in full stops, which are multiples of\n√\n2,\nsince this corresponds to doubling the area of the entrance pupil each time a smaller f-number\nis selected. (This doubling is also called changing the exposure by one exposure value or EV.\nIt has the same effect on the amount of light reaching the sensor as doubling the exposure\nduration, e.g., from 1/125 to 1/250, see Exercise 2.5.)\nNow that you know how to convert between f-numbers and aperture diameters, you can\nconstruct your own plots for the depth of ﬁeld as a function of focal length f, circle of\nconfusion c, and focus distance zo, as explained in Exercise 2.4 and see how well these match\nwhat you observe on actual lenses, such as those shown in Figure 2.20.\nOf course, real lenses are not inﬁnitely thin and therefore suffer from geometric aber-\nrations, unless compound elements are used to correct for them. The classic ﬁve Seidel\naberrations, which arise when using third-order optics, include spherical aberration, coma,\nastigmatism, curvature of ﬁeld, and distortion (M¨oller 1988; Hecht 2001; Ray 2002).\n8 This also explains why, with zoom lenses, the f-number varies with the current zoom (focal length) setting.\n2.2 Photometric image formation\n71\nzi’=103mm\nf’ = 101mm\nzo=5m\nP\nd\nc\nFigure 2.21\nIn a lens subject to chromatic aberration, light at different wavelengths (e.g.,\nthe red and blur arrows) is focused with a different focal length f ′ and hence a different depth\nz′\ni, resulting in both a geometric (in-plane) displacement and a loss of focus.\nChromatic aberration\nBecause the index of refraction for glass varies slightly as a function of wavelength, sim-\nple lenses suffer from chromatic aberration, which is the tendency for light of different\ncolors to focus at slightly different distances (and hence also with slightly different mag-\nniﬁcation factors), as shown in Figure 2.21. The wavelength-dependent magniﬁcation fac-\ntor, i.e., the transverse chromatic aberration, can be modeled as a per-color radial distortion\n(Section 2.1.6) and, hence, calibrated using the techniques described in Section 6.3.5. The\nwavelength-dependent blur caused by longitudinal chromatic aberration can be calibrated\nusing techniques described in Section 10.1.4. Unfortunately, the blur induced by longitudinal\naberration can be harder to undo, as higher frequencies can get strongly attenuated and hence\nhard to recover.\nIn order to reduce chromatic and other kinds of aberrations, most photographic lenses\ntoday are compound lenses made of different glass elements (with different coatings). Such\nlenses can no longer be modeled as having a single nodal point P through which all of the\nrays must pass (when approximating the lens with a pinhole model). Instead, these lenses\nhave both a front nodal point, through which the rays enter the lens, and a rear nodal point,\nthrough which they leave on their way to the sensor. In practice, only the location of the front\nnodal point is of interest when performing careful camera calibration, e.g., when determining\nthe point around which to rotate to capture a parallax-free panorama (see Section 9.1.3).\nNot all lenses, however, can be modeled as having a single nodal point. In particular, very\nwide-angle lenses such as ﬁsheye lenses (Section 2.1.6) and certain catadioptric imaging\nsystems consisting of lenses and curved mirrors (Baker and Nayar 1999) do not have a single\npoint through which all of the acquired light rays pass. In such cases, it is preferable to\nexplicitly construct a mapping function (look-up table) between pixel coordinates and 3D\nrays in space (Gremban, Thorpe, and Kanade 1988; Champleboux, Lavall´ee, Sautot et al.\n72\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nzi=102mm\nf = 100mm\nzo=5m\nδi\nd\nδo\nα\nα\nα\nP\nJ\nI\nO\nQ\nro\nFigure 2.22\nThe amount of light hitting a pixel of surface area δi depends on the square of\nthe ratio of the aperture diameter d to the focal length f, as well as the fourth power of the\noff-axis angle α cosine, cos4 α.\n1992; Grossberg and Nayar 2001; Sturm and Ramalingam 2004; Tardif, Sturm, Trudeau et\nal. 2009), as mentioned in Section 2.1.6.\nVignetting\nAnother property of real-world lenses is vignetting, which is the tendency for the brightness\nof the image to fall off towards the edge of the image.\nTwo kinds of phenomena usually contribute to this effect (Ray 2002). The ﬁrst is called\nnatural vignetting and is due to the foreshortening in the object surface, projected pixel, and\nlens aperture, as shown in Figure 2.22. Consider the light leaving the object surface patch\nof size δo located at an off-axis angle α. Because this patch is foreshortened with respect\nto the camera lens, the amount of light reaching the lens is reduced by a factor cos α. The\namount of light reaching the lens is also subject to the usual 1/r2 fall-off; in this case, the\ndistance ro = zo/ cos α. The actual area of the aperture through which the light passes\nis foreshortened by an additional factor cos α, i.e., the aperture as seen from point O is an\nellipse of dimensions d×d cos α. Putting all of these factors together, we see that the amount\nof light leaving O and passing through the aperture on its way to the image pixel located at I\nis proportional to\nδo cos α\nr2o\nπ\n\u0012d\n2\n\u00132\ncos α = δoπ\n4\nd2\nz2o\ncos4 α.\n(2.98)\nSince triangles ∆OPQ and ∆IPJ are similar, the projected areas of of the object surface δo\nand image pixel δi are in the same (squared) ratio as zo : zi,\nδo\nδi = z2\no\nz2\ni\n.\n(2.99)\nPutting these together, we obtain the ﬁnal relationship between the amount of light reaching",
  "image_path": "page_093.jpg",
  "pages": [
    92,
    93,
    94
  ]
}