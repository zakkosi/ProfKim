{
  "doc_id": "pages_572_574",
  "text": "550\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ning cost based on its color similarity and spatial distance, just as in bilinear ﬁltering (Fig-\nure 11.9c). (In fact, their aggregation step is closely related to doing a joint bilateral ﬁlter\non the color/disparity image, except that it is done symmetrically in both reference and target\nimages.) The segmentation-based aggregation method of Tombari, Mattoccia, and Di Stefano\n(2007) did even better, although a fast implementation of this algorithm does not yet exist.\nIn local methods, the emphasis is on the matching cost computation and cost aggregation\nsteps. Computing the ﬁnal disparities is trivial: simply choose at each pixel the disparity\nassociated with the minimum cost value. Thus, these methods perform a local “winner-\ntake-all” (WTA) optimization at each pixel. A limitation of this approach (and many other\ncorrespondence algorithms) is that uniqueness of matches is only enforced for one image\n(the reference image), while points in the other image might match multiple points, unless\ncross-checking and subsequent hole ﬁlling is used (Fua 1993; Hirschm¨uller and Scharstein\n2009).\n11.4.1 Sub-pixel estimation and uncertainty\nMost stereo correspondence algorithms compute a set of disparity estimates in some dis-\ncretized space, e.g., for integer disparities (exceptions include continuous optimization tech-\nniques such as optical ﬂow (Bergen, Anandan, Hanna et al. 1992) or splines (Szeliski and\nCoughlan 1997)). For applications such as robot navigation or people tracking, these may be\nperfectly adequate. However for image-based rendering, such quantized maps lead to very\nunappealing view synthesis results, i.e., the scene appears to be made up of many thin shear-\ning layers. To remedy this situation, many algorithms apply a sub-pixel reﬁnement stage after\nthe initial discrete correspondence stage. (An alternative is to simply start with more discrete\ndisparity levels (Szeliski and Scharstein 2004).)\nSub-pixel disparity estimates can be computed in a variety of ways, including iterative\ngradient descent and ﬁtting a curve to the matching costs at discrete disparity levels (Ryan,\nGray, and Hunt 1980; Lucas and Kanade 1981; Tian and Huhns 1986; Matthies, Kanade,\nand Szeliski 1989; Kanade and Okutomi 1994). This provides an easy way to increase the\nresolution of a stereo algorithm with little additional computation. However, to work well,\nthe intensities being matched must vary smoothly, and the regions over which these estimates\nare computed must be on the same (correct) surface.\nRecently, some questions have been raised about the advisability of ﬁtting correlation\ncurves to integer-sampled matching costs (Shimizu and Okutomi 2001). This situation may\neven be worse when sampling-insensitive dissimilarity measures are used (Birchﬁeld and\nTomasi 1998). These issues are explored in more depth by Szeliski and Scharstein (2004).\nBesides sub-pixel computations, there are other ways of post-processing the computed\ndisparities. Occluded areas can be detected using cross-checking, i.e., comparing left-to-\n11.4 Local methods\n551\n(a)\n(b)\n(c)\nFigure 11.10 Uncertainty in stereo depth estimation (Szeliski 1991b): (a) input image; (b)\nestimated depth map (blue is closer); (c) estimated conﬁdence(red is higher). As you can see,\nmore textured areas have higher conﬁdence.\nright and right-to-left disparity maps (Fua 1993). A median ﬁlter can be applied to clean\nup spurious mismatches, and holes due to occlusion can be ﬁlled by surface ﬁtting or by\ndistributing neighboring disparity estimates (Birchﬁeld and Tomasi 1999; Scharstein 1999;\nHirschm¨uller and Scharstein 2009).\nAnother kind of post-processing, which can be useful in later processing stages, is to asso-\nciate conﬁdences with per-pixel depth estimates (Figure 11.10), which can be done by looking\nat the curvature of the correlation surface, i.e., how strong the minimum in the DSI image is\nat the winning disparity. Matthies, Kanade, and Szeliski (1989) show that under the assump-\ntion of small noise, photometrically calibrated images, and densely sampled disparities, the\nvariance of a local depth estimate can be estimated as\nV ar(d) = σ2\nI\na ,\n(11.7)\nwhere a is the curvature of the DSI as a function of d, which can be measured using a local\nparabolic ﬁt or by squaring all the horizontal gradients in the window, and σ2\nI is the vari-\nance of the image noise, which can be estimated from the minimum SSD score. (See also\nSection 6.1.4, (8.44), and Appendix B.6.)\n11.4.2 Application: Stereo-based head tracking\nA common application of real-time stereo algorithms is for tracking the position of a user\ninteracting with a computer or game system. The use of stereo can dramatically improve\nthe reliability of such a system compared to trying to use monocular color and intensity\ninformation (Darrell, Gordon, Harville et al. 2000). Once recovered, this information can\nbe used in a variety of applications, including controlling a virtual environment or game,\n552\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ncorrecting the apparent gaze during video conferencing, and background replacement. We\ndiscuss the ﬁrst two applications below and defer the discussion of background replacement\nto Section 11.5.3.\nThe use of head tracking to control a user’s virtual viewpoint while viewing a 3D object\nor environment on a computer monitor is sometimes called ﬁsh tank virtual reality, since the\nuser is observing a 3D world as if it were contained inside a ﬁsh tank (Ware, Arthur, and\nBooth 1993). Early versions of these systems used mechanical head tracking devices and\nstereo glasses. Today, such systems can be controlled using stereo-based head tracking and\nstereo glasses can be replaced with autostereoscopic displays. Head tracking can also be used\nto construct a “virtual mirror”, where the user’s head can be modiﬁed in real-time using a\nvariety of visual effects (Darrell, Baker, Crow et al. 1997).\nAnother application of stereo head tracking and 3D reconstruction is in gaze correction\n(Ott, Lewis, and Cox 1993). When a user participates in a desktop video-conference or video\nchat, the camera is usually placed on top of the monitor. Since the person is gazing at a\nwindow somewhere on the screen, it appears as if they are looking down and away from the\nother participants, instead of straight at them. Replacing the single camera with two or more\ncameras enables a virtual view to be constructed right at the position where they are looking\nresulting in virtual eye contact. Real-time stereo matching is used to construct an accurate 3D\nhead model and view interpolation (Section 13.1) is used to synthesize the novel in-between\nview (Criminisi, Shotton, Blake et al. 2003).\n11.5 Global optimization\nGlobal stereo matching methods perform some optimization or iteration steps after the dis-\nparity computation phase and often skip the aggregation step altogether, because the global\nsmoothness constraints perform a similar function. Many global methods are formulated in\nan energy-minimization framework, where, as we saw in Sections 3.7 (3.100–3.102) and 8.4,\nthe objective is to ﬁnd a solution d that minimizes a global energy,\nE(d) = Ed(d) + λEs(d).\n(11.8)\nThe data term, Ed(d), measures how well the disparity function d agrees with the input image\npair. Using our previously deﬁned disparity space image, we deﬁne this energy as\nEd(d) =\nX\n(x,y)\nC(x, y, d(x, y)),\n(11.9)\nwhere C is the (initial or aggregated) matching cost DSI.\nThe smoothness term Es(d) encodes the smoothness assumptions made by the algorithm.\nTo make the optimization computationally tractable, the smoothness term is often restricted",
  "image_path": "page_573.jpg",
  "pages": [
    572,
    573,
    574
  ]
}