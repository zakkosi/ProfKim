{
  "doc_id": "pages_480_482",
  "text": "458\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 9.17\nSet of ﬁve photos tracking a snowboarder’s jump stitched together into a seam-\nless composite. Because the algorithm prefers pixels near the center of the image, multiple\ncopies of the boarder are retained.\nwhere S(x, y, lx, ly) is the image-dependent interaction penalty or seam cost of placing a\nseam between pixels x and y, and N is the set of N4 neighboring pixels. For example,\nthe simple color-based seam penalty used in (Kwatra, Sch¨odl, Essa et al. 2003; Agarwala,\nDontcheva, Agrawala et al. 2004) can be written as\nS(x, y, lx, ly) = ∥˜Ilx(x) −˜Ily(x)∥+ ∥˜Ilx(y) −˜Ily(y)∥.\n(9.43)\nMore sophisticated seam penalties can also look at image gradients or the presence of image\nedges (Agarwala, Dontcheva, Agrawala et al. 2004). Seam penalties are widely used in other\ncomputer vision applications such as stereo matching (Boykov, Veksler, and Zabih 2001) to\ngive the labeling function its coherence or smoothness. An alternative approach, which places\nseams along strong consistent edges in overlapping images using a watershed computation is\ndescribed by Soille (2006).\nThe sum of these two objective functions gives rise to a Markov random ﬁeld (MRF),\nfor which good optimization algorithms are described in Sections 3.7.2 and 5.5 and Ap-\npendix B.5. For label computations of this kind, the α-expansion algorithm developed by\nBoykov, Veksler, and Zabih (2001) works particularly well (Szeliski, Zabih, Scharstein et al.\n2008).\nFor the result shown in Figure 9.14g, Agarwala, Dontcheva, Agrawala et al. (2004) use\na large data penalty for invalid pixels and 0 for valid pixels. Notice how the seam placement\nalgorithm avoids regions of difference, including those that border the image and that might\nresult in objects being cut off. Graph cuts (Agarwala, Dontcheva, Agrawala et al. 2004) and\n9.3 Compositing\n459\nvertex cover (Uyttendaele, Eden, and Szeliski 2001) often produce similar looking results,\nalthough the former is signiﬁcantly slower since it optimizes over all pixels, while the latter\nis more sensitive to the thresholds used to determine regions of difference.\n9.3.3 Application: Photomontage\nWhile image stitching is normally used to composite partially overlapping photographs, it\ncan also be used to composite repeated shots of a scene taken with the aim of obtaining the\nbest possible composition and appearance of each element.\nFigure 9.16 shows the Photomontage system developed by Agarwala, Dontcheva, Agrawala\net al. (2004), where users draw strokes over a set of pre-aligned images to indicate which re-\ngions they wish to keep from each image. Once the system solves the resulting multi-label\ngraph cut (9.41–9.42), the various pieces taken from each source photo are blended together\nusing a variant of Poisson image blending (9.44–9.46). Their system can also be used to au-\ntomatically composite an all-focus image from a series of bracketed focus images (Hasinoff,\nKutulakos, Durand et al. 2009) or to remove wires and other unwanted elements from sets of\nphotographs. Exercise 9.10 has you implement this system and try out some of its variants.\n9.3.4 Blending\nOnce the seams between images have been determined and unwanted objects removed, we\nstill need to blend the images to compensate for exposure differences and other mis-alignments.\nThe spatially varying weighting (feathering) previously discussed can often be used to accom-\nplish this. However, it is difﬁcult in practice to achieve a pleasing balance between smoothing\nout low-frequency exposure variations and retaining sharp enough transitions to prevent blur-\nring (although using a high exponent in feathering can help).\nLaplacian pyramid blending.\nAn attractive solution to this problem is the Laplacian pyra-\nmid blending technique developed by Burt and Adelson (1983b), which we discussed in Sec-\ntion 3.5.5. Instead of using a single transition width, a frequency-adaptive width is used by\ncreating a band-pass (Laplacian) pyramid and making the transition widths within each level\na function of the level, i.e., the same width in pixels. In practice, a small number of levels,\ni.e., as few as two (Brown and Lowe 2007), may be adequate to compensate for differences\nin exposure. The result of applying this pyramid blending is shown in Figure 9.14h.\nGradient domain blending.\nAn alternative approach to multi-band image blending is to\nperform the operations in the gradient domain. Reconstructing images from their gradient\nﬁelds has a long history in computer vision (Horn 1986), starting originally with work in\n460\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.18\nPoisson image editing (P´erez, Gangnet, and Blake 2003) c⃝2003 ACM: (a)\nThe dog and the two children are chosen as source images to be pasted into the destination\nswimming pool. (b) Simple pasting fails to match the colors at the boundaries, whereas (c)\nPoisson image blending masks these differences.\nbrightness constancy (Horn 1974), shape from shading (Horn and Brooks 1989), and photo-\nmetric stereo (Woodham 1981). More recently, related ideas have been used for reconstruct-\ning images from their edges (Elder and Goldberg 2001), removing shadows from images\n(Weiss 2001), separating reﬂections from a single image (Levin, Zomet, and Weiss 2004;\nLevin and Weiss 2007), and tone mapping high dynamic range images by reducing the mag-\nnitude of image edges (gradients) (Fattal, Lischinski, and Werman 2002).\nP´erez, Gangnet, and Blake (2003) show how gradient domain reconstruction can be used\nto do seamless object insertion in image editing applications (Figure 9.18). Rather than copy-\ning pixels, the gradients of the new image fragment are copied instead. The actual pixel values\nfor the copied area are then computed by solving a Poisson equation that locally matches the\ngradients while obeying the ﬁxed Dirichlet (exact matching) conditions at the seam bound-\nary. P´erez, Gangnet, and Blake (2003) show that this is equivalent to computing an additive\nmembrane interpolant of the mismatch between the source and destination images along the\nboundary.14 In earlier work, Peleg (1981) also proposed adding a smooth function to enforce\nconsistency along the seam curve.\nAgarwala, Dontcheva, Agrawala et al. (2004) extended this idea to a multi-source formu-\nlation, where it no longer makes sense to talk of a destination image whose exact pixel values\nmust be matched at the seam. Instead, each source image contributes its own gradient ﬁeld\nand the Poisson equation is solved using Neumann boundary conditions, i.e., dropping any\nequations that involve pixels outside the boundary of the image.\n14 The membrane interpolant is known to have nicer interpolation properties for arbitrary-shaped constraints than\nfrequency-domain interpolants (Nielson 1993).",
  "image_path": "page_481.jpg",
  "pages": [
    480,
    481,
    482
  ]
}