{
  "doc_id": "pages_316_318",
  "text": "294\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nIn the mean-shift procedure, the current estimate of the mode yk at iteration k is replaced\nby its locally weighted mean,\nyk+1 = yk + m(yk) =\nP\ni xiG(yk −xi)\nP\ni G(yk −xi) .\n(5.39)\nComaniciu and Meer (2002) prove that this algorithm converges to a local maximum of f(x)\nunder reasonably weak conditions on the kernel k(r), i.e., that it is monotonically decreasing.\nThis convergence is not guaranteed for regular gradient descent unless appropriate step size\ncontrol is used.\nThe two kernels that Comaniciu and Meer (2002) studied are the Epanechnikov kernel,\nkE(r) = max(0, 1 −r),\n(5.40)\nwhich is a radial generalization of a bilinear kernel, and the Gaussian (normal) kernel,\nkN(r) = exp\n\u0012\n−1\n2r\n\u0013\n.\n(5.41)\nThe corresponding derivative kernels g(r) are a unit ball and another Gaussian, respectively.\nUsing the Epanechnikov kernel converges in a ﬁnite number of steps, while the Gaussian\nkernel has a smoother trajectory (and produces better results), but converges very slowly near\na mode (Exercise 5.5).\nThe simplest way to apply mean shift is to start a separate mean-shift mode estimate\ny at every input point xi and to iterate for a ﬁxed number of steps or until the mean-shift\nmagnitude is below a threshold. A faster approach is to randomly subsample the input points\nxi and to keep track of each point’s temporal evolution. The remaining points can then be\nclassiﬁed based on the nearest evolution path (Comaniciu and Meer 2002). Paris and Durand\n(2007) review a number of other more efﬁcient implementations of mean shift, including their\nown approach, which is based on using an efﬁcient low-resolution estimate of the complete\nmulti-dimensional space of f(x) along with its stationary points.\nThe color-based segmentation shown in Figure 5.16 only looks at pixel colors when deter-\nmining the best clustering. It may therefore cluster together small isolated pixels that happen\nto have the same color, which may not correspond to a semantically meaningful segmentation\nof the image.\nBetter results can usually be obtained by clustering in the joint domain of color and lo-\ncation. In this approach, the spatial coordinates of the image xs = (x, y), which are called\nthe spatial domain, are concatenated with the color values xr, which are known as the range\ndomain, and mean-shift clustering is applied in this ﬁve-dimensional space xj. Since location\nand color may have different scales, the kernels are adjusted accordingly, i.e., we use a kernel\nof the form\nK(xj) = k\n\u0012∥xr∥2\nh2r\n\u0013\nk\n\u0012∥xs∥2\nh2s\n\u0013\n,\n(5.42)\n5.3 Mean shift and mode ﬁnding\n295\nFigure 5.18\nMean-shift color image segmentation with parameters (hs, hr, M)\n=\n(16, 19, 40) (Comaniciu and Meer 2002) c⃝2002 IEEE.\nwhere separate parameters hs and hr are used to control the spatial and range bandwidths of\nthe ﬁlter kernels. Figure 5.18 shows an example of mean-shift clustering in the joint domain,\nwith parameters (hs, hr, M) = (16, 19, 40), where spatial regions containing less than M\npixels are eliminated.\nThe form of the joint domain ﬁlter kernel (5.42) is reminiscent of the bilateral ﬁlter kernel\n(3.34–3.37) discussed in Section 3.3.1. The difference between mean shift and bilateral ﬁl-\ntering, however, is that in mean shift the spatial coordinates of each pixel are adjusted along\nwith its color values, so that the pixel migrates more quickly towards other pixels with similar\ncolors, and can therefore later be used for clustering and segmentation.\nDetermining the best bandwidth parameters h to use with mean shift remains something\nof an art, although a number of approaches have been explored. These include optimizing\nthe bias–variance tradeoff, looking for parameter ranges where the number of clusters varies\nslowly, optimizing some external clustering criterion, or using top-down (application domain)\nknowledge (Comaniciu and Meer 2003). It is also possible to change the orientation of the\nkernel in joint parameter space for applications such as spatio-temporal (video) segmentations\n(Wang, Thiesson, Xu et al. 2004).\nMean shift has been applied to a number of different problems in computer vision, includ-\ning face tracking, 2D shape extraction, and texture segmentation (Comaniciu and Meer 2002),\nand more recently in stereo matching (Chapter 11) (Wei and Quan 2004), non-photorealistic\nrendering (Section 10.5.2) (DeCarlo and Santella 2002), and video editing (Section 10.4.5)\n(Wang, Bhat, Colburn et al. 2005). Paris and Durand (2007) provide a nice review of such\napplications, as well as techniques for more efﬁciently solving the mean-shift equations and\nproducing hierarchical segmentations.\n296\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nA\nA\nA\nA\nB\nB\nB\nA\nB\nsum\nA\nassoc(A, A)\ncut(A, B)\nassoc(A, V )\nB\ncut(B, A)\nassoc(B, B)\nassoc(B, V )\nsum\nassoc(A, V )\nassoc(B, v)\n(a)\n(b)\nFigure 5.19\nSample weighted graph and its normalized cut: (a) a small sample graph and\nits smallest normalized cut; (b) tabular form of the associations and cuts for this graph. The\nassoc and cut entries are computed as area sums of the associated weight matrix W (Fig-\nure 5.20). Normalizing the table entries by the row or column sums produces normalized\nassociations and cuts Nassoc and Ncut.\n5.4 Normalized cuts\nWhile bottom-up merging techniques aggregate regions into coherent wholes and mean-shift\ntechniques try to ﬁnd clusters of similar pixels using mode ﬁnding, the normalized cuts\ntechnique introduced by Shi and Malik (2000) examines the afﬁnities (similarities) between\nnearby pixels and tries to separate groups that are connected by weak afﬁnities.\nConsider the simple graph shown in Figure 5.19a. The pixels in group A are all strongly\nconnected with high afﬁnities, shown as thick red lines, as are the pixels in group B. The\nconnections between these two groups, shown as thinner blue lines, are much weaker. A\nnormalized cut between the two groups, shown as a dashed line, separates them into two\nclusters.\nThe cut between two groups A and B is deﬁned as the sum of all the weights being cut,\ncut(A, B) =\nX\ni∈A,j∈B\nwij,\n(5.43)\nwhere the weights between two pixels (or regions) i and j measure their similarity. Using\na minimum cut as a segmentation criterion, however, does not result in reasonable clusters,\nsince the smallest cuts usually involve isolating a single pixel.\nA better measure of segmentation is the normalized cut, which is deﬁned as\nNcut(A, B) =\ncut(A, B)\nassoc(A, V ) +\ncut(A, B)\nassoc(B, V ),\n(5.44)\nwhere assoc(A, A) = P\ni∈A,j∈A wij is the association (sum of all the weights) within a\ncluster and assoc(A, V ) = assoc(A, A) + cut(A, B) is the sum of all the weights associated",
  "image_path": "page_317.jpg",
  "pages": [
    316,
    317,
    318
  ]
}