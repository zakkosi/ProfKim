{
  "doc_id": "pages_395_397",
  "text": "7.4 Bundle adjustment\n373\n(a)\n(b)\n(c)\nFigure 7.12\n3D reconstructions produced by the incremental structure from motion algo-\nrithm developed by Snavely, Seitz, and Szeliski (2006) c⃝2006 ACM: (a) cameras and point\ncloud from Trafalgar Square; (b) cameras and points overlaid on an image from the Great Wall\nof China; (c) overhead view of a reconstruction of the Old Town Square in Prague registered\nto an aerial photograph.\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 7.13\nLarge scale structure from motion using skeletal sets (Snavely, Seitz, and\nSzeliski 2008b) c⃝2008 IEEE: (a) original match graph for 784 images; (b) skeletal set\ncontaining 101 images; (c) top-down view of scene (Pantheon) reconstructed from the skele-\ntal set; (d) reconstruction after adding in the remaining images using pose estimation; (e) ﬁnal\nbundle adjusted reconstruction, which is almost identical.\n374\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nically ﬁnd and label locations and regions of interest (Simon, Snavely, and Seitz 2007; Simon\nand Seitz 2008; Gammeter, Bossard, Quack et al. 2009) and to cluster large image collections\nso that they can be automatically labeled (Li, Wu, Zach et al. 2008; Quack, Leibe, and Van\nGool 2008). Some of these application are discussed in more detail in Section 13.1.2.\n7.5 Constrained structure and motion\nThe most general algorithms for structure from motion make no prior assumptions about the\nobjects or scenes that they are reconstructing. In many cases, however, the scene contains\nhigher-level geometric primitives, such as lines and planes. These can provide information\ncomplementary to interest points and also serve as useful building blocks for 3D modeling\nand visualization. Furthermore, these primitives are often arranged in particular relationships,\ni.e., many lines and planes are either parallel or orthogonal to each other. This is particularly\ntrue of architectural scenes and models, which we study in more detail in Section 12.6.1.\nSometimes, instead of exploiting regularity in the scene structure, it is possible to take\nadvantage of a constrained motion model. For example, if the object of interest is rotating\non a turntable (Szeliski 1991b), i.e., around a ﬁxed but unknown axis, specialized techniques\ncan be used to recover this motion (Fitzgibbon, Cross, and Zisserman 1998). In other situa-\ntions, the camera itself may be moving in a ﬁxed arc around some center of rotation (Shum\nand He 1999). Specialized capture setups, such as mobile stereo camera rigs or moving ve-\nhicles equipped with multiple ﬁxed cameras, can also take advantage of the knowledge that\nindividual cameras are (mostly) ﬁxed with respect to the capture rig, as shown in Figure 7.8.19\n7.5.1 Line-based techniques\nIt is well known that pairwise epipolar geometry cannot be recovered from line matches\nalone, even if the cameras are calibrated. To see this, think of projecting the set of lines in\neach image into a set of 3D planes in space. You can move the two cameras around into any\nconﬁguration you like and still obtain a valid reconstruction for 3D lines.\nWhen lines are visible in three or more views, the trifocal tensor can be used to transfer\nlines from one pair of images to another (Hartley and Zisserman 2004). The trifocal tensor\ncan also be computed on the basis of line matches alone.\nSchmid and Zisserman (1997) describe a widely used technique for matching 2D lines\nbased on the average of 15 × 15 pixel correlation scores evaluated at all pixels along their\n19 Because of mechanical compliance and jitter, it may be prudent to allow for a small amount of individual camera\nrotation around a nominal position.\n7.5 Constrained structure and motion\n375\nFigure 7.14 Two images of a toy house along with their matched 3D line segments (Schmid\nand Zisserman 1997) c⃝1997 Springer.\ncommon line segment intersection.20 In their system, the epipolar geometry is assumed to be\nknown, e.g., computed from point matches. For wide baselines, all possible homographies\ncorresponding to planes passing through the 3D line are used to warp pixels and the maximum\ncorrelation score is used. For triplets of images, the trifocal tensor is used to verify that\nthe lines are in geometric correspondence before evaluating the correlations between line\nsegments. Figure 7.14 shows the results of using their system.\nBartoli and Sturm (2003) describe a complete system for extending three view relations\n(trifocal tensors) computed from manual line correspondences to a full bundle adjustment of\nall the line and camera parameters. The key to their approach is to use the Pl¨ucker coor-\ndinates (2.12) to parameterize lines and to directly minimize reprojection errors. It is also\npossible to represent 3D line segments by their endpoints and to measure either the reprojec-\ntion error perpendicular to the detected 2D line segments in each image or the 2D errors using\nan elongated uncertainty ellipse aligned with the line segment direction (Szeliski and Kang\n1994).\nInstead of reconstructing 3D lines, Bay, Ferrari, and Van Gool (2005) use RANSAC to\ngroup lines into likely coplanar subsets. Four lines are chosen at random to compute a homog-\nraphy, which is then veriﬁed for these and other plausible line segment matches by evaluating\ncolor histogram-based correlation scores. The 2D intersection points of lines belonging to the\nsame plane are then used as virtual measurements to estimate the epipolar geometry, which\nis more accurate than using the homographies directly.\nAn alternative to grouping lines into coplanar subsets is to group lines by parallelism.\nWhenever three or more 2D lines share a common vanishing point, there is a good likelihood\nthat they are parallel in 3D. By ﬁnding multiple vanishing points in an image (Section 4.3.3)\nand establishing correspondences between such vanishing points in different images, the rel-\native rotations between the various images (and often the camera intrinsics) can be directly\nestimated (Section 6.3.2).\n20 Because lines often occur at depth or orientation discontinuities, it may be preferable to compute correlation\nscores (or to match color histograms (Bay, Ferrari, and Van Gool 2005)) separately on each side of the line.",
  "image_path": "page_396.jpg",
  "pages": [
    395,
    396,
    397
  ]
}