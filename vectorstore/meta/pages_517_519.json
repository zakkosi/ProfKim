{
  "doc_id": "pages_517_519",
  "text": "10.2 High dynamic range imaging\n495\n(a)\n(b)\nFigure 10.28 Interactive local tone mapping (Lischinski, Farbman, Uyttendaele et al. 2006b)\nc⃝2006 ACM: (a) user-drawn strokes with associated exposure values g(x, y) (b) correspond-\ning piecewise-smooth exposure adjustment map f(x, y).\n(a)\n(b)\n(c)\n(d)\nFigure 10.29 Detail transfer in ﬂash/no-ﬂash photography (Petschnigg, Agrawala, Hoppe et\nal. 2004) c⃝2004 ACM: (a) details of input ambient A and ﬂash F images; (b) joint bilaterally\nﬁltered no-ﬂash image ANR; (c) detail layer F Detail computed from the ﬂash image F; (d)\nﬁnal merged image AFinal.\n496\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ntaken under low light conditions often suffer from excessive noise (because of the high ISO\ngains and low photon counts) and blur (due to longer exposures). Is there some way to\ncombine a non-ﬂash photo taken just before the ﬂash goes off with the ﬂash photo to produce\nan image with good color values, sharpness, and low noise?15\nPetschnigg, Agrawala, Hoppe et al. (2004) approach this problem by ﬁrst ﬁltering the no-\nﬂash (ambient) image A with a variant of the bilateral ﬁlter called the joint bilateral ﬁlter16\nin which the range kernel (3.36)\nr(i, j, k, l) = exp\n\u0012\n−∥f(i, j) −f(k, l)∥2\n2σ2r\n\u0013\n(10.23)\nis evaluated on the ﬂash image F instead of the ambient image A, since the ﬂash image is less\nnoisy and hence has more reliable edges (Figure 10.29b). Because the contents of the ﬂash\nimage can be unreliable inside and at the boundaries of shadows and specularities, these are\ndetected and a regular bilaterally ﬁltered image ABase is used instead (Figure 10.30).\nThe second stage of their algorithm computes a ﬂash detail image\nF Detail =\nF + ϵ\nF Base + ϵ,\n(10.24)\nwhere F Base is a bilaterally ﬁltered version of the ﬂash image F and ϵ = 0.02. This detail im-\nage (Figure 10.29c) encodes details that may have been ﬁltered away from the noise-reduced\nno-ﬂash image ANR, as well as additional details created by the ﬂash camera, which often\nadd crispness. The detail image is used to modulate the noise-reduced ambient image ANR\nto produce the ﬁnal results\nAFinal = (1 −M)ANRF Detail + MABase\n(10.25)\nshown in Figures 10.1b and 10.29d.\nEisemann and Durand (2004) present an alternative algorithm that shares some of the\nsame basic concepts. Both papers are well worth reading and contrasting (Exercise 10.6).\nFlash images can also be used for a variety of additional applications such as extracting\nmore reliable foreground mattes of objects (Raskar, Tan, Feris et al. 2004; Sun, Li, Kang et al.\n2006). Flash photography is just one instance of the more general topic of active illumination,\nwhich is discussed in more detail by Raskar and Tumblin (2010).\n15 In fact, the discontinued FujiFilm FinePix F40fd camera takes a pair of ﬂash and no ﬂash images in quick\nsuccession; however, it only lets you decide to keep one of them.\n16 Eisemann and Durand (2004) call this the cross bilateral ﬁlter.\n10.3 Super-resolution and blur removal\n497\nFigure 10.30\nFlash/no-ﬂash photography algorithm (Petschnigg, Agrawala, Hoppe et al.\n2004) c⃝2004 ACM. The ambient (no-ﬂash) image A is ﬁltered with a regular bilateral ﬁlter\nto produce ABase, which is used in shadow and specularity regions, and a joint bilaterally\nﬁltered noise reduced image ANR. The ﬂash image F is bilaterally ﬁltered to produce a\nbase image F Base and a detail (ratio) image F Detail, which is used to modulate the de-\nnoised ambient image. The shadow/specularity mask M is computed by comparing linearized\nversions of the ﬂash and no-ﬂash images.\n10.3 Super-resolution and blur removal\nWhile high dynamic range imaging enables us to obtain an image with a larger dynamic\nrange than a single regular image, super-resolution enables us to create images with higher\nspatial resolution and less noise than regular camera images (Chaudhuri 2001; Park, Park,\nand Kang 2003; Capel and Zisserman 2003; Capel 2004; van Ouwerkerk 2006). Most com-\nmonly, super-resolution refers to the process of aligning and combining several input images\nto produce such high-resolution composites (Irani and Peleg 1991; Cheeseman, Kanefsky,\nHanson et al. 1993; Pickup, Capel, Roberts et al. 2009). However, some newer techniques\ncan super-resolve a single image (Freeman, Jones, and Pasztor 2002; Baker and Kanade 2002;\nFattal 2007) and are hence closely related to techniques for removing blur (Sections 3.4.3 and\n3.4.4).\nThe most principled way to formulate the super-resolution problem is to write down the\nstochastic image formation equations and image priors and to then use Bayesian inference to\nrecover the super-resolved (original) sharp image. We can do this by generalizing the image",
  "image_path": "page_518.jpg",
  "pages": [
    517,
    518,
    519
  ]
}