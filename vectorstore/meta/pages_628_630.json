{
  "doc_id": "pages_628_630",
  "text": "606\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nKr¨uger 2006) each list over 400 papers devoted to these topics.12 The HumanEva database\nof articulated human motions13 contains multi-view video sequences of human actions along\nwith corresponding motion capture data, evaluation code, and a reference 3D tracker based on\nparticle ﬁltering. The companion paper by Sigal, Balan, and Black (2010) not only describes\nthe database and evaluation but also has a nice survey of important work in this ﬁeld.\nGiven the breadth of this area, it is difﬁcult to categorize all of this research, especially\nsince different techniques usually build on each other. Moeslund, Hilton, and Kr¨uger (2006)\ndivide their survey into initialization, tracking (which includes background modeling and\nsegmentation), pose estimation, and action (activity) recognition. Forsyth, Arikan, Ikemoto et\nal. (2006) divide their survey into sections on tracking (background subtraction, deformable\ntemplates, ﬂow, and probabilistic models), recovering 3D pose from 2D observations, and\ndata association and body parts. They also include a section on motion synthesis, which is\nmore widely studied in computer graphics (Arikan and Forsyth 2002; Kovar, Gleicher, and\nPighin 2002; Lee, Chai, Reitsma et al. 2002; Li, Wang, and Shum 2002; Pullen and Bregler\n2002), see Section 13.5.2. Another potential taxonomy for work in this ﬁeld would be along\nthe lines of whether 2D or 3D (or multi-view) images are used as input and whether 2D or\n3D kinematic models are used.\nIn this section, we brieﬂy review some of the more seminal and widely cited papers in the\nareas of background subtraction, initialization and detection, tracking with ﬂow, 3D kinematic\nmodels, probabilistic models, adaptive shape modeling, and activity recognition. We refer the\nreader to the previously mentioned surveys for other topics and more details.\nBackground subtraction.\nOne of the ﬁrst steps in many (but certainly not all) human track-\ning systems is to model the background in order to extract the moving foreground objects\n(silhouettes) corresponding to people. Toyama, Krumm, Brumitt et al. (1999) review several\ndifference matting and background maintenance (modeling) techniques and provide a good\nintroduction to this topic. Stauffer and Grimson (1999) describe some techniques based on\nmixture models, while Sidenbladh and Black (2003) develop a more comprehensive treat-\nment, which models not only the background image statistics but also the appearance of the\nforeground objects, e.g., their edge and motion (frame difference) statistics.\nOnce silhouettes have been extracted from one or more cameras, they can then be mod-\neled using deformable templates or other contour models (Baumberg and Hogg 1996; Wren,\nAzarbayejani, Darrell et al. 1997). Tracking such silhouettes over time supports the analysis\nof multiple people moving around a scene, including building shape and appearance models\n12 Older surveys include those by Gavrila (1999) and Moeslund and Granum (2001). Some surveys on gesture\nrecognition, which we do not cover in this book, include those by Pavlovi´c, Sharma, and Huang (1997) and Yang,\nAhuja, and Tabb (2002).\n13 http://vision.cs.brown.edu/humaneva/.\n12.6 Model-based reconstruction\n607\nand detecting if they are carrying objects (Haritaoglu, Harwood, and Davis 2000; Mittal and\nDavis 2003; Dimitrijevic, Lepetit, and Fua 2006).\nInitialization and detection.\nIn order to track people in a fully automated manner, it is\nnecessary to ﬁrst detect (or re-acquire) their presence in individual video frames. This topic\nis closely related to pedestrian detection, which is often considered as a kind of object recog-\nnition (Mori, Ren, Efros et al. 2004; Felzenszwalb and Huttenlocher 2005; Felzenszwalb,\nMcAllester, and Ramanan 2008), and is therefore treated in more depth in Section 14.1.2.\nAdditional techniques for initializing 3D trackers based on 2D images include those described\nby Howe, Leventon, and Freeman (2000), Rosales and Sclaroff (2000), Shakhnarovich, Viola,\nand Darrell (2003), Sminchisescu, Kanaujia, Li et al. (2005), Agarwal and Triggs (2006), Lee\nand Cohen (2006), Sigal and Black (2006), and Stenger, Thayananthan, Torr et al. (2006).\nSingle-frame human detection and pose estimation algorithms can sometimes be used by\nthemselves to perform tracking (Ramanan, Forsyth, and Zisserman 2005; Rogez, Rihan, Ra-\nmalingam et al. 2008; Bourdev and Malik 2009), as described in Section 4.1.4. More often,\nhowever, they are combined with frame-to-frame tracking techniques to provide better relia-\nbility (Fossati, Dimitrijevic, Lepetit et al. 2007; Andriluka, Roth, and Schiele 2008; Ferrari,\nMarin-Jimenez, and Zisserman 2008).\nTracking with ﬂow.\nThe tracking of people and their pose from frame to frame can be en-\nhanced by computing optic ﬂow or matching the appearance of their limbs from one frame\nto another. For example, the cardboard people model of Ju, Black, and Yacoob (1996) mod-\nels the appearance of each leg portion (upper and lower) as a moving rectangle, and uses\noptic ﬂow to estimate their location in each subsequent frame. Cham and Rehg (1999) and\nSidenbladh, Black, and Fleet (2000) track limbs using optical ﬂow and templates, along with\ntechniques for dealing with multiple hypotheses and uncertainty. Bregler, Malik, and Pullen\n(2004) use a full 3D model of limb and body motion, as described below. It is also possible to\nmatch the estimated motion ﬁeld itself to some prototypes in order to identify the particular\nphase of a running motion or to match two low-resolution video portions in order to perform\nvideo replacement (Efros, Berg, Mori et al. 2003).\n3D kinematic models.\nThe effectiveness of human modeling and tracking can be greatly\nenhanced using a more accurate 3D model of a person’s shape and motion. Underlying such\nrepresentations, which are ubiquitous in 3D computer animation in games and special effects,\nis a kinematic model or kinematic chain, which speciﬁes the length of each limb in a skeleton\nas well as the 2D or 3D rotation angles between the limbs or segments (Figure 12.20a–b).\nInferring the values of the joint angles from the locations of the visible surface points is\ncalled inverse kinematics (IK) and is widely studied in computer graphics.\n608\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 12.20\nTracking 3D human motion: (a) kinematic chain model for a human hand\n(Rehg, Morris, and Kanade 2003) c⃝2003, reprinted by permission of SAGE; (b) tracking a\nkinematic chain blob model in a video sequence (Bregler, Malik, and Pullen 2004) c⃝2004\nSpringer; (c–d) probabilistic loose-limbed collection of body parts (Sigal, Bhatia, Roth et al.\n2004)\nFigure 12.20a shows the kinematic model for a human hand used by Rehg, Morris, and\nKanade (2003) to track hand motion in a video. As you can see, the attachment points between\nthe ﬁngers and the thumb have two degrees of freedom, while the ﬁnger joints themselves\nhave only one. Using this kind of model can greatly enhance the ability of an edge-based\ntracker to cope with rapid motion, ambiguities in 3D pose, and partial occlusions.\nKinematic chain models are even more widely used for whole body modeling and tracking\n(O’Rourke and Badler 1980; Hogg 1983; Rohr 1994). One popular approach is to associate\nan ellipsoid or superquadric with each rigid limb in the kinematic model, as shown in Fig-\nure 12.20b. This model can then be ﬁtted to each frame in one or more video streams either\nby matching silhouettes extracted from known backgrounds or by matching and tracking the\nlocations of occluding edges (Gavrila and Davis 1996; Kakadiaris and Metaxas 2000; Bre-\ngler, Malik, and Pullen 2004; Kehl and Van Gool 2006). Note that some techniques use 2D\nmodels coupled to 2D measurements, some use 3D measurements (range data or multi-view\nvideo) with 3D models, and some use monocular video to infer and track 3D models directly.\nIt is also possible to use temporal models to improve the tracking of periodic motions,\nsuch as walking, by analyzing the joint angles as functions of time (Polana and Nelson 1997;\nSeitz and Dyer 1997; Cutler and Davis 2000). The generality and applicability of such tech-\nniques can be improved by learning typical motion patterns using principal component anal-\nysis (Sidenbladh, Black, and Fleet 2000; Urtasun, Fleet, and Fua 2006).\nProbabilistic models.\nBecause tracking can be such a difﬁcult task, sophisticated proba-\nbilistic inference techniques are often used to estimate the likely states of the person being\ntracked. One popular approach, called particle ﬁltering (Isard and Blake 1998), was origi-\nnally developed for tracking the outlines of people and hands, as described in Section 5.1.2",
  "image_path": "page_629.jpg",
  "pages": [
    628,
    629,
    630
  ]
}