{
  "doc_id": "pages_044_046",
  "text": "22\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nn^\n2. Image Formation\n3. Image Processing\n4. Features\n5. Segmentation\n6-7. Structure from Motion\n8. Motion\n9. Stitching\n10. Computational Photography\n11. Stereo\n12. 3D Shape\n13. Image-based Rendering\n14. Recognition\nFigure 1.12\nA pictorial summary of the chapter contents. Sources: Brown, Szeliski, and\nWinder (2005); Comaniciu and Meer (2002); Snavely, Seitz, and Szeliski (2006); Nagel\nand Enkelmann (1986); Szeliski and Shum (1997); Debevec and Malik (1997); Gortler,\nGrzeszczuk, Szeliski et al. (1996); Viola and Jones (2004)—see the ﬁgures in the respec-\ntive chapters for copyright information.\n1.3 Book overview\n23\nnext chapter and dip into this material later. In Chapter 2, we break down image formation\ninto three major components. Geometric image formation (Section 2.1) deals with points,\nlines, and planes, and how these are mapped onto images using projective geometry and other\nmodels (including radial lens distortion). Photometric image formation (Section 2.2) covers\nradiometry, which describes how light interacts with surfaces in the world, and optics, which\nprojects light onto the sensor plane. Finally, Section 2.3 covers how sensors work, including\ntopics such as sampling and aliasing, color sensing, and in-camera compression.\nChapter 3 covers image processing, which is needed in almost all computer vision appli-\ncations. This includes topics such as linear and non-linear ﬁltering (Section 3.3), the Fourier\ntransform (Section 3.4), image pyramids and wavelets (Section 3.5), geometric transforma-\ntions such as image warping (Section 3.6), and global optimization techniques such as regu-\nlarization and Markov Random Fields (MRFs) (Section 3.7). While most of this material is\ncovered in courses and textbooks on image processing, the use of optimization techniques is\nmore typically associated with computer vision (although MRFs are now being widely used\nin image processing as well). The section on MRFs is also the ﬁrst introduction to the use\nof Bayesian inference techniques, which are covered at a more abstract level in Appendix B.\nChapter 3 also presents applications such as seamless image blending and image restoration.\nIn Chapter 4, we cover feature detection and matching. A lot of current 3D reconstruction\nand recognition techniques are built on extracting and matching feature points (Section 4.1),\nso this is a fundamental technique required by many subsequent chapters (Chapters 6, 7, 9\nand 14). We also cover edge and straight line detection in Sections 4.2 and 4.3.\nChapter 5 covers region segmentation techniques, including active contour detection and\ntracking (Section 5.1). Segmentation techniques include top-down (split) and bottom-up\n(merge) techniques, mean shift techniques that ﬁnd modes of clusters, and various graph-\nbased segmentation approaches. All of these techniques are essential building blocks that are\nwidely used in a variety of applications, including performance-driven animation, interactive\nimage editing, and recognition.\nIn Chapter 6, we cover geometric alignment and camera calibration. We introduce the\nbasic techniques of feature-based alignment in Section 6.1 and show how this problem can\nbe solved using either linear or non-linear least squares, depending on the motion involved.\nWe also introduce additional concepts, such as uncertainty weighting and robust regression,\nwhich are essential to making real-world systems work. Feature-based alignment is then used\nas a building block for 3D pose estimation (extrinsic calibration) in Section 6.2 and camera\n(intrinsic) calibration in Section 6.3. Chapter 6 also describes applications of these techniques\nto photo alignment for ﬂip-book animations, 3D pose estimation from a hand-held camera,\nand single-view reconstruction of building models.\nChapter 7 covers the topic of structure from motion, which involves the simultaneous\nrecovery of 3D camera motion and 3D scene structure from a collection of tracked 2D fea-\n24\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ntures. This chapter begins with the easier problem of 3D point triangulation (Section 7.1),\nwhich is the 3D reconstruction of points from matched features when the camera positions\nare known. It then describes two-frame structure from motion (Section 7.2), for which al-\ngebraic techniques exist, as well as robust sampling techniques such as RANSAC that can\ndiscount erroneous feature matches. The second half of Chapter 7 describes techniques for\nmulti-frame structure from motion, including factorization (Section 7.3), bundle adjustment\n(Section 7.4), and constrained motion and structure models (Section 7.5). It also presents\napplications in view morphing, sparse 3D model construction, and match move.\nIn Chapter 8, we go back to a topic that deals directly with image intensities (as op-\nposed to feature tracks), namely dense intensity-based motion estimation (optical ﬂow). We\nstart with the simplest possible motion models, translational motion (Section 8.1), and cover\ntopics such as hierarchical (coarse-to-ﬁne) motion estimation, Fourier-based techniques, and\niterative reﬁnement. We then present parametric motion models, which can be used to com-\npensate for camera rotation and zooming, as well as afﬁne or planar perspective motion (Sec-\ntion 8.2). This is then generalized to spline-based motion models (Section 8.3) and ﬁnally\nto general per-pixel optical ﬂow (Section 8.4), including layered and learned motion models\n(Section 8.5). Applications of these techniques include automated morphing, frame interpo-\nlation (slow motion), and motion-based user interfaces.\nChapter 9 is devoted to image stitching, i.e., the construction of large panoramas and com-\nposites. While stitching is just one example of computation photography (see Chapter 10),\nthere is enough depth here to warrant a separate chapter. We start by discussing various pos-\nsible motion models (Section 9.1), including planar motion and pure camera rotation. We\nthen discuss global alignment (Section 9.2), which is a special (simpliﬁed) case of general\nbundle adjustment, and then present panorama recognition, i.e., techniques for automatically\ndiscovering which images actually form overlapping panoramas. Finally, we cover the topics\nof image compositing and blending (Section 9.3), which involve both selecting which pixels\nfrom which images to use and blending them together so as to disguise exposure differences.\nImage stitching is a wonderful application that ties together most of the material covered\nin earlier parts of this book. It also makes for a good mid-term course project that can build\non previously developed techniques such as image warping and feature detection and match-\ning. Chapter 9 also presents more specialized variants of stitching such as whiteboard and\ndocument scanning, video summarization, panography, full 360◦spherical panoramas, and\ninteractive photomontage for blending repeated action shots together.\nChapter 10 presents additional examples of computational photography, which is the pro-\ncess of creating new images from one or more input photographs, often based on the careful\nmodeling and calibration of the image formation process (Section 10.1). Computational pho-\ntography techniques include merging multiple exposures to create high dynamic range images\n(Section 10.2), increasing image resolution through blur removal and super-resolution (Sec-",
  "image_path": "page_045.jpg",
  "pages": [
    44,
    45,
    46
  ]
}