{
  "doc_id": "pages_521_523",
  "text": "10.3 Super-resolution and blur removal\n499\n(Recall from (3.89) that once the warping function ˆhk is known, values of s(ˆhk(x)) depend\nlinearly on those in s(x).) An efﬁcient way to solve this least squares problem is to use\npreconditioned conjugate gradient descent (Capel 2004), although some earlier algorithms,\nsuch as the one developed by Irani and Peleg (1991), used regular gradient descent (also\nknown as iterative back projection (IBP), in the computed tomography literature).\nThe above formulation assumes that warping can be expressed as a simple (sinc or bicu-\nbic) interpolated resampling of the super-resolved sharp image, followed by a stationary\n(spatially invariant) blurring (PSF) and area integration process. However, if the surface is\nseverely foreshortened, we have to take into account the spatially varying ﬁltering that occurs\nduring the image warping (Section 3.6.1), before we can then model the PSF induced by the\noptics and camera sensor (Wang, Kang, Szeliski et al. 2001; Capel 2004).\nHow well does this least squares (MLE) approach to super-resolution work? In practice,\nthis depends a lot on the amount of blur and aliasing in the camera optics, as well as the accu-\nracy in the motion and PSF estimates (Baker and Kanade 2002; Jiang, Wong, and Bao 2003;\nCapel 2004). Less blurring and more aliasing means that there is more (aliased) high fre-\nquency information available to be recovered. However, because the least squares (maximum\nlikelihood) formulation uses no image prior, a lot of high-frequency noise can be introduced\ninto the solution (Figure 10.31c).\nFor this reason, most super-resolution algorithms assume some form of image prior. The\nsimplest of these is to place a penalty on the image derivatives similar to Equations (3.105\nand 3.113), e.g.,\nX\n(i,j)\nρp(s(i, j) −s(i + 1, j)) + ρp(s(i, j) −s(i, j + 1)).\n(10.29)\nAs discussed in Section 3.7.2, when ρp is quadratic, this is a form of Tikhonov regulariza-\ntion (Section 3.7.1), and the overall problem is still linear least squares. The resulting prior\nimage model is a Gaussian Markov random ﬁeld (GMRF), which can be extended to other\n(e.g., diagonal) differences, as in (Capel 2004) (Figure 10.31).\nUnfortunately, GMRFs tend to produce solutions with visible ripples, which can also\nbe interpreted as increased noise sensitivity in middle frequencies (Exercise 3.17). A bet-\nter image prior is a robust prior that encourages piecewise continuous solutions (Black and\nRangarajan 1996), see Appendix B.3. Examples of such priors include the Huber potential\n(Schultz and Stevenson 1996; Capel and Zisserman 2003), which is a blend of a Gaussian\nwith a longer-tailed Laplacian, and the even sparser (heavier-tailed) hyper-Laplacians used\nby Levin, Fergus, Durand et al. (2007) and Krishnan and Fergus (2009). It is also possible to\nlearn the parameters for such priors using cross-validation (Capel 2004; Pickup 2007).\nWhile sparse (robust) derivative priors can reduce rippling effects and increase edge\nsharpness, they cannot hallucinate higher-frequency texture or details. To do this, a train-\n500\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 10.31 Super-resolution results using a variety of image priors (Capel 2001): (a) Low-\nres ROI (bicubic 3× zoom); (b) average image; (c) MLE @ 1.25× pixel-zoom; (d) simple\n∥x∥2 prior (λ = 0.004); (e) GMRF (λ = 0.003); (f) HMRF (λ = 0.01, α = 0.04). 10\nimages are used as input and a 3× super-resolved image is produced in each case, except for\nthe MLE result in (c).\n(a)\n(b)\n(c)\nFigure 10.32 Example-based super-resolution: (a) original 32 × 32 low-resolution image;\n(b) example-based super-resolved 256 × 256 image (Freeman, Jones, and Pasztor 2002) c⃝\n2002 IEEE; (c) upsampling via imposed edge statistics (Fattal 2007) c⃝2007 ACM.\n10.3 Super-resolution and blur removal\n501\ning set of sample images can be used to ﬁnd plausible mappings between low-frequency\noriginals and the missing higher frequencies. Inspired by some of the example-based texture\nsynthesis algorithms we discuss in Section 10.5, the example-based super-resolution algo-\nrithm developed by Freeman, Jones, and Pasztor (2002) uses training images to learn the\nmapping between local texture patches and missing higher-frequency details. To ensure that\noverlapping patches are similar in appearance, a Markov random ﬁeld is used and optimized\nusing either belief propagation (Freeman, Pasztor, and Carmichael 2000) or a raster-scan de-\nterministic variant (Freeman, Jones, and Pasztor 2002). Figure 10.32 shows the results of\nhallucinating missing details using this approach and compares these results to a more recent\nalgorithm by Fattal (2007). This latter algorithm learns to predict oriented gradient magni-\ntudes in the ﬁner resolution image based on a pixel’s location relative to the nearest detected\nedge along with the corresponding edge statistics (magnitude and width). It is also possible\nto combine sparse (robust) derivative priors with example-based super-resolution, as shown\nby Tappen, Russell, and Freeman (2003).\nAn alternative (but closely related) form of hallucination is to recognize the parts of a\ntraining database of images to which a low-resolution pixel might correspond. In their work,\nBaker and Kanade (2002) use local derivative-of-Gaussian ﬁlter responses as features and\nthen match parent structure vectors in a manner similar to De Bonet (1997).19 The high-\nfrequency gradient at each recognized training image location is then used as a constraint on\nthe super-resolved image, along with the usual reconstruction (prediction) equation (10.27).\nFigure 10.33 shows the result of hallucinating higher-resolution faces from lower-resolution\ninputs; Baker and Kanade (2002) also show examples of super-resolving known-font text.\nExercise 10.7 gives more details on how to implement and test one or more of these super-\nresolution techniques.\nUnder favorable conditions, super-resolution and related upsampling techniques can in-\ncrease the resolution of a well-photographed image or image collection. When the input\nimages are blurry to start with, the best one can often hope for is to reduce the amount of blur.\nThis problem is closely related super-resolution, with the biggest differences being that the\nblur kernel b is usually much larger and the downsampling factor D is unity. A large literature\non image deblurring exists; some of the more recent publications with nice literature reviews\ninclude those by Fergus, Singh, Hertzmann et al. (2006), Yuan, Sun, Quan et al. (2008), and\nJoshi, Zitnick, Szeliski et al. (2009). It is also possible to reduce blur by combining sharp (but\nnoisy) images with blurrier (but cleaner) images (Yuan, Sun, Quan et al. 2007), take lots of\nquick exposures20 (Hasinoff and Kutulakos 2008; Hasinoff, Kutulakos, Durand et al. 2009;\nHasinoff, Durand, and Freeman 2010), or use coded aperture techniques to simultaneously\n19 For face super-resolution, where all the images are pre-aligned, only corresponding pixels in different images\nare examined.\n20 The SONY DSC-WX1 takes multiple shots to produce better low-light photos.",
  "image_path": "page_522.jpg",
  "pages": [
    521,
    522,
    523
  ]
}