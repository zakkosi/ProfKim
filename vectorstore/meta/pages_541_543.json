{
  "doc_id": "pages_541_543",
  "text": "10.5 Texture analysis and synthesis\n519\nradishes\nlots more radishes\nrocks\nyogurt\n(a)\n(b)\n(c)\nFigure 10.49 Texture synthesis: (a) given a small patch of texture, the task is to synthesize\n(b) a similar-looking larger patch; (c) other semi-structured textures that are challenging to\nsynthesize. (Images courtesy of Alyosha Efros.)\nparent structure, i.e., similar multi-scale oriented ﬁlter responses, and then randomly chooses\none of these matching locations as the current sample value.\nMore recent texture synthesis algorithms sequentially generate texture pixels by looking\nfor neighborhoods in the source texture that are similar to the currently synthesized image\n(Efros and Leung 1999). Consider the (as yet) unknown pixel p in the partially constructed\ntexture on the left side of Figure 10.50. Since some of its neighboring pixels have been\nalready been synthesized, we can look for similar partial neighborhoods in the sample texture\nimage on the right and randomly select one of these as the new value of p. This process\ncan be repeated down the new image either in a raster fashion or by scanning around the\nperiphery (“onion peeling”) when ﬁlling holes, as discussed in (Section 10.5.1). In their\nactual implementation, Efros and Leung (1999) ﬁnd the most similar neighborhood and then\ninclude all other neighborhoods within a d = (1 + ϵ) distance, with ϵ = 0.1. They also\noptionally weight the random pixel selections by the similarity metric d.\nTo accelerate this process and improve its visual quality, Wei and Levoy (2000) extend\nthis technique using a coarse-to-ﬁne generation process, where coarser levels of the pyramid,\nwhich have already been synthesized, are also considered during the matching (De Bonet\n1997). To accelerate the nearest neighbor ﬁnding, tree-structured vector quantization is used.\nEfros and Freeman (2001) propose an alternative acceleration and visual quality improve-\n520\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\np\nnon-parametric\nsampling\nInput image\nOutput image\nFigure 10.50\nTexture synthesis using non-parametric sampling (Efros and Leung 1999).\nThe value of the newest pixel p is randomly chosen from similar local (partial) patches in the\nsource texture (input image). (Figure courtesy of Alyosha Efros.)\np\nInput image\nnon-parametric\nsampling\nB\nOutput image\nB1\nB2\nMinimal error\nboundary cut\nFigure 10.51\nTexture synthesis by image quilting (Efros and Freeman 2001). Instead of\ngenerating a single pixel at a time, larger blocks are copied from the source texture. The tran-\nsitions in the overlap regions between the selected blocks are then optimized using dynamic\nprogramming. (Figure courtesy of Alyosha Efros.)\nment technique. Instead of synthesizing a single pixel at a time, overlapping square blocks\nare selected using similarity with previously synthesized regions (Figure 10.51). Once the\nappropriate blocks have been selected, the seam between newly overlapping blocks is deter-\nmined using dynamic programming. (Full graph cut seam selection is not required, since only\none seam location per row is needed for a vertical boundary.) Because this process involves\nselecting small patches and them stitching them together, Efros and Freeman (2001) call their\nsystem image quilting. Komodakis and Tziritas (2007b) present an MRF-based version of\nthis block synthesis algorithm that uses a new, efﬁcient version of loopy belief propagation\nthey call “Priority-BP”.\n10.5 Texture analysis and synthesis\n521\n(a)\n(b)\n(c)\n(d)\nFigure 10.52\nImage inpainting (hole ﬁlling): (a–b) propagation along isophote directions\n(Bertalmio, Sapiro, Caselles et al. 2000) c⃝2000 ACM; (c–d) exemplar-based inpainting\nwith conﬁdence-based ﬁlling order (Criminisi, P´erez, and Toyama 2004).\n10.5.1 Application: Hole ﬁlling and inpainting\nFilling holes left behind when objects or defects are excised from photographs, which is\nknown as inpainting, is one of the most common applications of texture synthesis. Such\ntechniques are used not only to remove unwanted people or interlopers from photographs\n(King 1997) but also to ﬁx small defects in old photos and movies (scratch removal) or to\nremove wires holding props or actors in mid-air during ﬁlming (wire removal). Bertalmio,\nSapiro, Caselles et al. (2000) solve the problem by propagating pixel values along isophote\n(constant-value) directions interleaved with some anisotropic diffusion steps (Figure 10.52a–\nb). Telea (2004) develops a faster technique that uses the fast marching method from level\nsets (Section 5.1.4). However, these techniques will not hallucinate texture in the missing\nregions. Bertalmio, Vese, Sapiro et al. (2003) augment their earlier technique by adding\nsynthetic texture to the inﬁlled regions.\nThe example-based (non-parametric) texture generation techniques discussed in the pre-\nvious section can also be used by ﬁlling the holes from the outside in (the “onion-peel” or-\ndering). However, this approach may fail to propagate strong oriented structures. Criminisi,\nP´erez, and Toyama (2004) use exemplar-based texture synthesis where the order of synthesis\nis determined by the strength of the gradient along the region boundary (Figures 10.1d and\n10.52c–d). Sun, Yuan, Jia et al. (2004) present a related approach where the user draws in-\nteractive lines to indicate where structures should be preferentially propagated. Additional\ntechniques related to these approaches include those developed by Drori, Cohen-Or, and\nYeshurun (2003), Kwatra, Sch¨odl, Essa et al. (2003), Kwatra, Essa, Bobick et al. (2005),\nWilczkowiak, Brostow, Tordoff et al. (2005), Komodakis and Tziritas (2007b), and Wexler,\nShechtman, and Irani (2007).\nMost hole ﬁlling algorithms borrow small pieces of the original image to ﬁll in the holes.\nWhen a large database of source images is available, e.g., when images are taken from a",
  "image_path": "page_542.jpg",
  "pages": [
    541,
    542,
    543
  ]
}