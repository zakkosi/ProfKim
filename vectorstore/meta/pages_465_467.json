{
  "doc_id": "pages_465_467",
  "text": "9.2 Global alignment\n443\nwhere the ˜xik function is the predicted location of feature i in frame k given by (9.27),\nˆxij is the observed location, and the “2D” in the subscript indicates that an image-plane\nerror is being minimized (Shum and Szeliski 2000). Note that since ˜xik depends on the ˆxij\nobserved value, we actually have an errors-in-variable problem, which in principle requires\nmore sophisticated techniques than least squares to solve (Van Huffel and Lemmerling 2002;\nMatei and Meer 2006). However, in practice, if we have enough features, we can directly\nminimize the above quantity using regular non-linear least squares and obtain an accurate\nmulti-frame alignment.\nWhile this approach works well in practice, it suffers from two potential disadvantages.\nFirst, since a summation is taken over all pairs with corresponding features, features that are\nobserved many times are overweighted in the ﬁnal solution. (In effect, a feature observed m\ntimes gets counted\n\u0000m\n2\n\u0001\ntimes instead of m times.) Second, the derivatives of ˜xik with respect\nto the {(Rj, fj)} are a little cumbersome, although using the incremental correction to Rj\nintroduced in Section 9.1.3 makes this more tractable.\nAn alternative way to formulate the optimization is to use true bundle adjustment, i.e., to\nsolve not only for the pose parameters {(Rj, fj)} but also for the 3D point positions {xi},\nEBA−2D =\nX\ni\nX\nj\ncij∥˜xij(xi; Rj, fj) −ˆxij∥2,\n(9.29)\nwhere ˜xij(xi; Rj, fj) is given by (9.26). The disadvantage of full bundle adjustment is that\nthere are more variables to solve for, so each iteration and also the overall convergence may\nbe slower. (Imagine how the 3D points need to “shift” each time some rotation matrices are\nupdated.) However, the computational complexity of each linearized Gauss–Newton step can\nbe reduced using sparse matrix techniques (Section 7.4.1) (Szeliski and Kang 1994; Triggs,\nMcLauchlan, Hartley et al. 1999; Hartley and Zisserman 2004).\nAn alternative formulation is to minimize the error in 3D projected ray directions (Shum\nand Szeliski 2000), i.e.,\nEBA−3D =\nX\ni\nX\nj\ncij∥˜xi(ˆxij; Rj, fj) −xi∥2,\n(9.30)\nwhere ˜xi(xij; Rj, fj) is given by the second half of (9.26). This has no particular advantage\nover (9.29). In fact, since errors are being minimized in 3D ray space, there is a bias towards\nestimating longer focal lengths, since the angles between rays become smaller as f increases.\nHowever, if we eliminate the 3D rays xi, we can derive a pairwise energy formulated in\n3D ray space (Shum and Szeliski 2000),\nEall−pairs−3D =\nX\ni\nX\njk\ncijcik∥˜xi(ˆxij; Rj, fj) −˜xi(ˆxik; Rk, fk)∥2.\n(9.31)\n444\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nThis results in the simplest set of update equations (Shum and Szeliski 2000), since the fk can\nbe folded into the creation of the homogeneous coordinate vector as in Equation (9.7). Thus,\neven though this formula over-weights features that occur more frequently, it is the method\nused by Shum and Szeliski (2000) and Brown, Szeliski, and Winder (2005). In order to reduce\nthe bias towards longer focal lengths, we multiply each residual (3D error) by\np\nfjfk, which\nis similar to projecting the 3D rays into a “virtual camera” of intermediate focal length.\nUp vector selection.\nAs mentioned above, there exists a global ambiguity in the pose of the\n3D cameras computed by the above methods. While this may not appear to matter, people\nprefer that the ﬁnal stitched image is “upright” rather than twisted or tilted. More concretely,\npeople are used to seeing photographs displayed so that the vertical (gravity) axis points\nstraight up in the image. Consider how you usually shoot photographs: while you may pan\nand tilt the camera any which way, you usually keep the horizontal edge of your camera (its\nx-axis) parallel to the ground plane (perpendicular to the world gravity direction).\nMathematically, this constraint on the rotation matrices can be expressed as follows. Re-\ncall from Equation (9.26) that the 3D to 2D projection is given by\n˜xik ∼KkRkxi.\n(9.32)\nWe wish to post-multiply each rotation matrix Rk by a global rotation Rg such that the pro-\njection of the global y-axis, ˆ= (0, 1, 0) is perpendicular to the image x-axis, ˆı = (1, 0, 0).10\nThis constraint can be written as\nˆıT RkRgˆ= 0\n(9.33)\n(note that the scaling by the calibration matrix is irrelevant here). This is equivalent to re-\nquiring that the ﬁrst row of Rk, rk0 = ˆıT Rk be perpendicular to the second column of Rg,\nrg1 = Rgˆ. This set of constraints (one per input image) can be written as a least squares\nproblem,\nrg1 = arg min\nr\nX\nk\n(rT rk0)2 = arg min\nr rT\n\"X\nk\nrk0rT\nk0\n#\nr.\n(9.34)\nThus, rg1 is the smallest eigenvector of the scatter or moment matrix spanned by the indi-\nvidual camera rotation x-vectors, which should generally be of the form (c, 0, s) when the\ncameras are upright.\nTo fully specify the Rg global rotation, we need to specify one additional constraint. This\nis related to the view selection problem discussed in Section 9.3.1. One simple heuristic is to\n10 Note that here we use the convention common in computer graphics that the vertical world axis corresponds to\ny. This is a natural choice if we wish the rotation matrix associated with a “regular” image taken horizontally to be\nthe identity, rather than a 90◦rotation around the x-axis.\n9.2 Global alignment\n445\nprefer the average z-axis of the individual rotation matrices, k = P\nk ˆk\nT Rk to be close to\nthe world z-axis, rg2 = Rgˆk. We can therefore compute the full rotation matrix Rg in three\nsteps:\n1. rg1 = min eigenvector (P\nk rk0rT\nk0);\n2. rg0 = N((P\nk rk2) × rg1);\n3. rg2 = rg0 × rg1,\nwhere N(v) = v/∥v∥normalizes a vector v.\n9.2.2 Parallax removal\nOnce we have optimized the global orientations and focal lengths of our cameras, we may ﬁnd\nthat the images are still not perfectly aligned, i.e., the resulting stitched image looks blurry\nor ghosted in some places. This can be caused by a variety of factors, including unmodeled\nradial distortion, 3D parallax (failure to rotate the camera around its optical center), small\nscene motions such as waving tree branches, and large-scale scene motions such as people\nmoving in and out of pictures.\nEach of these problems can be treated with a different approach. Radial distortion can be\nestimated (potentially ahead of time) using one of the techniques discussed in Section 2.1.6.\nFor example, the plumb-line method (Brown 1971; Kang 2001; El-Melegy and Farag 2003)\nadjusts radial distortion parameters until slightly curved lines become straight, while mosaic-\nbased approaches adjust them until mis-registration is reduced in image overlap areas (Stein\n1997; Sawhney and Kumar 1999).\n3D parallax can be handled by doing a full 3D bundle adjustment, i.e., by replacing the\nprojection equation (9.26) used in Equation (9.29) with Equation (2.68), which models cam-\nera translations. The 3D positions of the matched feature points and cameras can then be si-\nmultaneously recovered, although this can be signiﬁcantly more expensive than parallax-free\nimage registration. Once the 3D structure has been recovered, the scene could (in theory) be\nprojected to a single (central) viewpoint that contains no parallax. However, in order to do\nthis, dense stereo correspondence needs to be performed (Section 11.3) (Li, Shum, Tang et al.\n2004; Zheng, Kang, Cohen et al. 2007), which may not be possible if the images contain only\npartial overlap. In that case, it may be necessary to correct for parallax only in the overlap\nareas, which can be accomplished using a multi-perspective plane sweep (MPPS) algorithm\n(Kang, Szeliski, and Uyttendaele 2004; Uyttendaele, Criminisi, Kang et al. 2004).\nWhen the motion in the scene is very large, i.e., when objects appear and disappear com-\npletely, a sensible solution is to simply select pixels from only one image at a time as the\nsource for the ﬁnal composite (Milgram 1977; Davis 1998; Agarwala, Dontcheva, Agrawala",
  "image_path": "page_466.jpg",
  "pages": [
    465,
    466,
    467
  ]
}