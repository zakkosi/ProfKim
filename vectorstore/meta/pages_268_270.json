{
  "doc_id": "pages_268_270",
  "text": "246\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nN   0\nN   0\nW\n6\nNE  \n     1\n      7\nNW\nSW  \n     5\nFigure 4.34\nChain code representation of a grid-aligned linked edge chain. The code is\nrepresented as a series of direction codes, e.g, 0 1 0 7 6 5, which can further be compressed\nusing predictive and run-length coding.\ndisambiguation. Ideas from connected component computation can also sometimes be used\nto make the edge linking process even faster (see Exercise 4.8).\nOnce the edgels have been linked into chains, we can apply an optional thresholding\nwith hysteresis to remove low-strength contour segments (Canny 1986). The basic idea of\nhysteresis is to set two different thresholds and allow a curve being tracked above the higher\nthreshold to dip in strength down to the lower threshold.\nLinked edgel lists can be encoded more compactly using a variety of alternative repre-\nsentations. A chain code encodes a list of connected points lying on an N8 grid using a\nthree-bit code corresponding to the eight cardinal directions (N, NE, E, SE, S, SW, W, NW)\nbetween a point and its successor (Figure 4.34). While this representation is more compact\nthan the original edgel list (especially if predictive variable-length coding is used), it is not\nvery suitable for further processing.\nA more useful representation is the arc length parameterization of a contour, x(s), where\ns denotes the arc length along a curve. Consider the linked set of edgels shown in Fig-\nure 4.35a. We start at one point (the dot at (1.0, 0.5) in Figure 4.35a) and plot it at coordinate\ns = 0 (Figure 4.35b). The next point at (2.0, 0.5) gets plotted at s = 1, and the next point\nat (2.5, 1.0) gets plotted at s = 1.7071, i.e., we increment s by the length of each edge seg-\nment. The resulting plot can be resampled on a regular (say, integral) s grid before further\nprocessing.\nThe advantage of the arc-length parameterization is that it makes matching and processing\n(e.g., smoothing) operations much easier. Consider the two curves describing similar shapes\nshown in Figure 4.36. To compare the curves, we ﬁrst subtract the average values x0 =\nR\ns x(s) from each descriptor. Next, we rescale each descriptor so that s goes from 0 to 1\ninstead of 0 to S, i.e., we divide x(s) by S. Finally, we take the Fourier transform of each\n4.2 Edges\n247\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\nx\ny\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9 10 11\ns\n.\nx\ny\n(a)\n(b)\nFigure 4.35 Arc-length parameterization of a contour: (a) discrete points along the contour\nare ﬁrst transcribed as (b) (x, y) pairs along the arc length s. This curve can then be regularly\nre-sampled or converted into alternative (e.g., Fourier) representations.\nt\nx(s)\nκ\ns=0=1\nx0\ns=0=1\nx0\nFigure 4.36 Matching two contours using their arc-length parameterization. If both curves\nare normalized to unit length, s ∈[0, 1] and centered around their centroid x0, they will\nhave the same descriptor up to an overall “temporal” shift (due to different starting points for\ns = 0) and a phase (x-y) shift (due to rotation).\n248\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 4.37 Curve smoothing with a Gaussian kernel (Lowe 1988) c⃝1998 IEEE: (a) with-\nout a shrinkage correction term; (b) with a shrinkage correction term.\nFigure 4.38 Changing the character of a curve without affecting its sweep (Finkelstein and\nSalesin 1994) c⃝1994 ACM: higher frequency wavelets can be replaced with exemplars from\na style library to effect different local appearances.\nnormalized descriptor, treating each x = (x, y) value as a complex number. If the original\ncurves are the same (up to an unknown scale and rotation), the resulting Fourier transforms\nshould differ only by a scale change in magnitude plus a constant complex phase shift, due\nto rotation, and a linear phase shift in the domain, due to different starting points for s (see\nExercise 4.9).\nArc-length parameterization can also be used to smooth curves in order to remove digiti-\nzation noise. However, if we just apply a regular smoothing ﬁlter, the curve tends to shrink\non itself (Figure 4.37a). Lowe (1989) and Taubin (1995) describe techniques that compensate\nfor this shrinkage by adding an offset term based on second derivative estimates or a larger\nsmoothing kernel (Figure 4.37b). An alternative approach, based on selectively modifying\ndifferent frequencies in a wavelet decomposition, is presented by Finkelstein and Salesin\n(1994). In addition to controlling shrinkage without affecting its “sweep”, wavelets allow the\n“character” of a curve to be interactively modiﬁed, as shown in Figure 4.38.\nThe evolution of curves as they are smoothed and simpliﬁed is related to “grassﬁre” (dis-",
  "image_path": "page_269.jpg",
  "pages": [
    268,
    269,
    270
  ]
}