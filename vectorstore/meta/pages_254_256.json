{
  "doc_id": "pages_254_256",
  "text": "232\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 4.26 The three Haar wavelet coefﬁcients used for hashing the MOPS descriptor de-\nvised by Brown, Szeliski, and Winder (2005) are computed by summing each 8×8 normalized\npatch over the light and dark gray regions and taking their difference.\nEfﬁcient matching\nOnce we have decided on a matching strategy, we still need to search efﬁciently for poten-\ntial candidates. The simplest way to ﬁnd all corresponding feature points is to compare all\nfeatures against all other features in each pair of potentially matching images. Unfortunately,\nthis is quadratic in the number of extracted features, which makes it impractical for most\napplications.\nA better approach is to devise an indexing structure, such as a multi-dimensional search\ntree or a hash table, to rapidly search for features near a given feature. Such indexing struc-\ntures can either be built for each image independently (which is useful if we want to only\nconsider certain potential matches, e.g., searching for a particular object) or globally for all\nthe images in a given database, which can potentially be faster, since it removes the need to it-\nerate over each image. For extremely large databases (millions of images or more), even more\nefﬁcient structures based on ideas from document retrieval (e.g., vocabulary trees, (Nist´er and\nStew´enius 2006)) can be used (Section 14.3.2).\nOne of the simpler techniques to implement is multi-dimensional hashing, which maps\ndescriptors into ﬁxed size buckets based on some function applied to each descriptor vector.\nAt matching time, each new feature is hashed into a bucket, and a search of nearby buckets\nis used to return potential candidates, which can then be sorted or graded to determine which\nare valid matches.\nA simple example of hashing is the Haar wavelets used by Brown, Szeliski, and Winder\n(2005) in their MOPS paper. During the matching structure construction, each 8 × 8 scaled,\noriented, and normalized MOPS patch is converted into a three-element index by perform-\ning sums over different quadrants of the patch (Figure 4.26). The resulting three values are\nnormalized by their expected standard deviations and then mapped to the two (of b = 10)\nnearest 1D bins. The three-dimensional indices formed by concatenating the three quantized\nvalues are used to index the 23 = 8 bins where the feature is stored (added). At query time,\nonly the primary (closest) indices are used, so only a single three-dimensional bin needs to\n4.1 Points and patches\n233\n(a)\n(b)\nFigure 4.27 K-d tree and best bin ﬁrst (BBF) search (Beis and Lowe 1999) c⃝1999 IEEE:\n(a) The spatial arrangement of the axis-aligned cutting planes is shown using dashed lines.\nIndividual data points are shown as small diamonds. (b) The same subdivision can be repre-\nsented as a tree, where each interior node represents an axis-aligned cutting plane (e.g., the\ntop node cuts along dimension d1 at value .34) and each leaf node is a data point. During a\nBBF search, a query point (denoted by “+”) ﬁrst looks in its containing bin (D) and then in\nits nearest adjacent bin (B), rather than its closest neighbor in the tree (C).\nbe examined. The coefﬁcients in the bin can then be used to select k approximate nearest\nneighbors for further processing (such as computing the NNDR).\nA more complex, but more widely applicable, version of hashing is called locality sen-\nsitive hashing, which uses unions of independently computed hashing functions to index\nthe features (Gionis, Indyk, and Motwani 1999; Shakhnarovich, Darrell, and Indyk 2006).\nShakhnarovich, Viola, and Darrell (2003) extend this technique to be more sensitive to the\ndistribution of points in parameter space, which they call parameter-sensitive hashing. Even\nmore recent work converts high-dimensional descriptor vectors into binary codes that can be\ncompared using Hamming distances (Torralba, Weiss, and Fergus 2008; Weiss, Torralba, and\nFergus 2008) or that can accommodate arbitrary kernel functions (Kulis and Grauman 2009;\nRaginsky and Lazebnik 2009).\nAnother widely used class of indexing structures are multi-dimensional search trees. The\nbest known of these are k-d trees, also often written as kd-trees, which divide the multi-\ndimensional feature space along alternating axis-aligned hyperplanes, choosing the threshold\nalong each axis so as to maximize some criterion, such as the search tree balance (Samet\n1989). Figure 4.27 shows an example of a two-dimensional k-d tree. Here, eight different data\npoints A–H are shown as small diamonds arranged on a two-dimensional plane. The k-d tree\n234\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nrecursively splits this plane along axis-aligned (horizontal or vertical) cutting planes. Each\nsplit can be denoted using the dimension number and split value (Figure 4.27b). The splits are\narranged so as to try to balance the tree, i.e., to keep its maximum depth as small as possible.\nAt query time, a classic k-d tree search ﬁrst locates the query point (+) in its appropriate\nbin (D), and then searches nearby leaves in the tree (C, B, . . .) until it can guarantee that\nthe nearest neighbor has been found. The best bin ﬁrst (BBF) search (Beis and Lowe 1999)\nsearches bins in order of their spatial proximity to the query point and is therefore usually\nmore efﬁcient.\nMany additional data structures have been developed over the years for solving nearest\nneighbor problems (Arya, Mount, Netanyahu et al. 1998; Liang, Liu, Xu et al. 2001; Hjalta-\nson and Samet 2003). For example, Nene and Nayar (1997) developed a technique they call\nslicing that uses a series of 1D binary searches on the point list sorted along different dimen-\nsions to efﬁciently cull down a list of candidate points that lie within a hypercube of the query\npoint. Grauman and Darrell (2005) reweight the matches at different levels of an indexing\ntree, which allows their technique to be less sensitive to discretization errors in the tree con-\nstruction. Nist´er and Stew´enius (2006) use a metric tree, which compares feature descriptors\nto a small number of prototypes at each level in a hierarchy. The resulting quantized visual\nwords can then be used with classical information retrieval (document relevance) techniques\nto quickly winnow down a set of potential candidates from a database of millions of images\n(Section 14.3.2). Muja and Lowe (2009) compare a number of these approaches, introduce a\nnew one of their own (priority search on hierarchical k-means trees), and conclude that mul-\ntiple randomized k-d trees often provide the best performance. Despite all of this promising\nwork, the rapid computation of image feature correspondences remains a challenging open\nresearch problem.\nFeature match veriﬁcation and densiﬁcation\nOnce we have some hypothetical (putative) matches, we can often use geometric alignment\n(Section 6.1) to verify which matches are inliers and which ones are outliers. For example,\nif we expect the whole image to be translated or rotated in the matching view, we can ﬁt a\nglobal geometric transform and keep only those feature matches that are sufﬁciently close to\nthis estimated transformation. The process of selecting a small set of seed matches and then\nverifying a larger set is often called random sampling or RANSAC (Section 6.1.4). Once an\ninitial set of correspondences has been established, some systems look for additional matches,\ne.g., by looking for additional correspondences along epipolar lines (Section 11.1) or in the\nvicinity of estimated locations based on the global transform. These topics are discussed\nfurther in Sections 6.1, 11.2, and 14.3.1.",
  "image_path": "page_255.jpg",
  "pages": [
    254,
    255,
    256
  ]
}