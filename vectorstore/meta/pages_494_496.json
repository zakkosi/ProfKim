{
  "doc_id": "pages_494_496",
  "text": "472\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 10.3 Radiometric response calibration: (a) typical camera response function, show-\ning the mapping between incoming log irradiance (exposure) and output eight-bit pixel val-\nues, for one color channel (Debevec and Malik 1997) c⃝1997 ACM; (b) color checker chart.\npresent (either unintentionally or by design). Ignoring, for now, photon noise, on-chip noise,\nampliﬁer noise, and quantization noise, which we discuss shortly, you can often assume that\nthe mapping between incoming light and the values stored in a RAW camera ﬁle (if your\ncamera supports this) is roughly linear.\nIf images are being stored in the more common JPEG format, the camera’s digital signal\nprocessor (DSP) next performs Bayer pattern demosaicing (Sections 2.3.2 and 10.3.1), which\nis a mostly linear (but often non-stationary) process. Some sharpening is also often applied at\nthis stage. Next, the color values are multiplied by different constants (or sometimes a 3 × 3\ncolor twist matrix) to perform color balancing, i.e., to move the white point closer to pure\nwhite. Finally, a standard gamma is applied to the intensities in each color channel and the\ncolors are converted into YCbCr format before being transformed by a DCT, quantized, and\nthen compressed into the JPEG format (Section 2.3.3). Figure 10.2 shows all of these steps\nin pictorial form.\nGiven the complexity of all of this processing, it is difﬁcult to model the camera response\nfunction (Figure 10.3a), i.e., the mapping between incoming irradiance and digital RGB val-\nues, from ﬁrst principles. A more practical approach is to calibrate the camera by measuring\ncorrespondences between incoming light and ﬁnal values.\nThe most accurate, but most expensive, approach is to use an integrating sphere, which is\na large (typically 1m diameter) sphere carefully painted on the inside with white matte paint.\nAn accurately calibrated light at the top controls the amount of radiance inside the sphere\n(which is constant everywhere because of the sphere’s radiometry) and a small opening at the\nside allows for a camera/lens combination to be mounted. By slowly varying the current going\ninto the light, an accurate correspondence can be established between incoming radiance and\n10.1 Photometric calibration\n473\nmeasured pixel values. The vignetting and noise characteristics of the camera can also be\nsimultaneously determined.\nA more practical alternative is to use a calibration chart (Figure 10.3b) such as the Mac-\nbeth or Munsell ColorChecker Chart.8 The biggest problem with this approach is to ensure\nuniform lighting. One approach is to use a large dark room with a high-quality light source\nfar away from (and perpendicular to) the chart. Another is to place the chart outdoors away\nfrom any shadows. (The results will differ under these two conditions, because the color of\nthe illuminant will be different).\nThe easiest approach is probably to take multiple exposures of the same scene while the\ncamera is on a tripod and to recover the response function by simultaneously estimating the\nincoming irradiance at each pixel and the response curve (Mann and Picard 1995; Debevec\nand Malik 1997; Mitsunaga and Nayar 1999). This approach is discussed in more detail in\nSection 10.2 on high dynamic range imaging.\nIf all else fails, i.e., you just have one or more unrelated photos, you can use an Interna-\ntional Color Consortium (ICC) proﬁle for the camera (Fairchild 2005).9 Even more simply,\nyou can just assume that the response is linear if they are RAW ﬁles and that the images have\na γ = 2.2 non-linearity (plus clipping) applied to each RGB channel if they are JPEG images.\n10.1.2 Noise level estimation\nIn addition to knowing the camera response function, it is also often important to know the\namount of noise being injected under a particular camera setting (e.g., ISO/gain level). The\nsimplest characterization of noise is a single standard deviation, usually measured in gray\nlevels, independent of pixel value. A more accurate model can be obtained by estimating\nthe noise level as a function of pixel value (Figure 10.4), which is known as the noise level\nfunction (Liu, Szeliski, Kang et al. 2008).\nAs with the camera response function, the simplest way to estimate these quantities is in\nthe lab, using either an integrating sphere or a calibration chart. The noise can be estimated\neither at each pixel independently, by taking repeated exposures and computing the temporal\nvariance in the measurements (Healey and Kondepudy 1994), or over regions, by assuming\nthat pixel values should all be the same within some region (e.g., inside a color checker\nsquare) and computing a spatial variance.\nThis approach can be generalized to photos where there are regions of constant or slowly\nvarying intensity (Liu, Szeliski, Kang et al. 2008). First, segment the image into such regions\nand ﬁt a constant or linear function inside each region. Next, measure the (spatial) standard\ndeviation of the differences between the noisy input pixels and the smooth ﬁtted function\n8 http://www.xrite.com.\n9 See also the ICC Information on Proﬁles, http://www.color.org/info proﬁles2.xalter.\n474\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.4\nNoise level function estimates obtained from a single color photograph (Liu,\nSzeliski, Kang et al. 2008) c⃝2008 IEEE. The colored curves are the estimated NLF ﬁt as the\nprobabilistic lower envelope of the measured deviations between the noisy piecewise-smooth\nimages. The ground truth NLFs obtained by averaging 29 images are shown in gray.\naway from large gradients and region boundaries. Plot these as a function of output level for\neach color channel, as shown in Figure 10.4. Finally, ﬁt a lower envelope to this distribution\nin order to ignore pixels or deviations that are outliers. A fully Bayesian approach to this\nproblem that models the statistical distribution of each quantity is presented by (Liu, Szeliski,\nKang et al. 2008). A simpler approach, which should produce useful results in most cases,\nis to ﬁt a low-dimensional function (e.g., positive valued B-spline) to the lower envelope (see\nExercise 10.2).\nIn more recent work, Matsushita and Lin (2007) present a technique for simultaneously\nestimating a camera’s response and noise level functions based on skew (asymmetries) in\nlevel-dependent noise distributions. Their paper also contains extensive references to previ-\nous work in these areas.\n10.1.3 Vignetting\nA common problem with using wide-angle and wide-aperture lenses is that the image tends\nto darken in the corners (Figure 10.5a). This problem is generally known as vignetting and\ncomes in several different forms, including natural, optical, and mechanical vignetting (Sec-\ntion 2.2.3) (Ray 2002). As with radiometric response function calibration, the most accurate\nway to calibrate vignetting is to use an integrating sphere or a picture of a uniformly colored\nand illuminated blank wall.\nAn alternative approach is to stitch a panoramic scene and to assume that the true radiance\nat each pixel comes from the central portion of each input image. This is easier to do if\nthe radiometric response function is already known (e.g., by shooting in RAW mode) and\nif the exposure is kept constant. If the response function, image exposures, and vignetting\nfunction are unknown, they can still be recovered by optimizing a large least squares ﬁtting",
  "image_path": "page_495.jpg",
  "pages": [
    494,
    495,
    496
  ]
}