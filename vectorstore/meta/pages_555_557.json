{
  "doc_id": "pages_555_557",
  "text": "Chapter 11\nStereo correspondence\n11.1 Epipolar geometry\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537\n11.1.1 Rectiﬁcation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 538\n11.1.2 Plane sweep . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540\n11.2 Sparse correspondence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543\n11.2.1 3D curves and proﬁles . . . . . . . . . . . . . . . . . . . . . . . . . 543\n11.3 Dense correspondence\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545\n11.3.1 Similarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . 546\n11.4 Local methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 548\n11.4.1 Sub-pixel estimation and uncertainty . . . . . . . . . . . . . . . . . . 550\n11.4.2 Application: Stereo-based head tracking . . . . . . . . . . . . . . . . 551\n11.5 Global optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 552\n11.5.1 Dynamic programming . . . . . . . . . . . . . . . . . . . . . . . . . 554\n11.5.2 Segmentation-based techniques\n. . . . . . . . . . . . . . . . . . . . 556\n11.5.3 Application: Z-keying and background replacement . . . . . . . . . . 558\n11.6 Multi-view stereo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 558\n11.6.1 Volumetric and 3D surface reconstruction . . . . . . . . . . . . . . . 562\n11.6.2 Shape from silhouettes . . . . . . . . . . . . . . . . . . . . . . . . . 567\n11.7 Additional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 570\n11.8 Exercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571\n534\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 11.1\nStereo reconstruction techniques can convert (a–b) a pair of images into (c)\na depth map (http://vision.middlebury.edu/stereo/data/scenes2003/) or (d–e) a sequence of\nimages into (f) a 3D model (http://vision.middlebury.edu/mview/data/). (g) An analytical\nstereo plotter, courtesy of Kenney Aerial Mapping, Inc., can generate (h) contour plots.\n11 Stereo correspondence\n535\nStereo matching is the process of taking two or more images and estimating a 3D model of\nthe scene by ﬁnding matching pixels in the images and converting their 2D positions into\n3D depths. In Chapters 6–7, we described techniques for recovering camera positions and\nbuilding sparse 3D models of scenes or objects. In this chapter, we address the question\nof how to build a more complete 3D model, e.g., a sparse or dense depth map that assigns\nrelative depths to pixels in the input images. We also look at the topic of multi-view stereo\nalgorithms that produce complete 3D volumetric or surface-based object models.\nWhy are people interested in stereo matching? From the earliest inquiries into visual per-\nception, it was known that we perceive depth based on the differences in appearance between\nthe left and right eye.1 As a simple experiment, hold your ﬁnger vertically in front of your\neyes and close each eye alternately. You will notice that the ﬁnger jumps left and right relative\nto the background of the scene. The same phenomenon is visible in the image pair shown in\nFigure 11.1a–b, in which the foreground objects shift left and right relative to the background.\nAs we will shortly see, under simple imaging conﬁgurations (both eyes or cameras look-\ning straight ahead), the amount of horizontal motion or disparity is inversely proportional to\nthe distance from the observer. While the basic physics and geometry relating visual disparity\nto scene structure are well understood (Section 11.1), automatically measuring this disparity\nby establishing dense and accurate inter-image correspondences is a challenging task.\nThe earliest stereo matching algorithms were developed in the ﬁeld of photogrammetry\nfor automatically constructing topographic elevation maps from overlapping aerial images.\nPrior to this, operators would use photogrammetric stereo plotters, which displayed shifted\nversions of such images to each eye and allowed the operator to ﬂoat a dot cursor around con-\nstant elevation contours (Figure 11.1g). The development of fully automated stereo matching\nalgorithms was a major advance in this ﬁeld, enabling much more rapid and less expensive\nprocessing of aerial imagery (Hannah 1974; Hsieh, McKeown, and Perlant 1992).\nIn computer vision, the topic of stereo matching has been one of the most widely stud-\nied and fundamental problems (Marr and Poggio 1976; Barnard and Fischler 1982; Dhond\nand Aggarwal 1989; Scharstein and Szeliski 2002; Brown, Burschka, and Hager 2003; Seitz,\nCurless, Diebel et al. 2006), and continues to be one of the most active research areas. While\nphotogrammetric matching concentrated mainly on aerial imagery, computer vision applica-\ntions include modeling the human visual system (Marr 1982), robotic navigation and manip-\nulation (Moravec 1983; Konolige 1997; Thrun, Montemerlo, Dahlkamp et al. 2006), as well\nas view interpolation and image-based rendering (Figure 11.2a–d), 3D model building (Fig-\nure 11.2e–f and h–j), and mixing live action with computer-generated imagery (Figure 11.2g).\nIn this chapter, we describe the fundamental principles behind stereo matching, following\n1 The word stereo comes from the Greek for solid; stereo vision is how we perceive solid shape (Koenderink\n1990).",
  "image_path": "page_556.jpg",
  "pages": [
    555,
    556,
    557
  ]
}