{
  "doc_id": "pages_703_705",
  "text": "14.2 Face recognition\n681\n(a)\n(b)\n(c)\nFigure 14.21\nActive Appearance Models (Cootes, Edwards, and Taylor 2001) c⃝2001\nIEEE: (a) input image with registered feature points; (b) the feature points (shape vector\ns); (c) the shape-free appearance image (texture vector t).\nas well as the variation in texture t, which is normalized to a canonical shape before being\nanalyzed (Figure 14.21c).15\nBoth shape and texture are represented as deviations from a mean shape ¯s and texture ¯t,\ns\n=\n¯s + U sa\n(14.29)\nt\n=\n¯t + U ta,\n(14.30)\nwhere the eigenvectors in U s and U t have been pre-scaled (whitened) so that unit vectors in\na represent one standard deviation of variation observed in the training data. In addition to\nthese principal deformations, the shape parameters are transformed by a global similarity to\nmatch the location, size, and orientation of a given face. Similarly, the texture image contains\na scale and offset to best match novel illumination conditions.\nAs you can see, the same appearance parameters a in (14.29–14.30) simultaneously con-\ntrol both the shape and texture deformations from the mean, which makes sense if we believe\nthem to be correlated. Figure 14.22 shows how moving three standard deviations along each\nof the ﬁrst four principal directions ends up changing several correlated factors in a person’s\nappearance, including expression, gender, age, and identity.\nIn order to ﬁt an active appearance model to a novel image, Cootes, Edwards, and Taylor\n(2001) pre-compute a set of “difference decomposition” images, using an approach related to\nother fast techniques for incremental tracking, such as those we discussed in Sections 4.1.4,\n8.1.3, and 8.2 (Gleicher 1997; Hager and Belhumeur 1998), which often learn a discrimi-\nnative mapping between matching errors and incremental displacements (Avidan 2001; Jurie\nand Dhome 2002; Liu, Chen, and Kumar 2003; Sclaroff and Isidoro 2003; Romdhani and\nVetter 2003; Williams, Blake, and Cipolla 2003).\n15 When only the shape variation is being captured, such models are called active shape models (ASMs) (Cootes,\nCooper, Taylor et al. 1995; Davies, Twining, and Taylor 2008). These were already discussed in Section 5.1.1\n(5.13–5.17).\n682\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 14.22 Principal modes of variation in active appearance models (Cootes, Edwards,\nand Taylor 2001) c⃝2001 IEEE. The four images show the effects of simultaneously changing\nthe ﬁrst four modes of variation in both shape and texture by ±σ from the mean. You can\nclearly see how the shape of the face and the shading are simultaneously affected.\nIn more detail, Cootes, Edwards, and Taylor (2001) compute the derivatives of a set of\ntraining images with respect to each of the parameters in a using ﬁnite differences and then\ncompute a set of displacement weight images\nW =\n\u0014∂xT\n∂a\n∂x\n∂a\n\u0015−1 ∂xT\n∂a ,\n(14.31)\nwhich can be multiplied by the current error residual to produce an update step in the pa-\nrameters, δa = −W r. Matthews and Baker (2004) use their inverse compositional method,\nwhich they ﬁrst developed for parametric optical ﬂow (8.64–8.65), to further speed up active\nappearance model ﬁtting and tracking. Examples of AAMs being ﬁtted to two input images\nare shown in Figure 14.23.\nAlthough active appearance models are primarily designed to accurately capture the vari-\nability in appearance and deformation that are characteristic of faces, they can be adapted to\nface recognition by computing an identity subspace that separates variation in identity from\nother sources of variability such as lighting, pose, and expression (Costen, Cootes, Edwards\net al. 1999). The basic idea, which is modeled after similar work in eigenfaces (Belhumeur,\nHespanha, and Kriegman 1997; Moghaddam, Jebara, and Pentland 2000), is to compute sep-\narate statistics for intrapersonal and extrapersonal variation and then ﬁnd discriminating di-\nrections in these subspaces. While AAMs have sometimes been used directly for recognition\n(Blanz and Vetter 2003), their main use in the context of recognition is to align faces into\na canonical pose (Liang, Xiao, Wen et al. 2008) so that more traditional methods of face\n14.2 Face recognition\n683\nFigure 14.23\nMultiresolution model ﬁtting (search) in active appearance models (Cootes,\nEdwards, and Taylor 2001) c⃝2001 IEEE. The columns show the initial model, the results\nafter 3, 8, and 11 iterations, and the ﬁnal convergence. The rightmost column shows the input\nimage.\nrecognition (Penev and Atick 1996; Wiskott, Fellous, Kr¨uger et al. 1997; Ahonen, Hadid,\nand Pietik¨ainen 2006; Zhao and Pietik¨ainen 2007; Cao, Yin, Tang et al. 2010) can be used.\nAAMs (or, actually, their simpler version, Active Shape Models (ASMs)) can also be used to\nalign face images to perform automated morphing (Zanella and Fuentes 2004).\nActive appearance models continue to be an active research area, with enhancements to\ndeal with illumination and viewpoint variation (Gross, Baker, Matthews et al. 2005) as well\nas occlusions (Gross, Matthews, and Baker 2006). One of the most signiﬁcant extensions is\nto construct 3D models of shape (Matthews, Xiao, and Baker 2007), which are much better at\ncapturing and explaining the full variability of facial appearance across wide changes in pose.\nFigure 14.24\nHead tracking with 3D AAMs (Matthews, Xiao, and Baker 2007) c⃝2007\nSpringer. Each image shows a video frame along with the estimate yaw, pitch, and roll\nparameters and the ﬁtted 3D deformable mesh.",
  "image_path": "page_704.jpg",
  "pages": [
    703,
    704,
    705
  ]
}