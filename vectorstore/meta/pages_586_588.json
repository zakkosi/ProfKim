{
  "doc_id": "pages_586_588",
  "text": "564\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 11.19\nMulti-view stereo algorithms: (a) surface-based stereo (Fua and Leclerc\n1995); (b) voxel coloring (Seitz and Dyer 1999) c⃝1999 Springer; (c) depth map merg-\ning (Narayanan, Rander, and Kanade 1998); (d) level set evolution (Faugeras and Keriven\n1998) c⃝1998 IEEE; (e) silhouette and stereo fusion (Hernandez and Schmitt 2004) c⃝2004\nElsevier; (f) multi-view image matching (Pons, Keriven, and Faugeras 2005) c⃝2005 IEEE;\n(g) volumetric graph cut (Vogiatzis, Torr, and Cipolla 2005) c⃝2005 IEEE; (h) carved visual\nhulls (Furukawa and Ponce 2009) c⃝2009 Springer.\nular representation (Fua and Leclerc 1995; Narayanan, Rander, and Kanade 1998; Isidoro\nand Sclaroff 2003; Hernandez and Schmitt 2004; Furukawa and Ponce 2009; Hiep, Keriven,\nPons et al. 2009). Meshes are the standard representation used in computer graphics and\nalso readily support the computation of visibility and occlusions. Finally, as we discussed in\nthe previous section, multiple depth maps can also be used (Szeliski 1999; Kolmogorov and\nZabih 2002; Kang and Szeliski 2004). Many algorithms also use more than a single represen-\ntation, e.g., they may start by computing multiple depth maps and then merge them into a 3D\nobject model (Narayanan, Rander, and Kanade 1998; Furukawa and Ponce 2009; Goesele,\nCurless, and Seitz 2006; Goesele, Snavely, Curless et al. 2007; Furukawa, Curless, Seitz et\nal. 2010).\n11.6 Multi-view stereo\n565\nPhotoconsistency measure.\nAs we discussed in (Section 11.3.1), a variety of similarity\nmeasures can be used to compare pixel values in different images, including measures that\ntry to discount illumination effects or be less sensitive to outliers. In multi-view stereo, algo-\nrithms have a choice of computing these measures directly on the surface of the model, i.e., in\nscene space, or projecting pixel values from one image (or from a textured model) back into\nanother image, i.e., in image space. (The latter corresponds more closely to a Bayesian ap-\nproach, since input images are noisy measurements of the colored 3D model.) The geometry\nof the object, i.e., its distance to each camera and its local surface normal, when available, can\nbe used to adjust the matching windows used in the computation to account for foreshortening\nand scale change (Goesele, Snavely, Curless et al. 2007).\nVisibility model.\nA big advantage that multi-view stereo algorithms have over single-depth-\nmap approaches is their ability to reason in a principled manner about visibility and occlu-\nsions. Techniques that use the current state of the 3D model to predict which surface pixels\nare visible in each image (Kutulakos and Seitz 2000; Faugeras and Keriven 1998; Vogiatzis,\nHernandez, Torr et al. 2007; Hiep, Keriven, Pons et al. 2009) are classiﬁed as using geometric\nvisibility models in the taxonomy of Seitz, Curless, Diebel et al. (2006). Techniques that se-\nlect a neighboring subset of image to match are called quasi-geometric (Narayanan, Rander,\nand Kanade 1998; Kang and Szeliski 2004; Hernandez and Schmitt 2004), while techniques\nthat use traditional robust similarity measures are called outlier-based. While full geometric\nreasoning is the most principled and accurate approach, it can be very slow to evaluate and\ndepends on the evolving quality of the current surface estimate to predict visibility, which can\nbe a bit of a chicken-and-egg problem, unless conservative assumptions are used, as they are\nby Kutulakos and Seitz (2000).\nShape priors.\nBecause stereo matching is often underconstrained, especially in texture-\nless regions, most matching algorithms adopt (either explicitly or implicitly) some form of\nprior model for the expected shape. Many of the techniques that rely on optimization use a\n3D smoothness or area-based photoconsistency constraint, which, because of the natural ten-\ndency of smooth surfaces to shrink inwards, often results in a minimal surface prior (Faugeras\nand Keriven 1998; Sinha and Pollefeys 2005; Vogiatzis, Hernandez, Torr et al. 2007). Ap-\nproaches that carve away the volume of space often stop once a photoconsistent solution is\nfound (Seitz and Dyer 1999; Kutulakos and Seitz 2000), which corresponds to a maximal sur-\nface bias, i.e., these techniques tend to over-estimate the true shape. Finally, multiple depth\nmap approaches often adopt traditional image-based smoothness (regularization) constraints.\nReconstruction algorithm.\nThe details of how the actual reconstruction algorithm pro-\nceeds is where the largest variety—and greatest innovation—in multi-view stereo algorithms\n566\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ncan be found.\nSome approaches use global optimization deﬁned over a three-dimensional photoconsis-\ntency volume to recover a complete surface. Approaches based on graph cuts use polynomial\ncomplexity binary segmentation algorithms to recover the object model deﬁned on the voxel\ngrid (Sinha and Pollefeys 2005; Vogiatzis, Hernandez, Torr et al. 2007; Hiep, Keriven, Pons\net al. 2009). Level set approaches use a continuous surface evolution to ﬁnd a good mini-\nmum in the conﬁguration space of potential surfaces and therefore require a reasonably good\ninitialization (Faugeras and Keriven 1998; Pons, Keriven, and Faugeras 2007). In order for\nthe photoconsistency volume to be meaningful, matching costs need to be computed in some\nrobust fashion, e.g., using sets of limited views or by aggregating multiple depth maps.\nAn alternative approach to global optimization is to sweep through the 3D volume while\ncomputing both photoconsistency and visibility simultaneously. The voxel coloring algorithm\nof Seitz and Dyer (1999) performs a front-to-back plane sweep. On every plane, any voxels\nthat are sufﬁciently photoconsistent are labeled as part of the object. The corresponding\npixels in the source images can then be “erased”, since they are already accounted for, and\ntherefore do not contribute to further photoconsistency computations. (A similar approach,\nalbeit without the front-to-back sweep order, is used by Szeliski and Golland (1999).) The\nresulting 3D volume, under noise- and resampling-free conditions, is guaranteed to produce\nboth a photoconsistent 3D model and to enclose whatever true 3D object model generated the\nimages.\nUnfortunately, voxel coloring is only guaranteed to work if all of the cameras lie on the\nsame side of the sweep planes, which is not possible in general ring conﬁgurations of cameras.\nKutulakos and Seitz (2000) generalize voxel coloring to space carving, where subsets of\ncameras that satisfy the voxel coloring constraint are iteratively selected and the 3D voxel\ngrid is alternately carved away along different axes.\nAnother popular approach to multi-view stereo is to ﬁrst independently compute multiple\ndepth maps and then merge these partial maps into a complete 3D model. Approaches to\ndepth map merging, which are discussed in more detail in Section 12.2.1, include signed\ndistance functions (Curless and Levoy 1996), used by Goesele, Curless, and Seitz (2006),\nand Poisson surface reconstruction (Kazhdan, Bolitho, and Hoppe 2006), used by Goesele,\nSnavely, Curless et al. (2007). It is also possible to reconstruct sparser representations, such\nas 3D points and lines, and to interpolate them to full 3D surfaces (Section 12.3.1) (Taylor\n2003).\nInitialization requirements.\nOne ﬁnal element discussed by Seitz, Curless, Diebel et al.\n(2006) is the varying degrees of initialization required by different algorithms. Because some\nalgorithms reﬁne or evolve a rough 3D model, they require a reasonably accurate (or over-\ncomplete) initial model, which can often be obtained by reconstructing a volume from object",
  "image_path": "page_587.jpg",
  "pages": [
    586,
    587,
    588
  ]
}