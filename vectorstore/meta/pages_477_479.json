{
  "doc_id": "pages_477_479",
  "text": "9.3 Compositing\n455\nAgrawala et al. 2004) can sometimes be used to retain multiple copies of a moving object\n(Figure 9.17).\nA better approach to averaging is to weight pixels near the center of the image more\nheavily and to down-weight pixels near the edges. When an image has some cutout regions,\ndown-weighting pixels near the edges of both cutouts and the image is preferable. This can\nbe done by computing a distance map or grassﬁre transform,\nwk(x) = arg min\ny {∥y∥| ˜Ik(x + y) is invalid },\n(9.38)\nwhere each valid pixel is tagged with its Euclidean distance to the nearest invalid pixel (Sec-\ntion 3.3.3). The Euclidean distance map can be efﬁciently computed using a two-pass raster\nalgorithm (Danielsson 1980; Borgefors 1986).\nWeighted averaging with a distance map is often called feathering (Szeliski and Shum\n1997; Chen and Klette 1999; Uyttendaele, Eden, and Szeliski 2001) and does a reasonable job\nof blending over exposure differences. However, blurring and ghosting can still be problems\n(Figure 9.14c). Note that weighted averaging is not the same as compositing the individual\nimages with the classic over operation (Porter and Duff 1984; Blinn 1994a), even when using\nthe weight values (normalized to sum up to one) as alpha (translucency) channels. This is\nbecause the over operation attenuates the values from more distant surfaces and, hence, is not\nequivalent to a direct sum.\nOne way to improve feathering is to raise the distance map values to some large power,\ni.e., to use wp\nk(x) in Equation (9.37). The weighted averages then become dominated by\nthe larger values, i.e., they act somewhat like a p-norm. The resulting composite can often\nprovide a reasonable tradeoff between visible exposure differences and blur (Figure 9.14d).\nIn the limit as p →∞, only the pixel with the maximum weight is selected,\nC(x) = ˜Il(x)(x),\n(9.39)\nwhere\nl = arg max\nk\nwk(x)\n(9.40)\nis the label assignment or pixel selection function that selects which image to use at each\npixel. This hard pixel selection process produces a visibility mask-sensitive variant of the fa-\nmiliar Voronoi diagram, which assigns each pixel to the nearest image center in the set (Wood,\nFinkelstein, Hughes et al. 1997; Peleg, Rousso, Rav-Acha et al. 2000). The resulting com-\nposite, while useful for artistic guidance and in high-overlap panoramas (manifold mosaics)\ntends to have very hard edges with noticeable seams when the exposures vary (Figure 9.14e).\nXiong and Turkowski (1998) use this Voronoi idea (local maximum of the grassﬁre trans-\nform) to select seams for Laplacian pyramid blending (which is discussed below). However,\n456\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 9.15\nComputation of regions of difference (RODs) (Uyttendaele, Eden, and Szeliski\n2001) c⃝2001 IEEE: (a) three overlapping images with a moving face; (b) corresponding\nRODs; (c) graph of coincident RODs.\nsince the seam selection is performed sequentially as new images are added in, some artifacts\ncan occur.\nOptimal seam selection.\nComputing the Voronoi diagram is one way to select the seams\nbetween regions where different images contribute to the ﬁnal composite. However, Voronoi\nimages totally ignore the local image structure underlying the seam.\nA better approach is to place the seams in regions where the images agree, so that tran-\nsitions from one source to another are not visible. In this way, the algorithm avoids “cutting\nthrough” moving objects where a seam would look unnatural (Davis 1998). For a pair of\nimages, this process can be formulated as a simple dynamic program starting from one edge\nof the overlap region and ending at the other (Milgram 1975, 1977; Davis 1998; Efros and\nFreeman 2001).\nWhen multiple images are being composited, the dynamic program idea does not readily\ngeneralize. (For square texture tiles being composited sequentially, Efros and Freeman (2001)\nrun a dynamic program along each of the four tile sides.)\nTo overcome this problem, Uyttendaele, Eden, and Szeliski (2001) observed that, for\nwell-registered images, moving objects produce the most visible artifacts, namely translu-\ncent looking ghosts. Their system therefore decides which objects to keep and which ones\nto erase. First, the algorithm compares all overlapping input image pairs to determine re-\ngions of difference (RODs) where the images disagree. Next, a graph is constructed with the\nRODs as vertices and edges representing ROD pairs that overlap in the ﬁnal composite (Fig-\nure 9.15). Since the presence of an edge indicates an area of disagreement, vertices (regions)\nmust be removed from the ﬁnal composite until no edge spans a pair of remaining vertices.\nThe smallest such set can be computed using a vertex cover algorithm. Since several such\ncovers may exist, a weighted vertex cover is used instead, where the vertex weights are com-\nputed by summing the feather weights in the ROD (Uyttendaele, Eden, and Szeliski 2001).\nThe algorithm therefore prefers removing regions that are near the edge of the image, which\nreduces the likelihood that partially visible objects will appear in the ﬁnal composite. (It is\n9.3 Compositing\n457\nFigure 9.16\nPhotomontage (Agarwala, Dontcheva, Agrawala et al. 2004) c⃝2004 ACM.\nFrom a set of ﬁve source images (of which four are shown on the left), Photomontage quickly\ncreates a composite family portrait in which everyone is smiling and looking at the camera\n(right). Users simply ﬂip through the stack and coarsely draw strokes using the designated\nsource image objective over the people they wish to add to the composite. The user-applied\nstrokes and computed regions (middle) are color-coded by the borders of the source images\non the left.\nalso possible to infer which object in a region of difference is the foreground object by the\n“edginess” (pixel differences) across the ROD boundary, which should be higher when an\nobject is present (Herley 2005).) Once the desired excess regions of difference have been\nremoved, the ﬁnal composite can be created by feathering (Figure 9.14f).\nA different approach to pixel selection and seam placement is described by Agarwala,\nDontcheva, Agrawala et al. (2004). Their system computes the label assignment that opti-\nmizes the sum of two objective functions. The ﬁrst is a per-pixel image objective that deter-\nmines which pixels are likely to produce good composites,\nCD =\nX\nx\nD(x, l(x)),\n(9.41)\nwhere D(x, l) is the data penalty associated with choosing image l at pixel x. In their system,\nusers can select which pixels to use by “painting” over an image with the desired object or\nappearance, which sets D(x, l) to a large value for all labels l other than the one selected\nby the user (Figure 9.16). Alternatively, automated selection criteria can be used, such as\nmaximum likelihood, which prefers pixels that occur repeatedly in the background (for object\nremoval), or minimum likelihood for objects that occur infrequently, i.e., for moving object\nretention. Using a more traditional center-weighted data term tends to favor objects that are\ncentered in the input images (Figure 9.17).\nThe second term is a seam objective that penalizes differences in labelings between adja-\ncent images,\nCS =\nX\n(x,y)∈N\nS(x, y, l(x), l(y)),\n(9.42)",
  "image_path": "page_478.jpg",
  "pages": [
    477,
    478,
    479
  ]
}