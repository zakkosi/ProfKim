{
  "doc_id": "pages_426_428",
  "text": "404\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 8.6\nLearned parameterized motion ﬁelds for a walking sequence (Black, Yacoob,\nJepson et al. 1997) c⃝1997 IEEE: (a) learned basis ﬂow ﬁelds; (b) plots of motion coefﬁcients\nover time and corresponding estimated motion ﬁelds.\nunknown coefﬁcient ak in the parameterized ﬂow ﬁeld\nu(x) =\nX\nk\nakvk(x).\n(8.66)\nFigure 8.6a shows a set of basis ﬁelds learned by observing videos of walking motions.\nFigure 8.6b shows the temporal evolution of the basis coefﬁcients as well as a few of the\nrecovered parametric motion ﬁelds. Note that similar ideas can also be applied to feature\ntracks (Torresani, Hertzmann, and Bregler 2008), which is a topic we discuss in more detail\nin Sections 4.1.4 and 12.6.4.\n8.3 Spline-based motion\nWhile parametric motion models are useful in a wide variety of applications (such as video\nstabilization and mapping onto planar surfaces), most image motion is too complicated to be\ncaptured by such low-dimensional models.\nTraditionally, optical ﬂow algorithms (Section 8.4) compute an independent motion esti-\nmate for each pixel, i.e., the number of ﬂow vectors computed is equal to the number of input\npixels. The general optical ﬂow analog to Equation (8.1) can thus be written as\nESSD−OF({ui}) =\nX\ni\n[I1(xi + ui) −I0(xi)]2.\n(8.67)\n8.3 Spline-based motion\n405\nFigure 8.7 Spline motion ﬁeld: the displacement vectors ui = (ui, vi) are shown as pluses\n(+) and are controlled by the smaller number of control vertices ˆuj = (ˆui, ˆvj), which are\nshown as circles (◦).\nNotice how in the above equation, the number of variables {ui} is twice the number of\nmeasurements, so the problem is underconstrained.\nThe two classic approaches to this problem, which we study in Section 8.4, are to perform\nthe summation over overlapping regions (the patch-based or window-based approach) or to\nadd smoothness terms on the {ui} ﬁeld using regularization or Markov random ﬁelds (Sec-\ntion 3.7). In this section, we describe an alternative approach that lies somewhere between\ngeneral optical ﬂow (independent ﬂow at each pixel) and parametric ﬂow (a small number of\nglobal parameters). The approach is to represent the motion ﬁeld as a two-dimensional spline\ncontrolled by a smaller number of control vertices {ˆuj} (Figure 8.7),\nui =\nX\nj\nˆujBj(xi) =\nX\nj\nˆujwi,j,\n(8.68)\nwhere the Bj(xi) are called the basis functions and are only non-zero over a small ﬁnite sup-\nport interval (Szeliski and Coughlan 1997). We call the wij = Bj(xi) weights to emphasize\nthat the {ui} are known linear combinations of the {ˆuj}. Some commonly used spline basis\nfunctions are shown in Figure 8.8.\nSubstituting the formula for the individual per-pixel ﬂow vectors ui (8.68) into the SSD\nerror metric (8.67) yields a parametric motion formula similar to Equation (8.50). The biggest\ndifference is that the Jacobian J1(x′\ni) (8.52) now consists of the sparse entries in the weight\nmatrix W = [wij].\nIn situations where we know something more about the motion ﬁeld, e.g., when the mo-\ntion is due to a camera moving in a static scene, we can use more specialized motion models.\nFor example, the plane plus parallax model (Section 2.1.5) can be naturally combined with\na spline-based motion representation, where the in-plane motion is represented by a homog-\nraphy (6.19) and the out-of-plane parallax d is represented by a scalar variable at each spline\n406\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 8.8 Sample spline basis functions (Szeliski and Coughlan 1997) c⃝1997 Springer.\nThe block (constant) interpolator/basis corresponds to block-based motion estimation\n(Le Gall 1991). See Section 3.5.1 for more details on spline functions.",
  "image_path": "page_427.jpg",
  "pages": [
    426,
    427,
    428
  ]
}