{
  "doc_id": "pages_297_299",
  "text": "5.1 Active contours\n275\n(a)\n(b)\nFigure 5.5 Active Shape Model (ASM): (a) the effect of varying the ﬁrst four shape param-\neters for a set of faces (Cootes, Taylor, Lanitis et al. 1993) c⃝1993 IEEE; (b) searching for\nthe strongest gradient along the normal to each control point (Cootes, Cooper, Taylor et al.\n1995) c⃝1995 Elsevier.\nexamples (Figure 5.4a) can be described with a mean ¯x and a covariance\nC = 1\nP\nX\np\n(xp −¯x)(xp −¯x)T ,\n(5.14)\nwhere xp are the P training examples. Using eigenvalue analysis (Appendix A.1.2), which is\nalso known as Principal Component Analysis (PCA) (Appendix B.1.1), the covariance matrix\ncan be written as,\nC = Φ diag(λ0 . . . λK−1) ΦT .\n(5.15)\nIn most cases, the likely appearance of the points can be modeled using only a few eigen-\nvectors with the largest eigenvalues. The resulting point distribution model (Cootes, Taylor,\nLanitis et al. 1993; Cootes, Cooper, Taylor et al. 1995) can be written as\nx = ¯x + ˆΦ b,\n(5.16)\nwhere b is an M ≪K element shape parameter vector and ˆΦ are the ﬁrst m columns of Φ.\nTo constrain the shape parameters to reasonable values, we can use a quadratic penalty of the\nform\nEshape = 1\n2bT diag(λ0 . . . λM−1) b =\nX\nm\nb2\nm/2λm.\n(5.17)\nAlternatively, the range of allowable bm values can be limited to some range, e.g., |bm| ≤\n3√λm (Cootes, Cooper, Taylor et al. 1995). Alternative approaches for deriving a set of\nshape vectors are reviewed by Isard and Blake (1998).\n276\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nVarying the individual shape parameters bm over the range −2√λm ≤2√λm can give\na good indication of the expected variation in appearance, as shown in Figure 5.4d. Another\nexample, this time related to face contours, is shown in Figure 5.5a.\nIn order to align a point distribution model with an image, each control point searches\nin a direction normal to the contour to ﬁnd the most likely corresponding image edge point\n(Figure 5.5b). These individual measurements can be combined with priors on the shape\nparameters (and, if desired, position, scale, and orientation parameters) to estimate a new set\nof parameters. The resulting Active Shape Model (ASM) can be iteratively minimized to ﬁt\nimages to non-rigidly deforming objects such as medical images or body parts such as hands\n(Cootes, Cooper, Taylor et al. 1995). The ASM can also be combined with a PCA analysis of\nthe underlying gray-level distribution to create an Active Appearance Model (AAM) (Cootes,\nEdwards, and Taylor 2001), which we discuss in more detail in Section 14.2.2.\n5.1.2 Dynamic snakes and CONDENSATION\nIn many applications of active contours, the object of interest is being tracked from frame\nto frame as it deforms and evolves. In this case, it makes sense to use estimates from the\nprevious frame to predict and constrain the new estimates.\nOne way to do this is to use Kalman ﬁltering, which results in a formulation called Kalman\nsnakes (Terzopoulos and Szeliski 1992; Blake, Curwen, and Zisserman 1993). The Kalman\nﬁlter is based on a linear dynamic model of shape parameter evolution,\nxt = Axt−1 + wt,\n(5.18)\nwhere xt and xt−1 are the current and previous state variables, A is the linear transition\nmatrix, and w is a noise (perturbation) vector, which is often modeled as a Gaussian (Gelb\n1974). The matrices A and the noise covariance can be learned ahead of time by observing\ntypical sequences of the object being tracked (Blake and Isard 1998).\nThe qualitative behavior of the Kalman ﬁlter can be seen in Figure 5.6a. The linear dy-\nnamic model causes a deterministic change (drift) in the previous estimate, while the process\nnoise (perturbation) causes a stochastic diffusion that increases the system entropy (lack of\ncertainty). New measurements from the current frame restore some of the certainty (peaked-\nness) in the updated estimate.\nIn many situations, however, such as when tracking in clutter, a better estimate for the\ncontour can be obtained if we remove the assumptions that the distribution are Gaussian,\nwhich is what the Kalman ﬁlter requires. In this case, a general multi-modal distribution is\npropagated, as shown in Figure 5.6b. In order to model such multi-modal distributions, Isard\nand Blake (1998) introduced the use of particle ﬁltering to the computer vision community.5\n5 Alternatives to modeling multi-modal distributions include mixtures of Gaussians (Bishop 2006) and multiple\n5.1 Active contours\n277\n(a)\n(b)\nFigure 5.6\nProbability density propagation (Isard and Blake 1998) c⃝1998 Springer. At\nthe beginning of each estimation step, the probability density is updated according to the\nlinear dynamic model (deterministic drift) and its certainty is reduced due to process noise\n(stochastic diffusion). New measurements introduce additional information that helps reﬁne\nthe current estimate. (a) The Kalman ﬁlter models the distributions as uni-modal, i.e., using a\nmean and covariance. (b) Some applications require more general multi-modal distributions.",
  "image_path": "page_298.jpg",
  "pages": [
    297,
    298,
    299
  ]
}