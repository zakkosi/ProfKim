{
  "doc_id": "pages_592_594",
  "text": "570\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nviewpoint, by successively intersecting viewing ray segments with the binary silhouettes in\neach image. This not only leads to a fast computation algorithm but also enables fast texturing\nof the recovered model with color values from the input images. This approach can also\nbe combined with high-quality deformable templates to capture and re-animate whole body\nmotion (Vlasic, Baran, Matusik et al. 2008).\n11.7 Additional reading\nThe ﬁeld of stereo correspondence and depth estimation is one of the oldest and most widely\nstudied topics in computer vision. A number of good surveys have been written over the years\n(Marr and Poggio 1976; Barnard and Fischler 1982; Dhond and Aggarwal 1989; Scharstein\nand Szeliski 2002; Brown, Burschka, and Hager 2003; Seitz, Curless, Diebel et al. 2006) and\nthey can serve as good guides to this extensive literature.\nBecause of computational limitations and the desire to ﬁnd appearance-invariant cor-\nrespondences, early algorithms often focused on ﬁnding sparse correspondences (Hannah\n1974; Marr and Poggio 1979; Mayhew and Frisby 1980; Baker and Binford 1981; Arnold\n1983; Grimson 1985; Ohta and Kanade 1985; Bolles, Baker, and Marimont 1987; Matthies,\nKanade, and Szeliski 1989; Hsieh, McKeown, and Perlant 1992; Bolles, Baker, and Hannah\n1993).\nThe topic of computing epipolar geometry and pre-rectifying images is covered in Sec-\ntions 7.2 and 11.1 and is also treated in textbooks on multi-view geometry (Faugeras and\nLuong 2001; Hartley and Zisserman 2004) and articles speciﬁcally on this topic (Torr and\nMurray 1997; Zhang 1998a,b). The concepts of the disparity space and disparity space im-\nage are often associated with the seminal work by Marr (1982) and the papers of Yang, Yuille,\nand Lu (1993) and Intille and Bobick (1994). The plane sweep algorithm was ﬁrst popular-\nized by Collins (1996) and then generalized to a full arbitrary projective setting by Szeliski\nand Golland (1999) and Saito and Kanade (1999). Plane sweeps can also be formulated using\ncylindrical surfaces (Ishiguro, Yamamoto, and Tsuji 1992; Kang and Szeliski 1997; Shum\nand Szeliski 1999; Li, Shum, Tang et al. 2004; Zheng, Kang, Cohen et al. 2007) or even more\ngeneral topologies (Seitz 2001).\nOnce the topology for the cost volume or DSI has been set up, we need to compute the\nactual photoconsistency measures for each pixel and potential depth. A wide range of such\nmeasures have been proposed, as discussed in Section 11.3.1. Some of these are compared in\nrecent surveys and evaluations of matching costs (Scharstein and Szeliski 2002; Hirschm¨uller\nand Scharstein 2009).\nTo compute an actual depth map from these costs, some form of optimization or selection\ncriterion must be used. The simplest of these are sliding windows of various kinds, which\n11.8 Exercises\n571\nare discussed in Section 11.4 and surveyed by Gong, Yang, Wang et al. (2007) and Tombari,\nMattoccia, Di Stefano et al. (2008). More commonly, global optimization frameworks are\nused to compute the best disparity ﬁeld, as described in Section 11.5. These techniques\ninclude dynamic programming and truly global optimization algorithms, such as graph cuts\nand loopy belief propagation. Because the literature on this is so extensive, it is described in\nmore detail in Section 11.5. A good place to ﬁnd pointers to the latest results in this ﬁeld is\nthe Middlebury Stereo Vision Page at http://vision.middlebury.edu/stereo.\nAlgorithms for multi-view stereo typically fall into two categories. The ﬁrst include al-\ngorithms that compute traditional depth maps using several images for computing photocon-\nsistency measures (Okutomi and Kanade 1993; Kang, Webb, Zitnick et al. 1995; Nakamura,\nMatsuura, Satoh et al. 1996; Szeliski and Golland 1999; Kang, Szeliski, and Chai 2001;\nVaish, Szeliski, Zitnick et al. 2006; Gallup, Frahm, Mordohai et al. 2008). Optionally, some\nof these techniques compute multiple depth maps and use additional constraints to encourage\nthe different depth maps to be consistent (Szeliski 1999; Kolmogorov and Zabih 2002; Kang\nand Szeliski 2004; Maitre, Shinagawa, and Do 2008; Zhang, Jia, Wong et al. 2008).\nThe second category consists of papers that compute true 3D volumetric or surface-based\nobject models. Again, because of the large number of papers published on this topic, rather\nthan citing them here, we refer you to the material in Section 11.6.1, the survey by Seitz,\nCurless, Diebel et al. (2006), and the on-line evaluation Web site at http://vision.middlebury.\nedu/mview/.\n11.8 Exercises\nEx 11.1: Stereo pair rectiﬁcation\nImplement the following simple algorithm (Section 11.1.1):\n1. Rotate both cameras so that they are looking perpendicular to the line joining the two\ncamera centers c0 and c1. The smallest rotation can be computed from the cross prod-\nuct between the original and desired optical axes.\n2. Twist the optical axes so that the horizontal axis of each camera looks in the direction\nof the other camera. (Again, the cross product between the current x-axis after the ﬁrst\nrotation and the line joining the cameras gives the rotation.)\n3. If needed, scale up the smaller (less detailed) image so that it has the same resolution\n(and hence line-to-line correspondence) as the other image.\nNow compare your results to the algorithm proposed by Loop and Zhang (1999). Can you\nthink of situations where their approach may be preferable?\n572\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 11.2: Rigid direct alignment\nModify your spline-based or optical ﬂow motion estima-\ntor from Exercise 8.4 to use epipolar geometry, i.e. to only estimate disparity.\n(Optional) Extend your algorithm to simultaneously estimate the epipolar geometry (with-\nout ﬁrst using point correspondences) by estimating a base homography corresponding to a\nreference plane for the dominant motion and then an epipole for the residual parallax (mo-\ntion).\nEx 11.3: Shape from proﬁles\nReconstruct a surface model from a series of edge images\n(Section 11.2.1).\n1. Extract edges and link them (Exercises 4.7–4.8).\n2. Based on previously computed epipolar geometry, match up edges in triplets (or longer\nsets) of images.\n3. Reconstruct the 3D locations of the curves using osculating circles (11.5).\n4. Render the resulting 3D surface model as a sparse mesh, i.e., drawing the reconstructed\n3D proﬁle curves and links between 3D points in neighboring images with similar\nosculating circles.\nEx 11.4: Plane sweep\nImplement a plane sweep algorithm (Section 11.1.2).\nIf the images are already pre-rectiﬁed, this consists simply of shifting images relative to\neach other and comparing pixels. If the images are not pre-rectiﬁed, compute the homography\nthat resamples the target image into the reference image’s coordinate system for each plane.\nEvaluate a subset of the following similarity measures (Section 11.3.1) and compare their\nperformance by visualizing the disparity space image (DSI), which should be dark for pixels\nat correct depths:\n• squared difference (SD);\n• absolute difference (AD);\n• truncated or robust measures;\n• gradient differences;\n• rank or census transform (the latter usually performs better);\n• mutual information from a pre-computed joint density function.\nConsider using the Birchﬁeld and Tomasi (1998) technique of comparing ranges between\nneighboring pixels (different shifted or warped images). Also, try pre-compensating images\nfor bias or gain variations using one or more of the techniques discussed in Section 11.3.1.",
  "image_path": "page_593.jpg",
  "pages": [
    592,
    593,
    594
  ]
}