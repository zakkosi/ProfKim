{
  "doc_id": "pages_510_512",
  "text": "488\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\nFigure 10.20\nGlobal tone mapping: (a) input HDR image, linearly mapped; (b) gamma\napplied to each color channel independently; (c) gamma applied to intensity (colors are\nless washed out). Original HDR image courtesy of Paul Debevec, http://ict.debevec.org/\n∼debevec/Research/HDR/. Processed images courtesy of Fr´edo Durand, MIT 6.815/6.865\ncourse on Computational Photography.\ninto a displayable gamut. If gamma is applied separately to each channel (Figure 10.20b), the\ncolors become muted (less saturated), since higher-valued color channels contribute less (pro-\nportionately) to the ﬁnal color. Splitting the image up into its luminance and chrominance\n(say, L*a*b*) components (Section 2.3.2), applying the global mapping to the luminance\nchannel, and then reconstituting a color image works better (Figure 10.20c).\nUnfortunately, when the image has a really wide range of exposures, this global approach\nstill fails to preserve details in regions with widely varying exposures. What is needed, in-\nstead, is something akin to the dodging and burning performed by photographers in the dark-\nroom. Mathematically, this is similar to dividing each pixel by the average brightness in a\nregion around that pixel.\nFigure 10.21 shows how this process works. As before, the image is split into its lumi-\nnance and chrominance channels. The log luminance image\nH(x, y) = log L(x, y)\n(10.12)\nis then low-pass ﬁltered to produce a base layer\nHL(x, y) = B(x, y) ∗H(x, y),\n(10.13)\nand a high-pass detail layer\nHH(x, y) = H(x, y) −HL(x, y).\n(10.14)\nThe base layer is then contrast reduced by scaling to the desired log-luminance range,\nH′\nH(x, y) = s HH(x, y)\n(10.15)\n10.2 High dynamic range imaging\n489\nand added to the detail layer to produce the new log-luminance image\nI(x, y) = H′\nH(x, y) + HL(x, y),\n(10.16)\nwhich can then be exponentiated to produce the tone-mapped (compressed) luminance im-\nage. Note that this process is equivalent to dividing each luminance value by (a monotonic\nmapping of) the average log-luminance value in a region around that pixel.\nFigure 10.21 shows the low-pass and high-pass log luminance image and the resulting\ntone-mapped color image. Note how the detail layer has visible halos around the high-\ncontrast edges, which are visible in the ﬁnal tone-mapped image. This is because linear\nﬁltering, which is not edge preserving, produces halos in the detail layer (Figure 10.23).\nThe solution to this problem is to use an edge-preserving ﬁlter to create the base layer. Du-\nrand and Dorsey (2002) study a number of such edge-preserving ﬁlters, including anisotropic\nand robust anisotropic diffusion, and select bilateral ﬁltering (Section 3.3.1) as their edge-\npreserving ﬁlter. (A more recent paper by Farbman, Fattal, Lischinski et al. (2008) argues\nin favor of using a weighted least squares (WLF) ﬁlter as an alternative to the bilateral ﬁlter\nand Paris, Kornprobst, Tumblin et al. (2008) reviews bilateral ﬁltering and its applications\nin computer vision and computational photography.) Figure 10.22 shows how replacing the\nlinear low-pass ﬁlter with a bilateral ﬁlter produces tone-mapped images with no visible ha-\nlos. Figure 10.24 summarizes the complete information ﬂow in this process, starting with\nthe decomposition into log luminance and chrominance images, bilateral ﬁltering, contrast\nreduction, and re-composition into the ﬁnal output image.\nAn alternative to compressing the base layer is to compress its derivatives, i.e., the gra-\ndient of the log-luminance image (Fattal, Lischinski, and Werman 2002). Figure 10.25 illus-\ntrates this process. The log-luminance image is differentiated to obtain a gradient image\nH′(x, y) = ∇H(x, y).\n(10.17)\nThis gradient image is then attenuated by a spatially varying attenuation function Φ(x, y),\nG(x, y) = H′(x, y) Φ(x, y).\n(10.18)\nThe attenuation function I(x, y) is designed to attenuate large-scale brightness changes (Fig-\nure 10.26a) and is designed to take into account gradients at different spatial scales (Fattal,\nLischinski, and Werman 2002).\nAfter attenuation, the resulting gradient ﬁeld is re-integrated by solving a ﬁrst-order vari-\national (least squares) problem,\nmin\nZ Z\n∥∇I(x, y) −G(x, y)∥2dx dy\n(10.19)\n490\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 10.21 Local tone mapping using linear ﬁlters: (a) low-pass and high-pass ﬁltered log\nluminance images and color (chrominance) image; (b) resulting tone-mapped image (after at-\ntenuating the low-pass log luminance image) shows visible halos around the trees. Processed\nimages courtesy of Fr´edo Durand, MIT 6.815/6.865 course on Computational Photography.\n(a)\n(b)\nFigure 10.22 Local tone mapping using bilateral ﬁlter (Durand and Dorsey 2002): (a) low-\npass and high-pass bilateral ﬁltered log luminance images and color (chrominance) image;\n(b) resulting tone-mapped image (after attenuating the low-pass log luminance image) shows\nno halos. Processed images courtesy of Fr´edo Durand, MIT 6.815/6.865 course on Compu-\ntational Photography.",
  "image_path": "page_511.jpg",
  "pages": [
    510,
    511,
    512
  ]
}