{
  "doc_id": "pages_153_155",
  "text": "3.3 More neighborhood operators\n131\n(a)\n(b)\n(c)\nFigure 3.23 Connected component computation: (a) original grayscale image; (b) horizontal\nruns (nodes) connected by vertical (graph) edges (dashed blue)—runs are pseudocolored with\nunique colors inherited from parent nodes; (c) re-coloring after merging adjacent segments.\n1993; Szeliski and Lavall´ee 1996; Curless and Levoy 1996), especially if the vectorial version\nof the distance transform, i.e., a pointer from each pixel or voxel to the nearest boundary or\nsurface element, is stored and interpolated. Signed distance ﬁelds are also an essential com-\nponent of level set evolution (Section 5.1.4), where they are called characteristic functions.\n3.3.4 Connected components\nAnother useful semi-global image operation is ﬁnding connected components, which are de-\nﬁned as regions of adjacent pixels that have the same input value (or label). (In the remainder\nof this section, consider pixels to be adjacent if they are immediate N4 neighbors and they\nhave the same input value.) Connected components can be used in a variety of applications,\nsuch as ﬁnding individual letters in a scanned document or ﬁnding objects (say, cells) in a\nthresholded image and computing their area statistics.\nConsider the grayscale image in Figure 3.23a. There are four connected components in\nthis ﬁgure: the outermost set of white pixels, the large ring of gray pixels, the white enclosed\nregion, and the single gray pixel. These are shown pseudocolored in Figure 3.23c as pink,\ngreen, blue, and brown.\nTo compute the connected components of an image, we ﬁrst (conceptually) split the image\ninto horizontal runs of adjacent pixels, and then color the runs with unique labels, re-using\nthe labels of vertically adjacent runs whenever possible. In a second phase, adjacent runs of\ndifferent colors are then merged.\nWhile this description is a little sketchy, it should be enough to enable a motivated stu-\ndent to implement this algorithm (Exercise 3.14). Haralick and Shapiro (1992, Section 2.3)\ngive a much longer description of various connected component algorithms, including ones\n132\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nthat avoid the creation of a potentially large re-coloring (equivalence) table. Well-debugged\nconnected component algorithms are also available in most image processing libraries.\nOnce a binary or multi-valued image has been segmented into its connected components,\nit is often useful to compute the area statistics for each individual region R. Such statistics\ninclude:\n• the area (number of pixels);\n• the perimeter (number of boundary pixels);\n• the centroid (average x and y values);\n• the second moments,\nM =\nX\n(x,y)∈R\n\"\nx −x\ny −y\n# h\nx −x\ny −y\ni\n,\n(3.46)\nfrom which the major and minor axis orientation and lengths can be computed using\neigenvalue analysis.7\nThese statistics can then be used for further processing, e.g., for sorting the regions by the area\nsize (to consider the largest regions ﬁrst) or for preliminary matching of regions in different\nimages.\n3.4 Fourier transforms\nIn Section 3.2, we mentioned that Fourier analysis could be used to analyze the frequency\ncharacteristics of various ﬁlters. In this section, we explain both how Fourier analysis lets us\ndetermine these characteristics (or equivalently, the frequency content of an image) and how\nusing the Fast Fourier Transform (FFT) lets us perform large-kernel convolutions in time that\nis independent of the kernel’s size. More comprehensive introductions to Fourier transforms\nare provided by Bracewell (1986); Glassner (1995); Oppenheim and Schafer (1996); Oppen-\nheim, Schafer, and Buck (1999).\nHow can we analyze what a given ﬁlter does to high, medium, and low frequencies? The\nanswer is to simply pass a sinusoid of known frequency through the ﬁlter and to observe by\nhow much it is attenuated. Let\ns(x) = sin(2πfx + φi) = sin(ωx + φi)\n(3.47)\n7 Moments can also be computed using Green’s theorem applied to the boundary pixels (Yang and Albregtsen\n1996).\n3.4 Fourier transforms\n133\ns(x)\no(x)\nh(x)\ns\no\nx\nx\nA\nφ\nFigure 3.24\nThe Fourier Transform as the response of a ﬁlter h(x) to an input sinusoid\ns(x) = ejωx yielding an output sinusoid o(x) = h(x) ∗s(x) = Aejωx+φ.\nbe the input sinusoid whose frequency is f, angular frequency is ω = 2πf, and phase is φi.\nNote that in this section, we use the variables x and y to denote the spatial coordinates of an\nimage, rather than i and j as in the previous sections. This is both because the letters i and j\nare used for the imaginary number (the usage depends on whether you are reading complex\nvariables or electrical engineering literature) and because it is clearer how to distinguish the\nhorizontal (x) and vertical (y) components in frequency space. In this section, we use the\nletter j for the imaginary number, since that is the form more commonly found in the signal\nprocessing literature (Bracewell 1986; Oppenheim and Schafer 1996; Oppenheim, Schafer,\nand Buck 1999).\nIf we convolve the sinusoidal signal s(x) with a ﬁlter whose impulse response is h(x),\nwe get another sinusoid of the same frequency but different magnitude A and phase φo,\no(x) = h(x) ∗s(x) = A sin(ωx + φo),\n(3.48)\nas shown in Figure 3.24. To see that this is the case, remember that a convolution can be\nexpressed as a weighted summation of shifted input signals (3.14) and that the summation of\na bunch of shifted sinusoids of the same frequency is just a single sinusoid at that frequency.8\nThe new magnitude A is called the gain or magnitude of the ﬁlter, while the phase difference\n∆φ = φo −φi is called the shift or phase.\nIn fact, a more compact notation is to use the complex-valued sinusoid\ns(x) = ejωx = cos ωx + j sin ωx.\n(3.49)\nIn that case, we can simply write,\no(x) = h(x) ∗s(x) = Aejωx+φ.\n(3.50)\n8 If h is a general (non-linear) transform, additional harmonic frequencies are introduced. This was traditionally\nthe bane of audiophiles, who insisted on equipment with no harmonic distortion. Now that digital audio has intro-\nduced pure distortion-free sound, some audiophiles are buying retro tube ampliﬁers or digital signal processors that\nsimulate such distortions because of their “warmer sound”.",
  "image_path": "page_154.jpg",
  "pages": [
    153,
    154,
    155
  ]
}