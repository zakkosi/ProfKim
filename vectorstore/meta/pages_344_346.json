{
  "doc_id": "pages_344_346",
  "text": "322\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n6.2.1 Linear algorithms\nThe simplest way to recover the pose of the camera is to form a set of linear equations analo-\ngous to those used for 2D motion estimation (6.19) from the camera matrix form of perspec-\ntive projection (2.55–2.56),\nxi\n=\np00Xi + p01Yi + p02Zi + p03\np20Xi + p21Yi + p22Zi + p23\n(6.33)\nyi\n=\np10Xi + p11Yi + p12Zi + p13\np20Xi + p21Yi + p22Zi + p23\n,\n(6.34)\nwhere (xi, yi) are the measured 2D feature locations and (Xi, Yi, Zi) are the known 3D\nfeature locations (Figure 6.4). As with (6.21), this system of equations can be solved in a\nlinear fashion for the unknowns in the camera matrix P by multiplying the denominator on\nboth sides of the equation.9 The resulting algorithm is called the direct linear transform\n(DLT) and is commonly attributed to Sutherland (1974). (For a more in-depth discussion,\nrefer to the work of Hartley and Zisserman (2004).) In order to compute the 12 (or 11)\nunknowns in P , at least six correspondences between 3D and 2D locations must be known.\nAs with the case of estimating homographies (6.21–6.23), more accurate results for the\nentries in P can be obtained by directly minimizing the set of Equations (6.33–6.34) using\nnon-linear least squares with a small number of iterations.\nOnce the entries in P have been recovered, it is possible to recover both the intrinsic\ncalibration matrix K and the rigid transformation (R, t) by observing from Equation (2.56)\nthat\nP = K[R|t].\n(6.35)\nSince K is by convention upper-triangular (see the discussion in Section 2.1.5), both K and\nR can be obtained from the front 3 × 3 sub-matrix of P using RQ factorization (Golub and\nVan Loan 1996).10\nIn most applications, however, we have some prior knowledge about the intrinsic cali-\nbration matrix K, e.g., that the pixels are square, the skew is very small, and the optical\ncenter is near the center of the image (2.57–2.59). Such constraints can be incorporated into\na non-linear minimization of the parameters in K and (R, t), as described in Section 6.2.2.\nIn the case where the camera is already calibrated, i.e., the matrix K is known (Sec-\ntion 6.3), we can perform pose estimation using as few as three points (Fischler and Bolles\n1981; Haralick, Lee, Ottenberg et al. 1994; Quan and Lan 1999). The basic observation that\nthese linear PnP (perspective n-point) algorithms employ is that the visual angle between any\n9 Because P is unknown up to a scale, we can either ﬁx one of the entries, e.g., p23 = 1, or ﬁnd the smallest\nsingular vector of the set of linear equations.\n10 Note the unfortunate clash of terminologies: In matrix algebra textbooks, R represents an upper-triangular\nmatrix; in computer vision, R is an orthogonal rotation.\n6.2 Pose estimation\n323\npi = (Xi,Yi,Zi,Wi)\nxi\npj\ndij\ndi\ndj\nxj\nθij\nc\nFigure 6.4\nPose estimation by the direct linear transform and by measuring visual angles\nand distances between pairs of points.\npair of 2D points ˆxi and ˆxj must be the same as the angle between their corresponding 3D\npoints pi and pj (Figure 6.4).\nGiven a set of corresponding 2D and 3D points {(ˆxi, pi)}, where the ˆxi are unit directions\nobtained by transforming 2D pixel measurements xi to unit norm 3D directions ˆxi through\nthe inverse calibration matrix K,\nˆxi = N(K−1xi) = K−1xi/∥K−1xi∥,\n(6.36)\nthe unknowns are the distances di from the camera origin c to the 3D points pi, where\npi = diˆxi + c\n(6.37)\n(Figure 6.4). The cosine law for triangle ∆(c, pi, pj) gives us\nfij(di, dj) = d2\ni + d2\nj −2didjcij −d2\nij = 0,\n(6.38)\nwhere\ncij = cos θij = ˆxi · ˆxj\n(6.39)\nand\nd2\nij = ∥pi −pj∥2.\n(6.40)\nWe can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using\nSylvester resultants (Cox, Little, and O’Shea 2007) to obtain a quartic equation in d2\ni ,\ngijk(d2\ni ) = a4d8\ni + a3d6\ni + a2d4\ni + a1d2\ni + a0 = 0.\n(6.41)\nGiven ﬁve or more correspondences, we can generate (n−1)(n−2)\n2\ntriplets to obtain a linear\nestimate (using SVD) for the values of (d8\ni , d6\ni , d4\ni , d2\ni ) (Quan and Lan 1999). Estimates for\n324\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nd2\ni can computed as ratios of successive d2n+2\ni\n/d2n\ni\nestimates and these can be averaged to\nobtain a ﬁnal estimate of d2\ni (and hence di).\nOnce the individual estimates of the di distances have been computed, we can generate\na 3D structure consisting of the scaled point directions diˆxi, which can then be aligned with\nthe 3D point cloud {pi} using absolute orientation (Section 6.1.5) to obtained the desired\npose estimate. Quan and Lan (1999) give accuracy results for this and other techniques,\nwhich use fewer points but require more complicated algebraic manipulations. The paper by\nMoreno-Noguer, Lepetit, and Fua (2007) reviews more recent alternatives and also gives a\nlower complexity algorithm that typically produces more accurate results.\nUnfortunately, because minimal PnP solutions can be quite noise sensitive and also suffer\nfrom bas-relief ambiguities (e.g., depth reversals) (Section 7.4.3), it is often preferable to use\nthe linear six-point algorithm to guess an initial pose and then optimize this estimate using\nthe iterative technique described in Section 6.2.2.\nAn alternative pose estimation algorithm involves starting with a scaled orthographic pro-\njection model and then iteratively reﬁning this initial estimate using a more accurate perspec-\ntive projection model (DeMenthon and Davis 1995). The attraction of this model, as stated\nin the paper’s title, is that it can be implemented “in 25 lines of [Mathematica] code”.\n6.2.2 Iterative algorithms\nThe most accurate (and ﬂexible) way to estimate pose is to directly minimize the squared (or\nrobust) reprojection error for the 2D points as a function of the unknown pose parameters in\n(R, t) and optionally K using non-linear least squares (Tsai 1987; Bogart 1991; Gleicher\nand Witkin 1992). We can write the projection equations as\nxi = f(pi; R, t, K)\n(6.42)\nand iteratively minimize the robustiﬁed linearized reprojection errors\nENLP =\nX\ni\nρ\n\u0012 ∂f\n∂R∆R + ∂f\n∂t ∆t + ∂f\n∂K ∆K −ri\n\u0013\n,\n(6.43)\nwhere ri = ˜xi −ˆxi is the current residual vector (2D error in predicted position) and the\npartial derivatives are with respect to the unknown pose parameters (rotation, translation, and\noptionally calibration). Note that if full 2D covariance estimates are available for the 2D\nfeature locations, the above squared norm can be weighted by the inverse point covariance\nmatrix, as in Equation (6.11).\nAn easier to understand (and implement) version of the above non-linear regression prob-\nlem can be constructed by re-writing the projection equations as a concatenation of simpler\nsteps, each of which transforms a 4D homogeneous coordinate pi by a simple transformation",
  "image_path": "page_345.jpg",
  "pages": [
    344,
    345,
    346
  ]
}