{
  "doc_id": "pages_579_581",
  "text": "11.5 Global optimization\n557\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 11.12 Segmentation-based stereo matching (Zitnick, Kang, Uyttendaele et al. 2004)\nc⃝2004 ACM: (a) input color image; (b) color-based segmentation; (c) initial disparity es-\ntimates; (d) ﬁnal piecewise-smoothed disparities; (e) MRF neighborhood deﬁned over the\nsegments in the disparity space distribution (Zitnick and Kang 2007) c⃝2007 Springer.\n(a)\n(b)\nFigure 11.13\nStereo matching with adaptive over-segmentation and matting (Taguchi,\nWilburn, and Zitnick 2008) c⃝2008 IEEE: (a) segment boundaries are reﬁned during the\noptimization, leading to more accurate results (e.g., the thin green leaf in the bottom row); (b)\nalpha mattes are extracted at segment boundaries, which leads to visually better compositing\nresults (middle column).\nmore recent work of Zitnick and Kang (2007)) is used to adjust the disparity estimates for\neach segment, as shown in Figure 11.12. Taguchi, Wilburn, and Zitnick (2008) reﬁne the\nsegment shapes as part of the optimization process, which leads to much improved results, as\nshown in Figure 11.13.\nEven more accurate results are obtained by Klaus, Sormann, and Karner (2006), who ﬁrst\nsegment the reference image using mean shift, run a small (3 × 3) SAD plus gradient SAD\n(weighted by cross-checking) to get initial disparity estimates, ﬁt local planes, re-ﬁt with\nglobal planes, and then run a ﬁnal MRF on plane assignments with loopy belief propagation.\nWhen the algorithm was ﬁrst introduced in 2006, it was the top ranked algorithm on the\nevaluation site at http://vision.middlebury.edu/stereo; in early 2010, it still had the top rank\non the new evaluation datasets.\nThe highest ranked algorithm, by Wang and Zheng (2008), follows a similar approach of\nsegmenting the image, doing local plane ﬁts, and then performing cooperative optimization\n558\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nof neighboring plane ﬁt parameters. Another highly ranked algorithm, by Yang, Wang, Yang\net al. (2009), uses the color correlation approach of Yoon and Kweon (2006) and hierarchical\nbelief propagation to obtain an initial set of disparity estimates. After left–right consistency\nchecking to detect occluded pixels, the data terms for low-conﬁdence and occluded pixels\nare recomputed using segmentation-based plane ﬁts and one or more rounds of hierarchical\nbelief propagation are used to obtain the ﬁnal disparity estimates.\nAnother important ability of segmentation-based stereo algorithms, which they share with\nalgorithms that use explicit layers (Baker, Szeliski, and Anandan 1998; Szeliski and Golland\n1999) or boundary extraction (Hasinoff, Kang, and Szeliski 2006), is the ability to extract\nfractional pixel alpha mattes at depth discontinuities (Bleyer, Gelautz, Rother et al. 2009).\nThis ability is crucial when attempting to create virtual view interpolation without clinging\nboundary or tearing artifacts (Zitnick, Kang, Uyttendaele et al. 2004) and also to seamlessly\ninsert virtual objects (Taguchi, Wilburn, and Zitnick 2008), as shown in Figure 11.13b.\nSince new stereo matching algorithms continue to be introduced every year, it is a good\nidea to periodically check the Middlebury evaluation site at http://vision.middlebury.edu/\nstereo for a listing of the most recent algorithms to be evaluated.\n11.5.3 Application: Z-keying and background replacement\nAnother application of real-time stereo matching is z-keying, which is the process of seg-\nmenting a foreground actor from the background using depth information, usually for the\npurpose of replacing the background with some computer-generated imagery, as shown in\nFigure 11.2g.\nOriginally, z-keying systems required expensive custom-built hardware to produce the\ndesired depth maps in real time and were, therefore, restricted to broadcast studio applica-\ntions (Kanade, Yoshida, Oda et al. 1996; Iddan and Yahav 2001). Off-line systems were also\ndeveloped for estimating 3D multi-viewpoint geometry from video streams (Section 13.5.4)\n(Kanade, Rander, and Narayanan 1997; Carranza, Theobalt, Magnor et al. 2003; Zitnick,\nKang, Uyttendaele et al. 2004; Vedula, Baker, and Kanade 2005). Recent advances in highly\naccurate real-time stereo matching, however, now make it possible to perform z-keying on\nregular PCs, enabling desktop videoconferencing applications such as those shown in Fig-\nure 11.14 (Kolmogorov, Criminisi, Blake et al. 2006).\n11.6 Multi-view stereo\nWhile matching pairs of images is a useful way of obtaining depth information, matching\nmore images can lead to even better results. In this section, we review not only techniques for\n11.6 Multi-view stereo\n559\nFigure 11.14\nBackground replacement using z-keying with a bi-layer segmentation algo-\nrithm (Kolmogorov, Criminisi, Blake et al. 2006) c⃝2006 IEEE.\ncreating complete 3D object models, but also simpler techniques for improving the quality of\ndepth maps using multiple source images.\nAs we saw in our discussion of plane sweep (Section 11.1.2), it is possible to resample\nall neighboring k images at each disparity hypothesis d into a generalized disparity space\nvolume ˜I(x, y, d, k). The simplest way to take advantage of these additional images is to sum\nup their differences from the reference image Ir as in (11.4),\nC(x, y, d) =\nX\nk\nρ(˜I(x, y, d, k) −Ir(x, y)).\n(11.15)\nThis is the basis of the well-known sum of summed-squared-difference (SSSD) and SSAD\napproaches (Okutomi and Kanade 1993; Kang, Webb, Zitnick et al. 1995), which can be ex-\ntended to reason about likely patterns of occlusion (Nakamura, Matsuura, Satoh et al. 1996).\nMore recent work by Gallup, Frahm, Mordohai et al. (2008) show how to adapt the base-\nlines used to the expected depth in order to get the best tradeoff between geometric accuracy\n(wide baseline) and robustness to occlusion (narrow baseline). Alternative multi-view cost\nmetrics include measures such as synthetic focus sharpness and the entropy of the pixel color\ndistribution (Vaish, Szeliski, Zitnick et al. 2006).\nA useful way to visualize the multi-frame stereo estimation problem is to examine the\nepipolar plane image (EPI) formed by stacking corresponding scanlines from all the images,\nas shown in Figures 8.13c and 11.15 (Bolles, Baker, and Marimont 1987; Baker and Bolles\n1989; Baker 1989). As you can see in Figure 11.15, as a camera translates horizontally (in a\nstandard horizontally rectiﬁed geometry), objects at different depths move sideways at a rate\ninversely proportional to their depth (11.1).6 Foreground objects occlude background objects,\nwhich can be seen as EPI-strips (Criminisi, Kang, Swaminathan et al. 2005) occluding other\n6 The four-dimensional generalization of the EPI is the light ﬁeld, which we study in Section 13.3. In principle,",
  "image_path": "page_580.jpg",
  "pages": [
    579,
    580,
    581
  ]
}