{
  "doc_id": "pages_132_134",
  "text": "110\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nt\ns\nt\ns\n(a)\n(b)\nFigure 3.9 Local histogram interpolation using relative (s, t) coordinates: (a) block-based\nhistograms, with block centers shown as circles; (b) corner-based “spline” histograms. Pixels\nare located on grid intersections. The black square pixel’s transfer function is interpolated\nfrom the four adjacent lookup tables (gray arrows) using the computed (s, t) values. Block\nboundaries are shown as dashed lines.\nblocks. This technique is known as adaptive histogram equalization (AHE) and its contrast-\nlimited (gain-limited) version is known as CLAHE (Pizer, Amburn, Austin et al. 1987).3 The\nweighting function for a given pixel (i, j) can be computed as a function of its horizontal\nand vertical position (s, t) within a block, as shown in Figure 3.9a. To blend the four lookup\nfunctions {f00, . . . , f11}, a bilinear blending function,\nfs,t(I) = (1 −s)(1 −t)f00(I) + s(1 −t)f10(I) + (1 −s)tf01(I) + stf11(I)\n(3.10)\ncan be used. (See Section 3.5.2 for higher-order generalizations of such spline functions.)\nNote that instead of blending the four lookup tables for each output pixel (which would be\nquite slow), we can instead blend the results of mapping a given pixel through the four neigh-\nboring lookups.\nA variant on this algorithm is to place the lookup tables at the corners of each M × M\nblock (see Figure 3.9b and Exercise 3.7). In addition to blending four lookups to compute the\nﬁnal value, we can also distribute each input pixel into four adjacent lookup tables during the\nhistogram accumulation phase (notice that the gray arrows in Figure 3.9b point both ways),\ni.e.,\nhk,l(I(i, j)) += w(i, j, k, l),\n(3.11)\nwhere w(i, j, k, l) is the bilinear weighting function between pixel (i, j) and lookup table\n(k, l). This is an example of soft histogramming, which is used in a variety of other applica-\n3This algorithm is implemented in the MATLAB adapthist function.\n3.2 Linear ﬁltering\n111\ntions, including the construction of SIFT feature descriptors (Section 4.1.3) and vocabulary\ntrees (Section 14.3.2).\n3.1.5 Application: Tonal adjustment\nOne of the most widely used applications of point-wise image processing operators is the\nmanipulation of contrast or tone in photographs, to make them look either more attractive or\nmore interpretable. You can get a good sense of the range of operations possible by opening\nup any photo manipulation tool and trying out a variety of contrast, brightness, and color\nmanipulation options, as shown in Figures 3.2 and 3.7.\nExercises 3.1, 3.5, and 3.6 have you implement some of these operations, in order to\nbecome familiar with basic image processing operators. More sophisticated techniques for\ntonal adjustment (Reinhard, Ward, Pattanaik et al. 2005; Bae, Paris, and Durand 2006) are\ndescribed in the section on high dynamic range tone mapping (Section 10.2.1).\n3.2 Linear ﬁltering\nLocally adaptive histogram equalization is an example of a neighborhood operator or local\noperator, which uses a collection of pixel values in the vicinity of a given pixel to deter-\nmine its ﬁnal output value (Figure 3.10). In addition to performing local tone adjustment,\nneighborhood operators can be used to ﬁlter images in order to add soft blur, sharpen de-\ntails, accentuate edges, or remove noise (Figure 3.11b–d). In this section, we look at linear\nﬁltering operators, which involve weighted combinations of pixels in small neighborhoods.\nIn Section 3.3, we look at non-linear operators such as morphological ﬁlters and distance\ntransforms.\nThe most commonly used type of neighborhood operator is a linear ﬁlter, in which an\noutput pixel’s value is determined as a weighted sum of input pixel values (Figure 3.10),\ng(i, j) =\nX\nk,l\nf(i + k, j + l)h(k, l).\n(3.12)\nThe entries in the weight kernel or mask h(k, l) are often called the ﬁlter coefﬁcients. The\nabove correlation operator can be more compactly notated as\ng = f ⊗h.\n(3.13)\nA common variant on this formula is\ng(i, j) =\nX\nk,l\nf(i −k, j −l)h(k, l) =\nX\nk,l\nf(k, l)h(i −k, j −l),\n(3.14)\n112\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n45\n60\n98\n127 132 133 137 133\n46\n65\n98\n123 126 128 131 133\n69\n95\n116 125 129 132\n47\n65\n96\n115 119 123 135 137\n0.1\n0.1\n0.1\n68\n92\n110 120 126 132\n47\n63\n91\n107 113 122 138 134\n*\n0.1\n0.2\n0.1\n=\n66\n86\n104 114 124 132\n50\n59\n80\n97\n110 123 133 134\n0.1\n0.1\n0.1\n62\n78\n94\n108 120 129\n49\n53\n68\n83\n97\n113 128 133\n57\n69\n83\n98\n112 124\n50\n50\n58\n70\n84\n102 116 126\n53\n60\n71\n85\n100 114\n50\n50\n52\n58\n69\n86\n101 120\nf (x,y )\nh (x,y )\ng (x,y )\nFigure 3.10 Neighborhood ﬁltering (convolution): The image on the left is convolved with\nthe ﬁlter in the middle to yield the image on the right. The light blue pixels indicate the source\nneighborhood for the light green destination pixel.\nwhere the sign of the offsets in f has been reversed. This is called the convolution operator,\ng = f ∗h,\n(3.15)\nand h is then called the impulse response function.4 The reason for this name is that the kernel\nfunction, h, convolved with an impulse signal, δ(i, j) (an image that is 0 everywhere except\nat the origin) reproduces itself, h ∗δ = h, whereas correlation produces the reﬂected signal.\n(Try this yourself to verify that it is so.)\nIn fact, Equation (3.14) can be interpreted as the superposition (addition) of shifted im-\npulse response functions h(i−k, j −l) multiplied by the input pixel values f(k, l). Convolu-\ntion has additional nice properties, e.g., it is both commutative and associative. As well, the\nFourier transform of two convolved images is the product of their individual Fourier trans-\nforms (Section 3.4).\nBoth correlation and convolution are linear shift-invariant (LSI) operators, which obey\nboth the superposition principle (3.5),\nh ◦(f0 + f1) = h ◦f0 + h ◦f1,\n(3.16)\nand the shift invariance principle,\ng(i, j) = f(i + k, j + l) ⇔(h ◦g)(i, j) = (h ◦f)(i + k, j + l),\n(3.17)\nwhich means that shifting a signal commutes with applying the operator (◦stands for the LSI\noperator). Another way to think of shift invariance is that the operator “behaves the same\neverywhere”.\n4 The continuous version of convolution can be written as g(x) = R\nf(x −u)h(u)du.",
  "image_path": "page_133.jpg",
  "pages": [
    132,
    133,
    134
  ]
}