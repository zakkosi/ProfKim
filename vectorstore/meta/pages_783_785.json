{
  "doc_id": "pages_783_785",
  "text": "B.3 Robust statistics\n761\nmeasurement process. Examples of such outliers include bad feature matches (Section 6.1.4),\nocclusions in stereo matching (Chapter 11), and discontinuities in an otherwise smooth image,\ndepth map, or label image (Sections 3.7.1 and 3.7.2).\nIn such cases, it makes more sense to model the measurement noise with a long-tailed\ncontaminated noise model such as a Laplacian. The negative log likelihood in this case,\nrather than being quadratic in the measurement residuals (B.12–B.16), has a slower growth\nin the penalty function to account for the increased likelihood of large errors.\nThis formulation of the inference problem is called an M-estimator in the robust statistics\nliterature (Huber 1981; Hampel, Ronchetti, Rousseeuw et al. 1986; Black and Rangarajan\n1996; Stewart 1999) and involves applying a robust penalty function ρ(r) to the residuals\nERLS(∆p) =\nX\ni\nρ(∥ri∥)\n(B.17)\ninstead of squaring them.\nAs we mentioned in Section 6.1.4, we can take the derivative of this function with respect\nto p and set it to 0,\nX\ni\nψ(∥ri∥)∂∥ri∥\n∂p\n=\nX\ni\nψ(∥ri∥)\n∥ri∥\nrT\ni\n∂ri\n∂p = 0,\n(B.18)\nwhere ψ(r) = ρ′(r) is the derivative of ρ and is called the inﬂuence function. If we introduce a\nweight function, w(r) = Ψ(r)/r, we observe that ﬁnding the stationary point of (B.17) using\n(B.18) is equivalent to minimizing the iteratively re-weighted least squares (IRLS) problem\nEIRLS =\nX\ni\nw(∥ri∥)∥ri∥2,\n(B.19)\nwhere the w(∥ri∥) play the same local weighting role as Ci = Σ−1\ni\nin (B.12). Black and\nAnandan (1996) describe a variety of robust penalty functions and their corresponding inﬂu-\nence and weighting function.\nThe IRLS algorithm alternates between computing the inﬂuence functions w(∥ri∥) and\nsolving the resulting weighted least squares problem (with ﬁxed w values). Alternative in-\ncremental robust least squares algorithms can be found in the work of Sawhney and Ayer\n(1996); Black and Anandan (1996); Black and Rangarajan (1996); Baker, Gross, Ishikawa et\nal. (2003) and textbooks and tutorials on robust statistics (Huber 1981; Hampel, Ronchetti,\nRousseeuw et al. 1986; Rousseeuw and Leroy 1987; Stewart 1999). It is also possible to ap-\nply general optimization techniques (Appendix A.3) directly to the non-linear cost function\ngiven in Equation (B.19), which may sometimes have better convergence properties.\nMost robust penalty functions involve a scale parameter, which should typically be set to\nthe variance (or standard deviation, depending on the formulation) of the non-contaminated\n762\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(inlier) noise. Estimating such noise levels directly from the measurements or their residuals,\nhowever, can be problematic, as such estimates themselves become contaminated by outliers.\nThe robust statistics literature contains a variety of techniques to estimate such parameters.\nOne of the simplest and most effective is the median absolute deviation (MAD),\nMAD = medi∥ri∥,\n(B.20)\nwhich, when multiplied by 1.4, provides a robust estimate of the standard deviation of the\ninlier noise process.\nAs mentioned in Section 6.1.4, it is often better to start iterative non-linear minimiza-\ntion techniques, such as IRLS, in the vicinity of a good solution by ﬁrst randomly selecting\nsmall subsets of measurements until a good set of inliers is found. The best known of these\ntechniques is RANdom SAmple Consensus (RANSAC) (Fischler and Bolles 1981), although\neven better variants such as Preemptive RANSAC (Nist´er 2003) and PROgressive SAmple\nConsensus (PROSAC) (Chum and Matas 2005) have since been developed.\nB.4 Prior models and Bayesian inference\nWhile maximum likelihood estimation can often lead to good solutions, in some cases the\nrange of possible solutions consistent with the measurements is too large to be useful. For\nexample, consider the problem of image denoising (Sections 3.4.4 and 3.7.3). If we esti-\nmate each pixel separately based on just its noisy version, we cannot make any progress,\nas there are a large number of values that could lead to each noisy measurement.4 Instead,\nwe need to rely on typical properties of images, e.g., that they tend to be piecewise smooth\n(Section 3.7.1).\nThe propensity of images to be piecewise smooth can be encoded in a prior distribution\np(x), which measures the likelihood of an image being a natural image. For example, to\nencode piecewise smoothness, we can use a Markov random ﬁeld model (3.109 and B.24)\nwhose negative log likelihood is proportional to a robustiﬁed measure of image smoothness\n(gradient magnitudes).\nPrior models need not be restricted to image processing applications. For example, we\nmay have some external knowledge about the rough dimensions of an object being scanned,\nthe focal length of a lens being calibrated, or the likelihood that a particular object might\nappear in an image. All of these are examples of prior distributions or probabilities and they\ncan be used to produce more reliable estimates.\nAs we have already seen in (3.68) and (3.106), Bayes’ Rule states that a posterior distribu-\ntion p(x|y) over the unknowns x given the measurements y can be obtained by multiplying\n4 In fact, the maximum likelihood estimate is just the noisy image itself.\nB.5 Markov random ﬁelds\n763\nthe measurement likelihood p(y|x) by the prior distribution p(x),\np(x|y) = p(y|x)p(x)\np(y)\n,\n(B.21)\nwhere p(y) =\nR\nx p(y|x)p(x) is a normalizing constant used to make the p(x|y) distribution\nproper (integrate to 1). Taking the negative logarithm of both sides of Equation (B.21), we\nget\n−log p(x|y) = −log p(y|x) −log p(x) + log p(y),\n(B.22)\nwhich is the negative posterior log likelihood. It is common to drop the constant log p(y) be-\ncause its value does not matter during energy minimization. However, if the prior distribution\np(x) depends on some unknown parameters, we may wish to keep log p(y) in order to com-\npute the most likely value of these parameters using Occam’s razor, i.e., by maximizing the\nlikelihood of the observations, or to select the correct number of free parameters using model\nselection (Hastie, Tibshirani, and Friedman 2001; Torr 2002; Bishop 2006; Robert 2007).\nTo ﬁnd the most likely (maximum a posteriori or MAP) solution x given some measure-\nments y, we simply minimize this negative log likelihood, which can also be thought of as an\nenergy,\nE(x, y) = Ed(x, y) + Ep(x).\n(B.23)\nThe ﬁrst term Ed(x, y) is the data energy or data penalty and measures the negative log\nlikelihood that the measurements y were observed given the unknown state x. The second\nterm Ep(x) is the prior energy and it plays a role analogous to the smoothness energy in\nregularization. Note that the MAP estimate may not always be desirable, since it selects the\n“peak” in the posterior distribution rather than some more stable statistic such as MSE—see\nthe discussion in Appendix B.2 about loss functions and decision theory.\nB.5 Markov random ﬁelds\nMarkov random ﬁelds (Blake, Kohli, and Rother 2010) are the most popular types of prior\nmodel for gridded image-like data,5 which include not only regular natural images (Sec-\ntion 3.7.2) but also two-dimensional ﬁelds such as optic ﬂow (Chapter 8) or depth maps\n(Chapter 11), as well as binary ﬁelds, such as segmentations (Section 5.5).\nAs we discussed in Section 3.7.2, the prior probability p(x) for a Markov random ﬁeld is\na Gibbs or Boltzmann distribution, whose negative log likelihood (according to the Hammer-\n5 Alternative formulations include power spectra (Section 3.4.3) and non-local means (Buades, Coll, and Morel\n2008).",
  "image_path": "page_784.jpg",
  "pages": [
    783,
    784,
    785
  ]
}