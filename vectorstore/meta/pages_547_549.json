{
  "doc_id": "pages_547_549",
  "text": "10.6 Additional reading\n525\nDebevec (2006), and Hayes (2008), as well as two special journal issues edited by Bimber\n(2006) and Durand and Szeliski (2007). Notes from the courses on computational photog-\nraphy mentioned at the beginning of this chapter are another great source of material and\nreferences.24\nThe sub-ﬁeld of high dynamic range imaging has its own book discussing research in this\narea (Reinhard, Ward, Pattanaik et al. 2005), as well as some books describing related pho-\ntographic techniques (Freeman 2008; Gulbins and Gulbins 2009). Algorithms for calibrating\nthe radiometric response function of a camera can be found in articles by Mann and Picard\n(1995), Debevec and Malik (1997), and Mitsunaga and Nayar (1999).\nThe subject of tone mapping is treated extensively in (Reinhard, Ward, Pattanaik et al.\n2005). Representative papers from the large volume of literature on this topic include those\nby Tumblin and Rushmeier (1993), Larson, Rushmeier, and Piatko (1997), Pattanaik, Ferw-\nerda, Fairchild et al. (1998), Tumblin and Turk (1999), Durand and Dorsey (2002), Fattal,\nLischinski, and Werman (2002), Reinhard, Stark, Shirley et al. (2002), Lischinski, Farbman,\nUyttendaele et al. (2006b), and Farbman, Fattal, Lischinski et al. (2008).\nThe literature on super-resolution is quite extensive (Chaudhuri 2001; Park, Park, and\nKang 2003; Capel and Zisserman 2003; Capel 2004; van Ouwerkerk 2006). The term super-\nresolution usually describes techniques for aligning and merging multiple images to produce\nhigher-resolution composites (Keren, Peleg, and Brada 1988; Irani and Peleg 1991; Cheese-\nman, Kanefsky, Hanson et al. 1993; Mann and Picard 1994; Chiang and Boult 1996; Bascle,\nBlake, and Zisserman 1996; Capel and Zisserman 1998; Smelyanskiy, Cheeseman, Maluf et\nal. 2000; Capel and Zisserman 2000; Pickup, Capel, Roberts et al. 2009; Gulbins and Gul-\nbins 2009). However, single-image super-resolution techniques have also been developed\n(Freeman, Jones, and Pasztor 2002; Baker and Kanade 2002; Fattal 2007).\nA good survey on image matting is given by Wang and Cohen (2007a). Representative\npapers, which include extensive comparisons with previous work, include those by Chuang,\nCurless, Salesin et al. (2001), Wang and Cohen (2007b), Levin, Acha, and Lischinski (2008),\nRhemann, Rother, Rav-Acha et al. (2008), and Rhemann, Rother, Wang et al. (2009).\nThe literature on texture synthesis and hole ﬁlling includes traditional approaches to tex-\nture synthesis, which try to match image statistics between source and destination images\n(Heeger and Bergen 1995; De Bonet 1997; Portilla and Simoncelli 2000), as well as newer\napproaches, which search for matching neighborhoods or patches inside the source sample\n(Efros and Leung 1999; Wei and Levoy 2000; Efros and Freeman 2001). In a similar vein,\ntraditional approaches to hole ﬁlling involve the solution of local variational (smooth continu-\nation) problems (Bertalmio, Sapiro, Caselles et al. 2000; Bertalmio, Vese, Sapiro et al. 2003;\n24 MIT 6.815/6.865, http://stellar.mit.edu/S/course/6/sp08/6.815/materials.html, CMU 15-463, http://graphics.cs.\ncmu.edu/courses/15-463/2008 fall/, Stanford CS 448A, http://graphics.stanford.edu/courses/cs448a-08-spring/, and\nSIGGRAPH courses, http://web.media.mit.edu/∼raskar/photo/.\n526\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nTelea 2004). More recent techniques use data-driven texture synthesis approaches (Drori,\nCohen-Or, and Yeshurun 2003; Kwatra, Sch¨odl, Essa et al. 2003; Criminisi, P´erez, and\nToyama 2004; Sun, Yuan, Jia et al. 2004; Kwatra, Essa, Bobick et al. 2005; Wilczkowiak,\nBrostow, Tordoff et al. 2005; Komodakis and Tziritas 2007b; Wexler, Shechtman, and Irani\n2007).\n10.7 Exercises\nEx 10.1: Radiometric calibration\nImplement one of the multi-exposure radiometric cali-\nbration algorithms described in Section 10.2 (Debevec and Malik 1997; Mitsunaga and Nayar\n1999; Reinhard, Ward, Pattanaik et al. 2005). This calibration will be useful in a number of\ndifferent applications, such as stitching images or stereo matching with different exposures\nand shape from shading.\n1. Take a series of bracketed images with your camera on a tripod. If your camera has\nan automatic exposure bracketing (AEB) mode, taking three images may be sufﬁcient\nto calibrate most of your camera’s dynamic range, especially if your scene has a lot of\nbright and dark regions. (Shooting outdoors or through a window on a sunny day is\nbest.)\n2. If your images are not taken on a tripod, ﬁrst perform a global alignment (similarity\ntransform).\n3. Estimate the radiometric response function using one of the techniques cited above.\n4. Estimate the high dynamic range radiance image by selecting or blending pixels from\ndifferent exposures (Debevec and Malik 1997; Mitsunaga and Nayar 1999; Eden, Uyt-\ntendaele, and Szeliski 2006).\n5. Repeat your calibration experiments under different conditions, e.g., indoors under in-\ncandescent light, to get a sense for the range of color balancing effects that your camera\nimposes.\n6. If your camera supports RAW and JPEG mode, calibrate both sets of images simulta-\nneously and to each other (the radiance at each pixel will correspond). See if you can\ncome up with a model for what your camera does, e.g., whether it treats color balance\nas a diagonal or full 3 × 3 matrix multiply, whether it uses non-linearities in addition\nto gamma, whether it sharpens the image while “developing” the JPEG image, etc.\n7. Develop an interactive viewer to change the exposure of an image based on the average\nexposure of a region around the mouse. (One variant is to show the adjusted image\n10.7 Exercises\n527\ninside a window around the mouse. Another is to adjust the complete image based on\nthe mouse position.)\n8. Implement a tone mapping operator (Exercise 10.5) and use this to map your radiance\nimage to a displayable gamut.\nEx 10.2: Noise level function\nDetermine your camera’s noise level function using either\nmultiple shots or by analyzing smooth regions.\n1. Set up your camera on a tripod looking at a calibration target or a static scene with a\ngood variation in input levels and colors. (Check your camera’s histogram to ensure\nthat all values are being sampled.)\n2. Take repeated images of the same scene (ideally with a remote shutter release) and\naverage them to compute the variance at each pixel. Discarding pixels near high gra-\ndients (which are affected by camera motion), plot for each color channel the standard\ndeviation at each pixel as a function of its output value.\n3. Fit a lower envelope to these measurements and use this as your noise level function.\nHow much variation do you see in the noise as a function of input level? How much of\nthis is signiﬁcant, i.e., away from ﬂat regions in your camera response function where\nyou do not want to be sampling anyway?\n4. (Optional) Using the same images, develop a technique that segments the image into\nnear-constant regions (Liu, Szeliski, Kang et al. 2008). (This is easier if you are pho-\ntographing a calibration chart.) Compute the deviations for each region from a single\nimage and use them to estimate the NLF. How does this compare to the multi-image\ntechnique, and how stable are your estimates from image to image?\nEx 10.3: Vignetting\nEstimate the amount of vignetting in some of your lenses using one of\nthe following three techniques (or devise one of your choosing):\n1. Take an image of a large uniform intensity region (well-illuminated wall or blue sky—\nbut be careful of brightness gradients) and ﬁt a radial polynomial curve to estimate the\nvignetting.\n2. Construct a center-weighted panorama and compare these pixel values to the input im-\nage values to estimate the vignetting function. Weight pixels in slowly varying regions\nmore highly, as small misalignments will give large errors at high gradients. Option-\nally estimate the radiometric response function as well (Litvinov and Schechner 2005;\nGoldman 2011).",
  "image_path": "page_548.jpg",
  "pages": [
    547,
    548,
    549
  ]
}