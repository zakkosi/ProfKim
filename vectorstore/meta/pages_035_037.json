{
  "doc_id": "pages_035_037",
  "text": "1.2 A brief history\n13\n1974; Marr and Poggio 1976; Moravec 1977; Marr and Poggio 1979; Mayhew and Frisby\n1981; Baker 1982; Barnard and Fischler 1982; Ohta and Kanade 1985; Grimson 1985; Pol-\nlard, Mayhew, and Frisby 1985; Prazdny 1985) and intensity-based optical ﬂow algorithms\n(Figure 1.7f) (Horn and Schunck 1981; Huang 1981; Lucas and Kanade 1981; Nagel 1986).\nThe early work in simultaneously recovering 3D structure and camera motion (see Chapter 7)\nalso began around this time (Ullman 1979; Longuet-Higgins 1981).\nA lot of the philosophy of how vision was believed to work at the time is summarized\nin David Marr’s (1982) book.8 In particular, Marr introduced his notion of the three levels\nof description of a (visual) information processing system. These three levels, very loosely\nparaphrased according to my own interpretation, are:\n• Computational theory: What is the goal of the computation (task) and what are the\nconstraints that are known or can be brought to bear on the problem?\n• Representations and algorithms: How are the input, output, and intermediate infor-\nmation represented and which algorithms are used to calculate the desired result?\n• Hardware implementation: How are the representations and algorithms mapped onto\nactual hardware, e.g., a biological vision system or a specialized piece of silicon? Con-\nversely, how can hardware constraints be used to guide the choice of representation\nand algorithm? With the increasing use of graphics chips (GPUs) and many-core ar-\nchitectures for computer vision (see Section C.2), this question is again becoming quite\nrelevant.\nAs I mentioned earlier in this introduction, it is my conviction that a careful analysis of the\nproblem speciﬁcation and known constraints from image formation and priors (the scientiﬁc\nand statistical approaches) must be married with efﬁcient and robust algorithms (the engineer-\ning approach) to design successful vision algorithms. Thus, it seems that Marr’s philosophy\nis as good a guide to framing and solving problems in our ﬁeld today as it was 25 years ago.\n1980s.\nIn the 1980s, a lot of attention was focused on more sophisticated mathematical\ntechniques for performing quantitative image and scene analysis.\nImage pyramids (see Section 3.5) started being widely used to perform tasks such as im-\nage blending (Figure 1.8a) and coarse-to-ﬁne correspondence search (Rosenfeld 1980; Burt\nand Adelson 1983a,b; Rosenfeld 1984; Quam 1984; Anandan 1989). Continuous versions\nof pyramids using the concept of scale-space processing were also developed (Witkin 1983;\nWitkin, Terzopoulos, and Kass 1986; Lindeberg 1990). In the late 1980s, wavelets (see Sec-\ntion 3.5.4) started displacing or augmenting regular image pyramids in some applications\n8 More recent developments in visual perception theory are covered in (Palmer 1999; Livingstone 2008).\n14\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 1.8 Examples of computer vision algorithms from the 1980s: (a) pyramid blending\n(Burt and Adelson 1983b) c⃝1983 ACM, (b) shape from shading (Freeman and Adelson\n1991) c⃝1991 IEEE, (c) edge detection (Freeman and Adelson 1991) c⃝1991 IEEE, (d)\nphysically based models (Terzopoulos and Witkin 1988) c⃝1988 IEEE, (e) regularization-\nbased surface reconstruction (Terzopoulos 1988) c⃝1988 IEEE, (f) range data acquisition\nand merging (Banno, Masuda, Oishi et al. 2008) c⃝2008 Springer.\n(Adelson, Simoncelli, and Hingorani 1987; Mallat 1989; Simoncelli and Adelson 1990a,b;\nSimoncelli, Freeman, Adelson et al. 1992).\nThe use of stereo as a quantitative shape cue was extended by a wide variety of shape-\nfrom-X techniques, including shape from shading (Figure 1.8b) (see Section 12.1.1 and Horn\n1975; Pentland 1984; Blake, Zimmerman, and Knowles 1985; Horn and Brooks 1986, 1989),\nphotometric stereo (see Section 12.1.1 and Woodham 1981), shape from texture (see Sec-\ntion 12.1.2 and Witkin 1981; Pentland 1984; Malik and Rosenholtz 1997), and shape from\nfocus (see Section 12.1.3 and Nayar, Watanabe, and Noguchi 1995). Horn (1986) has a nice\ndiscussion of most of these techniques.\nResearch into better edge and contour detection (Figure 1.8c) (see Section 4.2) was also\nactive during this period (Canny 1986; Nalwa and Binford 1986), including the introduc-\ntion of dynamically evolving contour trackers (Section 5.1.1) such as snakes (Kass, Witkin,\nand Terzopoulos 1988), as well as three-dimensional physically based models (Figure 1.8d)\n(Terzopoulos, Witkin, and Kass 1987; Kass, Witkin, and Terzopoulos 1988; Terzopoulos and\nFleischer 1988; Terzopoulos, Witkin, and Kass 1988).\nResearchers noticed that a lot of the stereo, ﬂow, shape-from-X, and edge detection al-\n1.2 A brief history\n15\ngorithms could be uniﬁed, or at least described, using the same mathematical framework if\nthey were posed as variational optimization problems (see Section 3.7) and made more ro-\nbust (well-posed) using regularization (Figure 1.8e) (see Section 3.7.1 and Terzopoulos 1983;\nPoggio, Torre, and Koch 1985; Terzopoulos 1986b; Blake and Zisserman 1987; Bertero, Pog-\ngio, and Torre 1988; Terzopoulos 1988). Around the same time, Geman and Geman (1984)\npointed out that such problems could equally well be formulated using discrete Markov Ran-\ndom Field (MRF) models (see Section 3.7.2), which enabled the use of better (global) search\nand optimization algorithms, such as simulated annealing.\nOnline variants of MRF algorithms that modeled and updated uncertainties using the\nKalman ﬁlter were introduced a little later (Dickmanns and Graefe 1988; Matthies, Kanade,\nand Szeliski 1989; Szeliski 1989). Attempts were also made to map both regularized and\nMRF algorithms onto parallel hardware (Poggio and Koch 1985; Poggio, Little, Gamble\net al. 1988; Fischler, Firschein, Barnard et al. 1989). The book by Fischler and Firschein\n(1987) contains a nice collection of articles focusing on all of these topics (stereo, ﬂow,\nregularization, MRFs, and even higher-level vision).\nThree-dimensional range data processing (acquisition, merging, modeling, and recogni-\ntion; see Figure 1.8f) continued being actively explored during this decade (Agin and Binford\n1976; Besl and Jain 1985; Faugeras and Hebert 1987; Curless and Levoy 1996). The compi-\nlation by Kanade (1987) contains a lot of the interesting papers in this area.\n1990s.\nWhile a lot of the previously mentioned topics continued to be explored, a few of\nthem became signiﬁcantly more active.\nA burst of activity in using projective invariants for recognition (Mundy and Zisserman\n1992) evolved into a concerted effort to solve the structure from motion problem (see Chap-\nter 7). A lot of the initial activity was directed at projective reconstructions, which did not\nrequire knowledge of camera calibration (Faugeras 1992; Hartley, Gupta, and Chang 1992;\nHartley 1994a; Faugeras and Luong 2001; Hartley and Zisserman 2004). Simultaneously, fac-\ntorization techniques (Section 7.3) were developed to solve efﬁciently problems for which or-\nthographic camera approximations were applicable (Figure 1.9a) (Tomasi and Kanade 1992;\nPoelman and Kanade 1997; Anandan and Irani 2002) and then later extended to the perspec-\ntive case (Christy and Horaud 1996; Triggs 1996). Eventually, the ﬁeld started using full\nglobal optimization (see Section 7.4 and Taylor, Kriegman, and Anandan 1991; Szeliski and\nKang 1994; Azarbayejani and Pentland 1995), which was later recognized as being the same\nas the bundle adjustment techniques traditionally used in photogrammetry (Triggs, McLauch-\nlan, Hartley et al. 1999). Fully automated (sparse) 3D modeling systems were built using such\ntechniques (Beardsley, Torr, and Zisserman 1996; Schaffalitzky and Zisserman 2002; Brown\nand Lowe 2003; Snavely, Seitz, and Szeliski 2006).\nWork begun in the 1980s on using detailed measurements of color and intensity combined",
  "image_path": "page_036.jpg",
  "pages": [
    35,
    36,
    37
  ]
}