{
  "doc_id": "pages_401_403",
  "text": "7.7 Exercises\n379\nEx 7.4: Factorization\nImplement the factorization algorithm described in Section 7.3 us-\ning point tracks you computed in Exercise 4.5.\n1. (Optional) Implement uncertainty rescaling (Anandan and Irani 2002) and comment on\nwhether this improves your results.\n2. (Optional) Implement one of the perspective improvements to factorization discussed\nin Section 7.3.1 (Christy and Horaud 1996; Sturm and Triggs 1996; Triggs 1996). Does\nthis produce signiﬁcantly lower reprojection errors? Can you upgrade this reconstruc-\ntion to a metric one?\nEx 7.5: Bundle adjuster\nImplement a full bundle adjuster. This may sound daunting, but\nit really is not.\n1. Devise the internal data structures and external ﬁle representations to hold your camera\nparameters (position, orientation, and focal length), 3D point locations (Euclidean or\nhomogeneous), and 2D point tracks (frame and point identiﬁer as well as 2D locations).\n2. Use some other technique, such as factorization, to initialize the 3D point and camera\nlocations from your 2D tracks (e.g., a subset of points that appears in all frames).\n3. Implement the code corresponding to the forward transformations in Figure 7.7, i.e.,\nfor each 2D point measurement, take the corresponding 3D point, map it through the\ncamera transformations (including perspective projection and focal length scaling), and\ncompare it to the 2D point measurement to get a residual error.\n4. Take the residual error and compute its derivatives with respect to all the unknown\nmotion and structure parameters, using backward chaining, as shown, e.g., in Figure 7.7\nand Equation (6.47). This gives you the sparse Jacobian J used in Equations (6.13–\n6.17) and Equation (6.43).\n5. Use a sparse least squares or linear system solver, e.g., MATLAB, SparseSuite, or\nSPARSKIT (see Appendix A.4 and A.5), to solve the corresponding linearized system,\nadding a small amount of diagonal preconditioning, as in Levenberg–Marquardt.\n6. Update your parameters, make sure your rotation matrices are still orthonormal (e.g.,\nby re-computing them from your quaternions), and continue iterating while monitoring\nyour residual error.\n7. (Optional) Use the “Schur complement trick” (7.56) to reduce the size of the system\nbeing solved (Triggs, McLauchlan, Hartley et al. 1999; Hartley and Zisserman 2004;\nLourakis and Argyros 2009; Engels, Stew´enius, and Nist´er 2006).\n380\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n8. (Optional) Implement your own iterative sparse solver, e.g., conjugate gradient, and\ncompare its performance to a direct method.\n9. (Optional) Make your bundle adjuster robust to outliers, or try adding some of the other\nimprovements discussed in (Engels, Stew´enius, and Nist´er 2006). Can you think of any\nother ways to make your algorithm even faster or more robust?\nEx 7.6: Match move and augmented reality\nUse the results of the previous exercise to\nsuperimpose a rendered 3D model on top of video. See Section 7.4.2 for more details and\nideas. Check for how “locked down” the objects are.\nEx 7.7: Line-based reconstruction\nAugment the previously developed bundle adjuster to\ninclude lines, possibly with known 3D orientations.\nOptionally, use co-planar sets of points and lines to hypothesize planes and to enforce\nco-planarity (Schaffalitzky and Zisserman 2002; Robertson and Cipolla 2002)\nEx 7.8: Flexible bundle adjuster\nDesign a bundle adjuster that allows for arbitrary chains\nof transformations and prior knowledge about the unknowns, as suggested in Figures 7.7–7.8.\nEx 7.9: Unordered image matching\nCompute the camera pose and 3D structure of a scene\nfrom an arbitrary collection of photographs (Brown and Lowe 2003; Snavely, Seitz, and\nSzeliski 2006).\nChapter 8\nDense motion estimation\n8.1\nTranslational alignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384\n8.1.1\nHierarchical motion estimation . . . . . . . . . . . . . . . . . . . . . 387\n8.1.2\nFourier-based alignment . . . . . . . . . . . . . . . . . . . . . . . . 388\n8.1.3\nIncremental reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . 392\n8.2\nParametric motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398\n8.2.1\nApplication: Video stabilization . . . . . . . . . . . . . . . . . . . . 401\n8.2.2\nLearned motion models . . . . . . . . . . . . . . . . . . . . . . . . . 403\n8.3\nSpline-based motion\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404\n8.3.1\nApplication: Medical image registration . . . . . . . . . . . . . . . . 408\n8.4\nOptical ﬂow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409\n8.4.1\nMulti-frame motion estimation . . . . . . . . . . . . . . . . . . . . . 413\n8.4.2\nApplication: Video denoising\n. . . . . . . . . . . . . . . . . . . . . 414\n8.4.3\nApplication: De-interlacing\n. . . . . . . . . . . . . . . . . . . . . . 415\n8.5\nLayered motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415\n8.5.1\nApplication: Frame interpolation . . . . . . . . . . . . . . . . . . . . 418\n8.5.2\nTransparent layers and reﬂections . . . . . . . . . . . . . . . . . . . 419\n8.6\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421\n8.7\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422",
  "image_path": "page_402.jpg",
  "pages": [
    401,
    402,
    403
  ]
}