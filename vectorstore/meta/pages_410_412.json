{
  "doc_id": "pages_410_412",
  "text": "388\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(corresponding to the same range of motion) is ﬁrst performed at coarser levels (Quam 1984;\nAnandan 1989; Bergen, Anandan, Hanna et al. 1992). The motion estimate from one level\nof the pyramid is then used to initialize a smaller local search at the next ﬁner level. Al-\nternatively, several seeds (good solutions) from the coarse level can be used to initialize the\nﬁne-level search. While this is not guaranteed to produce the same result as a full search, it\nusually works almost as well and is much faster.\nMore formally, let\nI(l)\nk (xj) ←˜I(l−1)\nk\n(2xj)\n(8.15)\nbe the decimated image at level l obtained by subsampling (downsampling) a smoothed ver-\nsion of the image at level l−1. See Section 3.5 for how to perform the required downsampling\n(pyramid construction) without introducing too much aliasing.\nAt the coarsest level, we search for the best displacement u(l) that minimizes the dif-\nference between images I(l)\n0\nand I(l)\n1 . This is usually done using a full search over some\nrange of displacements u(l) ∈2−l[−S, S]2, where S is the desired search range at the ﬁnest\n(original) resolution level, optionally followed by the incremental reﬁnement step described\nin Section 8.1.3.\nOnce a suitable motion vector has been estimated, it is used to predict a likely displace-\nment\nˆu(l−1) ←2u(l)\n(8.16)\nfor the next ﬁner level.5 The search over displacements is then repeated at the ﬁner level over\na much narrower range of displacements, say ˆu(l−1) ± 1, again optionally combined with an\nincremental reﬁnement step (Anandan 1989). Alternatively, one of the images can be warped\n(resampled) by the current motion estimate, in which case only small incremental motions\nneed to be computed at the ﬁner level. A nice description of the whole process, extended to\nparametric motion estimation (Section 8.2), is provided by Bergen, Anandan, Hanna et al.\n(1992).\n8.1.2 Fourier-based alignment\nWhen the search range corresponds to a signiﬁcant fraction of the larger image (as is the case\nin image stitching, see Chapter 9), the hierarchical approach may not work that well, since\nit is often not possible to coarsen the representation too much before signiﬁcant features are\nblurred away. In this case, a Fourier-based approach may be preferable.\n5 This doubling of displacements is only necessary if displacements are deﬁned in integer pixel coordinates,\nwhich is the usual case in the literature (Bergen, Anandan, Hanna et al. 1992). If normalized device coordinates\n(Section 2.1.5) are used instead, the displacements (and search ranges) need not change from level to level, although\nthe step sizes will need to be adjusted, to keep search steps of roughly one pixel.\n8.1 Translational alignment\n389\nFourier-based alignment relies on the fact that the Fourier transform of a shifted signal\nhas the same magnitude as the original signal but a linearly varying phase (Section 3.4), i.e.,\nF {I1(x + u)} = F {I1(x)} e−ju·ω = I1(ω)e−ju·ω,\n(8.17)\nwhere ω is the vector-valued angular frequency of the Fourier transform and we use cal-\nligraphic notation I1(ω) = F {I1(x)} to denote the Fourier transform of a signal (Sec-\ntion 3.4).\nAnother useful property of Fourier transforms is that convolution in the spatial domain\ncorresponds to multiplication in the Fourier domain (Section 3.4).6 Thus, the Fourier trans-\nform of the cross-correlation function ECC can be written as\nF {ECC(u)} = F\n(X\ni\nI0(xi)I1(xi + u)\n)\n= F {I0(u)¯∗I1(u)} = I0(ω)I∗\n1(ω), (8.18)\nwhere\nf(u)¯∗g(u) =\nX\ni\nf(xi)g(xi + u)\n(8.19)\nis the correlation function, i.e., the convolution of one signal with the reverse of the other,\nand I∗\n1(ω) is the complex conjugate of I1(ω). This is because convolution is deﬁned as the\nsummation of one signal with the reverse of the other (Section 3.4).\nThus, to efﬁciently evaluate ECC over the range of all possible values of u, we take the\nFourier transforms of both images I0(x) and I1(x), multiply both transforms together (after\nconjugating the second one), and take the inverse transform of the result. The Fast Fourier\nTransform algorithm can compute the transform of an N × M image in O(NM log NM)\noperations (Bracewell 1986). This can be signiﬁcantly faster than the O(N 2M 2) operations\nrequired to do a full search when the full range of image overlaps is considered.\nWhile Fourier-based convolution is often used to accelerate the computation of image\ncorrelations, it can also be used to accelerate the sum of squared differences function (and its\nvariants). Consider the SSD formula given in (8.1). Its Fourier transform can be written as\nF {ESSD(u)}\n=\nF\n(X\ni\n[I1(xi + u) −I0(xi)]2\n)\n=\nδ(ω)\nX\ni\n[I2\n0(xi) + I2\n1(xi)] −2I0(ω)I∗\n1(ω).\n(8.20)\nThus, the SSD function can be computed by taking twice the correlation function and sub-\ntracting it from the sum of the energies in the two images.\n6 In fact, the Fourier shift property (8.17) derives from the convolution theorem by observing that shifting is\nequivalent to convolution with a displaced delta function δ(x −u).\n390\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWindowed correlation.\nUnfortunately, the Fourier convolution theorem only applies when\nthe summation over xi is performed over all the pixels in both images, using a circular shift\nof the image when accessing pixels outside the original boundaries. While this is acceptable\nfor small shifts and comparably sized images, it makes no sense when the images overlap by\na small amount or one image is a small subset of the other.\nIn that case, the cross-correlation function should be replaced with a windowed (weighted)\ncross-correlation function,\nEWCC(u)\n=\nX\ni\nw0(xi)I0(xi) w1(xi + u)I1(xi + u),\n(8.21)\n=\n[w0(x)I0(x)]¯∗[w1(x)I1(x)]\n(8.22)\nwhere the weighting functions w0 and w1 are zero outside the valid ranges of the images\nand both images are padded so that circular shifts return 0 values outside the original image\nboundaries.\nAn even more interesting case is the computation of the weighted SSD function intro-\nduced in Equation (8.5),\nEWSSD(u)\n=\nX\ni\nw0(xi)w1(xi + u)[I1(xi + u) −I0(xi)]2.\n(8.23)\nExpanding this as a sum of correlations and deriving the appropriate set of Fourier transforms\nis left for Exercise 8.1.\nThe same kind of derivation can also be applied to the bias–gain corrected sum of squared\ndifference function EBG (8.9). Again, Fourier transforms can be used to efﬁciently compute\nall the correlations needed to perform the linear regression in the bias and gain parameters in\norder to estimate the exposure-compensated difference for each potential shift (Exercise 8.1).\nPhase correlation.\nA variant of regular correlation (8.18) that is sometimes used for motion\nestimation is phase correlation (Kuglin and Hines 1975; Brown 1992). Here, the spectrum of\nthe two signals being matched is whitened by dividing each per-frequency product in (8.18)\nby the magnitudes of the Fourier transforms,\nF {EPC(u)} =\nI0(ω)I∗\n1(ω)\n∥I0(ω)∥∥I1(ω)∥\n(8.24)\nbefore taking the ﬁnal inverse Fourier transform. In the case of noiseless signals with perfect\n(cyclic) shift, we have I1(x + u) = I0(x) and hence, from Equation (8.17), we obtain\nF {I1(x + u)}\n=\nI1(ω)e−2πju·ω = I0(ω) and\nF {EPC(u)}\n=\ne−2πju·ω.\n(8.25)",
  "image_path": "page_411.jpg",
  "pages": [
    410,
    411,
    412
  ]
}