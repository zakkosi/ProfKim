{
  "doc_id": "pages_740_742",
  "text": "718\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nIn more recent work, Fergus, Perona, and Zisserman (2004) use a feature-based learning\nand recognition algorithm to re-rank the outputs from a traditional keyword-based image\nsearch engine. In follow-on work, Fergus, Fei-Fei, Perona et al. (2005) cluster the results\nreturned by image search using an extension of probabilistic latest semantic analysis (PLSA)\n(Hofmann 1999) and then select the clusters associated with the highest ranked results as the\nrepresentative images for that category.\nEven more recent work relies on carefully annotated image databases such as LabelMe\n(Russell, Torralba, Murphy et al. 2008). For example, Malisiewicz and Efros (2008) describe\na system that, given a query image, can ﬁnd similar LabelMe images, whereas Liu, Yuen, and\nTorralba (2009) combine feature-based correspondence algorithms with the labeled database\nto perform simultaneous recognition and segmentation.\n14.6 Recognition databases and test sets\nIn addition to rapid advances in machine learning and statistical modeling techniques, one\nof the key ingredients in the continued improvement of recognition algorithms has been the\nincreased availability and quality of image recognition databases.\nTables 14.1 and 14.2, which are based on similar tables in Fei-Fei, Fergus, and Torralba\n(2009), updated with more recent entries and URLs, show some of the mostly widely used\nrecognition databases. Some of these databases, such as the ones for face recognition and\nlocalization, date back over a decade. The most recent ones, such as the PASCAL database,\nare refreshed annually with ever more challenging problems. Table 14.1 shows examples of\ndatabases used primarily for (whole image) recognition while Table 14.2 shows databases\nwhere more accurate localization or segmentation information is available and expected.\nPonce, Berg, Everingham et al. (2006) discuss some of the problems with earlier datasets\nand describe how the latest PASCAL Visual Object Classes Challenge aims to overcome\nthese. Some examples of the 20 visual classes in the 2008 challenge are shown in Fig-\nure 14.54. The slides from the VOC workshops,22 are a great source for pointers to the\nbest recognition techniques currently available.\nTwo of the most recent trends in recognition databases are the emergence of Web-based\nannotation and data collection tools, and the use of search and recognition algorithms to build\nup databases (Ponce, Berg, Everingham et al. 2006). Some of the most interesting work in\nhuman annotation of images comes from a series of interactive multi-person games such as\nESP (von Ahn and Dabbish 2004) and Peekaboom (von Ahn, Liu, and Blum 2006). In these\ngames, people help each other guess the identity of a hidden image by giving textual clues\nas to its contents, which implicitly labels either the whole image or just regions. A more\n22 http://pascallin.ecs.soton.ac.uk/challenges/VOC/.\n14.6 Recognition databases and test sets\n719\nName / URL\nExtents\nContents / Reference\nFace and person recognition\nYale face database\nCentered face images\nFrontal faces\nhttp://www1.cs.columbia.edu/∼belhumeur/\nBelhumeur, Hespanha, and Kriegman (1997)\nResources for face detection\nVarious databases\nFaces in various poses\nhttp://vision.ai.uiuc.edu/mhyang/face-detection-survey.html\nYang, Kriegman, and Ahuja (2002)\nFERET\nCentered face images\nFrontal faces\nhttp://www.frvt.org/FERET\nPhillips, Moon, Rizvi et al. (2000)\nFRVT\nCentered face images\nFaces in various poses\nhttp://www.frvt.org/\nPhillips, Scruggs, O’Toole et al. (2010)\nCMU PIE database\nCentered face image\nFaces in various poses\nhttp://www.ri.cmu.edu/projects/project 418.html\nSim, Baker, and Bsat (2003)\nCMU Multi-PIE database\nCentered face image\nFaces in various poses\nhttp://multipie.org\nGross, Matthews, Cohn et al. (2010)\nFaces in the Wild\nInternet images\nFaces in various poses\nhttp://vis-www.cs.umass.edu/lfw/\nHuang, Ramesh, Berg et al. (2007)\nConsumer image person DB\nComplete images\nPeople\nhttp://chenlab.ece.cornell.edu/people/Andy/GallagherDataset.html\nGallagher and Chen (2008)\nObject recognition\nCaltech 101\nSegmentation masks\n101 categories\nhttp://www.vision.caltech.edu/Image Datasets/Caltech101/\nFei-Fei, Fergus, and Perona (2006)\nCaltech 256\nCentered objects\n256 categories and clutter\nhttp://www.vision.caltech.edu/Image Datasets/Caltech256/\nGrifﬁn, Holub, and Perona (2007)\nCOIL-100\nCentered objects\n100 instances\nhttp://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php\nNene, Nayar, and Murase (1996)\nETH-80\nCentered objects\n8 instances, 10 views\nhttp://www.mis.tu-darmstadt.de/datasets\nLeibe and Schiele (2003)\nInstance recognition benchmark\nObjects in various poses\n2550 objects\nhttp://vis.uky.edu/∼stewe/ukbench/\nNist´er and Stew´enius (2006)\nOxford buildings dataset\nPictures of buildings\n5062 images\nhttp://www.robots.ox.ac.uk/∼vgg/data/oxbuildings/\nPhilbin, Chum, Isard et al. (2007)\nNORB\nBounding box\n50 toys\nhttp://www.cs.nyu.edu/∼ylclab/data/norb-v1.0/\nLeCun, Huang, and Bottou (2004)\nTiny images\nComplete images\n75,000 (Wordnet) things\nhttp://people.csail.mit.edu/torralba/tinyimages/\nTorralba, Freeman, and Fergus (2008)\nImageNet\nComplete images\n14,000 (Wordnet) things\nhttp://www.image-net.org/\nDeng, Dong, Socher et al. (2009)\nTable 14.1\nImage databases for recognition, adapted and expanded from Fei-Fei, Fergus,\nand Torralba (2009).\n720\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nName / URL\nExtents\nContents / Reference\nObject detection / localization\nCMU frontal faces\nPatches\nFrontal faces\nhttp://vasc.ri.cmu.edu/idb/html/face/frontal images\nRowley, Baluja, and Kanade (1998a)\nMIT frontal faces\nPatches\nFrontal faces\nhttp://cbcl.mit.edu/software-datasets/FaceData2.html\nSung and Poggio (1998)\nCMU face detection databases\nMultiple faces\nFaces in various poses\nhttp://www.ri.cmu.edu/research project detail.html?project id=419\nSchneiderman and Kanade (2004)\nUIUC Image DB\nBounding boxes\nCars\nhttp://l2r.cs.uiuc.edu/∼cogcomp/Data/Car/\nAgarwal and Roth (2002)\nCaltech Pedestrian Dataset\nBounding boxes\nPedestrians\nhttp://www.vision.caltech.edu/Image Datasets/CaltechPedestrians/\nDoll`ar, Wojek, Schiele et al. (2009)\nGraz-02 Database\nSegmentation masks\nBikes, cars, people\nhttp://www.emt.tugraz.at/∼pinz/data/GRAZ 02/\nOpelt, Pinz, Fussenegger et al. (2006)\nETHZ Toys\nCluttered images\nToys, boxes, magazines\nhttp://www.vision.ee.ethz.ch/∼calvin/datasets.html\nFerrari, Tuytelaars, and Van Gool (2006b)\nTU Darmstadt DB\nSegmentation masks\nMotorbikes, cars, cows\nhttp://www.vision.ee.ethz.ch/∼bleibe/data/datasets.html\nLeibe, Leonardis, and Schiele (2008)\nMSR Cambridge\nSegmentation masks\n23 classes\nhttp://research.microsoft.com/en-us/projects/objectclassrecognition/\nShotton, Winn, Rother et al. (2009)\nLabelMe dataset\nPolygonal boundary\n>500 categories\nhttp://labelme.csail.mit.edu/\nRussell, Torralba, Murphy et al. (2008)\nLotus Hill\nSegmentation masks\nScenes and hierarchies\nhttp://www.imageparsing.com/\nYao, Yang, Lin et al. (2010)\nOn-line annotation tools\nESP game\nImage descriptions\nWeb images\nhttp://www.gwap.com/gwap/\nvon Ahn and Dabbish (2004)\nPeekaboom\nLabeled regions\nWeb images\nhttp://www.gwap.com/gwap/\nvon Ahn, Liu, and Blum (2006)\nLabelMe\nPolygonal boundary\nHigh-resolution images\nhttp://labelme.csail.mit.edu/\nRussell, Torralba, Murphy et al. (2008)\nCollections of challenges\nPASCAL\nSegmentation, boxes\nVarious\nhttp://pascallin.ecs.soton.ac.uk/challenges/VOC/\nEveringham, Van Gool, Williams et al. (2010)\nTable 14.2 Image databases for detection and localization, adapted and expanded from Fei-\nFei, Fergus, and Torralba (2009).",
  "image_path": "page_741.jpg",
  "pages": [
    740,
    741,
    742
  ]
}