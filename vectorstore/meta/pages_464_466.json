{
  "doc_id": "pages_464_466",
  "text": "442\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nby stretching the alignment of all the images using a process called gap closing (Szeliski and\nShum 1997). However, a better alternative is to simultaneously align all the images using a\nleast-squares framework to correctly distribute any mis-registration errors.\nThe process of simultaneously adjusting pose parameters for a large collection of overlap-\nping images is called bundle adjustment in the photogrammetry community (Triggs, McLauch-\nlan, Hartley et al. 1999). In computer vision, it was ﬁrst applied to the general structure from\nmotion problem (Szeliski and Kang 1994) and then later specialized for panoramic image\nstitching (Shum and Szeliski 2000; Sawhney and Kumar 1999; Coorg and Teller 2000).\nIn this section, we formulate the problem of global alignment using a feature-based ap-\nproach, since this results in a simpler system. An equivalent direct approach can be obtained\neither by dividing images into patches and creating a virtual feature correspondence for each\none (as discussed in Section 9.2.4 and by Shum and Szeliski (2000)) or by replacing the\nper-feature error metrics with per-pixel metrics.\nConsider the feature-based alignment problem given in Equation (6.2), i.e.,\nEpairwise−LS =\nX\ni\n∥ri∥2 = ∥˜x′\ni(xi; p) −ˆx′\ni∥2.\n(9.25)\nFor multi-image alignment, instead of having a single collection of pairwise feature corre-\nspondences, {(xi, ˆx′\ni)}, we have a collection of n features, with the location of the ith feature\npoint in the jth image denoted by xij and its scalar conﬁdence (i.e., inverse variance) denoted\nby cij.9 Each image also has some associated pose parameters.\nIn this section, we assume that this pose consists of a rotation matrix Rj and a focal\nlength fj, although formulations in terms of homographies are also possible (Szeliski and\nShum 1997; Sawhney and Kumar 1999). The equation mapping a 3D point xi into a point\nxij in frame j can be re-written from Equations (2.68) and (9.5) as\n˜xij ∼KjRjxi and xi ∼R−1\nj K−1\nj\n˜xij,\n(9.26)\nwhere Kj = diag(fj, fj, 1) is the simpliﬁed form of the calibration matrix. The motion\nmapping a point xij from frame j into a point xik in frame k is similarly given by\n˜xik ∼˜\nHkj ˜xij = KkRkR−1\nj K−1\nj\n˜xij.\n(9.27)\nGiven an initial set of {(Rj, fj)} estimates obtained from chaining pairwise alignments, how\ndo we reﬁne these estimates?\nOne approach is to directly extend the pairwise energy Epairwise−LS (9.25) to a multiview\nformulation,\nEall−pairs−2D =\nX\ni\nX\njk\ncijcik∥˜xik(ˆxij; Rj, fj, Rk, fk) −ˆxik∥2,\n(9.28)\n9 Features that are not seen in image j have cij = 0. We can also use 2 × 2 inverse covariance matrices Σ−1\nij in\nplace of cij, as shown in Equation (6.11).\n9.2 Global alignment\n443\nwhere the ˜xik function is the predicted location of feature i in frame k given by (9.27),\nˆxij is the observed location, and the “2D” in the subscript indicates that an image-plane\nerror is being minimized (Shum and Szeliski 2000). Note that since ˜xik depends on the ˆxij\nobserved value, we actually have an errors-in-variable problem, which in principle requires\nmore sophisticated techniques than least squares to solve (Van Huffel and Lemmerling 2002;\nMatei and Meer 2006). However, in practice, if we have enough features, we can directly\nminimize the above quantity using regular non-linear least squares and obtain an accurate\nmulti-frame alignment.\nWhile this approach works well in practice, it suffers from two potential disadvantages.\nFirst, since a summation is taken over all pairs with corresponding features, features that are\nobserved many times are overweighted in the ﬁnal solution. (In effect, a feature observed m\ntimes gets counted\n\u0000m\n2\n\u0001\ntimes instead of m times.) Second, the derivatives of ˜xik with respect\nto the {(Rj, fj)} are a little cumbersome, although using the incremental correction to Rj\nintroduced in Section 9.1.3 makes this more tractable.\nAn alternative way to formulate the optimization is to use true bundle adjustment, i.e., to\nsolve not only for the pose parameters {(Rj, fj)} but also for the 3D point positions {xi},\nEBA−2D =\nX\ni\nX\nj\ncij∥˜xij(xi; Rj, fj) −ˆxij∥2,\n(9.29)\nwhere ˜xij(xi; Rj, fj) is given by (9.26). The disadvantage of full bundle adjustment is that\nthere are more variables to solve for, so each iteration and also the overall convergence may\nbe slower. (Imagine how the 3D points need to “shift” each time some rotation matrices are\nupdated.) However, the computational complexity of each linearized Gauss–Newton step can\nbe reduced using sparse matrix techniques (Section 7.4.1) (Szeliski and Kang 1994; Triggs,\nMcLauchlan, Hartley et al. 1999; Hartley and Zisserman 2004).\nAn alternative formulation is to minimize the error in 3D projected ray directions (Shum\nand Szeliski 2000), i.e.,\nEBA−3D =\nX\ni\nX\nj\ncij∥˜xi(ˆxij; Rj, fj) −xi∥2,\n(9.30)\nwhere ˜xi(xij; Rj, fj) is given by the second half of (9.26). This has no particular advantage\nover (9.29). In fact, since errors are being minimized in 3D ray space, there is a bias towards\nestimating longer focal lengths, since the angles between rays become smaller as f increases.\nHowever, if we eliminate the 3D rays xi, we can derive a pairwise energy formulated in\n3D ray space (Shum and Szeliski 2000),\nEall−pairs−3D =\nX\ni\nX\njk\ncijcik∥˜xi(ˆxij; Rj, fj) −˜xi(ˆxik; Rk, fk)∥2.\n(9.31)\n444\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nThis results in the simplest set of update equations (Shum and Szeliski 2000), since the fk can\nbe folded into the creation of the homogeneous coordinate vector as in Equation (9.7). Thus,\neven though this formula over-weights features that occur more frequently, it is the method\nused by Shum and Szeliski (2000) and Brown, Szeliski, and Winder (2005). In order to reduce\nthe bias towards longer focal lengths, we multiply each residual (3D error) by\np\nfjfk, which\nis similar to projecting the 3D rays into a “virtual camera” of intermediate focal length.\nUp vector selection.\nAs mentioned above, there exists a global ambiguity in the pose of the\n3D cameras computed by the above methods. While this may not appear to matter, people\nprefer that the ﬁnal stitched image is “upright” rather than twisted or tilted. More concretely,\npeople are used to seeing photographs displayed so that the vertical (gravity) axis points\nstraight up in the image. Consider how you usually shoot photographs: while you may pan\nand tilt the camera any which way, you usually keep the horizontal edge of your camera (its\nx-axis) parallel to the ground plane (perpendicular to the world gravity direction).\nMathematically, this constraint on the rotation matrices can be expressed as follows. Re-\ncall from Equation (9.26) that the 3D to 2D projection is given by\n˜xik ∼KkRkxi.\n(9.32)\nWe wish to post-multiply each rotation matrix Rk by a global rotation Rg such that the pro-\njection of the global y-axis, ˆ= (0, 1, 0) is perpendicular to the image x-axis, ˆı = (1, 0, 0).10\nThis constraint can be written as\nˆıT RkRgˆ= 0\n(9.33)\n(note that the scaling by the calibration matrix is irrelevant here). This is equivalent to re-\nquiring that the ﬁrst row of Rk, rk0 = ˆıT Rk be perpendicular to the second column of Rg,\nrg1 = Rgˆ. This set of constraints (one per input image) can be written as a least squares\nproblem,\nrg1 = arg min\nr\nX\nk\n(rT rk0)2 = arg min\nr rT\n\"X\nk\nrk0rT\nk0\n#\nr.\n(9.34)\nThus, rg1 is the smallest eigenvector of the scatter or moment matrix spanned by the indi-\nvidual camera rotation x-vectors, which should generally be of the form (c, 0, s) when the\ncameras are upright.\nTo fully specify the Rg global rotation, we need to specify one additional constraint. This\nis related to the view selection problem discussed in Section 9.3.1. One simple heuristic is to\n10 Note that here we use the convention common in computer graphics that the vertical world axis corresponds to\ny. This is a natural choice if we wish the rotation matrix associated with a “regular” image taken horizontally to be\nthe identity, rather than a 90◦rotation around the x-axis.",
  "image_path": "page_465.jpg",
  "pages": [
    464,
    465,
    466
  ]
}