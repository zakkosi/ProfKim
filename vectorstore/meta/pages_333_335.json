{
  "doc_id": "pages_333_335",
  "text": "6.1 2D and 3D feature-based alignment\n311\ny\nx\nsimilarity\nEuclidean\naffine\nprojective\ntranslation\nFigure 6.2 Basic set of 2D planar transformations\nOnce we have extracted features from images, the next stage in many vision algorithms is\nto match these features across different images (Section 4.1.3). An important component of\nthis matching is to verify whether the set of matching features is geometrically consistent,\ne.g., whether the feature displacements can be described by a simple 2D or 3D geometric\ntransformation. The computed motions can then be used in other applications such as image\nstitching (Chapter 9) or augmented reality (Section 6.2.3).\nIn this chapter, we look at the topic of geometric image registration, i.e., the computation\nof 2D and 3D transformations that map features in one image to another (Section 6.1). One\nspecial case of this problem is pose estimation, which is determining a camera’s position\nrelative to a known 3D object or scene (Section 6.2). Another case is the computation of a\ncamera’s intrinsic calibration, which consists of the internal parameters such as focal length\nand radial distortion (Section 6.3). In Chapter 7, we look at the related problems of how\nto estimate 3D point structure from 2D matches (triangulation) and how to simultaneously\nestimate 3D geometry and camera motion (structure from motion).\n6.1 2D and 3D feature-based alignment\nFeature-based alignment is the problem of estimating the motion between two or more sets\nof matched 2D or 3D points. In this section, we restrict ourselves to global parametric trans-\nformations, such as those described in Section 2.1.2 and shown in Table 2.1 and Figure 6.2,\nor higher order transformation for curved surfaces (Shashua and Toelg 1997; Can, Stewart,\nRoysam et al. 2002). Applications to non-rigid or elastic deformations (Bookstein 1989;\nSzeliski and Lavall´ee 1996; Torresani, Hertzmann, and Bregler 2008) are examined in Sec-\ntions 8.3 and 12.6.4.\n312\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nTransform\nMatrix\nParameters p\nJacobian J\ntranslation\n\"\n1\n0\ntx\n0\n1\nty\n#\n(tx, ty)\n\"\n1\n0\n0\n1\n#\nEuclidean\n\"\ncθ\n−sθ\ntx\nsθ\ncθ\nty\n#\n(tx, ty, θ)\n\"\n1\n0\n−sθx −cθy\n0\n1\ncθx −sθy\n#\nsimilarity\n\"\n1 + a\n−b\ntx\nb\n1 + a\nty\n#\n(tx, ty, a, b)\n\"\n1\n0\nx\n−y\n0\n1\ny\nx\n#\nafﬁne\n\"\n1 + a00\na01\ntx\na10\n1 + a11\nty\n#\n(tx, ty, a00, a01, a10, a11)\n\"\n1\n0\nx\ny\n0\n0\n0\n1\n0\n0\nx\ny\n#\nprojective\n\n\n1 + h00\nh01\nh02\nh10\n1 + h11\nh12\nh20\nh21\n1\n\n\n(h00, h01, . . . , h21)\n(see Section 6.1.3)\nTable 6.1 Jacobians of the 2D coordinate transformations x′ = f(x; p) shown in Table 2.1,\nwhere we have re-parameterized the motions so that they are identity for p = 0.\n6.1.1 2D alignment using least squares\nGiven a set of matched feature points {(xi, x′\ni)} and a planar parametric transformation1 of\nthe form\nx′ = f(x; p),\n(6.1)\nhow can we produce the best estimate of the motion parameters p? The usual way to do this\nis to use least squares, i.e., to minimize the sum of squared residuals\nELS =\nX\ni\n∥ri∥2 =\nX\ni\n∥f(xi; p) −x′\ni∥2,\n(6.2)\nwhere\nri = f(xi; p) −x′\ni = ˆx′\ni −˜x′\ni\n(6.3)\nis the residual between the measured location ˆx′\ni and its corresponding current predicted\nlocation ˜x′\ni = f(xi; p). (See Appendix A.2 for more on least squares and Appendix B.2 for\na statistical justiﬁcation.)\n1 For examples of non-planar parametric models, such as quadrics, see the work of Shashua and Toelg (1997);\nShashua and Wexler (2001).\n6.1 2D and 3D feature-based alignment\n313\nMany of the motion models presented in Section 2.1.2 and Table 2.1, i.e., translation,\nsimilarity, and afﬁne, have a linear relationship between the amount of motion ∆x = x′ −x\nand the unknown parameters p,\n∆x = x′ −x = J(x)p,\n(6.4)\nwhere J = ∂f/∂p is the Jacobian of the transformation f with respect to the motion param-\neters p (see Table 6.1). In this case, a simple linear regression (linear least squares problem)\ncan be formulated as\nELLS\n=\nX\ni\n∥J(xi)p −∆xi∥2\n(6.5)\n=\npT\n\"X\ni\nJT (xi)J(xi)\n#\np −2pT\n\"X\ni\nJT (xi)∆xi\n#\n+\nX\ni\n∥∆xi∥2 (6.6)\n=\npT Ap −2pT b + c.\n(6.7)\nThe minimum can be found by solving the symmetric positive deﬁnite (SPD) system of nor-\nmal equations2\nAp = b,\n(6.8)\nwhere\nA =\nX\ni\nJT (xi)J(xi)\n(6.9)\nis called the Hessian and b = P\ni JT (xi)∆xi. For the case of pure translation, the result-\ning equations have a particularly simple form, i.e., the translation is the average translation\nbetween corresponding points or, equivalently, the translation of the point centroids.\nUncertainty weighting.\nThe above least squares formulation assumes that all feature points\nare matched with the same accuracy. This is often not the case, since certain points may fall\ninto more textured regions than others. If we associate a scalar variance estimate σ2\ni with\neach correspondence, we can minimize the weighted least squares problem instead,3\nEWLS =\nX\ni\nσ−2\ni\n∥ri∥2.\n(6.10)\nAs shown in Section 8.1.3, a covariance estimate for patch-based matching can be obtained\nby multiplying the inverse of the patch Hessian Ai (8.55) with the per-pixel noise covariance\n2 For poorly conditioned problems, it is better to use QR decomposition on the set of linear equations J(xi)p =\n∆xi instead of the normal equations (Bj¨orck 1996; Golub and Van Loan 1996). However, such conditions rarely\narise in image registration.\n3 Problems where each measurement can have a different variance or certainty are called heteroscedastic models.",
  "image_path": "page_334.jpg",
  "pages": [
    333,
    334,
    335
  ]
}