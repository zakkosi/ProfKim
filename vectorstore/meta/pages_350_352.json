{
  "doc_id": "pages_350_352",
  "text": "328\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 6.7\nCalibrating a lens by drawing straight lines on cardboard (Debevec, Wenger,\nTchou et al. 2002) c⃝2002 ACM: (a) an image taken by the video camera showing a hand\nholding a metal ruler whose right edge appears vertical in the image; (b) the set of lines drawn\non the cardboard converging on the front nodal point (center of projection) of the lens and\nindicating the horizontal ﬁeld of view.\nAn alternative method for estimating the focal length and center of projection of a lens\nis to place the camera on a large ﬂat piece of cardboard and use a long metal ruler to draw\nlines on the cardboard that appear vertical in the image, as shown in Figure 6.7a (Debevec,\nWenger, Tchou et al. 2002). Such lines lie on planes that are parallel to the vertical axis of\nthe camera sensor and also pass through the lens’ front nodal point. The location of the nodal\npoint (projected vertically onto the cardboard plane) and the horizontal ﬁeld of view (deter-\nmined from lines that graze the left and right edges of the visible image) can be recovered by\nintersecting these lines and measuring their angular extent (Figure 6.7b).\nIf no calibration pattern is available, it is also possible to perform calibration simulta-\nneously with structure and pose recovery (Sections 6.3.4 and 7.4), which is known as self-\ncalibration (Faugeras, Luong, and Maybank 1992; Hartley and Zisserman 2004; Moons, Van\nGool, and Vergauwen 2010). However, such an approach requires a large amount of imagery\nto be accurate.\nPlanar calibration patterns\nWhen a ﬁnite workspace is being used and accurate machining and motion control platforms\nare available, a good way to perform calibration is to move a planar calibration target in a\ncontrolled fashion through the workspace volume. This approach is sometimes called the N-\nplanes calibration approach (Gremban, Thorpe, and Kanade 1988; Champleboux, Lavall´ee,\nSzeliski et al. 1992; Grossberg and Nayar 2001) and has the advantage that each camera pixel\ncan be mapped to a unique 3D ray in space, which takes care of both linear effects modeled\n6.3 Geometric intrinsic calibration\n329\n(a)\n(b)\nFigure 6.8 Calibration patterns: (a) a three-dimensional target (Quan and Lan 1999) c⃝1999\nIEEE; (b) a two-dimensional target (Zhang 2000) c⃝2000 IEEE. Note that radial distortion\nneeds to be removed from such images before the feature points can be used for calibration.\nby the calibration matrix K and non-linear effects such as radial distortion (Section 6.3.5).\nA less cumbersome but also less accurate calibration can be obtained by waving a pla-\nnar calibration pattern in front of a camera (Figure 6.8b). In this case, the pattern’s pose\nhas (in principle) to be recovered in conjunction with the intrinsics. In this technique, each\ninput image is used to compute a separate homography (6.19–6.23) ˜\nH mapping the plane’s\ncalibration points (Xi, Yi, 0) into image coordinates (xi, yi),\nxi =\n\n\nxi\nyi\n1\n\n∼K\nh\nr0\nr1\nt\ni\n\n\nXi\nYi\n1\n\n∼˜\nHpi,\n(6.49)\nwhere the ri are the ﬁrst two columns of R and ∼indicates equality up to scale. From\nthese, Zhang (2000) shows how to form linear constraints on the nine entries in the B =\nK−T K−1 matrix, from which the calibration matrix K can be recovered using a matrix\nsquare root and inversion. (The matrix B is known as the image of the absolute conic (IAC)\nin projective geometry and is commonly used for camera calibration (Hartley and Zisserman\n2004, Section 7.5).) If only the focal length is being recovered, the even simpler approach of\nusing vanishing points can be used instead.\n6.3.2 Vanishing points\nA common case for calibration that occurs often in practice is when the camera is looking at\na man-made scene with strong extended rectahedral objects such as boxes or room walls. In\nthis case, we can intersect the 2D lines corresponding to 3D parallel lines to compute their\nvanishing points, as described in Section 4.3.3, and use these to determine the intrinsic and\nextrinsic calibration parameters (Caprile and Torre 1990; Becker and Bove 1995; Liebowitz\n330\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nx1\nx0\nx2\nx1\nx0\nx2\nc\n(a)\n(b)\nFigure 6.9 Calibration from vanishing points: (a) any pair of ﬁnite vanishing points (ˆxi, ˆxj)\ncan be used to estimate the focal length; (b) the orthocenter of the vanishing point triangle\ngives the optical center of the image c.\nand Zisserman 1998; Cipolla, Drummond, and Robertson 1999; Antone and Teller 2002;\nCriminisi, Reid, and Zisserman 2000; Hartley and Zisserman 2004; Pﬂugfelder 2008).\nLet us assume that we have detected two or more orthogonal vanishing points, all of which\nare ﬁnite, i.e., they are not obtained from lines that appear to be parallel in the image plane\n(Figure 6.9a). Let us also assume a simpliﬁed form for the calibration matrix K where only\nthe focal length is unknown (2.59). (It is often safe for rough 3D modeling to assume that\nthe optical center is at the center of the image, that the aspect ratio is 1, and that there is no\nskew.) In this case, the projection equation for the vanishing points can be written as\nˆxi =\n\n\nxi −cx\nyi −cy\nf\n\n∼Rpi = ri,\n(6.50)\nwhere pi corresponds to one of the cardinal directions (1, 0, 0), (0, 1, 0), or (0, 0, 1), and ri\nis the ith column of the rotation matrix R.\nFrom the orthogonality between columns of the rotation matrix, we have\nri · rj ∼(xi −cx)(xj −cy) + (yi −cy)(yj −cy) + f 2 = 0\n(6.51)\nfrom which we can obtain an estimate for f 2. Note that the accuracy of this estimate increases\nas the vanishing points move closer to the center of the image. In other words, it is best to tilt\nthe calibration pattern a decent amount around the 45◦axis, as in Figure 6.9a. Once the focal\nlength f has been determined, the individual columns of R can be estimated by normalizing\nthe left hand side of (6.50) and taking cross products. Alternatively, an SVD of the initial R\nestimate, which is a variant on orthogonal Procrustes (6.32), can be used.\nIf all three vanishing points are visible and ﬁnite in the same image, it is also possible to\nestimate the optical center as the orthocenter of the triangle formed by the three vanishing\npoints (Caprile and Torre 1990; Hartley and Zisserman 2004, Section 7.6) (Figure 6.9b).",
  "image_path": "page_351.jpg",
  "pages": [
    350,
    351,
    352
  ]
}