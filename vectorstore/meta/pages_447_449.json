{
  "doc_id": "pages_447_449",
  "text": "8.7 Exercises\n425\nEx 8.6: Motion-based user interaction\nWrite a program to compute a low-resolution mo-\ntion ﬁeld in order to interactively control a simple application (Cutler and Turk 1998). For\nexample:\n1. Downsample each image using a pyramid and compute the optical ﬂow (spline-based\nor pixel-based) from the previous frame.\n2. Segment each training video sequence into different “actions” (e.g., hand moving in-\nwards, moving up, no motion) and “learn” the velocity ﬁelds associated with each one.\n(You can simply ﬁnd the mean and variance for each motion ﬁeld or use something\nmore sophisticated, such as a support vector machine (SVM).)\n3. Write a recognizer that ﬁnds successive actions of approximately the right duration and\nhook it up to an interactive application (e.g., a sound generator or a computer game).\n4. Ask your friends to test it out.\nEx 8.7: Video denoising\nImplement the algorithm sketched in Application 8.4.2. Your al-\ngorithm should contain the following steps:\n1. Compute accurate per-pixel ﬂow.\n2. Determine which pixels in the reference image have good matches with other frames.\n3. Either average all of the matched pixels or choose the sharpest image, if trying to\ncompensate for blur. Don’t forget to use regular single-frame denoising techniques as\npart of your solution, (see Section 3.4.4, Section 3.7.3, and Exercise 3.11).\n4. Devise a fall-back strategy for areas where you don’t think the ﬂow estimates are accu-\nrate enough.\nEx 8.8: Motion segmentation\nWrite a program to segment an image into separately mov-\ning regions or to reliably ﬁnd motion boundaries.\nUse the human-assisted motion segmentation database at http://people.csail.mit.edu/celiu/\nmotionAnnotation/ as some of your test data.\nEx 8.9: Layered motion estimation\nDecompose into separate layers (Section 8.5) a video\nsequence of a scene taken with a moving camera:\n1. Find the set of dominant (afﬁne or planar perspective) motions, either by computing\nthem in blocks or ﬁnding a robust estimate and then iteratively re-ﬁtting outliers.\n2. Determine which pixels go with each motion.\n426\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n3. Construct the layers by blending pixels from different frames.\n4. (Optional) Add per-pixel residual ﬂows or depths.\n5. (Optional) Reﬁne your estimates using an iterative global optimization technique.\n6. (Optional) Write an interactive renderer to generate in-between frames or view the\nscene from different viewpoints (Shade, Gortler, He et al. 1998).\n7. (Optional) Construct an unwrap mosaic from a more complex scene and use this to do\nsome video editing (Rav-Acha, Kohli, Fitzgibbon et al. 2008).\nEx 8.10: Transparent motion and reﬂection estimation\nTake a video sequence looking\nthrough a window (or picture frame) and see if you can remove the reﬂection in order to\nbetter see what is inside.\nThe steps are described in Section 8.5.2 and by Szeliski, Avidan, and Anandan (2000).\nAlternative approaches can be found in work by Shizawa and Mase (1991), Bergen, Burt,\nHingorani et al. (1992), Darrell and Simoncelli (1993), Darrell and Pentland (1995), Irani,\nRousso, and Peleg (1994), Black and Anandan (1996), and Ju, Black, and Jepson (1996).\nChapter 9\nImage stitching\n9.1\nMotion models\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430\n9.1.1\nPlanar perspective motion\n. . . . . . . . . . . . . . . . . . . . . . . 431\n9.1.2\nApplication: Whiteboard and document scanning . . . . . . . . . . . 432\n9.1.3\nRotational panoramas . . . . . . . . . . . . . . . . . . . . . . . . . . 433\n9.1.4\nGap closing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435\n9.1.5\nApplication: Video summarization and compression\n. . . . . . . . . 436\n9.1.6\nCylindrical and spherical coordinates\n. . . . . . . . . . . . . . . . . 438\n9.2\nGlobal alignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n9.2.1\nBundle adjustment . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n9.2.2\nParallax removal . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445\n9.2.3\nRecognizing panoramas\n. . . . . . . . . . . . . . . . . . . . . . . . 446\n9.2.4\nDirect vs. feature-based alignment . . . . . . . . . . . . . . . . . . . 450\n9.3\nCompositing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450\n9.3.1\nChoosing a compositing surface . . . . . . . . . . . . . . . . . . . . 451\n9.3.2\nPixel selection and weighting (de-ghosting) . . . . . . . . . . . . . . 453\n9.3.3\nApplication: Photomontage\n. . . . . . . . . . . . . . . . . . . . . . 459\n9.3.4\nBlending\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 459\n9.4\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462\n9.5\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463",
  "image_path": "page_448.jpg",
  "pages": [
    447,
    448,
    449
  ]
}