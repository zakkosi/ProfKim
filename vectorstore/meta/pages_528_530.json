{
  "doc_id": "pages_528_530",
  "text": "506\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.38\nSoftening a hard segmentation boundary (border matting) (Rother, Kol-\nmogorov, and Blake 2004) c⃝2004 ACM: (a) the region surrounding a segmentation bound-\nary where pixels of mixed foreground and background colors are visible; (b) pixel values\nalong the boundary are used to compute a soft alpha matte; (c) at each point along the curve\nt, a displacement ∆and a width σ are estimated.\nvisible discretization artifacts, we need to pull a matte, i.e., to estimate a soft opacity channel\nα and the uncontaminated foreground colors F from the input composite image C. Recall\nfrom Section 3.1.3 (Figure 3.4) that the compositing equation (3.8) can be written as\nC = (1 −α)B + αF.\n(10.30)\nThis operator attenuates the inﬂuence of the background image B by a factor (1 −α) and\nthen adds in the (partial) color values corresponding to the foreground element F.\nWhile the compositing operation is easy to implement, the reverse matting operation of\nestimating F, α, and B given an input image C is much more challenging (Figure 10.39).\nTo see why, observe that while the composite pixel color C provides three measurements,\nthe F, α, and B unknowns have a total of seven degrees of freedom. Devising techniques to\nestimate these unknowns despite the underconstrained nature of the problem is the essence of\nimage matting.\nIn this section, we review a number of image matting techniques. We begin with blue\nscreen matting, which assumes that the background is a constant known color, and discuss its\nvariants, two-screen matting (when multiple backgrounds can be used) and difference matting\n(where the known background is arbitrary). We then discuss local variants of natural image\nmatting, where both the foreground and background are unknown. In these applications, it is\nusual to ﬁrst specify a trimap, i.e., a three-way labeling of the image into foreground, back-\nground, and unknown regions (Figure 10.39b). Next, we present some global optimization\napproaches to natural image matting. Finally, we discuss variants on the matting problem,\nincluding shadow matting, ﬂash matting, and environment matting.\n10.4 Image matting and compositing\n507\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 10.39 Natural image matting (Chuang, Curless, Salesin et al. 2001) c⃝2001 IEEE:\n(a) input image with a “natural” (non-constant) background; (b) hand-drawn trimap—gray\nindicates unknown regions; (c) extracted alpha map; (d) extracted (premultiplied) foreground\ncolors; (e) composite over a new background.\n10.4.1 Blue screen matting\nBlue screen matting involves ﬁlming an actor (or object) in front of a constant colored back-\nground. While originally bright blue was the preferred color, bright green is now more com-\nmonly used (Wright 2006; Brinkmann 2008). Smith and Blinn (1996) discuss a number of\ntechniques for blue screen matting, which are mostly described in patents rather than in the\nopen research literature. Early techniques used linear combination of object color channels\nwith user-tuned parameters to estimate the opacity α.\nChuang, Curless, Salesin et al. (2001) describe a newer technique called Mishima’s al-\ngorithm, which involves ﬁtting two polyhedral surfaces (centered at the mean background\ncolor), separating the foreground and background color distributions and then measuring the\nrelative distance of a novel color to these surfaces to estimate α (Figure 10.41e). While this\ntechnique works well in many studio settings, it can still suffer from blue spill, where translu-\ncent pixels around the edges of an object acquire some of the background blue coloration\n(Figure 10.40).\nTwo-screen matting.\nIn their paper, Smith and Blinn (1996) also introduce an algorithm\ncalled triangulation matting that uses more than one known background color to over-constrain\nthe equations required to estimate the opacity α and foreground color F.\n508\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 10.40\nBlue-screen matting results (Chuang, Curless, Salesin et al. 2001) c⃝2001\nIEEE. Mishima’s method produces visible blue spill (color fringing in the hair), while\nChuang’s Bayesian matting approach produces accurate results.\nFor example, consider in the compositing equation (10.30) setting the background color\nto black, i.e., B = 0. The resulting composite image C is therefore equal to αF. Replacing\nthe background color with a different known non-zero value B now results in\nC −αF = (1 −α)B,\n(10.31)\nwhich is an overconstrained set of (color) equations for estimating α. In practice, B should\nbe chosen so as not to saturate C and, for best accuracy, several values of B should be used.\nIt is also important that colors be linearized before processing, which is the case for all image\nmatting algorithms. Papers that generate ground truth alpha mattes for evaluation purposes\nnormally use these techniques to obtain accurate matte estimates (Chuang, Curless, Salesin\net al. 2001; Wang and Cohen 2007b; Levin, Acha, and Lischinski 2008; Rhemann, Rother,\nRav-Acha et al. 2008; Rhemann, Rother, Wang et al. 2009).22 Exercise 10.8 has you do this\nas well.\n22 See the alpha matting evaluation Web site at http://alphamatting.com/.",
  "image_path": "page_529.jpg",
  "pages": [
    528,
    529,
    530
  ]
}