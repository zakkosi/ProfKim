{
  "doc_id": "pages_361_363",
  "text": "6.5 Exercises\n339\n5. Estimate the full 3D pose (including translation) by ﬁnding one or more 3×3 grids and\nrecovering the plane’s full equation from this known homography using the technique\ndeveloped by Zhang (2000).\n6. Alternatively, since you already know the rotation, simply estimate the unknown trans-\nlation from the known 3D corner points on the cube and their measured 2D locations\nusing either linear or non-linear least squares.\n7. Use the 3D rotation and position to control a VRML or 3D game viewer.\nEx 6.6: Rotation-based calibration\nTake an outdoor or indoor sequence from a rotating\ncamera with very little parallax and use it to calibrate the focal length of your camera using\nthe techniques described in Section 6.3.4 or Sections 9.1.3–9.2.1.\n1. Take out any radial distortion in the images using one of the techniques from Exer-\ncises 6.10–6.11 or using parameters supplied for a given camera by your instructor.\n2. Detect and match feature points across neighboring frames and chain them into feature\ntracks.\n3. Compute homographies between overlapping frames and use Equations (6.56–6.57) to\nget an estimate of the focal length.\n4. Compute a full 360◦panorama and update your focal length estimate to close the gap\n(Section 9.1.4).\n5. (Optional) Perform a complete bundle adjustment in the rotation matrices and focal\nlength to obtain the highest quality estimate (Section 9.2.1).\nEx 6.7: Target-based calibration\nUse a three-dimensional target to calibrate your camera.\n1. Construct a three-dimensional calibration pattern with known 3D locations. It is not\neasy to get high accuracy unless you use a machine shop, but you can get close using\nheavy plywood and printed patterns.\n2. Find the corners, e.g, using a line ﬁnder and intersecting the lines.\n3. Implement one of the iterative calibration and pose estimation algorithms described\nin Tsai (1987); Bogart (1991); Gleicher and Witkin (1992) or the system described in\nSection 6.2.2.\n4. Take many pictures at different distances and orientations relative to the calibration\ntarget and report on both your re-projection errors and accuracy. (To do the latter, you\nmay need to use simulated data.)\n340\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 6.8: Calibration accuracy\nCompare the three calibration techniques (plane-based, rotation-\nbased, and 3D-target-based).\nOne approach is to have a different student implement each one and to compare the results.\nAnother approach is to use synthetic data, potentially re-using the software you developed\nfor Exercise 2.3. The advantage of using synthetic data is that you know the ground truth\nfor the calibration and pose parameters, you can easily run lots of experiments, and you can\nsynthetically vary the noise in your measurements.\nHere are some possible guidelines for constructing your test sets:\n1. Assume a medium-wide focal length (say, 50◦ﬁeld of view).\n2. For the plane-based technique, generate a 2D grid target and project it at different\ninclinations.\n3. For a 3D target, create an inner cube corner and position it so that it ﬁlls most of ﬁeld\nof view.\n4. For the rotation technique, scatter points uniformly on a sphere until you get a similar\nnumber of points as for other techniques.\nBefore comparing your techniques, predict which one will be the most accurate (normalize\nyour results by the square root of the number of points used).\nAdd varying amounts of noise to your measurements and describe the noise sensitivity of\nyour various techniques.\nEx 6.9: Single view metrology\nImplement a system to measure dimensions and reconstruct\na 3D model from a single image of a man-made scene using visible vanishing directions (Sec-\ntion 6.3.3) (Criminisi, Reid, and Zisserman 2000).\n1. Find the three orthogonal vanishing points from parallel lines and use them to establish\nthe three coordinate axes (rotation matrix R of the camera relative to the scene). If\ntwo of the vanishing points are ﬁnite (not at inﬁnity), use them to compute the focal\nlength, assuming a known optical center. Otherwise, ﬁnd some other way to calibrate\nyour camera; you could use some of the techniques described by Schaffalitzky and\nZisserman (2000).\n2. Click on a ground plane point to establish your origin and click on a point a known\ndistance away to establish the scene scale. This lets you compute the translation t\nbetween the camera and the scene. As an alternative, click on a pair of points, one\non the ground plane and one above it, and use the known height to establish the scene\nscale.\n6.5 Exercises\n341\n3. Write a user interface that lets you click on ground plane points to recover their 3D\nlocations. (Hint: you already know the camera matrix, so knowledge of a point’s z\nvalue is sufﬁcient to recover its 3D location.) Click on pairs of points (one on the\nground plane, one above it) to measure vertical heights.\n4. Extend your system to let you draw quadrilaterals in the scene that correspond to axis-\naligned rectangles in the world, using some of the techniques described by Sinha,\nSteedly, Szeliski et al. (2008). Export your 3D rectangles to a VRML or PLY15 ﬁle.\n5. (Optional) Warp the pixels enclosed by the quadrilateral using the correct homography\nto produce a texture map for each planar polygon.\nEx 6.10: Radial distortion with plumb lines\nImplement a plumb-line algorithm to deter-\nmine the radial distortion parameters.\n1. Take some images of scenes with lots of straight lines, e.g., hallways in your home or\nofﬁce, and try to get some of the lines as close to the edges of the image as possible.\n2. Extract the edges and link them into curves, as described in Section 4.2.2 and Exer-\ncise 4.8.\n3. Fit quadratic or elliptic curves to the linked edges using a generalization of the suc-\ncessive line approximation algorithm described in Section 4.3.1 and Exercise 4.11 and\nkeep the curves that ﬁt this form well.\n4. For each curved segment, ﬁt a straight line and minimize the perpendicular distance\nbetween the curve and the line while adjusting the radial distortion parameters.\n5. Alternate between re-ﬁtting the straight line and adjusting the radial distortion param-\neters until convergence.\nEx 6.11: Radial distortion with a calibration target\nUse a grid calibration target to de-\ntermine the radial distortion parameters.\n1. Print out a planar calibration target, mount it on a stiff board, and get it to ﬁll your ﬁeld\nof view.\n2. Detect the squares, lines, or dots in your calibration target.\n3. Estimate the homography mapping the target to the camera from the central portion of\nthe image that does not have any radial distortion.\n15 http://meshlab.sf.net.",
  "image_path": "page_362.jpg",
  "pages": [
    361,
    362,
    363
  ]
}