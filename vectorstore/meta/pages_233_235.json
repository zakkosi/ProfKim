{
  "doc_id": "pages_233_235",
  "text": "4.1 Points and patches\n211\n(a)\n(b)\n(c)\n(d)\nFigure 4.5 Three auto-correlation surfaces EAC(∆u) shown as both grayscale images and\nsurface plots: (a) The original image is marked with three red crosses to denote where the\nauto-correlation surfaces were computed; (b) this patch is from the ﬂower bed (good unique\nminimum); (c) this patch is from the roof edge (one-dimensional aperture problem); and (d)\nthis patch is from the cloud (no good peak). Each grid point in ﬁgures b–d is one value of\n∆u.\n212\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nUsing a Taylor Series expansion of the image function I0(xi+∆u) ≈I0(xi)+∇I0(xi)·\n∆u (Lucas and Kanade 1981; Shi and Tomasi 1994), we can approximate the auto-correlation\nsurface as\nEAC(∆u)\n=\nX\ni\nw(xi)[I0(xi + ∆u) −I0(xi)]2\n(4.3)\n≈\nX\ni\nw(xi)[I0(xi) + ∇I0(xi) · ∆u −I0(xi)]2\n(4.4)\n=\nX\ni\nw(xi)[∇I0(xi) · ∆u]2\n(4.5)\n=\n∆uT A∆u,\n(4.6)\nwhere\n∇I0(xi) = (∂I0\n∂x , ∂I0\n∂y )(xi)\n(4.7)\nis the image gradient at xi. This gradient can be computed using a variety of techniques\n(Schmid, Mohr, and Bauckhage 2000). The classic “Harris” detector (Harris and Stephens\n1988) uses a [-2 -1 0 1 2] ﬁlter, but more modern variants (Schmid, Mohr, and Bauckhage\n2000; Triggs 2004) convolve the image with horizontal and vertical derivatives of a Gaussian\n(typically with σ = 1).\nThe auto-correlation matrix A can be written as\nA = w ∗\n\"\nI2\nx\nIxIy\nIxIy\nI2\ny\n#\n,\n(4.8)\nwhere we have replaced the weighted summations with discrete convolutions with the weight-\ning kernel w. This matrix can be interpreted as a tensor (multiband) image, where the outer\nproducts of the gradients ∇I are convolved with a weighting function w to provide a per-pixel\nestimate of the local (quadratic) shape of the auto-correlation function.\nAs ﬁrst shown by Anandan (1984; 1989) and further discussed in Section 8.1.3 and (8.44),\nthe inverse of the matrix A provides a lower bound on the uncertainty in the location of a\nmatching patch. It is therefore a useful indicator of which patches can be reliably matched.\nThe easiest way to visualize and reason about this uncertainty is to perform an eigenvalue\nanalysis of the auto-correlation matrix A, which produces two eigenvalues (λ0, λ1) and two\neigenvector directions (Figure 4.6). Since the larger uncertainty depends on the smaller eigen-\nvalue, i.e., λ−1/2\n0\n, it makes sense to ﬁnd maxima in the smaller eigenvalue to locate good\nfeatures to track (Shi and Tomasi 1994).\nF¨orstner–Harris.\nWhile Anandan and Lucas and Kanade (1981) were the ﬁrst to analyze\nthe uncertainty structure of the auto-correlation matrix, they did so in the context of asso-\nciating certainties with optic ﬂow measurements. F¨orstner (1986) and Harris and Stephens\n4.1 Points and patches\n213\nFigure 4.6\nUncertainty ellipse corresponding to an eigenvalue analysis of the auto-\ncorrelation matrix A.\n(1988) were the ﬁrst to propose using local maxima in rotationally invariant scalar measures\nderived from the auto-correlation matrix to locate keypoints for the purpose of sparse feature\nmatching. (Schmid, Mohr, and Bauckhage (2000); Triggs (2004) give more detailed histori-\ncal reviews of feature detection algorithms.) Both of these techniques also proposed using a\nGaussian weighting window instead of the previously used square patches, which makes the\ndetector response insensitive to in-plane image rotations.\nThe minimum eigenvalue λ0 (Shi and Tomasi 1994) is not the only quantity that can be\nused to ﬁnd keypoints. A simpler quantity, proposed by Harris and Stephens (1988), is\ndet(A) −α trace(A)2 = λ0λ1 −α(λ0 + λ1)2\n(4.9)\nwith α = 0.06. Unlike eigenvalue analysis, this quantity does not require the use of square\nroots and yet is still rotationally invariant and also downweights edge-like features where\nλ1 ≫λ0. Triggs (2004) suggests using the quantity\nλ0 −αλ1\n(4.10)\n(say, with α = 0.05), which also reduces the response at 1D edges, where aliasing errors\nsometimes inﬂate the smaller eigenvalue. He also shows how the basic 2 × 2 Hessian can be\nextended to parametric motions to detect points that are also accurately localizable in scale\nand rotation. Brown, Szeliski, and Winder (2005), on the other hand, use the harmonic mean,\ndet A\ntr A\n=\nλ0λ1\nλ0 + λ1\n,\n(4.11)\nwhich is a smoother function in the region where λ0 ≈λ1. Figure 4.7 shows isocontours\nof the various interest point operators, from which we can see how the two eigenvalues are\nblended to determine the ﬁnal interest value.",
  "image_path": "page_234.jpg",
  "pages": [
    233,
    234,
    235
  ]
}