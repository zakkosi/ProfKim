{
  "doc_id": "pages_030_032",
  "text": "8\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 1.5\nSome consumer applications of computer vision: (a) image stitching: merging\ndifferent views (Szeliski and Shum 1997) c⃝1997 ACM; (b) exposure bracketing: merging\ndifferent exposures; (c) morphing: blending between two photographs (Gomes, Darsa, Costa\net al. 1999) c⃝1999 Morgan Kaufmann; (d) turning a collection of photographs into a 3D\nmodel (Sinha, Steedly, Szeliski et al. 2008) c⃝2008 ACM.\n1.1 What is computer vision?\n9\nThe great thing about these applications is that they are already familiar to most students;\nthey are, at least, technologies that students can immediately appreciate and use with their\nown personal media. Since computer vision is a challenging topic, given the wide range\nof mathematics being covered4 and the intrinsically difﬁcult nature of the problems being\nsolved, having fun and relevant problems to work on can be highly motivating and inspiring.\nThe other major reason why this book has a strong focus on applications is that they can\nbe used to formulate and constrain the potentially open-ended problems endemic in vision.\nFor example, if someone comes to me and asks for a good edge detector, my ﬁrst question is\nusually to ask why? What kind of problem are they trying to solve and why do they believe\nthat edge detection is an important component? If they are trying to locate faces, I usually\npoint out that most successful face detectors use a combination of skin color detection (Exer-\ncise 2.8) and simple blob features Section 14.1.1; they do not rely on edge detection. If they\nare trying to match door and window edges in a building for the purpose of 3D reconstruction,\nI tell them that edges are a ﬁne idea but it is better to tune the edge detector for long edges\n(see Sections 3.2.3 and 4.2) and link them together into straight lines with common vanishing\npoints before matching (see Section 4.3).\nThus, it is better to think back from the problem at hand to suitable techniques, rather\nthan to grab the ﬁrst technique that you may have heard of. This kind of working back from\nproblems to solutions is typical of an engineering approach to the study of vision and reﬂects\nmy own background in the ﬁeld. First, I come up with a detailed problem deﬁnition and\ndecide on the constraints and speciﬁcations for the problem. Then, I try to ﬁnd out which\ntechniques are known to work, implement a few of these, evaluate their performance, and\nﬁnally make a selection. In order for this process to work, it is important to have realistic test\ndata, both synthetic, which can be used to verify correctness and analyze noise sensitivity,\nand real-world data typical of the way the system will ﬁnally be used.\nHowever, this book is not just an engineering text (a source of recipes). It also takes a\nscientiﬁc approach to basic vision problems. Here, I try to come up with the best possible\nmodels of the physics of the system at hand: how the scene is created, how light interacts\nwith the scene and atmospheric effects, and how the sensors work, including sources of noise\nand uncertainty. The task is then to try to invert the acquisition process to come up with the\nbest possible description of the scene.\nThe book often uses a statistical approach to formulating and solving computer vision\nproblems. Where appropriate, probability distributions are used to model the scene and the\nnoisy image acquisition process. The association of prior distributions with unknowns is often\n3 For a fun student project on this topic, see the “PhotoBook” project at http://www.cc.gatech.edu/dvfx/videos/\ndvfx2005.html.\n4 These techniques include physics, Euclidean and projective geometry, statistics, and optimization. They make\ncomputer vision a fascinating ﬁeld to study and a great way to learn techniques widely applicable in other ﬁelds.\n10\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\ncalled Bayesian modeling (Appendix B). It is possible to associate a risk or loss function with\nmis-estimating the answer (Section B.2) and to set up your inference algorithm to minimize\nthe expected risk. (Consider a robot trying to estimate the distance to an obstacle: it is\nusually safer to underestimate than to overestimate.) With statistical techniques, it often helps\nto gather lots of training data from which to learn probabilistic models. Finally, statistical\napproaches enable you to use proven inference techniques to estimate the best answer (or\ndistribution of answers) and to quantify the uncertainty in the resulting estimates.\nBecause so much of computer vision involves the solution of inverse problems or the esti-\nmation of unknown quantities, my book also has a heavy emphasis on algorithms, especially\nthose that are known to work well in practice. For many vision problems, it is all too easy to\ncome up with a mathematical description of the problem that either does not match realistic\nreal-world conditions or does not lend itself to the stable estimation of the unknowns. What\nwe need are algorithms that are both robust to noise and deviation from our models and rea-\nsonably efﬁcient in terms of run-time resources and space. In this book, I go into these issues\nin detail, using Bayesian techniques, where applicable, to ensure robustness, and efﬁcient\nsearch, minimization, and linear system solving algorithms to ensure efﬁciency. Most of the\nalgorithms described in this book are at a high level, being mostly a list of steps that have to\nbe ﬁlled in by students or by reading more detailed descriptions elsewhere. In fact, many of\nthe algorithms are sketched out in the exercises.\nNow that I’ve described the goals of this book and the frameworks that I use, I devote the\nrest of this chapter to two additional topics. Section 1.2 is a brief synopsis of the history of\ncomputer vision. It can easily be skipped by those who want to get to “the meat” of the new\nmaterial in this book and do not care as much about who invented what when.\nThe second is an overview of the book’s contents, Section 1.3, which is useful reading for\neveryone who intends to make a study of this topic (or to jump in partway, since it describes\nchapter inter-dependencies). This outline is also useful for instructors looking to structure\none or more courses around this topic, as it provides sample curricula based on the book’s\ncontents.\n1.2 A brief history\nIn this section, I provide a brief personal synopsis of the main developments in computer\nvision over the last 30 years (Figure 1.6); at least, those that I ﬁnd personally interesting\nand which appear to have stood the test of time. Readers not interested in the provenance\nof various ideas and the evolution of this ﬁeld should skip ahead to the book overview in\nSection 1.3.",
  "image_path": "page_031.jpg",
  "pages": [
    30,
    31,
    32
  ]
}