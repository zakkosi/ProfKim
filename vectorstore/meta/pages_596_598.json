{
  "doc_id": "pages_596_598",
  "text": "574\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 11.7: View interpolation, revisited\nCompute a dense depth map using one of the tech-\nniques you developed above and use it (or, better yet, a depth map for each source image) to\ngenerate smooth in-between views from a stereo data set.\nCompare your results against using the ground truth depth data (if available).\nWhat kinds of artifacts do you see? Can you think of ways to reduce them?\nMore details on implementing such algorithms can be found in Section 13.1 and Exercises\n13.1â€“13.4.\nEx 11.8: Multi-frame stereo\nExtend one of your previous techniques to use multiple input\nframes (Section 11.6) and try to improve the results you obtained with just two views.\nIf helpful, try using temporal selection (Kang and Szeliski 2004) to deal with the increased\nnumber of occlusions in multi-frame data sets.\nYou can also try to simultaneously estimate multiple depth maps and make them consis-\ntent (Kolmogorov and Zabih 2002; Kang and Szeliski 2004).\nTest your algorithms out on some standard multi-view data sets.\nEx 11.9: Volumetric stereo\nImplement voxel coloring (Seitz and Dyer 1999) as a simple\nextension to the plane sweep algorithm you implemented in Exercise 11.4.\n1. Instead of computing the complete DSI all at once, evaluate each plane one at a time\nfrom front to back.\n2. Tag every voxel whose photoconsistency is below a certain threshold as being part of\nthe object and remember its average (or robust) color (Seitz and Dyer 1999; Eisert,\nSteinbach, and Girod 2000; Kutulakos 2000; Slabaugh, Culbertson, Slabaugh et al.\n2004).\n3. Erase the input pixels corresponding to tagged voxels in the input images, e.g., by\nsetting their alpha value to 0 (or to some reduced number, depending on occupancy).\n4. As you evaluate the next plane, use the source image alpha values to modify your\nphotoconsistency score, e.g., only consider pixels that have full alpha or weight pixels\nby their alpha values.\n5. If the cameras are not all on the same side of your plane sweeps, use space carving\n(Kutulakos and Seitz 2000) to cycle through different subsets of source images while\ncarving away the volume from different directions.\nEx 11.10: Depth map merging\nUse the technique you developed for multi-frame stereo in\nExercise 11.8 or a different technique, such as the one described by Goesele, Snavely, Curless\net al. (2007), to compute a depth map for every input image.\n11.8 Exercises\n575\nMerge these depth maps into a coherent 3D model, e.g., using Poisson surface reconstruc-\ntion (Kazhdan, Bolitho, and Hoppe 2006).\nEx 11.11: Shape from silhouettes\nBuild a silhouette-based volume reconstruction algo-\nrithm (Section 11.6.2). Use an octree or some other representation of your choosing.\n576\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)",
  "image_path": "page_597.jpg",
  "pages": [
    596,
    597,
    598
  ]
}