{
  "doc_id": "pages_041_043",
  "text": "1.3 Book overview\n19\nDontcheva, Agrawala et al. 2004).\nTexture synthesis (Figure 1.10d) (see Section 10.5), quilting (Efros and Leung 1999; Efros\nand Freeman 2001; Kwatra, Sch¨odl, Essa et al. 2003) and inpainting (Bertalmio, Sapiro,\nCaselles et al. 2000; Bertalmio, Vese, Sapiro et al. 2003; Criminisi, P´erez, and Toyama 2004)\nare additional topics that can be classiﬁed as computational photography techniques, since\nthey re-combine input image samples to produce new photographs.\nA second notable trend during this past decade has been the emergence of feature-based\ntechniques (combined with learning) for object recognition (see Section 14.3 and Ponce,\nHebert, Schmid et al. 2006). Some of the notable papers in this area include the constellation\nmodel of Fergus, Perona, and Zisserman (2007) (Figure 1.10e) and the pictorial structures\nof Felzenszwalb and Huttenlocher (2005). Feature-based techniques also dominate other\nrecognition tasks, such as scene recognition (Zhang, Marszalek, Lazebnik et al. 2007) and\npanorama and location recognition (Brown and Lowe 2007; Schindler, Brown, and Szeliski\n2007). And while interest point (patch-based) features tend to dominate current research,\nsome groups are pursuing recognition based on contours (Belongie, Malik, and Puzicha 2002)\nand region segmentation (Figure 1.10f) (Mori, Ren, Efros et al. 2004).\nAnother signiﬁcant trend from this past decade has been the development of more efﬁcient\nalgorithms for complex global optimization problems (see Sections 3.7 and B.5 and Szeliski,\nZabih, Scharstein et al. 2008; Blake, Kohli, and Rother 2010). While this trend began with\nwork on graph cuts (Boykov, Veksler, and Zabih 2001; Kohli and Torr 2007), a lot of progress\nhas also been made in message passing algorithms, such as loopy belief propagation (LBP)\n(Yedidia, Freeman, and Weiss 2001; Kumar and Torr 2006).\nThe ﬁnal trend, which now dominates a lot of the visual recognition research in our com-\nmunity, is the application of sophisticated machine learning techniques to computer vision\nproblems (see Section 14.5.1 and Freeman, Perona, and Sch¨olkopf 2008). This trend coin-\ncides with the increased availability of immense quantities of partially labelled data on the\nInternet, which makes it more feasible to learn object categories without the use of careful\nhuman supervision.\n1.3 Book overview\nIn the ﬁnal part of this introduction, I give a brief tour of the material in this book, as well\nas a few notes on notation and some additional general references. Since computer vision is\nsuch a broad ﬁeld, it is possible to study certain aspects of it, e.g., geometric image formation\nand 3D structure recovery, without engaging other parts, e.g., the modeling of reﬂectance and\nshading. Some of the chapters in this book are only loosely coupled with others, and it is not\nstrictly necessary to read all of the material in sequence.\n20\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nImages (2D)\nGeometry (3D) \nshape\nPhotometry \nappearance\n+\nvision\ngraphics\nimage processing\n2.1 Geometric \nimage formation\n2.2 Photometric \nimage formation\n2.3 Sampling\nand aliasing\n3 Image \nprocessing\n4 Feature \ndetection\n6 Feature-based \nalignment\n7 Structure \nfrom motion\n8 Motion\nestimation\n10 Computational \nphotography\n11 Stereo \ncorrespondence\n12 3D shape \nrecovery\n12 Texture \nrecovery\n13 Image-based \nrendering\n14 Recognition\n5 Segmentation\n9 Stitching\nFigure 1.11 Relationship between images, geometry, and photometry, as well as a taxonomy\nof the topics covered in this book. Topics are roughly positioned along the left–right axis\ndepending on whether they are more closely related to image-based (left), geometry-based\n(middle) or appearance-based (right) representations, and on the vertical axis by increasing\nlevel of abstraction. The whole ﬁgure should be taken with a large grain of salt, as there are\nmany additional subtle connections between topics not illustrated here.\n1.3 Book overview\n21\nFigure 1.11 shows a rough layout of the contents of this book. Since computer vision\ninvolves going from images to a structural description of the scene (and computer graphics\nthe converse), I have positioned the chapters horizontally in terms of which major component\nthey address, in addition to vertically according to their dependence.\nGoing from left to right, we see the major column headings as Images (which are 2D\nin nature), Geometry (which encompasses 3D descriptions), and Photometry (which encom-\npasses object appearance). (An alternative labeling for these latter two could also be shape\nand appearance—see, e.g., Chapter 13 and Kang, Szeliski, and Anandan (2000).) Going\nfrom top to bottom, we see increasing levels of modeling and abstraction, as well as tech-\nniques that build on previously developed algorithms. Of course, this taxonomy should be\ntaken with a large grain of salt, as the processing and dependencies in this diagram are not\nstrictly sequential and subtle additional dependencies and relationships also exist (e.g., some\nrecognition techniques make use of 3D information). The placement of topics along the hor-\nizontal axis should also be taken lightly, as most vision algorithms involve mapping between\nat least two different representations.9\nInterspersed throughout the book are sample applications, which relate the algorithms\nand mathematical material being presented in various chapters to useful, real-world applica-\ntions. Many of these applications are also presented in the exercises sections, so that students\ncan write their own.\nAt the end of each section, I provide a set of exercises that the students can use to imple-\nment, test, and reﬁne the algorithms and techniques presented in each section. Some of the\nexercises are suitable as written homework assignments, others as shorter one-week projects,\nand still others as open-ended research problems that make for challenging ﬁnal projects.\nMotivated students who implement a reasonable subset of these exercises will, by the end of\nthe book, have a computer vision software library that can be used for a variety of interesting\ntasks and projects.\nAs a reference book, I try wherever possible to discuss which techniques and algorithms\nwork well in practice, as well as providing up-to-date pointers to the latest research results in\nthe areas that I cover. The exercises can be used to build up your own personal library of self-\ntested and validated vision algorithms, which is more worthwhile in the long term (assuming\nyou have the time) than simply pulling algorithms out of a library whose performance you do\nnot really understand.\nThe book begins in Chapter 2 with a review of the image formation processes that create\nthe images that we see and capture. Understanding this process is fundamental if you want\nto take a scientiﬁc (model-based) approach to computer vision. Students who are eager to\njust start implementing algorithms (or courses that have limited time) can skip ahead to the\n9 For an interesting comparison with what is known about the human visual system, e.g., the largely parallel what\nand where pathways, see some textbooks on human perception (Palmer 1999; Livingstone 2008).",
  "image_path": "page_042.jpg",
  "pages": [
    41,
    42,
    43
  ]
}