{
  "doc_id": "pages_409_411",
  "text": "8.1 Translational alignment\n387\nFor this reason, normalized cross-correlation is more commonly used,\nENCC(u) =\nP\ni[I0(xi) −I0] [I1(xi + u) −I1]\nqP\ni[I0(xi) −I0]2\nqP\ni[I1(xi + u) −I1]2\n,\n(8.11)\nwhere\nI0\n=\n1\nN\nX\ni\nI0(xi)\nand\n(8.12)\nI1\n=\n1\nN\nX\ni\nI1(xi + u)\n(8.13)\nare the mean images of the corresponding patches and N is the number of pixels in the patch.\nThe normalized cross-correlation score is always guaranteed to be in the range [−1, 1], which\nmakes it easier to handle in some higher-level applications, such as deciding which patches\ntruly match. Normalized correlation works well when matching images taken with different\nexposures, e.g., when creating high dynamic range images (Section 10.2). Note, however,\nthat the NCC score is undeﬁned if either of the two patches has zero variance (and, in fact, its\nperformance degrades for noisy low-contrast regions).\nA variant on NCC, which is related to the bias–gain regression implicit in the matching\nscore (8.9), is the normalized SSD score\nENSSD(u) = 1\n2\nP\ni\n\u0002\n[I0(xi) −I0] −[I1(xi + u) −I1]\n\u00032\nqP\ni[I0(xi) −I0]2 + [I1(xi + u) −I1]2\n(8.14)\nrecently proposed by Criminisi, Shotton, Blake et al. (2007). In their experiments, they ﬁnd\nthat it produces comparable results to NCC, but is more efﬁcient when applied to a large\nnumber of overlapping patches using a moving average technique (Section 3.2.2).\n8.1.1 Hierarchical motion estimation\nNow that we have a well-deﬁned alignment cost function to optimize, how can we ﬁnd its\nminimum? The simplest solution is to do a full search over some range of shifts, using ei-\nther integer or sub-pixel steps. This is often the approach used for block matching in motion\ncompensated video compression, where a range of possible motions (say, ±16 pixels) is ex-\nplored.4\nTo accelerate this search process, hierarchical motion estimation is often used: an image\npyramid (Section 3.5) is constructed and a search over a smaller number of discrete pixels\n4 In stereo matching (Section 11.1.2), an explicit search over all possible disparities (i.e., a plane sweep) is almost\nalways performed, since the number of search hypotheses is much smaller due to the 1D nature of the potential\ndisplacements.\n388\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(corresponding to the same range of motion) is ﬁrst performed at coarser levels (Quam 1984;\nAnandan 1989; Bergen, Anandan, Hanna et al. 1992). The motion estimate from one level\nof the pyramid is then used to initialize a smaller local search at the next ﬁner level. Al-\nternatively, several seeds (good solutions) from the coarse level can be used to initialize the\nﬁne-level search. While this is not guaranteed to produce the same result as a full search, it\nusually works almost as well and is much faster.\nMore formally, let\nI(l)\nk (xj) ←˜I(l−1)\nk\n(2xj)\n(8.15)\nbe the decimated image at level l obtained by subsampling (downsampling) a smoothed ver-\nsion of the image at level l−1. See Section 3.5 for how to perform the required downsampling\n(pyramid construction) without introducing too much aliasing.\nAt the coarsest level, we search for the best displacement u(l) that minimizes the dif-\nference between images I(l)\n0\nand I(l)\n1 . This is usually done using a full search over some\nrange of displacements u(l) ∈2−l[−S, S]2, where S is the desired search range at the ﬁnest\n(original) resolution level, optionally followed by the incremental reﬁnement step described\nin Section 8.1.3.\nOnce a suitable motion vector has been estimated, it is used to predict a likely displace-\nment\nˆu(l−1) ←2u(l)\n(8.16)\nfor the next ﬁner level.5 The search over displacements is then repeated at the ﬁner level over\na much narrower range of displacements, say ˆu(l−1) ± 1, again optionally combined with an\nincremental reﬁnement step (Anandan 1989). Alternatively, one of the images can be warped\n(resampled) by the current motion estimate, in which case only small incremental motions\nneed to be computed at the ﬁner level. A nice description of the whole process, extended to\nparametric motion estimation (Section 8.2), is provided by Bergen, Anandan, Hanna et al.\n(1992).\n8.1.2 Fourier-based alignment\nWhen the search range corresponds to a signiﬁcant fraction of the larger image (as is the case\nin image stitching, see Chapter 9), the hierarchical approach may not work that well, since\nit is often not possible to coarsen the representation too much before signiﬁcant features are\nblurred away. In this case, a Fourier-based approach may be preferable.\n5 This doubling of displacements is only necessary if displacements are deﬁned in integer pixel coordinates,\nwhich is the usual case in the literature (Bergen, Anandan, Hanna et al. 1992). If normalized device coordinates\n(Section 2.1.5) are used instead, the displacements (and search ranges) need not change from level to level, although\nthe step sizes will need to be adjusted, to keep search steps of roughly one pixel.\n8.1 Translational alignment\n389\nFourier-based alignment relies on the fact that the Fourier transform of a shifted signal\nhas the same magnitude as the original signal but a linearly varying phase (Section 3.4), i.e.,\nF {I1(x + u)} = F {I1(x)} e−ju·ω = I1(ω)e−ju·ω,\n(8.17)\nwhere ω is the vector-valued angular frequency of the Fourier transform and we use cal-\nligraphic notation I1(ω) = F {I1(x)} to denote the Fourier transform of a signal (Sec-\ntion 3.4).\nAnother useful property of Fourier transforms is that convolution in the spatial domain\ncorresponds to multiplication in the Fourier domain (Section 3.4).6 Thus, the Fourier trans-\nform of the cross-correlation function ECC can be written as\nF {ECC(u)} = F\n(X\ni\nI0(xi)I1(xi + u)\n)\n= F {I0(u)¯∗I1(u)} = I0(ω)I∗\n1(ω), (8.18)\nwhere\nf(u)¯∗g(u) =\nX\ni\nf(xi)g(xi + u)\n(8.19)\nis the correlation function, i.e., the convolution of one signal with the reverse of the other,\nand I∗\n1(ω) is the complex conjugate of I1(ω). This is because convolution is deﬁned as the\nsummation of one signal with the reverse of the other (Section 3.4).\nThus, to efﬁciently evaluate ECC over the range of all possible values of u, we take the\nFourier transforms of both images I0(x) and I1(x), multiply both transforms together (after\nconjugating the second one), and take the inverse transform of the result. The Fast Fourier\nTransform algorithm can compute the transform of an N × M image in O(NM log NM)\noperations (Bracewell 1986). This can be signiﬁcantly faster than the O(N 2M 2) operations\nrequired to do a full search when the full range of image overlaps is considered.\nWhile Fourier-based convolution is often used to accelerate the computation of image\ncorrelations, it can also be used to accelerate the sum of squared differences function (and its\nvariants). Consider the SSD formula given in (8.1). Its Fourier transform can be written as\nF {ESSD(u)}\n=\nF\n(X\ni\n[I1(xi + u) −I0(xi)]2\n)\n=\nδ(ω)\nX\ni\n[I2\n0(xi) + I2\n1(xi)] −2I0(ω)I∗\n1(ω).\n(8.20)\nThus, the SSD function can be computed by taking twice the correlation function and sub-\ntracting it from the sum of the energies in the two images.\n6 In fact, the Fourier shift property (8.17) derives from the convolution theorem by observing that shifting is\nequivalent to convolution with a displaced delta function δ(x −u).",
  "image_path": "page_410.jpg",
  "pages": [
    409,
    410,
    411
  ]
}