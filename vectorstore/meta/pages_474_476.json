{
  "doc_id": "pages_474_476",
  "text": "452\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nView selection.\nOnce we have chosen the output parameterization, we still need to deter-\nmine which part of the scene will be centered in the ﬁnal view. As mentioned above, for a ﬂat\ncomposite, we can choose one of the images as a reference. Often, a reasonable choice is the\none that is geometrically most central. For example, for rotational panoramas represented as\na collection of 3D rotation matrices, we can choose the image whose z-axis is closest to the\naverage z-axis (assuming a reasonable ﬁeld of view). Alternatively, we can use the average\nz-axis (or quaternion, but this is trickier) to deﬁne the reference rotation matrix.\nFor larger, e.g., cylindrical or spherical, panoramas, we can use the same heuristic if a\nsubset of the viewing sphere has been imaged. In the case of full 360◦panoramas, a better\nchoice might be to choose the middle image from the sequence of inputs, or sometimes the\nﬁrst image, assuming this contains the object of greatest interest. In all of these cases, having\nthe user control the ﬁnal view is often highly desirable. If the “up vector” computation de-\nscribed in Section 9.2.1 is working correctly, this can be as simple as panning over the image\nor setting a vertical “center line” for the ﬁnal panorama.\nCoordinate transformations.\nAfter selecting the parameterization and reference view, we\nstill need to compute the mappings between the input and output pixels coordinates.\nIf the ﬁnal compositing surface is ﬂat (e.g., a single plane or the face of a cube map)\nand the input images have no radial distortion, the coordinate transformation is the simple\nhomography described by (9.5). This kind of warping can be performed in graphics hardware\nby appropriately setting texture mapping coordinates and rendering a single quadrilateral.\nIf the ﬁnal composite surface has some other analytic form (e.g., cylindrical or spherical),\nwe need to convert every pixel in the ﬁnal panorama into a viewing ray (3D point) and then\nmap it back into each image according to the projection (and optionally radial distortion)\nequations. This process can be made more efﬁcient by precomputing some lookup tables,\ne.g., the partial trigonometric functions needed to map cylindrical or spherical coordinates to\n3D coordinates or the radial distortion ﬁeld at each pixel. It is also possible to accelerate this\nprocess by computing exact pixel mappings on a coarser grid and then interpolating these\nvalues.\nWhen the ﬁnal compositing surface is a texture-mapped polyhedron, a slightly more so-\nphisticated algorithm must be used. Not only do the 3D and texture map coordinates have to\nbe properly handled, but a small amount of overdraw outside the triangle footprints in the tex-\nture map is necessary, to ensure that the texture pixels being interpolated during 3D rendering\nhave valid values (Szeliski and Shum 1997).\nSampling issues.\nWhile the above computations can yield the correct (fractional) pixel\naddresses in each input image, we still need to pay attention to sampling issues. For example,\nfor “little planet projection”.\n9.3 Compositing\n453\nif the ﬁnal panorama has a lower resolution than the input images, pre-ﬁltering the input\nimages is necessary to avoid aliasing. These issues have been extensively studied in both the\nimage processing and computer graphics communities. The basic problem is to compute the\nappropriate pre-ﬁlter, which depends on the distance (and arrangement) between neighboring\nsamples in a source image. As discussed in Sections 3.5.2 and 3.6.1, various approximate\nsolutions, such as MIP mapping (Williams 1983) or elliptically weighted Gaussian averaging\n(Greene and Heckbert 1986) have been developed in the graphics community. For highest\nvisual quality, a higher order (e.g., cubic) interpolator combined with a spatially adaptive pre-\nﬁlter may be necessary (Wang, Kang, Szeliski et al. 2001). Under certain conditions, it may\nalso be possible to produce images with a higher resolution than the input images using the\nprocess of super-resolution (Section 10.3).\n9.3.2 Pixel selection and weighting (de-ghosting)\nOnce the source pixels have been mapped onto the ﬁnal composite surface, we must still\ndecide how to blend them in order to create an attractive-looking panorama. If all of the\nimages are in perfect registration and identically exposed, this is an easy problem, i.e., any\npixel or combination will do. However, for real images, visible seams (due to exposure\ndifferences), blurring (due to mis-registration), or ghosting (due to moving objects) can occur.\nCreating clean, pleasing-looking panoramas involves both deciding which pixels to use\nand how to weight or blend them. The distinction between these two stages is a little ﬂuid,\nsince per-pixel weighting can be thought of as a combination of selection and blending. In\nthis section, we discuss spatially varying weighting, pixel selection (seam placement), and\nthen more sophisticated blending.\nFeathering and center-weighting.\nThe simplest way to create a ﬁnal composite is to sim-\nply take an average value at each pixel,\nC(x) =\nX\nk\nwk(x)˜Ik(x)\n,X\nk\nwk(x) ,\n(9.37)\nwhere ˜Ik(x) are the warped (re-sampled) images and wk(x) is 1 at valid pixels and 0 else-\nwhere. On computer graphics hardware, this kind of summation can be performed in an\naccumulation buffer (using the A channel as the weight).\nSimple averaging usually does not work very well, since exposure differences, mis-\nregistrations, and scene movement are all very visible (Figure 9.14a). If rapidly moving\nobjects are the only problem, taking a median ﬁlter (which is a kind of pixel selection opera-\ntor) can often be used to remove them (Figure 9.14b) (Irani and Anandan 1998). Conversely,\ncenter-weighting (discussed below) and minimum likelihood selection (Agarwala, Dontcheva,\n454\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 9.14\nFinal composites computed by a variety of algorithms (Szeliski 2006a): (a)\naverage, (b) median, (c) feathered average, (d) p-norm p = 10, (e) Voronoi, (f) weighted\nROD vertex cover with feathering, (g) graph cut seams with Poisson blending and (h) with\npyramid blending.",
  "image_path": "page_475.jpg",
  "pages": [
    474,
    475,
    476
  ]
}