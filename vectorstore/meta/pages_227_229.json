{
  "doc_id": "pages_227_229",
  "text": "Chapter 4\nFeature detection and matching\n4.1\nPoints and patches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n4.1.1\nFeature detectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\n4.1.2\nFeature descriptors . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\n4.1.3\nFeature matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\n4.1.4\nFeature tracking\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\n4.1.5\nApplication: Performance-driven animation . . . . . . . . . . . . . . 237\n4.2\nEdges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n4.2.1\nEdge detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n4.2.2\nEdge linking\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\n4.2.3\nApplication: Edge editing and enhancement . . . . . . . . . . . . . . 249\n4.3\nLines\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\n4.3.1\nSuccessive approximation\n. . . . . . . . . . . . . . . . . . . . . . . 250\n4.3.2\nHough transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\n4.3.3\nVanishing points\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 254\n4.3.4\nApplication: Rectangle detection . . . . . . . . . . . . . . . . . . . . 257\n4.4\nAdditional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257\n4.5\nExercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n206\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 4.1 A variety of feature detectors and descriptors can be used to analyze, describe and\nmatch images: (a) point-like interest operators (Brown, Szeliski, and Winder 2005) c⃝2005\nIEEE; (b) region-like interest operators (Matas, Chum, Urban et al. 2004) c⃝2004 Elsevier;\n(c) edges (Elder and Goldberg 2001) c⃝2001 IEEE; (d) straight lines (Sinha, Steedly, Szeliski\net al. 2008) c⃝2008 ACM.\n4.1 Points and patches\n207\nFeature detection and matching are an essential component of many computer vision appli-\ncations. Consider the two pairs of images shown in Figure 4.2. For the ﬁrst pair, we may\nwish to align the two images so that they can be seamlessly stitched into a composite mosaic\n(Chapter 9). For the second pair, we may wish to establish a dense set of correspondences so\nthat a 3D model can be constructed or an in-between view can be generated (Chapter 11). In\neither case, what kinds of features should you detect and then match in order to establish such\nan alignment or set of correspondences? Think about this for a few moments before reading\non.\nThe ﬁrst kind of feature that you may notice are speciﬁc locations in the images, such as\nmountain peaks, building corners, doorways, or interestingly shaped patches of snow. These\nkinds of localized feature are often called keypoint features or interest points (or even corners)\nand are often described by the appearance of patches of pixels surrounding the point location\n(Section 4.1). Another class of important features are edges, e.g., the proﬁle of mountains\nagainst the sky, (Section 4.2). These kinds of features can be matched based on their orien-\ntation and local appearance (edge proﬁles) and can also be good indicators of object bound-\naries and occlusion events in image sequences. Edges can be grouped into longer curves and\nstraight line segments, which can be directly matched or analyzed to ﬁnd vanishing points\nand hence internal and external camera parameters (Section 4.3).\nIn this chapter, we describe some practical approaches to detecting such features and\nalso discuss how feature correspondences can be established across different images. Point\nfeatures are now used in such a wide variety of applications that it is good practice to read and\nimplement some of the algorithms from (Section 4.1). Edges and lines provide information\nthat is complementary to both keypoint and region-based descriptors and are well-suited to\ndescribing object boundaries and man-made objects. These alternative descriptors, while\nextremely useful, can be skipped in a short introductory course.\n4.1 Points and patches\nPoint features can be used to ﬁnd a sparse set of corresponding locations in different im-\nages, often as a pre-cursor to computing camera pose (Chapter 7), which is a prerequisite for\ncomputing a denser set of correspondences using stereo matching (Chapter 11). Such corre-\nspondences can also be used to align different images, e.g., when stitching image mosaics or\nperforming video stabilization (Chapter 9). They are also used extensively to perform object\ninstance and category recognition (Sections 14.3 and 14.4). A key advantage of keypoints\nis that they permit matching even in the presence of clutter (occlusion) and large scale and\norientation changes.\nFeature-based correspondence techniques have been used since the early days of stereo",
  "image_path": "page_228.jpg",
  "pages": [
    227,
    228,
    229
  ]
}