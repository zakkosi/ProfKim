{
  "doc_id": "pages_690_692",
  "text": "668\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 14.9\nPart-based object detection (Felzenszwalb, McAllester, and Ramanan 2008)\nc⃝2008 IEEE: (a) An input photograph and its associated person (blue) and part (yellow)\ndetection results. (b) The detection model is deﬁned by a coarse template, several higher\nresolution part templates, and a spatial model for the location of each part. (c) True positive\ndetection of a skier and (d) false positive detection of a cow (labeled as a person).\nclude the work by Andriluka, Roth, and Schiele (2009) and Kumar, Zisserman, and H.S.Torr\n(2009).\nAn even more accurate estimate of a person’s pose and location is presented by Rogez,\nRihan, Ramalingam et al. (2008), who compute both the phase of a person in a walk cycle and\nthe locations of individual joints, using random forests built on top of HOGs (Figure 14.11).\nSince their system produces full 3D pose information, it is closer in its application domain to\n3D person trackers (Sidenbladh, Black, and Fleet 2000; Andriluka, Roth, and Schiele 2010),\nwhich we discussed in Section 12.6.4.\nOne ﬁnal note on person and object detection. When video sequences are available, the\nadditional information present in the optic ﬂow and motion discontinuities can greatly aid in\nthe detection task, as discussed by Efros, Berg, Mori et al. (2003), Viola, Jones, and Snow\n(2003), and Dalal, Triggs, and Schmid (2006).\n14.2 Face recognition\nAmong the various recognition tasks that computers might be asked to perform, face recog-\nnition is the one where they have arguably had the most success.5 While computers cannot\npick out suspects from thousands of people streaming in front of video cameras (even people\ncannot readily distinguish between similar people with whom they are not familiar (O’Toole,\nJiang, Roark et al. 2006; O’Toole, Phillips, Jiang et al. 2009)), their ability to distinguish\n5Instance recognition, i.e., the re-recognition of known objects such as locations or planar objects, is the other\nmost successful application of general image recognition. In the general domain of biometrics, i.e., identity recogni-\ntion, specialized images such as irises and ﬁngerprints perform even better (Jain, Bolle, and Pankanti 1999; Pankanti,\nBolle, and Jain 2000; Daugman 2004).\n14.2 Face recognition\n669\nFigure 14.10\nPart-based object detection results for people, bicycles, and horses (Felzen-\nszwalb, McAllester, and Ramanan 2008) c⃝2008 IEEE. The ﬁrst three columns show correct\ndetections, while the rightmost column shows false positives.\nFigure 14.11 Pose detection using random forests (Rogez, Rihan, Ramalingam et al. 2008)\nc⃝2008 IEEE. The estimated pose (state of the kinematic model) is drawn over each input\nframe.\n670\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 14.12 Humans can recognize low-resolution faces of familiar people (Sinha, Balas,\nOstrovsky et al. 2006) c⃝2006 IEEE.\namong a small number of family members and friends has found its way into consumer-level\nphoto applications, such as Picasa and iPhoto. Face recognition can also be used in a variety\nof additional applications, including human–computer interaction (HCI), identity veriﬁcation\n(Kirovski, Jojic, and Jancke 2004), desktop login, parental controls, and patient monitoring\n(Zhao, Chellappa, Phillips et al. 2003).\nToday’s face recognizers work best when they are given full frontal images of faces under\nrelatively uniform illumination conditions, although databases that include large amounts\nof pose and lighting variation have been collected (Phillips, Moon, Rizvi et al. 2000; Sim,\nBaker, and Bsat 2003; Gross, Shi, and Cohn 2005; Huang, Ramesh, Berg et al. 2007; Phillips,\nScruggs, O’Toole et al. 2010). (See Table 14.1 in Section 14.6 for more details.)\nSome of the earliest approaches to face recognition involved ﬁnding the locations of\ndistinctive image features, such as the eyes, nose, and mouth, and measuring the distances\nbetween these feature locations (Fischler and Elschlager 1973; Kanade 1977; Yuille 1991).\nMore recent approaches rely on comparing gray-level images projected onto lower dimen-\nsional subspaces called eigenfaces (Section 14.2.1) and jointly modeling shape and appear-\nance variations (while discounting pose variations) using active appearance models (Sec-\ntion 14.2.2).\nDescriptions of additional face recognition techniques can be found in a number of sur-\nveys and books on this topic (Chellappa, Wilson, and Sirohey 1995; Zhao, Chellappa, Phillips\net al. 2003; Li and Jain 2005) as well as the Face Recognition Web site.6 The survey on face\nrecognition by humans by Sinha, Balas, Ostrovsky et al. (2006) is also well worth reading; it\nincludes a number of surprising results, such as humans’ ability to recognize low-resolution\nimages of familiar faces (Figure 14.12) and the importance of eyebrows in recognition.\n6 http://www.face-rec.org/.",
  "image_path": "page_691.jpg",
  "pages": [
    690,
    691,
    692
  ]
}