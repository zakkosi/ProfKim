{
  "doc_id": "pages_551_553",
  "text": "10.7 Exercises\n529\nEx 10.7: Super-resolution\nImplement one or more super-resolution algorithms and com-\npare their performance.\n1. Take a set of photographs of the same scene using a hand-held camera (to ensure that\nthere is some jitter between the photographs).\n2. Determine the PSF for the images you are trying to super-resolve using one of the\ntechniques in Exercise 10.4.\n3. Alternatively, simulate a collection of lower-resolution images by taking a high-quality\nphotograph (avoid those with compression artifacts) and applying your own pre-ﬁlter\nkernel and downsampling.\n4. Estimate the relative motion between the images using a parametric translation and\nrotation motion estimation algorithm (Sections 6.1.3 or 8.2).\n5. Implement a basic least squares super-resolution algorithm by minimizing the differ-\nence between the observed and downsampled images (10.27–10.28).\n6. Add in a gradient image prior, either as another least squares term or as a robust term\nthat can be minimized using iteratively reweighted least squares (Appendix A.3).\n7. (Optional) Implement one of the example-based super-resolution techniques, where\nmatching against a set of exemplar images is used either to infer higher-frequency\ninformation to be added to the reconstruction (Freeman, Jones, and Pasztor 2002)\nor higher-frequency gradients to be matched in the super-resolved image (Baker and\nKanade 2002).\n8. (Optional) Use local edge statistic information to improve the quality of the super-\nresolved image (Fattal 2007).\nEx 10.8: Image matting\nDevelop an algorithm for pulling a foreground matte from natural\nimages, as described in Section 10.4.\n1. Make sure that the images you are taking are linearized (Exercise 10.1 and Section 10.1)\nand that your camera exposure is ﬁxed (full manual mode), at least when taking multi-\nple shots of the same scene.\n2. To acquire ground truth data, place your object in front of a computer monitor and\ndisplay a variety of solid background colors as well as some natural imagery.\n3. Remove your object and re-display the same images to acquire known background\ncolors.\n530\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n4. Use triangulation matting (Smith and Blinn 1996) to estimate the ground truth opacities\nα and pre-multiplied foreground colors αF for your objects.\n5. Implement one or more of the natural image matting algorithms described in Sec-\ntion 10.4 and compare your results to the ground truth values you computed. Alter-\nnatively, use the matting test images published on http://alphamatting.com/.\n6. (Optional) Run your algorithms on other images taken with the same calibrated camera\n(or other images you ﬁnd interesting).\nEx 10.9: Smoke and shadow matting\nExtract smoke or shadow mattes from one scene\nand insert them into another (Chuang, Agarwala, Curless et al. 2002; Chuang, Goldman,\nCurless et al. 2003).\n1. Take a still or video sequence of images with and without some intermittent smoke and\nshadows. (Remember to linearize your images before proceeding with any computa-\ntions.)\n2. For each pixel, ﬁt a line to the observed color values.\n3. If performing smoke matting, robustly compute the intersection of these lines to obtain\nthe smoke color estimate. Then, estimate the background color as the other extremum\n(unless you already took a smoke-free background image).\nIf performing shadow matting, compute robust shadow (minimum) and lit (maximum)\nvalues for each pixel.\n4. Extract the smoke or shadow mattes from each frame as the fraction between these two\nvalues (background and smoke or shadowed and lit).\n5. Scan a new (destination) scene or modify the original background with an image editor.\n6. Re-insert the smoke or shadow matte, along with any other foreground objects you may\nhave extracted.\n7. (Optional) Using a series of cast stick shadows, estimate the deformation ﬁeld for the\ndestination scene in order to correctly warp (drape) the shadows across the new ge-\nometry. (This is related to the shadow scanning technique developed by Bouguet and\nPerona (1999) and implemented in Exercise 12.2.)\n8. (Optional) Chuang, Goldman, Curless et al. (2003) only demonstrated their technique\nfor planar source geometries. Can you extend their technique to capture shadows ac-\nquired from an irregular source geometry?\n10.7 Exercises\n531\n9. (Optional) Can you change the direction of the shadow, i.e., simulate the effect of\nchanging the light source direction?\nEx 10.10: Texture synthesis\nImplement one of the texture synthesis or hole ﬁlling algo-\nrithms presented in Section 10.5. Here is one possible procedure:\n1. Implement the basic Efros and Leung (1999) algorithm, i.e., starting from the outside\n(for hole ﬁlling) or in raster order (for texture synthesis), search for a similar neighbor-\nhood in the source texture image, and copy that pixel.\n2. Add in the Wei and Levoy (2000) extension of generating the pixels in a coarse-to-ﬁne\nfashion, i.e., generate a lower-resolution synthetic texture (or ﬁlled image), and use this\nas a guide for matching regions in the ﬁner resolution version.\n3. Add in the Criminisi, P´erez, and Toyama (2004) idea of prioritizing pixels to be ﬁlled\nby some function of the local structure (gradient or orientation strength).\n4. Extend any of the above algorithms by selecting sub-blocks in the source texture and\nusing optimization to determine the seam between the new block and the existing image\nthat it overlaps (Efros and Freeman 2001).\n5. (Optional) Implement one of the isophote (smooth continuation) inpainting algorithms\n(Bertalmio, Sapiro, Caselles et al. 2000; Telea 2004).\n6. (Optional) Add the ability to supply a target (reference) image (Efros and Freeman\n2001) or to provide sample ﬁltered or unﬁltered (reference and rendered) images (Hertz-\nmann, Jacobs, Oliver et al. 2001), see Section 10.5.2.\nEx 10.11: Colorization\nImplement the Levin, Lischinski, and Weiss (2004) colorization al-\ngorithm that is sketched out in Section 10.3.2 and Figure 10.37. Find some historic monochrome\nphotographs and some modern color ones. Write an interactive tool that lets you “pick” col-\nors from a modern photo and paint over the old one. Tune the algorithm parameters to give\nyou good results. Are you pleased with the results? Can you think of ways to make them\nlook more “antique”, e.g., with softer (less saturated and edgy) colors?",
  "image_path": "page_552.jpg",
  "pages": [
    551,
    552,
    553
  ]
}