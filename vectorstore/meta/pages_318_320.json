{
  "doc_id": "pages_318_320",
  "text": "296\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nA\nA\nA\nA\nB\nB\nB\nA\nB\nsum\nA\nassoc(A, A)\ncut(A, B)\nassoc(A, V )\nB\ncut(B, A)\nassoc(B, B)\nassoc(B, V )\nsum\nassoc(A, V )\nassoc(B, v)\n(a)\n(b)\nFigure 5.19\nSample weighted graph and its normalized cut: (a) a small sample graph and\nits smallest normalized cut; (b) tabular form of the associations and cuts for this graph. The\nassoc and cut entries are computed as area sums of the associated weight matrix W (Fig-\nure 5.20). Normalizing the table entries by the row or column sums produces normalized\nassociations and cuts Nassoc and Ncut.\n5.4 Normalized cuts\nWhile bottom-up merging techniques aggregate regions into coherent wholes and mean-shift\ntechniques try to ﬁnd clusters of similar pixels using mode ﬁnding, the normalized cuts\ntechnique introduced by Shi and Malik (2000) examines the afﬁnities (similarities) between\nnearby pixels and tries to separate groups that are connected by weak afﬁnities.\nConsider the simple graph shown in Figure 5.19a. The pixels in group A are all strongly\nconnected with high afﬁnities, shown as thick red lines, as are the pixels in group B. The\nconnections between these two groups, shown as thinner blue lines, are much weaker. A\nnormalized cut between the two groups, shown as a dashed line, separates them into two\nclusters.\nThe cut between two groups A and B is deﬁned as the sum of all the weights being cut,\ncut(A, B) =\nX\ni∈A,j∈B\nwij,\n(5.43)\nwhere the weights between two pixels (or regions) i and j measure their similarity. Using\na minimum cut as a segmentation criterion, however, does not result in reasonable clusters,\nsince the smallest cuts usually involve isolating a single pixel.\nA better measure of segmentation is the normalized cut, which is deﬁned as\nNcut(A, B) =\ncut(A, B)\nassoc(A, V ) +\ncut(A, B)\nassoc(B, V ),\n(5.44)\nwhere assoc(A, A) = P\ni∈A,j∈A wij is the association (sum of all the weights) within a\ncluster and assoc(A, V ) = assoc(A, A) + cut(A, B) is the sum of all the weights associated\n5.4 Normalized cuts\n297\nwith nodes in A. Figure 5.19b shows how the cuts and associations can be thought of as area\nsums in the weight matrix W = [wij], where the entries of the matrix have been arranged so\nthat the nodes in A come ﬁrst and the nodes in B come second. Figure 5.20 shows an actual\nweight matrix for which these area sums can be computed. Dividing each of these areas by\nthe corresponding row sum (the rightmost column of Figure 5.19b) results in the normalized\ncut and association values. These normalized values better reﬂect the ﬁtness of a particular\nsegmentation, since they look for collections of edges that are weak relative to all of the edges\nboth inside and emanating from a particular region.\nUnfortunately, computing the optimal normalized cut is NP-complete. Instead, Shi and\nMalik (2000) suggest computing a real-valued assignment of nodes to groups. Let x be the\nindicator vector where xi = +1 iff i ∈A and xi = −1 iff i ∈B. Let d = W 1 be the row\nsums of the symmetric matrix W and D = diag(d) be the corresponding diagonal matrix.\nShi and Malik (2000) show that minimizing the normalized cut over all possible indicator\nvectors x is equivalent to minimizing\nmin\ny\nyT (D −W )y\nyT Dy\n,\n(5.45)\nwhere y = ((1+x)−b(1−x))/2 is a vector consisting of all 1s and −bs such that y·d = 0.\nMinimizing this Rayleigh quotient is equivalent to solving the generalized eigenvalue system\n(D −W )y = λDy,\n(5.46)\nwhich can be turned into a regular eigenvalue problem\n(I −N)z = λz,\n(5.47)\nwhere N = D−1/2W D−1/2 is the normalized afﬁnity matrix (Weiss 1999) and z =\nD1/2y. Because these eigenvectors can be interpreted as the large modes of vibration in\na spring-mass system, normalized cuts is an example of a spectral method for image segmen-\ntation.\nExtending an idea originally proposed by Scott and Longuet-Higgins (1990), Weiss (1999)\nsuggests normalizing the afﬁnity matrix and then using the top k eigenvectors to reconstitute a\nQ matrix. Other papers have extended the basic normalized cuts framework by modifying the\nafﬁnity matrix in different ways, ﬁnding better discrete solutions to the minimization prob-\nlem, or applying multi-scale techniques (Meil˘a and Shi 2000, 2001; Ng, Jordan, and Weiss\n2001; Yu and Shi 2003; Cour, B´en´ezit, and Shi 2005; Tolliver and Miller 2006).\nFigure 5.20b shows the second smallest (real-valued) eigenvector corresponding to the\nweight matrix shown in Figure 5.20a. (Here, the rows have been permuted to separate the\ntwo groups of variables that belong to the different components of this eigenvector.) Af-\nter this real-valued vector is computed, the variables corresponding to positive and negative\n298\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\nFigure 5.20 Sample weight table and its second smallest eigenvector (Shi and Malik 2000)\nc⃝2000 IEEE: (a) sample 32 × 32 weight matrix W ; (b) eigenvector corresponding to the\nsecond smallest eigenvalue of the generalized eigenvalue problem (D −W )y = λDy.\neigenvector values are associated with the two cut components. This process can be further\nrepeated to hierarchically subdivide an image, as shown in Figure 5.21.\nThe original algorithm proposed by Shi and Malik (2000) used spatial position and image\nfeature differences to compute the pixel-wise afﬁnities,\nwij = exp\n\u0012\n−∥F i −F j∥2\nσ2\nF\n−∥xi −xj∥2\nσ2s\n\u0013\n,\n(5.48)\nfor pixels within a radius ∥xi −xj∥< r, where F is a feature vector that consists of intensi-\nties, colors, or oriented ﬁlter histograms. (Note how (5.48) is the negative exponential of the\njoint feature space distance (5.42).)\nIn subsequent work, Malik, Belongie, Leung et al. (2001) look for intervening contours\nbetween pixels i and j and deﬁne an intervening contour weight\nwIC\nij = 1 −max\nx∈lij pcon(x),\n(5.49)\nwhere lij is the image line joining pixels i and j and pcon(x) is the probability of an inter-\nvening contour perpendicular to this line, which is deﬁned as the negative exponential of the\noriented energy in the perpendicular direction. They multiply these weights with a texton-\nbased texture similarity metric and use an initial over-segmentation based purely on local\npixel-wise features to re-estimate intervening contours and texture statistics in a region-based\nmanner. Figure 5.22 shows the results of running this improved algorithm on a number of\ntest images.\nBecause it requires the solution of large sparse eigenvalue problems, normalized cuts can\nbe quite slow. Sharon, Galun, Sharon et al. (2006) present a way to accelerate the com-\nputation of the normalized cuts using an approach inspired by algebraic multigrid (Brandt",
  "image_path": "page_319.jpg",
  "pages": [
    318,
    319,
    320
  ]
}