{
  "doc_id": "pages_411_413",
  "text": "8.1 Translational alignment\n389\nFourier-based alignment relies on the fact that the Fourier transform of a shifted signal\nhas the same magnitude as the original signal but a linearly varying phase (Section 3.4), i.e.,\nF {I1(x + u)} = F {I1(x)} e−ju·ω = I1(ω)e−ju·ω,\n(8.17)\nwhere ω is the vector-valued angular frequency of the Fourier transform and we use cal-\nligraphic notation I1(ω) = F {I1(x)} to denote the Fourier transform of a signal (Sec-\ntion 3.4).\nAnother useful property of Fourier transforms is that convolution in the spatial domain\ncorresponds to multiplication in the Fourier domain (Section 3.4).6 Thus, the Fourier trans-\nform of the cross-correlation function ECC can be written as\nF {ECC(u)} = F\n(X\ni\nI0(xi)I1(xi + u)\n)\n= F {I0(u)¯∗I1(u)} = I0(ω)I∗\n1(ω), (8.18)\nwhere\nf(u)¯∗g(u) =\nX\ni\nf(xi)g(xi + u)\n(8.19)\nis the correlation function, i.e., the convolution of one signal with the reverse of the other,\nand I∗\n1(ω) is the complex conjugate of I1(ω). This is because convolution is deﬁned as the\nsummation of one signal with the reverse of the other (Section 3.4).\nThus, to efﬁciently evaluate ECC over the range of all possible values of u, we take the\nFourier transforms of both images I0(x) and I1(x), multiply both transforms together (after\nconjugating the second one), and take the inverse transform of the result. The Fast Fourier\nTransform algorithm can compute the transform of an N × M image in O(NM log NM)\noperations (Bracewell 1986). This can be signiﬁcantly faster than the O(N 2M 2) operations\nrequired to do a full search when the full range of image overlaps is considered.\nWhile Fourier-based convolution is often used to accelerate the computation of image\ncorrelations, it can also be used to accelerate the sum of squared differences function (and its\nvariants). Consider the SSD formula given in (8.1). Its Fourier transform can be written as\nF {ESSD(u)}\n=\nF\n(X\ni\n[I1(xi + u) −I0(xi)]2\n)\n=\nδ(ω)\nX\ni\n[I2\n0(xi) + I2\n1(xi)] −2I0(ω)I∗\n1(ω).\n(8.20)\nThus, the SSD function can be computed by taking twice the correlation function and sub-\ntracting it from the sum of the energies in the two images.\n6 In fact, the Fourier shift property (8.17) derives from the convolution theorem by observing that shifting is\nequivalent to convolution with a displaced delta function δ(x −u).\n390\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWindowed correlation.\nUnfortunately, the Fourier convolution theorem only applies when\nthe summation over xi is performed over all the pixels in both images, using a circular shift\nof the image when accessing pixels outside the original boundaries. While this is acceptable\nfor small shifts and comparably sized images, it makes no sense when the images overlap by\na small amount or one image is a small subset of the other.\nIn that case, the cross-correlation function should be replaced with a windowed (weighted)\ncross-correlation function,\nEWCC(u)\n=\nX\ni\nw0(xi)I0(xi) w1(xi + u)I1(xi + u),\n(8.21)\n=\n[w0(x)I0(x)]¯∗[w1(x)I1(x)]\n(8.22)\nwhere the weighting functions w0 and w1 are zero outside the valid ranges of the images\nand both images are padded so that circular shifts return 0 values outside the original image\nboundaries.\nAn even more interesting case is the computation of the weighted SSD function intro-\nduced in Equation (8.5),\nEWSSD(u)\n=\nX\ni\nw0(xi)w1(xi + u)[I1(xi + u) −I0(xi)]2.\n(8.23)\nExpanding this as a sum of correlations and deriving the appropriate set of Fourier transforms\nis left for Exercise 8.1.\nThe same kind of derivation can also be applied to the bias–gain corrected sum of squared\ndifference function EBG (8.9). Again, Fourier transforms can be used to efﬁciently compute\nall the correlations needed to perform the linear regression in the bias and gain parameters in\norder to estimate the exposure-compensated difference for each potential shift (Exercise 8.1).\nPhase correlation.\nA variant of regular correlation (8.18) that is sometimes used for motion\nestimation is phase correlation (Kuglin and Hines 1975; Brown 1992). Here, the spectrum of\nthe two signals being matched is whitened by dividing each per-frequency product in (8.18)\nby the magnitudes of the Fourier transforms,\nF {EPC(u)} =\nI0(ω)I∗\n1(ω)\n∥I0(ω)∥∥I1(ω)∥\n(8.24)\nbefore taking the ﬁnal inverse Fourier transform. In the case of noiseless signals with perfect\n(cyclic) shift, we have I1(x + u) = I0(x) and hence, from Equation (8.17), we obtain\nF {I1(x + u)}\n=\nI1(ω)e−2πju·ω = I0(ω) and\nF {EPC(u)}\n=\ne−2πju·ω.\n(8.25)\n8.1 Translational alignment\n391\nThe output of phase correlation (under ideal conditions) is therefore a single spike (impulse)\nlocated at the correct value of u, which (in principle) makes it easier to ﬁnd the correct\nestimate.\nPhase correlation has a reputation in some quarters of outperforming regular correlation,\nbut this behavior depends on the characteristics of the signals and noise. If the original images\nare contaminated by noise in a narrow frequency band (e.g., low-frequency noise or peaked\nfrequency “hum”), the whitening process effectively de-emphasizes the noise in these regions.\nHowever, if the original signals have very low signal-to-noise ratio at some frequencies (say,\ntwo blurry or low-textured images with lots of high-frequency noise), the whitening process\ncan actually decrease performance (see Exercise 8.1).\nRecently, gradient cross-correlation has emerged as a promising alternative to phase cor-\nrelation (Argyriou and Vlachos 2003), although further systematic studies are probably war-\nranted. Phase correlation has also been studied by Fleet and Jepson (1990) as a method for\nestimating general optical ﬂow and stereo disparity.\nRotations and scale.\nWhile Fourier-based alignment is mostly used to estimate transla-\ntional shifts between images, it can, under certain limited conditions, also be used to estimate\nin-plane rotations and scales. Consider two images that are related purely by rotation, i.e.,\nI1( ˆRx) = I0(x).\n(8.26)\nIf we re-sample the images into polar coordinates,\n˜I0(r, θ) = I0(r cos θ, r sin θ) and ˜I1(r, θ) = I1(r cos θ, r sin θ),\n(8.27)\nwe obtain\n˜I1(r, θ + ˆθ) = ˜I0(r, θ).\n(8.28)\nThe desired rotation can then be estimated using a Fast Fourier Transform (FFT) shift-based\ntechnique.\nIf the two images are also related by a scale,\nI1(eˆs ˆRx) = I0(x),\n(8.29)\nwe can re-sample into log-polar coordinates,\n˜I0(s, θ) = I0(es cos θ, es sin θ) and ˜I1(s, θ) = I1(es cos θ, es sin θ),\n(8.30)\nto obtain\n˜I1(s + ˆs, θ + ˆθ) = I0(s, θ).\n(8.31)",
  "image_path": "page_412.jpg",
  "pages": [
    411,
    412,
    413
  ]
}