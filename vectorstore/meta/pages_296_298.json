{
  "doc_id": "pages_296_298",
  "text": "274\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 5.4\nPoint distribution model for a set of resistors (Cootes, Cooper, Taylor et al.\n1995) c⃝1995 Elsevier: (a) set of input resistor shapes; (b) assignment of control points\nto the boundary; (c) distribution (scatter plot) of point locations; (d) ﬁrst (largest) mode of\nvariation in the ensemble shapes.\nIf the object being tracked or recognized has large variations in location, scale, or ori-\nentation, these can be modeled as an additional transformation on the control points, e.g.,\nx′\nk = sRxk + t (2.18), which can be estimated at the same time as the values of the control\npoints. Alternatively, separate detection and alignment stages can be run to ﬁrst localize and\norient the objects of interest (Cootes, Cooper, Taylor et al. 1995).\nIn a B-snake, because the snake is controlled by fewer degrees of freedom, there is less\nneed for the internal smoothness forces used with the original snakes, although these can still\nbe derived and implemented using ﬁnite element analysis, i.e., taking derivatives and integrals\nof the B-spline basis functions (Terzopoulos 1983; Bathe 2007).\nIn practice, it is more common to estimate a set of shape priors on the typical distribution\nof the control points {xk} (Cootes, Cooper, Taylor et al. 1995). Consider the set of resistor\nshapes shown in Figure 5.4a. If we describe each contour with the set of control points\nshown in Figure 5.4b, we can plot the distribution of each point in a scatter plot, as shown in\nFigure 5.4c.\nOne potential way of describing this distribution would be by the location ¯xk and 2D\ncovariance Ck of each individual point xk. These could then be turned into a quadratic\npenalty (prior energy) on the point location,\nEloc(xk) = 1\n2(xk −¯xk)T C−1\nk (xk −¯xk).\n(5.13)\nIn practice, however, the variation in point locations is usually highly correlated.\nA preferable approach is to estimate the joint covariance of all the points simultaneously.\nFirst, concatenate all of the point locations {xk} into a single vector x, e.g., by interleaving\nthe x and y locations of each point. The distribution of these vectors across all training\n5.1 Active contours\n275\n(a)\n(b)\nFigure 5.5 Active Shape Model (ASM): (a) the effect of varying the ﬁrst four shape param-\neters for a set of faces (Cootes, Taylor, Lanitis et al. 1993) c⃝1993 IEEE; (b) searching for\nthe strongest gradient along the normal to each control point (Cootes, Cooper, Taylor et al.\n1995) c⃝1995 Elsevier.\nexamples (Figure 5.4a) can be described with a mean ¯x and a covariance\nC = 1\nP\nX\np\n(xp −¯x)(xp −¯x)T ,\n(5.14)\nwhere xp are the P training examples. Using eigenvalue analysis (Appendix A.1.2), which is\nalso known as Principal Component Analysis (PCA) (Appendix B.1.1), the covariance matrix\ncan be written as,\nC = Φ diag(λ0 . . . λK−1) ΦT .\n(5.15)\nIn most cases, the likely appearance of the points can be modeled using only a few eigen-\nvectors with the largest eigenvalues. The resulting point distribution model (Cootes, Taylor,\nLanitis et al. 1993; Cootes, Cooper, Taylor et al. 1995) can be written as\nx = ¯x + ˆΦ b,\n(5.16)\nwhere b is an M ≪K element shape parameter vector and ˆΦ are the ﬁrst m columns of Φ.\nTo constrain the shape parameters to reasonable values, we can use a quadratic penalty of the\nform\nEshape = 1\n2bT diag(λ0 . . . λM−1) b =\nX\nm\nb2\nm/2λm.\n(5.17)\nAlternatively, the range of allowable bm values can be limited to some range, e.g., |bm| ≤\n3√λm (Cootes, Cooper, Taylor et al. 1995). Alternative approaches for deriving a set of\nshape vectors are reviewed by Isard and Blake (1998).\n276\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nVarying the individual shape parameters bm over the range −2√λm ≤2√λm can give\na good indication of the expected variation in appearance, as shown in Figure 5.4d. Another\nexample, this time related to face contours, is shown in Figure 5.5a.\nIn order to align a point distribution model with an image, each control point searches\nin a direction normal to the contour to ﬁnd the most likely corresponding image edge point\n(Figure 5.5b). These individual measurements can be combined with priors on the shape\nparameters (and, if desired, position, scale, and orientation parameters) to estimate a new set\nof parameters. The resulting Active Shape Model (ASM) can be iteratively minimized to ﬁt\nimages to non-rigidly deforming objects such as medical images or body parts such as hands\n(Cootes, Cooper, Taylor et al. 1995). The ASM can also be combined with a PCA analysis of\nthe underlying gray-level distribution to create an Active Appearance Model (AAM) (Cootes,\nEdwards, and Taylor 2001), which we discuss in more detail in Section 14.2.2.\n5.1.2 Dynamic snakes and CONDENSATION\nIn many applications of active contours, the object of interest is being tracked from frame\nto frame as it deforms and evolves. In this case, it makes sense to use estimates from the\nprevious frame to predict and constrain the new estimates.\nOne way to do this is to use Kalman ﬁltering, which results in a formulation called Kalman\nsnakes (Terzopoulos and Szeliski 1992; Blake, Curwen, and Zisserman 1993). The Kalman\nﬁlter is based on a linear dynamic model of shape parameter evolution,\nxt = Axt−1 + wt,\n(5.18)\nwhere xt and xt−1 are the current and previous state variables, A is the linear transition\nmatrix, and w is a noise (perturbation) vector, which is often modeled as a Gaussian (Gelb\n1974). The matrices A and the noise covariance can be learned ahead of time by observing\ntypical sequences of the object being tracked (Blake and Isard 1998).\nThe qualitative behavior of the Kalman ﬁlter can be seen in Figure 5.6a. The linear dy-\nnamic model causes a deterministic change (drift) in the previous estimate, while the process\nnoise (perturbation) causes a stochastic diffusion that increases the system entropy (lack of\ncertainty). New measurements from the current frame restore some of the certainty (peaked-\nness) in the updated estimate.\nIn many situations, however, such as when tracking in clutter, a better estimate for the\ncontour can be obtained if we remove the assumptions that the distribution are Gaussian,\nwhich is what the Kalman ﬁlter requires. In this case, a general multi-modal distribution is\npropagated, as shown in Figure 5.6b. In order to model such multi-modal distributions, Isard\nand Blake (1998) introduced the use of particle ﬁltering to the computer vision community.5\n5 Alternatives to modeling multi-modal distributions include mixtures of Gaussians (Bishop 2006) and multiple",
  "image_path": "page_297.jpg",
  "pages": [
    296,
    297,
    298
  ]
}