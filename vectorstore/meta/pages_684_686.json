{
  "doc_id": "pages_684_686",
  "text": "662\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nFigure 14.5\nA neural network for face detection (Rowley, Baluja, and Kanade 1998a) c⃝\n1998 IEEE. Overlapping patches are extracted from different levels of a pyramid and then\npre-processed as shown in Figure 14.3b. A three-layer neural network is then used to detect\nlikely face locations.\nof every overlapping patch in a multi-resolution pyramid. Since several overlapping patches\n(in both space and resolution) may ﬁre near a face, an additional merging network is used\nto merge overlapping detections. The authors also experiment with training several networks\nand merging their outputs. Figure 14.2 shows a sample result from their face detector.\nTo make the detector run faster, a separate network operating on 30×30 patches is trained\nto detect both faces and faces shifted by ±5 pixels. This network is evaluated at every 10th\npixel in the image (horizontally and vertically) and the results of this “coarse” or “sloppy”\ndetector are used to select regions on which to run the slower single-pixel overlap technique.\nTo deal with in-plane rotations of faces, Rowley, Baluja, and Kanade (1998b) train a router\nnetwork to estimate likely rotation angles from input patches and then apply the estimated\nrotation to each patch before running the result through their upright face detector.\nSupport vector machines.\nInstead of using a neural network to classify patches, Osuna,\nFreund, and Girosi (1997) use a support vector machine (SVM) (Hastie, Tibshirani, and\nFriedman 2001; Sch¨olkopf and Smola 2002; Bishop 2006; Lampert 2008) to classify the same\npreprocessed patches as Sung and Poggio (1998). An SVM searches for a series of maximum\nmargin separating planes in feature space between different classes (in this case, face and\nnon-face patches). In those cases where linear classiﬁcation boundaries are insufﬁcient, the\nfeature space can be lifted into higher-dimensional features using kernels (Hastie, Tibshirani,\nand Friedman 2001; Sch¨olkopf and Smola 2002; Bishop 2006). SVMs have been used by\nother researchers for both face detection and face recognition (Heisele, Ho, Wu et al. 2003;\n14.1 Object detection\n663\n(a)\n(b)\nFigure 14.6\nSimple features used in boosting-based face detector (Viola and Jones 2004)\nc⃝2004 Springer: (a) difference of rectangle feature composed of 2–4 different rectangles\n(pixels inside the white rectangles are subtracted from the gray ones); (b) the ﬁrst and second\nfeatures selected by AdaBoost. The ﬁrst feature measures the differences in intensity between\nthe eyes and the cheeks, the second one between the eyes and the bridge of the nose.\nHeisele, Serre, and Poggio 2007) and are a widely used tool in object recognition in general.\nBoosting.\nOf all the face detectors currently in use, the one introduced by Viola and Jones\n(2004) is probably the best known and most widely used. Their technique was the ﬁrst to\nintroduce the concept of boosting to the computer vision community, which involves train-\ning a series of increasingly discriminating simple classiﬁers and then blending their outputs\n(Hastie, Tibshirani, and Friedman 2001; Bishop 2006).\nIn more detail, boosting involves constructing a classiﬁer h(x) as a sum of simple weak\nlearners,\nh(x) = sign\n\n\nm−1\nX\nj=0\nαjhj(x)\n\n,\n(14.1)\nwhere each of the weak learners hj(x) is an extremely simple function of the input, and hence\nis not expected to contribute much (in isolation) to the classiﬁcation performance.\nIn most variants of boosting, the weak learners are threshold functions,\nhj(x) = aj[fj < θj] + bj[fj ≥θj] =\n(\naj\nif fj < θj\nbj\notherwise,\n(14.2)\nwhich are also known as decision stumps (basically, the simplest possible version of decision\ntrees). In most cases, it is also traditional (and simpler) to set aj and bj to ±1, i.e., aj = −sj,\nbj = +sj, so that only the feature fj, the threshold value θj, and the polarity of the threshold\nsj ∈±1 need to be selected.4\n4Some variants, such as that of Viola and Jones (2004), use (aj, bj) ∈[0, 1] and adjust the learning algorithm\n664\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nWeak classifier 1\nWeights increased\nWeak classifier 2\nWeights increased\nWeak classifier 3\nFinal classifier\nFigure 14.7 Schematic illustration of boosting, courtesy of Svetlana Lazebnik, after origi-\nnal illustrations from Paul Viola and David Lowe. After each weak classiﬁer (decision stump\nor hyperplane) is selected, data points that are erroneously classiﬁed have their weights in-\ncreased. The ﬁnal classiﬁer is a linear combination of the simple weak classiﬁers.\nIn many applications of boosting, the features are simply coordinate axes xk, i.e., the\nboosting algorithm selects one of the input vector components as the best one to threshold. In\nViola and Jones’ face detector, the features are differences of rectangular regions in the input\npatch, as shown in Figure 14.6. The advantage of using these features is that, while they are\nmore discriminating than single pixels, they are extremely fast to compute once a summed\narea table has been pre-computed, as described in Section 3.2.3 (3.31–3.32). Essentially, for\nthe cost of an O(N) pre-computation phase (where N is the number of pixels in the image),\nsubsequent differences of rectangles can be computed in 4r additions or subtractions, where\nr ∈{2, 3, 4} is the number of rectangles in the feature.\nThe key to the success of boosting is the method for incrementally selecting the weak\nlearners and for re-weighting the training examples after each stage (Figure 14.7). The Ad-\naBoost (Adaptive Boosting) algorithm (Hastie, Tibshirani, and Friedman 2001; Bishop 2006)\ndoes this by re-weighting each sample as a function of whether it is correctly classiﬁed at each\nstage, and using the stage-wise average classiﬁcation error to determine the ﬁnal weightings\nαj among the weak classiﬁers, as described in Algorithm 14.1. While the resulting classi-\nﬁer is extremely fast in practice, the training time can be quite slow (in the order of weeks),\nbecause of the large number of feature (difference of rectangle) hypotheses that need to be\nexamined at each stage.\nTo further increase the speed of the detector, it is possible to create a cascade of classiﬁers,\nwhere each classiﬁer uses a small number of tests (say, a two-term AdaBoost classiﬁer) to\nreject a large fraction of non-faces while trying to pass through all potential face candidates\n(Fleuret and Geman 2001; Viola and Jones 2004). An even faster algorithm for performing\ncascade learning has recently been developed by Brubaker, Wu, Sun et al. (2008).\naccordingly.",
  "image_path": "page_685.jpg",
  "pages": [
    684,
    685,
    686
  ]
}