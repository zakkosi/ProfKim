{
  "doc_id": "pages_413_415",
  "text": "8.1 Translational alignment\n391\nThe output of phase correlation (under ideal conditions) is therefore a single spike (impulse)\nlocated at the correct value of u, which (in principle) makes it easier to ﬁnd the correct\nestimate.\nPhase correlation has a reputation in some quarters of outperforming regular correlation,\nbut this behavior depends on the characteristics of the signals and noise. If the original images\nare contaminated by noise in a narrow frequency band (e.g., low-frequency noise or peaked\nfrequency “hum”), the whitening process effectively de-emphasizes the noise in these regions.\nHowever, if the original signals have very low signal-to-noise ratio at some frequencies (say,\ntwo blurry or low-textured images with lots of high-frequency noise), the whitening process\ncan actually decrease performance (see Exercise 8.1).\nRecently, gradient cross-correlation has emerged as a promising alternative to phase cor-\nrelation (Argyriou and Vlachos 2003), although further systematic studies are probably war-\nranted. Phase correlation has also been studied by Fleet and Jepson (1990) as a method for\nestimating general optical ﬂow and stereo disparity.\nRotations and scale.\nWhile Fourier-based alignment is mostly used to estimate transla-\ntional shifts between images, it can, under certain limited conditions, also be used to estimate\nin-plane rotations and scales. Consider two images that are related purely by rotation, i.e.,\nI1( ˆRx) = I0(x).\n(8.26)\nIf we re-sample the images into polar coordinates,\n˜I0(r, θ) = I0(r cos θ, r sin θ) and ˜I1(r, θ) = I1(r cos θ, r sin θ),\n(8.27)\nwe obtain\n˜I1(r, θ + ˆθ) = ˜I0(r, θ).\n(8.28)\nThe desired rotation can then be estimated using a Fast Fourier Transform (FFT) shift-based\ntechnique.\nIf the two images are also related by a scale,\nI1(eˆs ˆRx) = I0(x),\n(8.29)\nwe can re-sample into log-polar coordinates,\n˜I0(s, θ) = I0(es cos θ, es sin θ) and ˜I1(s, θ) = I1(es cos θ, es sin θ),\n(8.30)\nto obtain\n˜I1(s + ˆs, θ + ˆθ) = I0(s, θ).\n(8.31)\n392\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nI\nx\nei\nΔu I0(xi)\nI1(xi+u)\nJ1(xi+u)\nI0\nI1\nxi\nFigure 8.2\nTaylor series approximation of a function and the incremental computation of\nthe optical ﬂow correction amount. J1(xi + u) is the image gradient at (xi + u) and ei is\nthe current intensity difference.\nIn this case, care must be taken to choose a suitable range of s values that reasonably samples\nthe original image.\nFor images that are also translated by a small amount,\nI1(eˆs ˆRx + t) = I0(x),\n(8.32)\nDe Castro and Morandi (1987) propose an ingenious solution that uses several steps to esti-\nmate the unknown parameters. First, both images are converted to the Fourier domain and\nonly the magnitudes of the transformed images are retained. In principle, the Fourier mag-\nnitude images are insensitive to translations in the image plane (although the usual caveats\nabout border effects apply). Next, the two magnitude images are aligned in rotation and scale\nusing the polar or log-polar representations. Once rotation and scale are estimated, one of the\nimages can be de-rotated and scaled and a regular translational algorithm can be applied to\nestimate the translational shift.\nUnfortunately, this trick only applies when the images have large overlap (small transla-\ntional motion). For more general motion of patches or images, the parametric motion estima-\ntor described in Section 8.2 or the feature-based approaches described in Section 6.1 need to\nbe used.\n8.1.3 Incremental reﬁnement\nThe techniques described up till now can estimate alignment to the nearest pixel (or poten-\ntially fractional pixel if smaller search steps are used). In general, image stabilization and\nstitching applications require much higher accuracies to obtain acceptable results.\nTo obtain better sub-pixel estimates, we can use one of several techniques described by\nTian and Huhns (1986). One possibility is to evaluate several discrete (integer or fractional)\nvalues of (u, v) around the best value found so far and to interpolate the matching score to\nﬁnd an analytic minimum.\n8.1 Translational alignment\n393\nA more commonly used approach, ﬁrst proposed by Lucas and Kanade (1981), is to\nperform gradient descent on the SSD energy function (8.1), using a Taylor series expansion\nof the image function (Figure 8.2),\nELK−SSD(u + ∆u)\n=\nX\ni\n[I1(xi + u + ∆u) −I0(xi)]2\n(8.33)\n≈\nX\ni\n[I1(xi + u) + J1(xi + u)∆u −I0(xi)]2\n(8.34)\n=\nX\ni\n[J1(xi + u)∆u + ei]2,\n(8.35)\nwhere\nJ1(xi + u) = ∇I1(xi + u) = (∂I1\n∂x , ∂I1\n∂y )(xi + u)\n(8.36)\nis the image gradient or Jacobian at (xi + u) and\nei = I1(xi + u) −I0(xi),\n(8.37)\nﬁrst introduced in (8.1), is the current intensity error.7 The gradient at a particular sub-pixel\nlocation (xi + u) can be computed using a variety of techniques, the simplest of which is\nto simply take the horizontal and vertical differences between pixels x and x + (1, 0) or\nx + (0, 1). More sophisticated derivatives can sometimes lead to noticeable performance\nimprovements.\nThe linearized form of the incremental update to the SSD error (8.35) is often called the\noptical ﬂow constraint or brightness constancy constraint equation\nIxu + Iyv + It = 0,\n(8.38)\nwhere the subscripts in Ix and Iy denote spatial derivatives, and It is called the temporal\nderivative, which makes sense if we are computing instantaneous velocity in a video se-\nquence. When squared and summed or integrated over a region, it can be used to compute\noptic ﬂow (Horn and Schunck 1981).\nThe above least squares problem (8.35) can be minimized by solving the associated nor-\nmal equations (Appendix A.2),\nA∆u = b\n(8.39)\nwhere\nA =\nX\ni\nJT\n1 (xi + u)J1(xi + u)\n(8.40)\n7 We follow the convention, commonly used in robotics and by Baker and Matthews (2004), that derivatives with\nrespect to (column) vectors result in row vectors, so that fewer transposes are needed in the formulas.",
  "image_path": "page_414.jpg",
  "pages": [
    413,
    414,
    415
  ]
}