{
  "doc_id": "pages_362_364",
  "text": "340\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 6.8: Calibration accuracy\nCompare the three calibration techniques (plane-based, rotation-\nbased, and 3D-target-based).\nOne approach is to have a different student implement each one and to compare the results.\nAnother approach is to use synthetic data, potentially re-using the software you developed\nfor Exercise 2.3. The advantage of using synthetic data is that you know the ground truth\nfor the calibration and pose parameters, you can easily run lots of experiments, and you can\nsynthetically vary the noise in your measurements.\nHere are some possible guidelines for constructing your test sets:\n1. Assume a medium-wide focal length (say, 50◦ﬁeld of view).\n2. For the plane-based technique, generate a 2D grid target and project it at different\ninclinations.\n3. For a 3D target, create an inner cube corner and position it so that it ﬁlls most of ﬁeld\nof view.\n4. For the rotation technique, scatter points uniformly on a sphere until you get a similar\nnumber of points as for other techniques.\nBefore comparing your techniques, predict which one will be the most accurate (normalize\nyour results by the square root of the number of points used).\nAdd varying amounts of noise to your measurements and describe the noise sensitivity of\nyour various techniques.\nEx 6.9: Single view metrology\nImplement a system to measure dimensions and reconstruct\na 3D model from a single image of a man-made scene using visible vanishing directions (Sec-\ntion 6.3.3) (Criminisi, Reid, and Zisserman 2000).\n1. Find the three orthogonal vanishing points from parallel lines and use them to establish\nthe three coordinate axes (rotation matrix R of the camera relative to the scene). If\ntwo of the vanishing points are ﬁnite (not at inﬁnity), use them to compute the focal\nlength, assuming a known optical center. Otherwise, ﬁnd some other way to calibrate\nyour camera; you could use some of the techniques described by Schaffalitzky and\nZisserman (2000).\n2. Click on a ground plane point to establish your origin and click on a point a known\ndistance away to establish the scene scale. This lets you compute the translation t\nbetween the camera and the scene. As an alternative, click on a pair of points, one\non the ground plane and one above it, and use the known height to establish the scene\nscale.\n6.5 Exercises\n341\n3. Write a user interface that lets you click on ground plane points to recover their 3D\nlocations. (Hint: you already know the camera matrix, so knowledge of a point’s z\nvalue is sufﬁcient to recover its 3D location.) Click on pairs of points (one on the\nground plane, one above it) to measure vertical heights.\n4. Extend your system to let you draw quadrilaterals in the scene that correspond to axis-\naligned rectangles in the world, using some of the techniques described by Sinha,\nSteedly, Szeliski et al. (2008). Export your 3D rectangles to a VRML or PLY15 ﬁle.\n5. (Optional) Warp the pixels enclosed by the quadrilateral using the correct homography\nto produce a texture map for each planar polygon.\nEx 6.10: Radial distortion with plumb lines\nImplement a plumb-line algorithm to deter-\nmine the radial distortion parameters.\n1. Take some images of scenes with lots of straight lines, e.g., hallways in your home or\nofﬁce, and try to get some of the lines as close to the edges of the image as possible.\n2. Extract the edges and link them into curves, as described in Section 4.2.2 and Exer-\ncise 4.8.\n3. Fit quadratic or elliptic curves to the linked edges using a generalization of the suc-\ncessive line approximation algorithm described in Section 4.3.1 and Exercise 4.11 and\nkeep the curves that ﬁt this form well.\n4. For each curved segment, ﬁt a straight line and minimize the perpendicular distance\nbetween the curve and the line while adjusting the radial distortion parameters.\n5. Alternate between re-ﬁtting the straight line and adjusting the radial distortion param-\neters until convergence.\nEx 6.11: Radial distortion with a calibration target\nUse a grid calibration target to de-\ntermine the radial distortion parameters.\n1. Print out a planar calibration target, mount it on a stiff board, and get it to ﬁll your ﬁeld\nof view.\n2. Detect the squares, lines, or dots in your calibration target.\n3. Estimate the homography mapping the target to the camera from the central portion of\nthe image that does not have any radial distortion.\n15 http://meshlab.sf.net.\n342\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n4. Predict the positions of the remaining targets and use the differences between the ob-\nserved and predicted positions to estimate the radial distortion.\n5. (Optional) Fit a general spline model (for severe distortion) instead of the quartic dis-\ntortion model.\n6. (Optional) Extend your technique to calibrate a ﬁsheye lens.\nEx 6.12: Chromatic aberration\nUse the radial distortion estimates for each color channel\ncomputed in the previous exercise to clean up wide-angle lens images by warping all of the\nchannels into alignment. (Optional) Straighten out the images at the same time.\nCan you think of any reasons why this warping strategy may not always work?",
  "image_path": "page_363.jpg",
  "pages": [
    362,
    363,
    364
  ]
}