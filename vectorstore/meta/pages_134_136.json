{
  "doc_id": "pages_134_136",
  "text": "112\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n45\n60\n98\n127 132 133 137 133\n46\n65\n98\n123 126 128 131 133\n69\n95\n116 125 129 132\n47\n65\n96\n115 119 123 135 137\n0.1\n0.1\n0.1\n68\n92\n110 120 126 132\n47\n63\n91\n107 113 122 138 134\n*\n0.1\n0.2\n0.1\n=\n66\n86\n104 114 124 132\n50\n59\n80\n97\n110 123 133 134\n0.1\n0.1\n0.1\n62\n78\n94\n108 120 129\n49\n53\n68\n83\n97\n113 128 133\n57\n69\n83\n98\n112 124\n50\n50\n58\n70\n84\n102 116 126\n53\n60\n71\n85\n100 114\n50\n50\n52\n58\n69\n86\n101 120\nf (x,y )\nh (x,y )\ng (x,y )\nFigure 3.10 Neighborhood ﬁltering (convolution): The image on the left is convolved with\nthe ﬁlter in the middle to yield the image on the right. The light blue pixels indicate the source\nneighborhood for the light green destination pixel.\nwhere the sign of the offsets in f has been reversed. This is called the convolution operator,\ng = f ∗h,\n(3.15)\nand h is then called the impulse response function.4 The reason for this name is that the kernel\nfunction, h, convolved with an impulse signal, δ(i, j) (an image that is 0 everywhere except\nat the origin) reproduces itself, h ∗δ = h, whereas correlation produces the reﬂected signal.\n(Try this yourself to verify that it is so.)\nIn fact, Equation (3.14) can be interpreted as the superposition (addition) of shifted im-\npulse response functions h(i−k, j −l) multiplied by the input pixel values f(k, l). Convolu-\ntion has additional nice properties, e.g., it is both commutative and associative. As well, the\nFourier transform of two convolved images is the product of their individual Fourier trans-\nforms (Section 3.4).\nBoth correlation and convolution are linear shift-invariant (LSI) operators, which obey\nboth the superposition principle (3.5),\nh ◦(f0 + f1) = h ◦f0 + h ◦f1,\n(3.16)\nand the shift invariance principle,\ng(i, j) = f(i + k, j + l) ⇔(h ◦g)(i, j) = (h ◦f)(i + k, j + l),\n(3.17)\nwhich means that shifting a signal commutes with applying the operator (◦stands for the LSI\noperator). Another way to think of shift invariance is that the operator “behaves the same\neverywhere”.\n4 The continuous version of convolution can be written as g(x) = R\nf(x −u)h(u)du.\n3.2 Linear ﬁltering\n113\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\n(h)\nFigure 3.11 Some neighborhood operations: (a) original image; (b) blurred; (c) sharpened;\n(d) smoothed with edge-preserving ﬁlter; (e) binary image; (f) dilated; (g) distance transform;\n(h) connected components. For the dilation and connected components, black (ink) pixels are\nassumed to be active, i.e., to have a value of 1 in Equations (3.41–3.45).\n114\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n72\n88\n62\n52\n37 ∗\n1/4\n1/2\n1/4\n⇔\n1\n4\n\n\n2\n1\n.\n.\n.\n1\n2\n1\n.\n.\n.\n1\n2\n1\n.\n.\n.\n1\n2\n1\n.\n.\n.\n1\n2\n\n\n\n\n72\n88\n62\n52\n37\n\n\nFigure 3.12\nOne-dimensional signal convolution as a sparse matrix-vector multiply, g =\nHf.\nOccasionally, a shift-variant version of correlation or convolution may be used, e.g.,\ng(i, j) =\nX\nk,l\nf(i −k, j −l)h(k, l; i, j),\n(3.18)\nwhere h(k, l; i, j) is the convolution kernel at pixel (i, j). For example, such a spatially\nvarying kernel can be used to model blur in an image due to variable depth-dependent defocus.\nCorrelation and convolution can both be written as a matrix-vector multiply, if we ﬁrst\nconvert the two-dimensional images f(i, j) and g(i, j) into raster-ordered vectors f and g,\ng = Hf,\n(3.19)\nwhere the (sparse) H matrix contains the convolution kernels. Figure 3.12 shows how a\none-dimensional convolution can be represented in matrix-vector form.\nPadding (border effects)\nThe astute reader will notice that the matrix multiply shown in Figure 3.12 suffers from\nboundary effects, i.e., the results of ﬁltering the image in this form will lead to a darkening of\nthe corner pixels. This is because the original image is effectively being padded with 0 values\nwherever the convolution kernel extends beyond the original image boundaries.\nTo compensate for this, a number of alternative padding or extension modes have been\ndeveloped (Figure 3.13):\n• zero: set all pixels outside the source image to 0 (a good choice for alpha-matted cutout\nimages);\n• constant (border color): set all pixels outside the source image to a speciﬁed border\nvalue;\n• clamp (replicate or clamp to edge): repeat edge pixels indeﬁnitely;\n• (cyclic) wrap (repeat or tile): loop “around” the image in a “toroidal” conﬁguration;",
  "image_path": "page_135.jpg",
  "pages": [
    134,
    135,
    136
  ]
}