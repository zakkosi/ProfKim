{
  "doc_id": "pages_565_567",
  "text": "11.2 Sparse correspondence\n543\n11.2 Sparse correspondence\nEarly stereo matching algorithms were feature-based, i.e., they ﬁrst extracted a set of poten-\ntially matchable image locations, using either interest operators or edge detectors, and then\nsearched for corresponding locations in other images using a patch-based metric (Hannah\n1974; Marr and Poggio 1979; Mayhew and Frisby 1980; Baker and Binford 1981; Arnold\n1983; Grimson 1985; Ohta and Kanade 1985; Bolles, Baker, and Marimont 1987; Matthies,\nKanade, and Szeliski 1989; Hsieh, McKeown, and Perlant 1992; Bolles, Baker, and Hannah\n1993). This limitation to sparse correspondences was partially due to computational resource\nlimitations, but was also driven by a desire to limit the answers produced by stereo algorithms\nto matches with high certainty. In some applications, there was also a desire to match scenes\nwith potentially very different illuminations, where edges might be the only stable features\n(Collins 1996). Such sparse 3D reconstructions could later be interpolated using surface ﬁt-\nting algorithms such as those discussed in Sections 3.7.1 and 12.3.1.\nMore recent work in this area has focused on ﬁrst extracting highly reliable features and\nthen using these as seeds to grow additional matches (Zhang and Shan 2000; Lhuillier and\nQuan 2002). Similar approaches have also been extended to wide baseline multi-view stereo\nproblems and combined with 3D surface reconstruction (Lhuillier and Quan 2005; Strecha,\nTuytelaars, and Van Gool 2003; Goesele, Snavely, Curless et al. 2007) or free-space reasoning\n(Taylor 2003), as described in more detail in Section 11.6.\n11.2.1 3D curves and proﬁles\nAnother example of sparse correspondence is the matching of proﬁle curves (or occluding\ncontours), which occur at the boundaries of objects (Figure 11.7) and at interior self occlu-\nsions, where the surface curves away from the camera viewpoint.\nThe difﬁculty in matching proﬁle curves is that in general, the locations of proﬁle curves\nvary as a function of camera viewpoint. Therefore, matching curves directly in two images\nand then triangulating these matches can lead to erroneous shape measurements. Fortunately,\nif three or more closely spaced frames are available, it is possible to ﬁt a local circular arc to\nthe locations of corresponding edgels (Figure 11.7a) and therefore obtain semi-dense curved\nsurface meshes directly from the matches (Figures 11.7c and g). Another advantage of match-\ning such curves is that they can be used to reconstruct surface shape for untextured surfaces,\nso long as there is a visible difference between foreground and background colors.\nOver the years, a number of different techniques have been developed for reconstructing\nsurface shape from proﬁle curves (Giblin and Weiss 1987; Cipolla and Blake 1992; Vaillant\nand Faugeras 1992; Zheng 1994; Boyer and Berger 1997; Szeliski and Weiss 1998). Cipolla\nand Giblin (2000) describe many of these techniques, as well as related topics such as in-\n544\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\nFigure 11.7 Surface reconstruction from occluding contours (Szeliski and Weiss 1998) c⃝\n2002 Springer: (a) circular arc ﬁtting in the epipolar plane; (b) synthetic example of an el-\nlipsoid with a truncated side and elliptic surface markings; (c) partially reconstructed surface\nmesh seen from an oblique and top-down view; (d) real-world image sequence of a soda can\non a turntable; (e) extracted edges; (f) partially reconstructed proﬁle curves; (g) partially re-\nconstructed surface mesh. (Partial reconstructions are shown so as not to clutter the images.)\nferring camera motion from proﬁle curve sequences. Below, we summarize the approach\ndeveloped by Szeliski and Weiss (1998), which assumes a discrete set of images, rather than\nformulating the problem in a continuous differential framework.\nLet us assume that the camera is moving smoothly enough that the local epipolar geometry\nvaries slowly, i.e., the epipolar planes induced by the successive camera centers and an edgel\nunder consideration are nearly co-planar. The ﬁrst step in the processing pipeline is to extract\nand link edges in each of the input images (Figures 11.7b and e). Next, edgels in successive\nimages are matched using pairwise epipolar geometry, proximity and (optionally) appearance.\nThis provides a linked set of edges in the spatio-temporal volume, which is sometimes called\nthe weaving wall (Baker 1989).\nTo reconstruct the 3D location of an individual edgel, along with its local in-plane normal\nand curvature, we project the viewing rays corresponding to its neighbors onto the instanta-\nneous epipolar plane deﬁned by the camera center, the viewing ray, and the camera velocity,\nas shown in Figure 11.7a. We then ﬁt an osculating circle to the projected lines, parameteriz-\n11.3 Dense correspondence\n545\ning the circle by its centerpoint c = (xc, yc) and radius r,\ncixc + siyc + r = di,\n(11.5)\nwhere ci = ˆti · ˆt0 and si = −ˆti · ˆn0 are the cosine and sine of the angle between viewing ray\ni and the central viewing ray 0, and di = (qi −q0)· ˆn0 is the perpendicular distance between\nviewing ray i and the local origin q0, which is a point chosen on the central viewing ray close\nto the line intersections (Szeliski and Weiss 1998). The resulting set of linear equations can\nbe solved using least squares, and the quality of the solution (residual error) can be used to\ncheck for erroneous correspondences.\nThe resulting set of 3D points, along with their spatial (in-image) and temporal (between-\nimage) neighbors, form a 3D surface mesh with local normal and curvature estimates (Fig-\nures 11.7c and g). Note that whenever a curve is due to a surface marking or a sharp crease\nedge, rather than a smooth surface proﬁle curve, this shows up as a 0 or small radius of curva-\nture. Such curves result in isolated 3D space curves, rather than elements of smooth surface\nmeshes, but can still be incorporated into the 3D surface model during a later stage of surface\ninterpolation (Section 12.3.1).\n11.3 Dense correspondence\nWhile sparse matching algorithms are still occasionally used, most stereo matching algo-\nrithms today focus on dense correspondence, since this is required for applications such as\nimage-based rendering or modeling. This problem is more challenging than sparse corre-\nspondence, since inferring depth values in textureless regions requires a certain amount of\nguesswork. (Think of a solid colored background seen through a picket fence. What depth\nshould it be?)\nIn this section, we review the taxonomy and categorization scheme for dense correspon-\ndence algorithms ﬁrst proposed by Scharstein and Szeliski (2002). The taxonomy consists\nof a set of algorithmic “building blocks” from which a large set of algorithms can be con-\nstructed. It is based on the observation that stereo algorithms generally perform some subset\nof the following four steps:\n1. matching cost computation;\n2. cost (support) aggregation;\n3. disparity computation and optimization; and\n4. disparity reﬁnement.",
  "image_path": "page_566.jpg",
  "pages": [
    565,
    566,
    567
  ]
}