{
  "doc_id": "pages_185_187",
  "text": "3.6 Geometric transformations\n163\nf\nx\nh\nf\nf\ng\nh\ng\nh\nh\ng\nx\nf\nx\ng\nx\nFigure 3.44 Image warping involves modifying the domain of an image function rather than\nits range.\ny\nx\nsimilarity\nEuclidean\naffine\nprojective\ntranslation\nFigure 3.45 Basic set of 2D geometric image transformations.\nhere we look at functions that transform the domain,\ng(x) = f(h(x))\n(3.88)\n(see Figure 3.44).\nWe begin by studying the global parametric 2D transformation ﬁrst introduced in Sec-\ntion 2.1.2. (Such a transformation is called parametric because it is controlled by a small\nnumber of parameters.) We then turn our attention to more local general deformations such as\nthose deﬁned on meshes (Section 3.6.2). Finally, we show how image warps can be combined\nwith cross-dissolves to create interesting morphs (in-between animations) in Section 3.6.3.\nFor readers interested in more details on these topics, there is an excellent survey by Heck-\nbert (1986) as well as very accessible textbooks by Wolberg (1990), Gomes, Darsa, Costa\net al. (1999) and Akenine-M¨oller and Haines (2002). Note that Heckbert’s survey is on tex-\nture mapping, which is how the computer graphics community refers to the topic of warping\nimages onto surfaces.\n3.6.1 Parametric transformations\nParametric transformations apply a global deformation to an image, where the behavior of the\ntransformation is controlled by a small number of parameters. Figure 3.45 shows a few ex-\n164\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nTransformation\nMatrix\n# DoF\nPreserves\nIcon\ntranslation\nh\nI\nt\ni\n2×3\n2\norientation\nrigid (Euclidean)\nh\nR\nt\ni\n2×3\n3\nlengths\n\u001a\n\u001a\n\u001a\u001a\nS\nS S\nS\nsimilarity\nh\nsR\nt\ni\n2×3\n4\nangles\n\u001a\n\u001a\nS S\nafﬁne\nh\nA\ni\n2×3\n6\nparallelism\n\u0002\u0002\n\u0002\u0002\nprojective\nh\n˜\nH\ni\n3×3\n8\nstraight lines\n``\n  \nTable 3.5 Hierarchy of 2D coordinate transformations. Each transformation also preserves\nthe properties listed in the rows below it, i.e., similarity preserves not only angles but also\nparallelism and straight lines. The 2×3 matrices are extended with a third [0T 1] row to form\na full 3 × 3 matrix for homogeneous coordinate transformations.\namples of such transformations, which are based on the 2D geometric transformations shown\nin Figure 2.4. The formulas for these transformations were originally given in Table 2.1 and\nare reproduced here in Table 3.5 for ease of reference.\nIn general, given a transformation speciﬁed by a formula x′ = h(x) and a source image\nf(x), how do we compute the values of the pixels in the new image g(x), as given in (3.88)?\nThink about this for a minute before proceeding and see if you can ﬁgure it out.\nIf you are like most people, you will come up with an algorithm that looks something like\nAlgorithm 3.1. This process is called forward warping or forward mapping and is shown in\nFigure 3.46a. Can you think of any problems with this approach?\nprocedure forwardWarp(f, h, out g):\nFor every pixel x in f(x)\n1. Compute the destination location x′ = h(x).\n2. Copy the pixel f(x) to g(x′).\nAlgorithm 3.1\nForward warping algorithm for transforming an image f(x) into an image\ng(x′) through the parametric transform x′ = h(x).\n3.6 Geometric transformations\n165\nf(x)\ng(x’)\nx\nx’\nx’=h(x)\nf(x)\ng(x’)\nx\nx’\nx’=h(x)\n(a)\n(b)\nFigure 3.46\nForward warping algorithm: (a) a pixel f(x) is copied to its corresponding\nlocation x′ = h(x) in image g(x′); (b) detail of the source and destination pixel locations.\nIn fact, this approach suffers from several limitations. The process of copying a pixel\nf(x) to a location x′ in g is not well deﬁned when x′ has a non-integer value. What do we\ndo in such a case? What would you do?\nYou can round the value of x′ to the nearest integer coordinate and copy the pixel there,\nbut the resulting image has severe aliasing and pixels that jump around a lot when animating\nthe transformation. You can also “distribute” the value among its four nearest neighbors in\na weighted (bilinear) fashion, keeping track of the per-pixel weights and normalizing at the\nend. This technique is called splatting and is sometimes used for volume rendering in the\ngraphics community (Levoy and Whitted 1985; Levoy 1988; Westover 1989; Rusinkiewicz\nand Levoy 2000).\nUnfortunately, it suffers from both moderate amounts of aliasing and a\nfair amount of blur (loss of high-resolution detail).\nThe second major problem with forward warping is the appearance of cracks and holes,\nespecially when magnifying an image. Filling such holes with their nearby neighbors can\nlead to further aliasing and blurring.\nWhat can we do instead? A preferable solution is to use inverse warping (Algorithm 3.2),\nwhere each pixel in the destination image g(x′) is sampled from the original image f(x)\n(Figure 3.47).\nHow does this differ from the forward warping algorithm? For one thing, since ˆh(x′)\nis (presumably) deﬁned for all pixels in g(x′), we no longer have holes. More importantly,\nresampling an image at non-integer locations is a well-studied problem (general image inter-\npolation, see Section 3.5.2) and high-quality ﬁlters that control aliasing can be used.\nWhere does the function ˆh(x′) come from? Quite often, it can simply be computed as the\ninverse of h(x). In fact, all of the parametric transforms listed in Table 3.5 have closed form\nsolutions for the inverse transform: simply take the inverse of the 3 × 3 matrix specifying the\ntransform.\nIn other cases, it is preferable to formulate the problem of image warping as that of re-\nsampling a source image f(x) given a mapping x = ˆh(x′) from destination pixels x′ to\nsource pixels x. For example, in optical ﬂow (Section 8.4), we estimate the ﬂow ﬁeld as the",
  "image_path": "page_186.jpg",
  "pages": [
    185,
    186,
    187
  ]
}