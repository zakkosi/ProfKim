{
  "doc_id": "pages_200_202",
  "text": "178\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nf (i, j)\nsx(i, j)\nf (i, j+1)\nsy(i, j)\nw(i, j)\nd (i, j)\nf (i+1, j)\nf (i+1, j+1)\nFigure 3.55\nGraphical model interpretation of ﬁrst-order regularization. The white circles\nare the unknowns f(i, j) while the dark circles are the input data d(i, j). In the resistive grid\ninterpretation, the d and f values encode input and output voltages and the black squares\ndenote resistors whose conductance is set to sx(i, j), sy(i, j), and w(i, j). In the spring-mass\nsystem analogy, the circles denote elevations and the black squares denote springs. The same\ngraphical model can be used to depict a ﬁrst-order Markov random ﬁeld (Figure 3.56).\nwhich can be done using a variety of sparse matrix techniques, such as multigrid (Briggs,\nHenson, and McCormick 2000) and hierarchical preconditioners (Szeliski 2006b), as de-\nscribed in Appendix A.5.\nWhile regularization was ﬁrst introduced to the vision community by Poggio, Torre, and\nKoch (1985) and Terzopoulos (1986b) for problems such as surface interpolation, it was\nquickly adopted by other vision researchers for such varied problems as edge detection (Sec-\ntion 4.2), optical ﬂow (Section 8.4), and shape from shading (Section 12.1) (Poggio, Torre,\nand Koch 1985; Horn and Brooks 1986; Terzopoulos 1986b; Bertero, Poggio, and Torre 1988;\nBrox, Bruhn, Papenberg et al. 2004). Poggio, Torre, and Koch (1985) also showed how the\ndiscrete energy deﬁned by Equations (3.100–3.101) could be implemented in a resistive grid,\nas shown in Figure 3.55. In computational photography (Chapter 10), regularization and its\nvariants are commonly used to solve problems such as high-dynamic range tone mapping\n(Fattal, Lischinski, and Werman 2002; Lischinski, Farbman, Uyttendaele et al. 2006a), Pois-\nson and gradient-domain blending (P´erez, Gangnet, and Blake 2003; Levin, Zomet, Peleg et\nal. 2004; Agarwala, Dontcheva, Agrawala et al. 2004), colorization (Levin, Lischinski, and\nWeiss 2004), and natural image matting (Levin, Lischinski, and Weiss 2008).\nRobust regularization\nWhile regularization is most commonly formulated using quadratic (L2) norms (compare\nwith the squared derivatives in (3.92–3.95) and squared differences in (3.100–3.101)), it can\n3.7 Global optimization\n179\nalso be formulated using non-quadratic robust penalty functions (Appendix B.3). For exam-\nple, (3.100) can be generalized to\nE1r\n=\nX\ni,j\nsx(i, j)ρ(f(i + 1, j) −f(i, j))\n(3.104)\n+ sy(i, j)ρ(f(i, j + 1) −f(i, j)),\nwhere ρ(x) is some monotonically increasing penalty function. For example, the family of\nnorms ρ(x) = |x|p is called p-norms. When p < 2, the resulting smoothness terms become\nmore piecewise continuous than totally smooth, which can better model the discontinuous\nnature of images, ﬂow ﬁelds, and 3D surfaces.\nAn early example of robust regularization is the graduated non-convexity (GNC) algo-\nrithm introduced by Blake and Zisserman (1987). Here, the norms on the data and derivatives\nare clamped to a maximum value\nρ(x) = min(x2, V ).\n(3.105)\nBecause the resulting problem is highly non-convex (it has many local minima), a continua-\ntion method is proposed, where a quadratic norm (which is convex) is gradually replaced by\nthe non-convex robust norm (Allgower and Georg 2003). (Around the same time, Terzopou-\nlos (1988) was also using continuation to infer the tear and crease variables in his surface\ninterpolation problems.)\nToday, it is more common to use the L1 (p = 1) norm, which is often called total variation\n(Chan, Osher, and Shen 2001; Tschumperl´e and Deriche 2005; Tschumperl´e 2006; Kaftory,\nSchechner, and Zeevi 2007). Other norms, for which the inﬂuence (derivative) more quickly\ndecays to zero, are presented by Black and Rangarajan (1996); Black, Sapiro, Marimont et\nal. (1998) and discussed in Appendix B.3.\nEven more recently, hyper-Laplacian norms with p < 1 have gained popularity, based\non the observation that the log-likelihood distribution of image derivatives follows a p ≈\n0.5 −0.8 slope and is therefore a hyper-Laplacian distribution (Simoncelli 1999; Levin and\nWeiss 2007; Weiss and Freeman 2007; Krishnan and Fergus 2009). Such norms have an even\nstronger tendency to prefer large discontinuities over small ones. See the related discussion\nin Section 3.7.2 (3.114).\nWhile least squares regularized problems using L2 norms can be solved using linear sys-\ntems, other p-norms require different iterative techniques, such as iteratively reweighted least\nsquares (IRLS), Levenberg–Marquardt, or alternation between local non-linear subproblems\nand global quadratic regularization (Krishnan and Fergus 2009). Such techniques are dis-\ncussed in Section 6.1.3 and Appendices A.3 and B.3.\n180\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n3.7.2 Markov random ﬁelds\nAs we have just seen, regularization, which involves the minimization of energy functionals\ndeﬁned over (piecewise) continuous functions, can be used to formulate and solve a variety\nof low-level computer vision problems. An alternative technique is to formulate a Bayesian\nmodel, which separately models the noisy image formation (measurement) process, as well\nas assuming a statistical prior model over the solution space. In this section, we look at\npriors based on Markov random ﬁelds, whose log-likelihood can be described using local\nneighborhood interaction (or penalty) terms (Kindermann and Snell 1980; Geman and Geman\n1984; Marroquin, Mitter, and Poggio 1987; Li 1995; Szeliski, Zabih, Scharstein et al. 2008).\nThe use of Bayesian modeling has several potential advantages over regularization (see\nalso Appendix B). The ability to model measurement processes statistically enables us to\nextract the maximum information possible from each measurement, rather than just guessing\nwhat weighting to give the data. Similarly, the parameters of the prior distribution can often\nbe learned by observing samples from the class we are modeling (Roth and Black 2007a;\nTappen 2007; Li and Huttenlocher 2008). Furthermore, because our model is probabilistic,\nit is possible to estimate (in principle) complete probability distributions over the unknowns\nbeing recovered and, in particular, to model the uncertainty in the solution, which can be\nuseful in latter processing stages. Finally, Markov random ﬁeld models can be deﬁned over\ndiscrete variables, such as image labels (where the variables have no proper ordering), for\nwhich regularization does not apply.\nRecall from (3.68) in Section 3.4.3 (or see Appendix B.4) that, according to Bayes’ Rule,\nthe posterior distribution for a given set of measurements y, p(y|x), combined with a prior\np(x) over the unknowns x, is given by\np(x|y) = p(y|x)p(x)\np(y)\n,\n(3.106)\nwhere p(y) =\nR\nx p(y|x)p(x) is a normalizing constant used to make the p(x|y) distribution\nproper (integrate to 1). Taking the negative logarithm of both sides of (3.106), we get\n−log p(x|y) = −log p(y|x) −log p(x) + C,\n(3.107)\nwhich is the negative posterior log likelihood.\nTo ﬁnd the most likely (maximum a posteriori or MAP) solution x given some measure-\nments y, we simply minimize this negative log likelihood, which can also be thought of as an\nenergy,\nE(x, y) = Ed(x, y) + Ep(x).\n(3.108)\n(We drop the constant C because its value does not matter during energy minimization.) The\nﬁrst term Ed(x, y) is the data energy or data penalty; it measures the negative log likelihood",
  "image_path": "page_201.jpg",
  "pages": [
    200,
    201,
    202
  ]
}