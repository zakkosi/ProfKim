{
  "doc_id": "pages_219_221",
  "text": "3.9 Exercises\n197\n• Describe in more detail the advantages and disadvantages of these various modes.\n• (Optional) Check what your graphics card does by drawing a texture-mapped rectangle\nwhere the texture coordinates lie beyond the [0.0, 1.0] range and using different texture\nclamping modes.\nEx 3.9: Separable ﬁlters\nImplement convolution with a separable kernel. The input should\nbe a grayscale or color image along with the horizontal and vertical kernels. Make sure\nyou support the padding mechanisms developed in the previous exercise. You will need this\nfunctionality for some of the later exercises. If you already have access to separable ﬁltering\nin an image processing package you are using (such as IPL), skip this exercise.\n• (Optional) Use Pietro Perona’s (1995) technique to approximate convolution as a sum\nof a number of separable kernels. Let the user specify the number of kernels and report\nback some sensible metric of the approximation ﬁdelity.\nEx 3.10: Discrete Gaussian ﬁlters\nDiscuss the following issues with implementing a dis-\ncrete Gaussian ﬁlter:\n• If you just sample the equation of a continuous Gaussian ﬁlter at discrete locations,\nwill you get the desired properties, e.g., will the coefﬁcients sum up to 0? Similarly, if\nyou sample a derivative of a Gaussian, do the samples sum up to 0 or have vanishing\nhigher-order moments?\n• Would it be preferable to take the original signal, interpolate it with a sinc, blur with a\ncontinuous Gaussian, then pre-ﬁlter with a sinc before re-sampling? Is there a simpler\nway to do this in the frequency domain?\n• Would it make more sense to produce a Gaussian frequency response in the Fourier\ndomain and to then take an inverse FFT to obtain a discrete ﬁlter?\n• How does truncation of the ﬁlter change its frequency response? Does it introduce any\nadditional artifacts?\n• Are the resulting two-dimensional ﬁlters as rotationally invariant as their continuous\nanalogs? Is there some way to improve this? In fact, can any 2D discrete (separable or\nnon-separable) ﬁlter be truly rotationally invariant?\nEx 3.11: Sharpening, blur, and noise removal\nImplement some softening, sharpening, and\nnon-linear diffusion (selective sharpening or noise removal) ﬁlters, such as Gaussian, median,\nand bilateral (Section 3.3.1), as discussed in Section 3.4.4.\nTake blurry or noisy images (shooting in low light is a good way to get both) and try to\nimprove their appearance and legibility.\n198\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nEx 3.12: Steerable ﬁlters\nImplement Freeman and Adelson’s (1991) steerable ﬁlter algo-\nrithm. The input should be a grayscale or color image and the output should be a multi-banded\nimage consisting of G0◦\n1 and G90◦\n1\n. The coefﬁcients for the ﬁlters can be found in the paper\nby Freeman and Adelson (1991).\nTest the various order ﬁlters on a number of images of your choice and see if you can\nreliably ﬁnd corner and intersection features. These ﬁlters will be quite useful later to detect\nelongated structures, such as lines (Section 4.3).\nEx 3.13: Distance transform\nImplement some (raster-scan) algorithms for city block and\nEuclidean distance transforms. Can you do it without peeking at the literature (Danielsson\n1980; Borgefors 1986)? If so, what problems did you come across and resolve?\nLater on, you can use the distance functions you compute to perform feathering during\nimage stitching (Section 9.3.2).\nEx 3.14: Connected components\nImplement one of the connected component algorithms\nfrom Section 3.3.4 or Section 2.3 from Haralick and Shapiro’s book (1992) and discuss its\ncomputational complexity.\n• Threshold or quantize an image to obtain a variety of input labels and then compute the\narea statistics for the regions that you ﬁnd.\n• Use the connected components that you have found to track or match regions in differ-\nent images or video frames.\nEx 3.15: Fourier transform\nProve the properties of the Fourier transform listed in Ta-\nble 3.1 and derive the formulas for the Fourier transforms listed in Tables 3.2 and 3.3. These\nexercises are very useful if you want to become comfortable working with Fourier transforms,\nwhich is a very useful skill when analyzing and designing the behavior and efﬁciency of many\ncomputer vision algorithms.\nEx 3.16: Wiener ﬁltering\nEstimate the frequency spectrum of your personal photo collec-\ntion and use it to perform Wiener ﬁltering on a few images with varying degrees of noise.\n1. Collect a few hundred of your images by re-scaling them to ﬁt within a 512 × 512\nwindow and cropping them.\n2. Take their Fourier transforms, throw away the phase information, and average together\nall of the spectra.\n3. Pick two of your favorite images and add varying amounts of Gaussian noise, σn ∈\n{1, 2, 5, 10, 20} gray levels.\n3.9 Exercises\n199\n4. For each combination of image and noise, determine by eye which width of a Gaussian\nblurring ﬁlter σs gives the best denoised result. You will have to make a subjective\ndecision between sharpness and noise.\n5. Compute the Wiener ﬁltered version of all the noised images and compare them against\nyour hand-tuned Gaussian-smoothed images.\n6. (Optional) Do your image spectra have a lot of energy concentrated along the horizontal\nand vertical axes (fx = 0 and fy = 0)? Can you think of an explanation for this? Does\nrotating your image samples by 45◦move this energy to the diagonals? If not, could it\nbe due to edge effects in the Fourier transform? Can you suggest some techniques for\nreducing such effects?\nEx 3.17: Deblurring using Wiener ﬁltering\nUse Wiener ﬁltering to deblur some images.\n1. Modify the Wiener ﬁlter derivation (3.66–3.74) to incorporate blur (3.75).\n2. Discuss the resulting Wiener ﬁlter in terms of its noise suppression and frequency\nboosting characteristics.\n3. Assuming that the blur kernel is Gaussian and the image spectrum follows an inverse\nfrequency law, compute the frequency response of the Wiener ﬁlter, and compare it to\nthe unsharp mask.\n4. Synthetically blur two of your sample images with Gaussian blur kernels of different\nradii, add noise, and then perform Wiener ﬁltering.\n5. Repeat the above experiment with a “pillbox” (disc) blurring kernel, which is charac-\nteristic of a ﬁnite aperture lens (Section 2.2.3). Compare these results to Gaussian blur\nkernels (be sure to inspect your frequency plots).\n6. It has been suggested that regular apertures are anathema to de-blurring because they\nintroduce zeros in the sensed frequency spectrum (Veeraraghavan, Raskar, Agrawal et\nal. 2007). Show that this is indeed an issue if no prior model is assumed for the signal,\ni.e., P −1\ns\nl1. If a reasonable power spectrum is assumed, is this still a problem (do we\nstill get banding or ringing artifacts)?\nEx 3.18: High-quality image resampling\nImplement several of the low-pass ﬁlters pre-\nsented in Section 3.5.2 and also the discussion of the windowed sinc shown in Table 3.2 and\nFigure 3.29. Feel free to implement other ﬁlters (Wolberg 1990; Unser 1999).\nApply your ﬁlters to continuously resize an image, both magnifying (interpolating) and\nminifying (decimating) it; compare the resulting animations for several ﬁlters. Use both a",
  "image_path": "page_220.jpg",
  "pages": [
    219,
    220,
    221
  ]
}