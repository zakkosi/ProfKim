{
  "doc_id": "pages_388_390",
  "text": "366\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nIf we order the structure variables before the motion variables in the Hessian matrix A\n(and hence also the right hand side vector b), we obtain a structure for the Hessian shown in\nFigure 7.9c.14 When such a system is solved using sparse Cholesky factorization (see Ap-\npendix A.4) (Bj¨orck 1996; Golub and Van Loan 1996), the ﬁll-in occurs in the smaller motion\nHessian Acc (Szeliski and Kang 1994; Triggs, McLauchlan, Hartley et al. 1999; Hartley and\nZisserman 2004; Lourakis and Argyros 2009; Engels, Stew´enius, and Nist´er 2006). Some re-\ncent papers by (Byr¨od and øAstr¨om 2009), Jeong, Nist´er, Steedly et al. (2010) and (Agarwal,\nSnavely, Seitz et al. 2010) explore the use of iterative (conjugate gradient) techniques for the\nsolution of bundle adjustment problems.\nIn more detail, the reduced motion Hessian is computed using the Schur complement,\nA′\ncc = Acc −AT\npcA−1\npp Apc,\n(7.56)\nwhere App is the point (structure) Hessian (the top left block of Figure 7.9c), Apc is the\npoint-camera Hessian (the top right block), and Acc and A′\ncc are the motion Hessians before\nand after the point variable elimination (the bottom right block of Figure 7.9c). Notice that\nA′\ncc has a non-zero entry between two cameras if they see any 3D point in common. This is\nindicated with dashed arcs in Figure 7.9a and light blue squares in Figure 7.9c.\nWhenever there are global parameters present in the reconstruction algorithm, such as\ncamera intrinsics that are common to all of the cameras, or camera rig calibration parameters\nsuch as those shown in Figure 7.8, they should be ordered last (placed along the right and\nbottom edges of A) in order to reduce ﬁll-in.\nEngels, Stew´enius, and Nist´er (2006) provide a nice recipe for sparse bundle adjustment,\nincluding all the steps needed to initialize the iterations, as well as typical computation times\nfor a system that uses a ﬁxed number of backward-looking frames in a real-time setting. They\nalso recommend using homogeneous coordinates for the structure parameters pi, which is a\ngood idea, since it avoids numerical instabilities for points near inﬁnity.\nBundle adjustment is now the standard method of choice for most structure-from-motion\nproblems and is commonly applied to problems with hundreds of weakly calibrated images\nand tens of thousands of points, e.g., in systems such as Photosynth. (Much larger prob-\nlems are commonly solved in photogrammetry and aerial imagery, but these are usually care-\nfully calibrated and make use of surveyed ground control points.) However, as the problems\nbecome larger, it becomes impractical to re-solve full bundle adjustment problems at each\niteration.\nOne approach to dealing with this problem is to use an incremental algorithm, where new\ncameras are added over time. (This makes particular sense if the data is being acquired from\n14 This ordering is preferable when there are fewer cameras than 3D points, which is the usual case. The exception\nis when we are tracking a small number of points through many video frames, in which case this ordering should be\nreversed.\n7.4 Bundle adjustment\n367\na video camera or moving vehicle (Nist´er, Naroditsky, and Bergen 2006; Pollefeys, Nist´er,\nFrahm et al. 2008).) A Kalman ﬁlter can be used to incrementally update estimates as new\ninformation is acquired. Unfortunately, such sequential updating is only statistically optimal\nfor linear least squares problems.\nFor non-linear problems such as structure from motion, an extended Kalman ﬁlter, which\nlinearizes measurement and update equations around the current estimate, needs to be used\n(Gelb 1974; Vi´eville and Faugeras 1990). To overcome this limitation, several passes can\nbe made through the data (Azarbayejani and Pentland 1995). Because points disappear from\nview (and old cameras become irrelevant), a variable state dimension ﬁlter (VSDF) can be\nused to adjust the set of state variables over time, for example, by keeping only cameras and\npoint tracks seen in the last k frames (McLauchlan 2000). A more ﬂexible approach to using\na ﬁxed number of frames is to propagate corrections backwards through points and cameras\nuntil the changes on parameters are below a threshold (Steedly and Essa 2001). Variants of\nthese techniques, including methods that use a ﬁxed window for bundle adjustment (Engels,\nStew´enius, and Nist´er 2006) or select keyframes for doing full bundle adjustment (Klein and\nMurray 2008) are now commonly used in real-time tracking and augmented-reality applica-\ntions, as discussed in Section 7.4.2.\nWhen maximum accuracy is required, it is still preferable to perform a full bundle ad-\njustment over all the frames. In order to control the resulting computational complexity, one\napproach is to lock together subsets of frames into locally rigid conﬁgurations and to optimize\nthe relative positions of these cluster (Steedly, Essa, and Dellaert 2003). A different approach\nis to select a smaller number of frames to form a skeletal set that still spans the whole dataset\nand produces reconstructions of comparable accuracy (Snavely, Seitz, and Szeliski 2008b).\nWe describe this latter technique in more detail in Section 7.4.4, where we discuss applica-\ntions of structure from motion to large image sets.\nWhile bundle adjustment and other robust non-linear least squares techniques are the\nmethods of choice for most structure-from-motion problems, they suffer from initialization\nproblems, i.e., they can get stuck in local energy minima if not started sufﬁciently close\nto the global optimum. Many systems try to mitigate this by being conservative in what\nreconstruction they perform early on and which cameras and points they add to the solution\n(Section 7.4.4). An alternative, however, is to re-formulate the problem using a norm that\nsupports the computation of global optima.\nKahl and Hartley (2008) describe techniques for using L∞norms in geometric recon-\nstruction problems. The advantage of such norms is that globally optimal solutions can be\nefﬁciently computed using second-order cone programming (SOCP). The disadvantage is that\nL∞norms are particularly sensitive to outliers and so must be combined with good outlier\nrejection techniques before they can be used.\n368\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n7.4.2 Application: Match move and augmented reality\nOne of the neatest applications of structure from motion is to estimate the 3D motion of a\nvideo or ﬁlm camera, along with the geometry of a 3D scene, in order to superimpose 3D\ngraphics or computer-generated images (CGI) on the scene. In the visual effects industry,\nthis is known as the match move problem (Roble 1999), since the motion of the synthetic 3D\ncamera used to render the graphics must be matched to that of the real-world camera. For\nvery small motions, or motions involving pure camera rotations, one or two tracked points can\nsufﬁce to compute the necessary visual motion. For planar surfaces moving in 3D, four points\nare needed to compute the homography, which can then be used to insert planar overlays, e.g.,\nto replace the contents of advertising billboards during sporting events.\nThe general version of this problem requires the estimation of the full 3D camera pose\nalong with the focal length (zoom) of the lens and potentially its radial distortion parameters\n(Roble 1999). When the 3D structure of the scene is known ahead of time, pose estima-\ntion techniques such as view correlation (Bogart 1991) or through-the-lens camera control\n(Gleicher and Witkin 1992) can be used, as described in Section 6.2.3.\nFor more complex scenes, it is usually preferable to recover the 3D structure simultane-\nously with the camera motion using structure-from-motion techniques. The trick with using\nsuch techniques is that in order to prevent any visible jitter between the synthetic graph-\nics and the actual scene, features must be tracked to very high accuracy and ample feature\ntracks must be available in the vicinity of the insertion location. Some of today’s best known\nmatch move software packages, such as the boujou package from 2d3,15 which won an Emmy\naward in 2002, originated in structure-from-motion research in the computer vision commu-\nnity (Fitzgibbon and Zisserman 1998).\nClosely related to the match move problem is robotics navigation, where a robot must es-\ntimate its location relative to its environment, while simultaneously avoiding any dangerous\nobstacles. This problem is often known as simultaneous localization and mapping (SLAM)\n(Thrun, Burgard, and Fox 2005) or visual odometry (Levin and Szeliski 2004; Nist´er, Nar-\noditsky, and Bergen 2006; Maimone, Cheng, and Matthies 2007). Early versions of such\nalgorithms used range-sensing techniques, such as ultrasound, laser range ﬁnders, or stereo\nmatching, to estimate local 3D geometry, which could then be fused into a 3D model. Newer\ntechniques can perform the same task based purely on visual feature tracking, sometimes not\neven requiring a stereo camera rig (Davison, Reid, Molton et al. 2007).\nAnother closely related application is augmented reality, where 3D objects are inserted\ninto a video feed in real time, often to annotate or help users understand a scene (Azuma,\nBaillot, Behringer et al. 2001). While traditional systems require prior knowledge about the\nscene or object being visually tracked (Rosten and Drummond 2005), newer systems can\n15 http://www.2d3.com/.",
  "image_path": "page_389.jpg",
  "pages": [
    388,
    389,
    390
  ]
}