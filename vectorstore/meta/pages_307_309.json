{
  "doc_id": "pages_307_309",
  "text": "5.2 Split and merge\n285\n(a)\n(b)\n(c)\nFigure 5.13\nLocally constrained watershed segmentation (Beare 2006) c⃝2006 IEEE: (a)\noriginal confocal microscopy image with marked seeds (line segments); (b) standard water-\nshed segmentation; (c) locally constrained watershed segmentation.\nrain would ﬂow into the same lake. An efﬁcient way to compute such regions is to start ﬂood-\ning the landscape at all of the local minima and to label ridges wherever differently evolving\ncomponents meet. The whole algorithm can be implemented using a priority queue of pixels\nand breadth-ﬁrst search (Vincent and Soille 1991).8\nSince images rarely have dark regions separated by lighter ridges, watershed segmen-\ntation is usually applied to a smoothed version of the gradient magnitude image, which also\nmakes it usable with color images. As an alternative, the maximum oriented energy in a steer-\nable ﬁlter (3.28–3.29) (Freeman and Adelson 1991) can be used as the basis of the oriented\nwatershed transform developed by Arbel´aez, Maire, Fowlkes et al. (2010). Such techniques\nend up ﬁnding smooth regions separated by visible (higher gradient) boundaries. Since such\nboundaries are what active contours usually follow, active contour algorithms (Mortensen and\nBarrett 1999; Li, Sun, Tang et al. 2004) often precompute such a segmentation using either\nthe watershed or the related tobogganing technique (Section 5.1.3).\nUnfortunately, watershed segmentation associates a unique region with each local mini-\nmum, which can lead to over-segmentation. Watershed segmentation is therefore often used\nas part of an interactive system, where the user ﬁrst marks seed locations (with a click or\na short stroke) that correspond to the centers of different desired components. Figure 5.13\nshows the results of running the watershed algorithm with some manually placed markers on\na confocal microscopy image. It also shows the result for an improved version of watershed\nthat uses local morphology to smooth out and optimize the boundaries separating the regions\n(Beare 2006).\n8 A related algorithm can be used to compute maximally stable extremal regions (MSERs) efﬁciently (Sec-\ntion 4.1.1) (Nist´er and Stew´enius 2008).\n286\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n5.2.2 Region splitting (divisive clustering)\nSplitting the image into successively ﬁner regions is one of the oldest techniques in computer\nvision. Ohlander, Price, and Reddy (1978) present such a technique, which ﬁrst computes a\nhistogram for the whole image and then ﬁnds a threshold that best separates the large peaks\nin the histogram. This process is repeated until regions are either fairly uniform or below a\ncertain size.\nMore recent splitting algorithms often optimize some metric of intra-region similarity and\ninter-region dissimilarity. These are covered in Sections 5.4 and 5.5.\n5.2.3 Region merging (agglomerative clustering)\nRegion merging techniques also date back to the beginnings of computer vision. Brice and\nFennema (1970) use a dual grid for representing boundaries between pixels and merge re-\ngions based on their relative boundary lengths and the strength of the visible edges at these\nboundaries.\nIn data clustering, algorithms can link clusters together based on the distance between\ntheir closest points (single-link clustering), their farthest points (complete-link clustering), or\nsomething in between (Jain, Topchy, Law et al. 2004). Kamvar, Klein, and Manning (2002)\nprovide a probabilistic interpretation of these algorithms and show how additional models\ncan be incorporated within this framework.\nA very simple version of pixel-based merging combines adjacent regions whose average\ncolor difference is below a threshold or whose regions are too small. Segmenting the image\ninto such superpixels (Mori, Ren, Efros et al. 2004), which are not semantically meaningful,\ncan be a useful pre-processing stage to make higher-level algorithms such as stereo matching\n(Zitnick, Kang, Uyttendaele et al. 2004; Taguchi, Wilburn, and Zitnick 2008), optic ﬂow\n(Zitnick, Jojic, and Kang 2005; Brox, Bregler, and Malik 2009), and recognition (Mori, Ren,\nEfros et al. 2004; Mori 2005; Gu, Lim, Arbelaez et al. 2009; Lim, Arbel´aez, Gu et al. 2009)\nboth faster and more robust.\n5.2.4 Graph-based segmentation\nWhile many merging algorithms simply apply a ﬁxed rule that groups pixels and regions\ntogether, Felzenszwalb and Huttenlocher (2004b) present a merging algorithm that uses rel-\native dissimilarities between regions to determine which ones should be merged; it produces\nan algorithm that provably optimizes a global grouping metric. They start with a pixel-to-\npixel dissimilarity measure w(e) that measures, for example, intensity differences between\nN8 neighbors. (Alternatively, they can use the joint feature space distances (5.42) introduced\nby Comaniciu and Meer (2002), which we discuss in Section 5.3.2.)\n5.2 Split and merge\n287\n(a)\n(b)\n(c)\nFigure 5.14\nGraph-based merging segmentation (Felzenszwalb and Huttenlocher 2004b)\nc⃝2004 Springer: (a) input grayscale image that is successfully segmented into three regions\neven though the variation inside the smaller rectangle is larger than the variation across the\nmiddle edge; (b) input grayscale image; (c) resulting segmentation using an N8 pixel neigh-\nborhood.\nFor any region R, its internal difference is deﬁned as the largest edge weight in the re-\ngion’s minimum spanning tree,\nInt(R) =\nmin\ne∈MST (R) w(e).\n(5.20)\nFor any two adjacent regions with at least one edge connecting their vertices, the difference\nbetween these regions is deﬁned as the minimum weight edge connecting the two regions,\nDif (R1, R2) =\nmin\ne=(v1,v2)|v1∈R1,v2∈R2 w(e).\n(5.21)\nTheir algorithm merges any two adjacent regions whose difference is smaller than the mini-\nmum internal difference of these two regions,\nMInt(R1, R2) = min(Int(R1) + τ(R1), Int(R2) + τ(R2)),\n(5.22)\nwhere τ(R) is a heuristic region penalty that Felzenszwalb and Huttenlocher (2004b) set to\nk/|R|, but which can be set to any application-speciﬁc measure of region goodness.\nBy merging regions in decreasing order of the edges separating them (which can be efﬁ-\nciently evaluated using a variant of Kruskal’s minimum spanning tree algorithm), they prov-\nably produce segmentations that are neither too ﬁne (there exist regions that could have been\nmerged) nor too coarse (there are regions that could be split without being mergeable). For\nﬁxed-size pixel neighborhoods, the running time for this algorithm is O(N log N), where N\nis the number of image pixels, which makes it one of the fastest segmentation algorithms\n(Paris and Durand 2007). Figure 5.14 shows two examples of images segmented using their\ntechnique.",
  "image_path": "page_308.jpg",
  "pages": [
    307,
    308,
    309
  ]
}