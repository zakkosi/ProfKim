{
  "doc_id": "pages_099_101",
  "text": "2.3 The digital camera\n77\napproach is to look for regions of near-constant value and to estimate the noise variance in\nsuch regions (Liu, Szeliski, Kang et al. 2008).\nADC resolution.\nThe ﬁnal step in the analog processing chain occurring within an imaging\nsensor is the analog to digital conversion (ADC). While a variety of techniques can be used\nto implement this process, the two quantities of interest are the resolution of this process\n(how many bits it yields) and its noise level (how many of these bits are useful in practice).\nFor most cameras, the number of bits quoted (eight bits for compressed JPEG images and a\nnominal 16 bits for the RAW formats provided by some DSLRs) exceeds the actual number\nof usable bits. The best way to tell is to simply calibrate the noise of a given sensor, e.g.,\nby taking repeated shots of the same scene and plotting the estimated noise as a function of\nbrightness (Exercise 2.6).\nDigital post-processing.\nOnce the irradiance values arriving at the sensor have been con-\nverted to digital bits, most cameras perform a variety of digital signal processing (DSP)\noperations to enhance the image before compressing and storing the pixel values. These in-\nclude color ﬁlter array (CFA) demosaicing, white point setting, and mapping of the luminance\nvalues through a gamma function to increase the perceived dynamic range of the signal. We\ncover these topics in Section 2.3.2 but, before we do, we return to the topic of aliasing, which\nwas mentioned in connection with sensor array ﬁll factors.\n2.3.1 Sampling and aliasing\nWhat happens when a ﬁeld of light impinging on the image sensor falls onto the active sense\nareas in the imaging chip? The photons arriving at each active cell are integrated and then\ndigitized. However, if the ﬁll factor on the chip is small and the signal is not otherwise\nband-limited, visually unpleasing aliasing can occur.\nTo explore the phenomenon of aliasing, let us ﬁrst look at a one-dimensional signal (Fig-\nure 2.24), in which we have two sine waves, one at a frequency of f = 3/4 and the other at\nf = 5/4. If we sample these two signals at a frequency of f = 2, we see that they produce\nthe same samples (shown in black), and so we say that they are aliased.14 Why is this a bad\neffect? In essence, we can no longer reconstruct the original signal, since we do not know\nwhich of the two original frequencies was present.\nIn fact, Shannon’s Sampling Theorem shows that the minimum sampling (Oppenheim\nand Schafer 1996; Oppenheim, Schafer, and Buck 1999) rate required to reconstruct a signal\n14 An alias is an alternate name for someone, so the sampled signal corresponds to two different aliases.\n78\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n*\nf = 3/4\nf = 5/4\n=\nFigure 2.24\nAliasing of a one-dimensional signal: The blue sine wave at f = 3/4 and the\nred sine wave at f = 5/4 have the same digital samples, when sampled at f = 2. Even after\nconvolution with a 100% ﬁll factor box ﬁlter, the two signals, while no longer of the same\nmagnitude, are still aliased in the sense that the sampled red signal looks like an inverted\nlower magnitude version of the blue signal. (The image on the right is scaled up for better\nvisibility. The actual sine magnitudes are 30% and −18% of their original values.)\nfrom its instantaneous samples must be at least twice the highest frequency,15\nfs ≥2fmax.\n(2.102)\nThe maximum frequency in a signal is known as the Nyquist frequency and the inverse of the\nminimum sampling frequency rs = 1/fs is known as the Nyquist rate.\nHowever, you may ask, since an imaging chip actually averages the light ﬁeld over a\nﬁnite area, are the results on point sampling still applicable? Averaging over the sensor area\ndoes tend to attenuate some of the higher frequencies. However, even if the ﬁll factor is\n100%, as in the right image of Figure 2.24, frequencies above the Nyquist limit (half the\nsampling frequency) still produce an aliased signal, although with a smaller magnitude than\nthe corresponding band-limited signals.\nA more convincing argument as to why aliasing is bad can be seen by downsampling\na signal using a poor quality ﬁlter such as a box (square) ﬁlter. Figure 2.25 shows a high-\nfrequency chirp image (so called because the frequencies increase over time), along with the\nresults of sampling it with a 25% ﬁll-factor area sensor, a 100% ﬁll-factor sensor, and a high-\nquality 9-tap ﬁlter. Additional examples of downsampling (decimation) ﬁlters can be found\nin Section 3.5.2 and Figure 3.30.\nThe best way to predict the amount of aliasing that an imaging system (or even an image\nprocessing algorithm) will produce is to estimate the point spread function (PSF), which\nrepresents the response of a particular pixel sensor to an ideal point light source. The PSF\nis a combination (convolution) of the blur induced by the optical system (lens) and the ﬁnite\nintegration area of a chip sensor.16\n15 The actual theorem states that fs must be at least twice the signal bandwidth but, since we are not dealing with\nmodulated signals such as radio waves during image capture, the maximum frequency sufﬁces.\n16 Imaging chips usually interpose an optical anti-aliasing ﬁlter just before the imaging chip to reduce or control\nthe amount of aliasing.\n2.3 The digital camera\n79\n(a)\n(b)\n(c)\n(d)\nFigure 2.25\nAliasing of a two-dimensional signal: (a) original full-resolution image; (b)\ndownsampled 4× with a 25% ﬁll factor box ﬁlter; (c) downsampled 4× with a 100% ﬁll\nfactor box ﬁlter; (d) downsampled 4× with a high-quality 9-tap ﬁlter. Notice how the higher\nfrequencies are aliased into visible frequencies with the lower quality ﬁlters, while the 9-tap\nﬁlter completely removes these higher frequencies.\nIf we know the blur function of the lens and the ﬁll factor (sensor area shape and spacing)\nfor the imaging chip (plus, optionally, the response of the anti-aliasing ﬁlter), we can convolve\nthese (as described in Section 3.2) to obtain the PSF. Figure 2.26a shows the one-dimensional\ncross-section of a PSF for a lens whose blur function is assumed to be a disc of a radius\nequal to the pixel spacing s plus a sensing chip whose horizontal ﬁll factor is 80%. Taking\nthe Fourier transform of this PSF (Section 3.4), we obtain the modulation transfer function\n(MTF), from which we can estimate the amount of aliasing as the area of the Fourier magni-\ntude outside the f ≤fs Nyquist frequency.17 If we de-focus the lens so that the blur function\nhas a radius of 2s (Figure 2.26c), we see that the amount of aliasing decreases signiﬁcantly,\nbut so does the amount of image detail (frequencies closer to f = fs).\nUnder laboratory conditions, the PSF can be estimated (to pixel precision) by looking at a\npoint light source such as a pin hole in a black piece of cardboard lit from behind. However,\nthis PSF (the actual image of the pin hole) is only accurate to a pixel resolution and, while\nit can model larger blur (such as blur caused by defocus), it cannot model the sub-pixel\nshape of the PSF and predict the amount of aliasing. An alternative technique, described in\nSection 10.1.4, is to look at a calibration pattern (e.g., one consisting of slanted step edges\n(Reichenbach, Park, and Narayanswamy 1991; Williams and Burns 2001; Joshi, Szeliski, and\nKriegman 2008)) whose ideal appearance can be re-synthesized to sub-pixel precision.\nIn addition to occurring during image acquisition, aliasing can also be introduced in var-\nious image processing operations, such as resampling, upsampling, and downsampling. Sec-\ntions 3.4 and 3.5.2 discuss these issues and show how careful selection of ﬁlters can reduce\n17 The complex Fourier transform of the PSF is actually called the optical transfer function (OTF) (Williams\n1999). Its magnitude is called the modulation transfer function (MTF) and its phase is called the phase transfer\nfunction (PTF).",
  "image_path": "page_100.jpg",
  "pages": [
    99,
    100,
    101
  ]
}