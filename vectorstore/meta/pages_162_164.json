{
  "doc_id": "pages_162_164",
  "text": "140\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n3.4.2 Two-dimensional Fourier transforms\nThe formulas and insights we have developed for one-dimensional signals and their trans-\nforms translate directly to two-dimensional images. Here, instead of just specifying a hor-\nizontal or vertical frequency ωx or ωy, we can create an oriented sinusoid of frequency\n(ωx, ωy),\ns(x, y) = sin(ωxx + ωyy).\n(3.62)\nThe corresponding two-dimensional Fourier transforms are then\nH(ωx, ωy) =\nZ ∞\n−∞\nZ ∞\n−∞\nh(x, y)e−j(ωxx+ωyy)dx dy,\n(3.63)\nand in the discrete domain,\nH(kx, ky) =\n1\nMN\nM−1\nX\nx=0\nN−1\nX\ny=0\nh(x, y)e−j2π\nkxx+kyy\nMN\n,\n(3.64)\nwhere M and N are the width and height of the image.\nAll of the Fourier transform properties from Table 3.1 carry over to two dimensions if\nwe replace the scalar variables x, ω, x0 and a with their 2D vector counterparts x = (x, y),\nω = (ωx, ωy), x0 = (x0, y0), and a = (ax, ay), and use vector inner products instead of\nmultiplications.\n3.4.3 Wiener ﬁltering\nWhile the Fourier transform is a useful tool for analyzing the frequency characteristics of a\nﬁlter kernel or image, it can also be used to analyze the frequency spectrum of a whole class\nof images.\nA simple model for images is to assume that they are random noise ﬁelds whose expected\nmagnitude at each frequency is given by this power spectrum Ps(ωx, ωy), i.e.,\n\n[S(ωx, ωy)]2\u000b\n= Ps(ωx, ωy),\n(3.65)\nwhere the angle brackets ⟨·⟩denote the expected (mean) value of a random variable.9 To\ngenerate such an image, we simply create a random Gaussian noise image S(ωx, ωy) where\neach “pixel” is a zero-mean Gaussian10 of variance Ps(ωx, ωy) and then take its inverse FFT.\nThe observation that signal spectra capture a ﬁrst-order description of spatial statistics\nis widely used in signal and image processing. In particular, assuming that an image is a\n9 The notation E[·] is also commonly used.\n10 We set the DC (i.e., constant) component at S(0, 0) to the mean grey level. See Algorithm C.1 in Appendix C.2\nfor code to generate Gaussian noise.\n3.4 Fourier transforms\n141\nsample from a correlated Gaussian random noise ﬁeld combined with a statistical model of\nthe measurement process yields an optimum restoration ﬁlter known as the Wiener ﬁlter.11\nTo derive the Wiener ﬁlter, we analyze each frequency component of a signal’s Fourier\ntransform independently. The noisy image formation process can be written as\no(x, y) = s(x, y) + n(x, y),\n(3.66)\nwhere s(x, y) is the (unknown) image we are trying to recover, n(x, y) is the additive noise\nsignal, and o(x, y) is the observed noisy image. Because of the linearity of the Fourier trans-\nform, we can write\nO(ωx, ωy) = S(ωx, ωy) + N(ωx, ωy),\n(3.67)\nwhere each quantity in the above equation is the Fourier transform of the corresponding\nimage.\nAt each frequency (ωx, ωy), we know from our image spectrum that the unknown trans-\nform component S(ωx, ωy) has a prior distribution which is a zero-mean Gaussian with vari-\nance Ps(ωx, ωy). We also have noisy measurement O(ωx, ωy) whose variance is Pn(ωx, ωy),\ni.e., the power spectrum of the noise, which is usually assumed to be constant (white),\nPn(ωx, ωy) = σ2\nn.\nAccording to Bayes’ Rule (Appendix B.4), the posterior estimate of S can be written as\np(S|O) = p(O|S)p(S)\np(O)\n,\n(3.68)\nwhere p(O) =\nR\nS p(O|S)p(S) is a normalizing constant used to make the p(S|O) distribution\nproper (integrate to 1). The prior distribution p(S) is given by\np(S) = e−(S−µ)2\n2Ps\n,\n(3.69)\nwhere µ is the expected mean at that frequency (0 everywhere except at the origin) and the\nmeasurement distribution P(O|S) is given by\np(S) = e−(S−O)2\n2Pn\n.\n(3.70)\nTaking the negative logarithm of both sides of (3.68) and setting µ = 0 for simplicity, we\nget\n−log p(S|O)\n=\n−log p(O|S) −log p(S) + C\n(3.71)\n=\n1/2P −1\nn (S −O)2 + 1/2P −1\ns\nS2 + C,\n(3.72)\n11 Wiener is pronounced “veener” since, in German, the “w” is pronounced “v”. Remember that next time you\norder “Wiener schnitzel”.\n142\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\nP\nn\nW\n(a)\n(b)\nFigure 3.25 One-dimensional Wiener ﬁlter: (a) power spectrum of signal Ps(f), noise level\nσ2, and Wiener ﬁlter transform W(f); (b) Wiener ﬁlter spatial kernel.\nwhich is the negative posterior log likelihood. The minimum of this quantity is easy to\ncompute,\nSopt =\nP −1\nn\nP −1\nn\n+ P −1\ns\nO =\nPs\nPs + Pn\nO =\n1\n1 + Pn/Ps\nO.\n(3.73)\nThe quantity\nW(ωx, ωy) =\n1\n1 + σ2n/Ps(ωx, ωy)\n(3.74)\nis the Fourier transform of the optimum Wiener ﬁlter needed to remove the noise from an\nimage whose power spectrum is Ps(ωx, ωy).\nNotice that this ﬁlter has the right qualitative properties, i.e., for low frequencies where\nPs ≫σ2\nn, it has unit gain, whereas for high frequencies, it attenuates the noise by a factor\nPs/σ2\nn. Figure 3.25 shows the one-dimensional transform W(f) and the corresponding ﬁlter\nkernel w(x) for the commonly assumed case of P(f) = f −2 (Field 1987). Exercise 3.16 has\nyou compare the Wiener ﬁlter as a denoising algorithm to hand-tuned Gaussian smoothing.\nThe methodology given above for deriving the Wiener ﬁlter can easily be extended to the\ncase where the observed image is a noisy blurred version of the original image,\no(x, y) = b(x, y) ∗s(x, y) + n(x, y),\n(3.75)\nwhere b(x, y) is the known blur kernel. Rather than deriving the corresponding Wiener ﬁl-\nter, we leave it as an exercise (Exercise 3.17), which also encourages you to compare your\nde-blurring results with unsharp masking and na¨ıve inverse ﬁltering. More sophisticated al-\ngorithms for blur removal are discussed in Sections 3.7 and 10.3.\nDiscrete cosine transform\nThe discrete cosine transform (DCT) is a variant of the Fourier transform particularly well-\nsuited to compressing images in a block-wise fashion. The one-dimensional DCT is com-\nputed by taking the dot product of each N-wide block of pixels with a set of cosines of",
  "image_path": "page_163.jpg",
  "pages": [
    162,
    163,
    164
  ]
}