{
  "doc_id": "pages_489_491",
  "text": "Chapter 10\nComputational photography\n10.1 Photometric calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470\n10.1.1 Radiometric response function . . . . . . . . . . . . . . . . . . . . . 470\n10.1.2 Noise level estimation\n. . . . . . . . . . . . . . . . . . . . . . . . . 473\n10.1.3 Vignetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 474\n10.1.4 Optical blur (spatial response) estimation . . . . . . . . . . . . . . . 476\n10.2 High dynamic range imaging . . . . . . . . . . . . . . . . . . . . . . . . . . 479\n10.2.1 Tone mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487\n10.2.2 Application: Flash photography . . . . . . . . . . . . . . . . . . . . 494\n10.3 Super-resolution and blur removal . . . . . . . . . . . . . . . . . . . . . . . 497\n10.3.1 Color image demosaicing\n. . . . . . . . . . . . . . . . . . . . . . . 502\n10.3.2 Application: Colorization\n. . . . . . . . . . . . . . . . . . . . . . . 504\n10.4 Image matting and compositing . . . . . . . . . . . . . . . . . . . . . . . . . 505\n10.4.1 Blue screen matting . . . . . . . . . . . . . . . . . . . . . . . . . . . 507\n10.4.2 Natural image matting . . . . . . . . . . . . . . . . . . . . . . . . . 509\n10.4.3 Optimization-based matting\n. . . . . . . . . . . . . . . . . . . . . . 513\n10.4.4 Smoke, shadow, and ﬂash matting . . . . . . . . . . . . . . . . . . . 516\n10.4.5 Video matting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 518\n10.5 Texture analysis and synthesis\n. . . . . . . . . . . . . . . . . . . . . . . . . 518\n10.5.1 Application: Hole ﬁlling and inpainting . . . . . . . . . . . . . . . . 521\n10.5.2 Application: Non-photorealistic rendering . . . . . . . . . . . . . . . 522\n10.6 Additional reading\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 524\n10.7 Exercises\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526\n468\nComputer Vision: Algorithms and Applications (September 3, 2010 draft)\n(a)\n(b)\n(c)\n(d)\nFigure 10.1\nComputational photography: (a) merging multiple exposures to create high\ndynamic range images (Debevec and Malik 1997) c⃝1997 ACM; (b) merging ﬂash and non-\nﬂash photographs; (Petschnigg, Agrawala, Hoppe et al. 2004) c⃝2004 ACM; (c) image mat-\nting and compositing; (Chuang, Curless, Salesin et al. 2001) c⃝2001 IEEE; (d) hole ﬁlling\nwith inpainting (Criminisi, P´erez, and Toyama 2004) c⃝2004 IEEE.\n10 Computational photography\n469\nStitching multiple images into wide ﬁeld of view panoramas, which we covered in Chapter 9,\nallows us create photographs that could not be captured with a regular camera. This is just\none instance of computational photography, where image analysis and processing algorithms\nare applied to one or more photographs to create images that go beyond the capabilities of\ntraditional imaging systems. Some of these techniques are now being incorporated directly\ninto digital still cameras. For example, some of the newer digital still cameras have sweep\npanorama modes and take multiple shots in low-light conditions to reduce image noise.\nIn this chapter, we cover a number of additional computational photography algorithms.\nWe begin with a review of photometric image calibration (Section 10.1), i.e., the measurement\nof camera and lens responses, which is a prerequisite for many of the algorithms we describe\nlater. We then discuss high dynamic range imaging (Section 10.2), which captures the full\nrange of brightness in a scene through the use of multiple exposures (Figure 10.1a). We also\ndiscuss tone mapping operators, which map rich images back into regular display devices,\nsuch as screens and printers, as well as algorithms that merge ﬂash and regular images to\nobtain better exposures (Figure 10.1b).\nNext, we discuss how the resolution of images can be improved either by merging mul-\ntiple photographs together or using sophisticated image priors (Section 10.3). This includes\nalgorithms for extracting full-color images from the patterned Bayer mosaics present in most\ncameras.\nIn Section 10.4, we discuss algorithms for cutting pieces of images from one photograph\nand pasting them into others (Figure 10.1c). In Section 10.5, we describe how to generate\nnovel textures from real-world samples for applications such as ﬁlling holes in images (Fig-\nure 10.1d). We close with a brief overview of non-photorealistic rendering (Section 10.5.2),\nwhich can turn regular photographs into artistic renderings that resemble traditional drawings\nand paintings.\nOne topic that we do not cover extensively in this book is novel computational sensors,\noptics, and cameras. A nice survey can be found in an article by Nayar (2006), a recently\npublished book by Raskar and Tumblin (2010), and more recent research papers (Levin,\nFergus, Durand et al. 2007). Some related discussion can also be found in Sections 10.2\nand 13.3.\nA good general-audience introduction to computational photography can be found in the\narticle by Hayes (2008) as well as survey papers by Nayar (2006), Cohen and Szeliski (2006),\nLevoy (2006), and Debevec (2006).1 Raskar and Tumblin (2010) give extensive coverage of\ntopics in this area, with particular emphasis on computational cameras and sensors. The\nsub-ﬁeld of high dynamic range imaging has its own book discussing research in this area\n(Reinhard, Ward, Pattanaik et al. 2005), as well as a wonderful book aimed more at profes-\n1 See also the two special issue journals edited by Bimber (2006) and Durand and Szeliski (2007).",
  "image_path": "page_490.jpg",
  "pages": [
    489,
    490,
    491
  ]
}