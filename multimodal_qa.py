import os
import json
from Utils.image_utils import load_image_as_bytes, load_image_resized
from Utils.faiss_utils import retrieve_similar_images_from_text
from inference.image_description import describe_image, describe_image_contextual
from inference.professor_response import generate_professor_response

# ------------------------------
# [1] ì…ë ¥ ì¤€ë¹„
# ------------------------------
IMAGE_PATH = "sample_input/TEST_1.png"
QUESTION_PATH = "sample_input/question.txt"
VECTOR_DB_PATH = "vectorstore/index_textonly.faiss"

with open(QUESTION_PATH, 'r', encoding='utf-8') as f:
    question = f.read().strip()

image_bytes_qwen = load_image_as_bytes(IMAGE_PATH)
# image_resized = load_image_resized(IMAGE_PATH)(ì¶”ê°€ ìŠ¤í„°ë””ìš©ìš©)
# ------------------------------
# [2] ì´ë¯¸ì§€ ì„¤ëª… + í‚¤ì›Œë“œ ì¶”ì¶œ (Qwen2.5)
# ------------------------------
print("[1] Qwen2.5-VLë¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì¤‘...")
image_description = describe_image(image_bytes_qwen)
print("\nğŸ“Œ ì´ë¯¸ì§€ ì„¤ëª…:")
print(image_description)

# ------------------------------
# [3] í…ìŠ¤íŠ¸ ê¸°ë°˜ FAISS ê²€ìƒ‰
# ------------------------------
print("\n[2] FAISSë¡œ ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
retrieved_images = retrieve_similar_images_from_text(image_description, VECTOR_DB_PATH)
print("\nğŸ” ìœ ì‚¬ ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸:", retrieved_images)

# ------------------------------
# [4] Qwen2.5-VLë¡œ ë¬¸ë§¥ ê¸°ë°˜ ì„¤ëª… (Top-K Doc)
# ------------------------------
print("\n[3] Qwen2.5-VLë¡œ ìœ ì‚¬ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ë¬¸ë§¥ ì„¤ëª… ìƒì„± ì¤‘...")

retrieved_descriptions = []

for doc_id in retrieved_images:
    try:
        meta_path = f"vectorstore/meta/{doc_id}.json"
        with open(meta_path, encoding="utf-8") as f:
            meta = json.load(f)

        text_block = meta["text"]
        page_ids = meta["pages"]

        image_bytes_list = []
        for pid in page_ids:
            path = f"converted_pages/page_{pid}.jpg"
            if os.path.exists(path):
                img_bytes = load_image_as_bytes(path)
                image_bytes_list.append(img_bytes)

        if not image_bytes_list:
            retrieved_descriptions.append(f"[{doc_id}] ì´ë¯¸ì§€ ì—†ìŒ")
            continue

        print(f"[{doc_id}] Qwen2.5-VL ë¬¸ë§¥ í˜¸ì¶œ ì¤‘...")
        response = describe_image_contextual(
            images=image_bytes_list,
            question=text_block + "\nì´ ë‚´ìš©ê³¼ ì‹œê°ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°•ì˜ íë¦„ì„ ì„¤ëª…í•´ì¤˜."
        )
        retrieved_descriptions.append(f"[{doc_id}]\n{response}")

    except Exception as e:
        retrieved_descriptions.append(f"[{doc_id}] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

context_summary = "\n\n".join(retrieved_descriptions)
print("\nğŸ§  ë¬¸ë§¥ ìš”ì•½:")
print(context_summary)

# ------------------------------
# [5] êµìˆ˜ë‹˜ ìŠ¤íƒ€ì¼ ìµœì¢… ì‘ë‹µ (LLaMA3)
# ------------------------------
print("\n[4] LLaMA3ë¡œ ìµœì¢… êµìˆ˜ë‹˜ ì‘ë‹µ ìƒì„± ì¤‘...")
final_response = generate_professor_response(question, context_summary, retrieved_images)
print("\nğŸ“ êµìˆ˜ë‹˜ì˜ ìµœì¢… ì¡°ì–¸:")
print(final_response)
